import os
import sys
import logging
import torch
import numpy as np
from datasets import load_from_disk
from transformers import (
    Trainer, 
    TrainingArguments, 
    BertTokenizerFast,
    EarlyStoppingCallback,
    DataCollatorWithPadding,
    TrainerCallback
)
from sklearn.metrics import accuracy_score, f1_score
from bertTextRNN import BertTextRNN
import datetime
import time

# ========================== ï¿½ è‡ªå®šä¹‰æ—¥å¿—å›è°ƒ ==========================
class CustomLogCallback(TrainerCallback):
    """
    è‡ªå®šä¹‰æ—¥å¿—å›è°ƒï¼Œç”¨äºè¾“å‡ºç¬¦åˆè¦æ±‚çš„æ ¼å¼ï¼š
    Time - INFO - Epoch: X, Step: Y, Train Loss: Z, LR: ..., Speed: ...
    """
    def __init__(self):
        self.last_time = time.time()
        self.last_step = 0

    def on_log(self, args, state, control, logs=None, **kwargs):
        if state.is_local_process_zero and logs:
            # è®¡ç®—é€Ÿåº¦
            current_time = time.time()
            time_delta = current_time - self.last_time
            step_delta = state.global_step - self.last_step
            
            # é¿å…é™¤ä»¥é›¶
            if step_delta > 0 and time_delta > 0:
                steps_per_sec = step_delta / time_delta
                ms_per_step = (time_delta / step_delta) * 1000
                speed_info = f"{ms_per_step:.2f}ms/step"
            else:
                speed_info = "N/A"
            
            # æ›´æ–°çŠ¶æ€
            self.last_time = current_time
            self.last_step = state.global_step

            # è·å–å½“å‰æ—¶é—´
            now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # æ„å»ºæ—¥å¿—ä¿¡æ¯ parts
            msg_parts = []
            
            # Epoch
            if 'epoch' in logs:
                msg_parts.append(f"Epoch: {logs['epoch']:.2f}")
            
            # Step
            msg_parts.append(f"Step: {state.global_step}")
            
            # Train Loss
            if 'loss' in logs:
                msg_parts.append(f"Train Loss: {logs['loss']:.4f}")
            
            # Learning Rate
            if 'learning_rate' in logs:
                msg_parts.append(f"LR: {logs['learning_rate']:.2e}")

            # Batch Size (å•å¡)
            msg_parts.append(f"Batch: {args.per_device_train_batch_size}")

            # Speed
            msg_parts.append(f"Speed: {speed_info}")

            # Eval Metrics (å¦‚æœæœ‰)
            if 'eval_loss' in logs:
                msg_parts.append(f"Eval Loss: {logs['eval_loss']:.4f}")
            if 'eval_accuracy' in logs:
                msg_parts.append(f"Accuracy: {logs['eval_accuracy']:.4f}")
            if 'eval_f1_macro' in logs:
                msg_parts.append(f"F1: {logs['eval_f1_macro']:.4f}")
                
            # ç»„åˆæ¶ˆæ¯
            log_msg = ", ".join(msg_parts)
            
            # è·å– logger
            logger = logging.getLogger(__name__)
            logger.info(log_msg)

# ========================== ï¿½ğŸ› ï¸ æ ¸å¿ƒé…ç½®åŒº ==========================
# 1. è°ƒè¯•æ¨¡å¼å¼€å…³
DEBUG_MODE = False 

# 2. æ˜¾å¡æŒ‡å®š
if DEBUG_MODE:
    os.environ["CUDA_VISIBLE_DEVICES"] = "1"
else:
    # âš ï¸ è¯·æ ¹æ®å®é™…ç©ºé—²æ˜¾å¡ä¿®æ”¹æ­¤å¤„
    os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,3,5" 

# 3. è·¯å¾„é…ç½®
DATA_DIR = "ft_data_stratified" # ğŸ†• ç»Ÿä¸€ä½¿ç”¨åˆ†å±‚åˆ‡åˆ†çš„æ•°æ®
PRETRAINED_MODEL_PATH = "bert_small_4096_final"

if DEBUG_MODE:
    OUTPUT_DIR = "output_ft_rnn_debug"
else:
    OUTPUT_DIR = "output_ft_rnn"

# 4. è®­ç»ƒè¶…å‚
SEQ_LEN = 4096
NUM_LABELS = 14

if DEBUG_MODE:
    NUM_EPOCHS = 1
    BATCH_SIZE = 4
    REPORT_TO = "none"
    SAVE_STRATEGY = "steps"
    EVAL_STRATEGY = "steps"
    EVAL_STEPS = 10
    SAVE_STEPS = 10
else:
    NUM_EPOCHS = 10
    # ğŸš€ ä¼˜åŒ–ï¼šRNN æ¯” CNN æ›´åƒæ˜¾å­˜ (BPTT)ï¼Œæ‰€ä»¥ Batch Size ä¸èƒ½åƒ CNN é‚£ä¹ˆå¤§ (32)ã€‚
    # A40 (48GB) è·‘ 4096 LSTMï¼Œå»ºè®®å°è¯• 8-16ã€‚
    # å¦‚æœ OOMï¼Œè¯·å‡å°æ­¤å€¼ã€‚
    BATCH_SIZE = 8
    REPORT_TO = "tensorboard"
    
    SAVE_STRATEGY = "steps"
    EVAL_STRATEGY = "steps"
    EVAL_STEPS = 500
    SAVE_STEPS = 500

# ====================================================================

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    
    acc = accuracy_score(labels, predictions)
    f1 = f1_score(labels, predictions, average='macro')
    
    return {
        'accuracy': acc,
        'f1_macro': f1
    }

def main():
    local_rank = int(os.environ.get("LOCAL_RANK", -1))
    is_main_process = local_rank in [-1, 0]

    # 0. è®¾ç½®æ—¥å¿—
    if is_main_process:
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        log_file = os.path.join(OUTPUT_DIR, "training_detailed.log")
        
        logging.basicConfig(
            format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
            datefmt="%m/%d/%Y %H:%M:%S",
            level=logging.INFO,
            handlers=[
                logging.StreamHandler(sys.stdout),
                logging.FileHandler(log_file, mode="w")
            ]
        )
        logger = logging.getLogger(__name__)
        logger.info(f"Logging to {log_file}")
    else:
        logging.basicConfig(
            format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
            datefmt="%m/%d/%Y %H:%M:%S",
            level=logging.WARN
        )

    if is_main_process:
        print(f"\n{'='*40}")
        print(f"ğŸš€ Starting Fine-tuning (RNN Stratified)...")
        print(f"ğŸ› ï¸  Mode: {'[DEBUG]' if DEBUG_MODE else '[FULL TRAINING]'}")
        print(f"{'='*40}\n")
    
    # 1. åŠ è½½æ•°æ®
    if not os.path.exists(DATA_DIR):
        raise FileNotFoundError(f"Data directory {DATA_DIR} not found. Run FT_data.py first.")
        
    if is_main_process:
        print(f"Loading data from {DATA_DIR}...")
    
    dataset = load_from_disk(DATA_DIR)
    train_dataset = dataset["train"]
    eval_dataset = dataset["validation"]
    
    if DEBUG_MODE:
        if is_main_process:
            print("âš ï¸ Debug mode: using small subset...")
        train_dataset = train_dataset.select(range(100))
        eval_dataset = eval_dataset.select(range(100))

    if is_main_process:
        print(f"Train size: {len(train_dataset)}")
        print(f"Eval size: {len(eval_dataset)}")

    # 2. åˆå§‹åŒ–æ¨¡å‹
    if is_main_process:
        print(f"Initializing BertTextRNN from {PRETRAINED_MODEL_PATH}...")
    
    model = BertTextRNN(
        bert_model_path=PRETRAINED_MODEL_PATH, 
        num_labels=NUM_LABELS,
        hidden_size=256,
        num_layers=2,
        dropout=0.1,
        bidirectional=True
    )
    
    # 3. è®­ç»ƒå‚æ•°
    # å¼ºåˆ¶ç¦ç”¨ torch.compile (é¿å…åŠ¨æ€ Padding é—®é¢˜)
    os.environ["TORCH_COMPILE_DISABLE"] = "1"
    import torch._dynamo
    torch._dynamo.config.suppress_errors = True
    torch._dynamo.config.disable = True

    training_args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        overwrite_output_dir=True,
        
        num_train_epochs=NUM_EPOCHS,
        per_device_train_batch_size=BATCH_SIZE,
        per_device_eval_batch_size=BATCH_SIZE,
        
        learning_rate=2e-5,
        weight_decay=0.01,
        warmup_ratio=0.1,
        
        eval_strategy=EVAL_STRATEGY, 
        eval_steps=EVAL_STEPS,
        save_strategy=SAVE_STRATEGY,
        save_steps=SAVE_STEPS,
        save_total_limit=2,
        
        load_best_model_at_end=True,
        metric_for_best_model="f1_macro",
        greater_is_better=True,
        
        bf16=False, 
        # ğŸš€ RNN å¿…é¡»å¼€å¯ Gradient Checkpointing æ‰èƒ½è·‘é•¿åºåˆ—
        gradient_checkpointing=True, 
        dataloader_num_workers=8, # åˆ©ç”¨å¤šæ ¸ CPU
        dataloader_pin_memory=True,
        
        logging_steps=50,
        report_to=REPORT_TO,
        
        ddp_find_unused_parameters=False
    )

    # 4. Data Collator (åŠ¨æ€å¡«å……)
    tokenizer = BertTokenizerFast.from_pretrained(PRETRAINED_MODEL_PATH)
    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding="longest")

    # 5. Trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        compute_metrics=compute_metrics,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=3), CustomLogCallback()],
        data_collator=data_collator
    )

    # 6. å¼€å§‹è®­ç»ƒ
    if is_main_process:
        print("ğŸ”¥ Starting Training...")
    trainer.train()
    
    # 7. ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_path = f"{OUTPUT_DIR}/final_model"
    trainer.save_model(final_path)
    if is_main_process:
        print(f"âœ… Done! Model saved to {final_path}")

if __name__ == "__main__":
    main()
