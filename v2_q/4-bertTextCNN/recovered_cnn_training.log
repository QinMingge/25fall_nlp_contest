2025-12-12 23:37:37 - INFO - Epoch: 0.04, Step: 50, Train Loss: 3.3360, Learning Rate: 7.73e-07
2025-12-12 23:39:47 - INFO - Epoch: 0.08, Step: 100, Train Loss: 3.0746, Learning Rate: 1.56e-06
2025-12-12 23:41:57 - INFO - Epoch: 0.12, Step: 150, Train Loss: 2.5513, Learning Rate: 2.35e-06
2025-12-12 23:44:07 - INFO - Epoch: 0.16, Step: 200, Train Loss: 1.9134, Learning Rate: 3.14e-06
2025-12-12 23:46:16 - INFO - Epoch: 0.20, Step: 250, Train Loss: 1.1257, Learning Rate: 3.93e-06
2025-12-12 23:48:26 - INFO - Epoch: 0.24, Step: 300, Train Loss: 0.6405, Learning Rate: 4.72e-06
2025-12-12 23:50:36 - INFO - Epoch: 0.28, Step: 350, Train Loss: 0.4254, Learning Rate: 5.50e-06
2025-12-12 23:52:46 - INFO - Epoch: 0.32, Step: 400, Train Loss: 0.3694, Learning Rate: 6.29e-06
2025-12-12 23:54:56 - INFO - Epoch: 0.35, Step: 450, Train Loss: 0.3024, Learning Rate: 7.08e-06
2025-12-12 23:57:05 - INFO - Epoch: 0.39, Step: 500, Train Loss: 0.2685, Learning Rate: 7.87e-06
2025-12-12 23:57:05 - INFO - Epoch: 0.39, Step: 500, Eval Loss: 0.2514, Accuracy: 0.9248, F1: 0.8859
2025-12-12 23:59:15 - INFO - Epoch: 0.43, Step: 550, Train Loss: 0.2252, Learning Rate: 8.66e-06
2025-12-13 00:01:25 - INFO - Epoch: 0.47, Step: 600, Train Loss: 0.2285, Learning Rate: 9.45e-06
2025-12-13 00:03:35 - INFO - Epoch: 0.51, Step: 650, Train Loss: 0.2086, Learning Rate: 1.02e-05
2025-12-13 00:05:45 - INFO - Epoch: 0.55, Step: 700, Train Loss: 0.2258, Learning Rate: 1.10e-05
2025-12-13 00:07:54 - INFO - Epoch: 0.59, Step: 750, Train Loss: 0.2065, Learning Rate: 1.18e-05
2025-12-13 00:10:04 - INFO - Epoch: 0.63, Step: 800, Train Loss: 0.2050, Learning Rate: 1.26e-05
2025-12-13 00:12:14 - INFO - Epoch: 0.67, Step: 850, Train Loss: 0.1841, Learning Rate: 1.34e-05
2025-12-13 00:14:24 - INFO - Epoch: 0.71, Step: 900, Train Loss: 0.1883, Learning Rate: 1.42e-05
2025-12-13 00:16:34 - INFO - Epoch: 0.75, Step: 950, Train Loss: 0.1609, Learning Rate: 1.50e-05
2025-12-13 00:18:43 - INFO - Epoch: 0.79, Step: 1000, Train Loss: 0.1783, Learning Rate: 1.58e-05
2025-12-13 00:18:43 - INFO - Epoch: 0.79, Step: 1000, Eval Loss: 0.1641, Accuracy: 0.9492, F1: 0.9397
2025-12-13 00:20:53 - INFO - Epoch: 0.83, Step: 1050, Train Loss: 0.1639, Learning Rate: 1.65e-05
2025-12-13 00:23:03 - INFO - Epoch: 0.87, Step: 1100, Train Loss: 0.1635, Learning Rate: 1.73e-05
2025-12-13 00:25:13 - INFO - Epoch: 0.91, Step: 1150, Train Loss: 0.1661, Learning Rate: 1.81e-05
2025-12-13 00:27:23 - INFO - Epoch: 0.95, Step: 1200, Train Loss: 0.1513, Learning Rate: 1.89e-05
2025-12-13 00:29:32 - INFO - Epoch: 0.99, Step: 1250, Train Loss: 0.1630, Learning Rate: 1.97e-05
2025-12-13 00:31:42 - INFO - Epoch: 1.03, Step: 1300, Train Loss: 0.1671, Learning Rate: 1.99e-05
2025-12-13 00:33:52 - INFO - Epoch: 1.06, Step: 1350, Train Loss: 0.1295, Learning Rate: 1.99e-05
2025-12-13 00:36:02 - INFO - Epoch: 1.10, Step: 1400, Train Loss: 0.1511, Learning Rate: 1.98e-05
2025-12-13 00:38:12 - INFO - Epoch: 1.14, Step: 1450, Train Loss: 0.1319, Learning Rate: 1.97e-05
2025-12-13 00:40:21 - INFO - Epoch: 1.18, Step: 1500, Train Loss: 0.1450, Learning Rate: 1.96e-05
2025-12-13 00:40:21 - INFO - Epoch: 1.18, Step: 1500, Eval Loss: 0.1354, Accuracy: 0.9576, F1: 0.9516
2025-12-13 00:42:31 - INFO - Epoch: 1.22, Step: 1550, Train Loss: 0.1356, Learning Rate: 1.95e-05
2025-12-13 00:44:41 - INFO - Epoch: 1.26, Step: 1600, Train Loss: 0.1340, Learning Rate: 1.94e-05
2025-12-13 00:46:51 - INFO - Epoch: 1.30, Step: 1650, Train Loss: 0.1212, Learning Rate: 1.93e-05
2025-12-13 00:49:01 - INFO - Epoch: 1.34, Step: 1700, Train Loss: 0.1319, Learning Rate: 1.92e-05
2025-12-13 00:51:10 - INFO - Epoch: 1.38, Step: 1750, Train Loss: 0.1254, Learning Rate: 1.92e-05
2025-12-13 00:53:20 - INFO - Epoch: 1.42, Step: 1800, Train Loss: 0.1329, Learning Rate: 1.91e-05
2025-12-13 00:55:30 - INFO - Epoch: 1.46, Step: 1850, Train Loss: 0.1322, Learning Rate: 1.90e-05
2025-12-13 00:57:40 - INFO - Epoch: 1.50, Step: 1900, Train Loss: 0.1332, Learning Rate: 1.89e-05
2025-12-13 00:59:50 - INFO - Epoch: 1.54, Step: 1950, Train Loss: 0.1327, Learning Rate: 1.88e-05
2025-12-13 01:01:59 - INFO - Epoch: 1.58, Step: 2000, Train Loss: 0.1294, Learning Rate: 1.87e-05
2025-12-13 01:01:59 - INFO - Epoch: 1.58, Step: 2000, Eval Loss: 0.1243, Accuracy: 0.9603, F1: 0.9558
2025-12-13 01:04:09 - INFO - Epoch: 1.62, Step: 2050, Train Loss: 0.1159, Learning Rate: 1.86e-05
2025-12-13 01:06:19 - INFO - Epoch: 1.66, Step: 2100, Train Loss: 0.1328, Learning Rate: 1.85e-05
2025-12-13 01:08:29 - INFO - Epoch: 1.70, Step: 2150, Train Loss: 0.1167, Learning Rate: 1.85e-05
2025-12-13 01:10:39 - INFO - Epoch: 1.74, Step: 2200, Train Loss: 0.1157, Learning Rate: 1.84e-05
2025-12-13 01:12:48 - INFO - Epoch: 1.77, Step: 2250, Train Loss: 0.1264, Learning Rate: 1.83e-05
2025-12-13 01:14:58 - INFO - Epoch: 1.81, Step: 2300, Train Loss: 0.1169, Learning Rate: 1.82e-05
2025-12-13 01:17:08 - INFO - Epoch: 1.85, Step: 2350, Train Loss: 0.1248, Learning Rate: 1.81e-05
2025-12-13 01:19:18 - INFO - Epoch: 1.89, Step: 2400, Train Loss: 0.1244, Learning Rate: 1.80e-05
2025-12-13 01:21:28 - INFO - Epoch: 1.93, Step: 2450, Train Loss: 0.1106, Learning Rate: 1.79e-05
2025-12-13 01:23:37 - INFO - Epoch: 1.97, Step: 2500, Train Loss: 0.1143, Learning Rate: 1.78e-05
2025-12-13 01:23:37 - INFO - Epoch: 1.97, Step: 2500, Eval Loss: 0.1186, Accuracy: 0.9628, F1: 0.9572
2025-12-13 01:25:47 - INFO - Epoch: 2.01, Step: 2550, Train Loss: 0.1150, Learning Rate: 1.78e-05
2025-12-13 01:27:57 - INFO - Epoch: 2.05, Step: 2600, Train Loss: 0.0937, Learning Rate: 1.77e-05
2025-12-13 01:30:07 - INFO - Epoch: 2.09, Step: 2650, Train Loss: 0.0903, Learning Rate: 1.76e-05
2025-12-13 01:32:17 - INFO - Epoch: 2.13, Step: 2700, Train Loss: 0.0893, Learning Rate: 1.75e-05
2025-12-13 01:34:26 - INFO - Epoch: 2.17, Step: 2750, Train Loss: 0.0836, Learning Rate: 1.74e-05
2025-12-13 01:36:36 - INFO - Epoch: 2.21, Step: 2800, Train Loss: 0.0864, Learning Rate: 1.73e-05
2025-12-13 01:38:46 - INFO - Epoch: 2.25, Step: 2850, Train Loss: 0.0927, Learning Rate: 1.72e-05
2025-12-13 01:40:56 - INFO - Epoch: 2.29, Step: 2900, Train Loss: 0.0857, Learning Rate: 1.71e-05
2025-12-13 01:43:06 - INFO - Epoch: 2.33, Step: 2950, Train Loss: 0.0847, Learning Rate: 1.71e-05
2025-12-13 01:45:15 - INFO - Epoch: 2.37, Step: 3000, Train Loss: 0.0896, Learning Rate: 1.70e-05
2025-12-13 01:45:15 - INFO - Epoch: 2.37, Step: 3000, Eval Loss: 0.1143, Accuracy: 0.9639, F1: 0.9604
2025-12-13 01:47:25 - INFO - Epoch: 2.41, Step: 3050, Train Loss: 0.0931, Learning Rate: 1.69e-05
2025-12-13 01:49:35 - INFO - Epoch: 2.44, Step: 3100, Train Loss: 0.0882, Learning Rate: 1.68e-05
2025-12-13 01:51:45 - INFO - Epoch: 2.48, Step: 3150, Train Loss: 0.0943, Learning Rate: 1.67e-05
2025-12-13 01:53:54 - INFO - Epoch: 2.52, Step: 3200, Train Loss: 0.0804, Learning Rate: 1.66e-05
2025-12-13 01:56:04 - INFO - Epoch: 2.56, Step: 3250, Train Loss: 0.0939, Learning Rate: 1.65e-05
2025-12-13 01:58:14 - INFO - Epoch: 2.60, Step: 3300, Train Loss: 0.0901, Learning Rate: 1.64e-05
2025-12-13 02:00:24 - INFO - Epoch: 2.64, Step: 3350, Train Loss: 0.0998, Learning Rate: 1.64e-05
2025-12-13 02:02:34 - INFO - Epoch: 2.68, Step: 3400, Train Loss: 0.0857, Learning Rate: 1.63e-05
2025-12-13 02:04:43 - INFO - Epoch: 2.72, Step: 3450, Train Loss: 0.0878, Learning Rate: 1.62e-05
2025-12-13 02:06:53 - INFO - Epoch: 2.76, Step: 3500, Train Loss: 0.0926, Learning Rate: 1.61e-05
2025-12-13 02:06:53 - INFO - Epoch: 2.76, Step: 3500, Eval Loss: 0.1215, Accuracy: 0.9614, F1: 0.9591
2025-12-13 02:09:03 - INFO - Epoch: 2.80, Step: 3550, Train Loss: 0.0886, Learning Rate: 1.60e-05
2025-12-13 02:11:13 - INFO - Epoch: 2.84, Step: 3600, Train Loss: 0.0787, Learning Rate: 1.59e-05
2025-12-13 02:13:23 - INFO - Epoch: 2.88, Step: 3650, Train Loss: 0.0876, Learning Rate: 1.58e-05
2025-12-13 02:15:32 - INFO - Epoch: 2.92, Step: 3700, Train Loss: 0.1053, Learning Rate: 1.57e-05
2025-12-13 02:17:42 - INFO - Epoch: 2.96, Step: 3750, Train Loss: 0.0813, Learning Rate: 1.57e-05
2025-12-13 02:19:52 - INFO - Epoch: 3.00, Step: 3800, Train Loss: 0.0889, Learning Rate: 1.56e-05
2025-12-13 02:22:02 - INFO - Epoch: 3.04, Step: 3850, Train Loss: 0.0624, Learning Rate: 1.55e-05
2025-12-13 02:24:12 - INFO - Epoch: 3.08, Step: 3900, Train Loss: 0.0541, Learning Rate: 1.54e-05
2025-12-13 02:26:21 - INFO - Epoch: 3.12, Step: 3950, Train Loss: 0.0663, Learning Rate: 1.53e-05
2025-12-13 02:28:31 - INFO - Epoch: 3.15, Step: 4000, Train Loss: 0.0737, Learning Rate: 1.52e-05
2025-12-13 02:28:31 - INFO - Epoch: 3.15, Step: 4000, Eval Loss: 0.1159, Accuracy: 0.9639, F1: 0.9606
2025-12-13 02:30:41 - INFO - Epoch: 3.19, Step: 4050, Train Loss: 0.0645, Learning Rate: 1.51e-05
2025-12-13 02:32:51 - INFO - Epoch: 3.23, Step: 4100, Train Loss: 0.0647, Learning Rate: 1.50e-05
2025-12-13 02:35:01 - INFO - Epoch: 3.27, Step: 4150, Train Loss: 0.0627, Learning Rate: 1.50e-05
2025-12-13 02:37:10 - INFO - Epoch: 3.31, Step: 4200, Train Loss: 0.0670, Learning Rate: 1.49e-05
2025-12-13 02:39:20 - INFO - Epoch: 3.35, Step: 4250, Train Loss: 0.0712, Learning Rate: 1.48e-05
2025-12-13 02:41:30 - INFO - Epoch: 3.39, Step: 4300, Train Loss: 0.0696, Learning Rate: 1.47e-05
2025-12-13 02:43:40 - INFO - Epoch: 3.43, Step: 4350, Train Loss: 0.0682, Learning Rate: 1.46e-05
2025-12-13 02:45:50 - INFO - Epoch: 3.47, Step: 4400, Train Loss: 0.0642, Learning Rate: 1.45e-05
2025-12-13 02:47:59 - INFO - Epoch: 3.51, Step: 4450, Train Loss: 0.0615, Learning Rate: 1.44e-05
2025-12-13 02:50:09 - INFO - Epoch: 3.55, Step: 4500, Train Loss: 0.0624, Learning Rate: 1.43e-05
2025-12-13 02:50:09 - INFO - Epoch: 3.55, Step: 4500, Eval Loss: 0.1133, Accuracy: 0.9653, F1: 0.9614
2025-12-13 02:52:19 - INFO - Epoch: 3.59, Step: 4550, Train Loss: 0.0742, Learning Rate: 1.42e-05
2025-12-13 02:54:29 - INFO - Epoch: 3.63, Step: 4600, Train Loss: 0.0611, Learning Rate: 1.42e-05
2025-12-13 02:56:39 - INFO - Epoch: 3.67, Step: 4650, Train Loss: 0.0635, Learning Rate: 1.41e-05
2025-12-13 02:58:48 - INFO - Epoch: 3.71, Step: 4700, Train Loss: 0.0696, Learning Rate: 1.40e-05
2025-12-13 03:00:58 - INFO - Epoch: 3.75, Step: 4750, Train Loss: 0.0731, Learning Rate: 1.39e-05
2025-12-13 03:03:08 - INFO - Epoch: 3.79, Step: 4800, Train Loss: 0.0639, Learning Rate: 1.38e-05
2025-12-13 03:05:18 - INFO - Epoch: 3.82, Step: 4850, Train Loss: 0.0679, Learning Rate: 1.37e-05
2025-12-13 03:07:28 - INFO - Epoch: 3.86, Step: 4900, Train Loss: 0.0748, Learning Rate: 1.36e-05
2025-12-13 03:09:37 - INFO - Epoch: 3.90, Step: 4950, Train Loss: 0.0543, Learning Rate: 1.35e-05
2025-12-13 03:11:47 - INFO - Epoch: 3.94, Step: 5000, Train Loss: 0.0594, Learning Rate: 1.35e-05
2025-12-13 03:11:47 - INFO - Epoch: 3.94, Step: 5000, Eval Loss: 0.1108, Accuracy: 0.9661, F1: 0.9621
2025-12-13 03:13:57 - INFO - Epoch: 3.98, Step: 5050, Train Loss: 0.0721, Learning Rate: 1.34e-05
2025-12-13 03:16:07 - INFO - Epoch: 4.02, Step: 5100, Train Loss: 0.0516, Learning Rate: 1.33e-05
2025-12-13 03:18:17 - INFO - Epoch: 4.06, Step: 5150, Train Loss: 0.0481, Learning Rate: 1.32e-05
2025-12-13 03:20:26 - INFO - Epoch: 4.10, Step: 5200, Train Loss: 0.0546, Learning Rate: 1.31e-05
2025-12-13 03:22:36 - INFO - Epoch: 4.14, Step: 5250, Train Loss: 0.0543, Learning Rate: 1.30e-05
2025-12-13 03:24:46 - INFO - Epoch: 4.18, Step: 5300, Train Loss: 0.0556, Learning Rate: 1.29e-05
2025-12-13 03:26:56 - INFO - Epoch: 4.22, Step: 5350, Train Loss: 0.0487, Learning Rate: 1.28e-05
2025-12-13 03:29:06 - INFO - Epoch: 4.26, Step: 5400, Train Loss: 0.0409, Learning Rate: 1.28e-05
2025-12-13 03:31:15 - INFO - Epoch: 4.30, Step: 5450, Train Loss: 0.0533, Learning Rate: 1.27e-05
2025-12-13 03:33:25 - INFO - Epoch: 4.34, Step: 5500, Train Loss: 0.0456, Learning Rate: 1.26e-05
2025-12-13 03:33:25 - INFO - Epoch: 4.34, Step: 5500, Eval Loss: 0.1135, Accuracy: 0.9664, F1: 0.9630
2025-12-13 03:35:35 - INFO - Epoch: 4.38, Step: 5550, Train Loss: 0.0557, Learning Rate: 1.25e-05
2025-12-13 03:37:45 - INFO - Epoch: 4.42, Step: 5600, Train Loss: 0.0506, Learning Rate: 1.24e-05
2025-12-13 03:39:55 - INFO - Epoch: 4.46, Step: 5650, Train Loss: 0.0467, Learning Rate: 1.23e-05
2025-12-13 03:42:04 - INFO - Epoch: 4.50, Step: 5700, Train Loss: 0.0576, Learning Rate: 1.22e-05
2025-12-13 03:44:14 - INFO - Epoch: 4.53, Step: 5750, Train Loss: 0.0448, Learning Rate: 1.21e-05
2025-12-13 03:46:24 - INFO - Epoch: 4.57, Step: 5800, Train Loss: 0.0447, Learning Rate: 1.21e-05
2025-12-13 03:48:34 - INFO - Epoch: 4.61, Step: 5850, Train Loss: 0.0467, Learning Rate: 1.20e-05
2025-12-13 03:50:44 - INFO - Epoch: 4.65, Step: 5900, Train Loss: 0.0527, Learning Rate: 1.19e-05
2025-12-13 03:52:53 - INFO - Epoch: 4.69, Step: 5950, Train Loss: 0.0469, Learning Rate: 1.18e-05
2025-12-13 03:55:03 - INFO - Epoch: 4.73, Step: 6000, Train Loss: 0.0570, Learning Rate: 1.17e-05
2025-12-13 03:55:03 - INFO - Epoch: 4.73, Step: 6000, Eval Loss: 0.1179, Accuracy: 0.9657, F1: 0.9617
2025-12-13 03:57:13 - INFO - Epoch: 4.77, Step: 6050, Train Loss: 0.0463, Learning Rate: 1.16e-05
2025-12-13 03:59:23 - INFO - Epoch: 4.81, Step: 6100, Train Loss: 0.0509, Learning Rate: 1.15e-05
2025-12-13 04:01:33 - INFO - Epoch: 4.85, Step: 6150, Train Loss: 0.0550, Learning Rate: 1.14e-05
2025-12-13 04:03:42 - INFO - Epoch: 4.89, Step: 6200, Train Loss: 0.0453, Learning Rate: 1.14e-05
2025-12-13 04:05:52 - INFO - Epoch: 4.93, Step: 6250, Train Loss: 0.0476, Learning Rate: 1.13e-05
2025-12-13 04:08:02 - INFO - Epoch: 4.97, Step: 6300, Train Loss: 0.0457, Learning Rate: 1.12e-05
2025-12-13 04:10:12 - INFO - Epoch: 5.01, Step: 6350, Train Loss: 0.0441, Learning Rate: 1.11e-05
2025-12-13 04:12:21 - INFO - Epoch: 5.05, Step: 6400, Train Loss: 0.0365, Learning Rate: 1.10e-05
2025-12-13 04:14:31 - INFO - Epoch: 5.09, Step: 6450, Train Loss: 0.0327, Learning Rate: 1.09e-05
2025-12-13 04:16:41 - INFO - Epoch: 5.13, Step: 6500, Train Loss: 0.0315, Learning Rate: 1.08e-05
2025-12-13 04:16:41 - INFO - Epoch: 5.13, Step: 6500, Eval Loss: 0.1194, Accuracy: 0.9669, F1: 0.9632
2025-12-13 04:18:51 - INFO - Epoch: 5.17, Step: 6550, Train Loss: 0.0341, Learning Rate: 1.07e-05
2025-12-13 04:21:01 - INFO - Epoch: 5.21, Step: 6600, Train Loss: 0.0401, Learning Rate: 1.07e-05
2025-12-13 04:23:10 - INFO - Epoch: 5.24, Step: 6650, Train Loss: 0.0386, Learning Rate: 1.06e-05
2025-12-13 04:25:20 - INFO - Epoch: 5.28, Step: 6700, Train Loss: 0.0405, Learning Rate: 1.05e-05
2025-12-13 04:27:30 - INFO - Epoch: 5.32, Step: 6750, Train Loss: 0.0375, Learning Rate: 1.04e-05
2025-12-13 04:29:40 - INFO - Epoch: 5.36, Step: 6800, Train Loss: 0.0365, Learning Rate: 1.03e-05
2025-12-13 04:31:50 - INFO - Epoch: 5.40, Step: 6850, Train Loss: 0.0377, Learning Rate: 1.02e-05
2025-12-13 04:33:59 - INFO - Epoch: 5.44, Step: 6900, Train Loss: 0.0321, Learning Rate: 1.01e-05
2025-12-13 04:36:09 - INFO - Epoch: 5.48, Step: 6950, Train Loss: 0.0423, Learning Rate: 1.00e-05
2025-12-13 04:38:19 - INFO - Epoch: 5.52, Step: 7000, Train Loss: 0.0376, Learning Rate: 9.96e-06
2025-12-13 04:38:19 - INFO - Epoch: 5.52, Step: 7000, Eval Loss: 0.1238, Accuracy: 0.9665, F1: 0.9637
2025-12-13 04:40:29 - INFO - Epoch: 5.56, Step: 7050, Train Loss: 0.0397, Learning Rate: 9.87e-06
2025-12-13 04:42:39 - INFO - Epoch: 5.60, Step: 7100, Train Loss: 0.0411, Learning Rate: 9.78e-06
2025-12-13 04:44:48 - INFO - Epoch: 5.64, Step: 7150, Train Loss: 0.0309, Learning Rate: 9.69e-06
2025-12-13 04:46:58 - INFO - Epoch: 5.68, Step: 7200, Train Loss: 0.0317, Learning Rate: 9.61e-06
2025-12-13 04:49:08 - INFO - Epoch: 5.72, Step: 7250, Train Loss: 0.0328, Learning Rate: 9.52e-06
2025-12-13 04:51:18 - INFO - Epoch: 5.76, Step: 7300, Train Loss: 0.0393, Learning Rate: 9.43e-06
2025-12-13 04:53:28 - INFO - Epoch: 5.80, Step: 7350, Train Loss: 0.0339, Learning Rate: 9.34e-06
2025-12-13 04:55:37 - INFO - Epoch: 5.84, Step: 7400, Train Loss: 0.0298, Learning Rate: 9.26e-06
2025-12-13 04:57:47 - INFO - Epoch: 5.88, Step: 7450, Train Loss: 0.0406, Learning Rate: 9.17e-06
2025-12-13 04:59:57 - INFO - Epoch: 5.91, Step: 7500, Train Loss: 0.0339, Learning Rate: 9.08e-06
2025-12-13 04:59:57 - INFO - Epoch: 5.91, Step: 7500, Eval Loss: 0.1278, Accuracy: 0.9662, F1: 0.9636
2025-12-13 05:02:07 - INFO - Epoch: 5.95, Step: 7550, Train Loss: 0.0323, Learning Rate: 8.99e-06
2025-12-13 05:04:17 - INFO - Epoch: 5.99, Step: 7600, Train Loss: 0.0288, Learning Rate: 8.90e-06
2025-12-13 05:06:26 - INFO - Epoch: 6.03, Step: 7650, Train Loss: 0.0245, Learning Rate: 8.82e-06
2025-12-13 05:08:36 - INFO - Epoch: 6.07, Step: 7700, Train Loss: 0.0242, Learning Rate: 8.73e-06
2025-12-13 05:10:46 - INFO - Epoch: 6.11, Step: 7750, Train Loss: 0.0217, Learning Rate: 8.64e-06
2025-12-13 05:12:56 - INFO - Epoch: 6.15, Step: 7800, Train Loss: 0.0266, Learning Rate: 8.55e-06
2025-12-13 05:15:06 - INFO - Epoch: 6.19, Step: 7850, Train Loss: 0.0289, Learning Rate: 8.47e-06
2025-12-13 05:17:15 - INFO - Epoch: 6.23, Step: 7900, Train Loss: 0.0269, Learning Rate: 8.38e-06
2025-12-13 05:19:25 - INFO - Epoch: 6.27, Step: 7950, Train Loss: 0.0252, Learning Rate: 8.29e-06
2025-12-13 05:21:35 - INFO - Epoch: 6.31, Step: 8000, Train Loss: 0.0254, Learning Rate: 8.20e-06
2025-12-13 05:21:35 - INFO - Epoch: 6.31, Step: 8000, Eval Loss: 0.1341, Accuracy: 0.9655, F1: 0.9626
2025-12-13 05:23:45 - INFO - Epoch: 6.35, Step: 8050, Train Loss: 0.0276, Learning Rate: 8.12e-06
2025-12-13 05:25:55 - INFO - Epoch: 6.39, Step: 8100, Train Loss: 0.0234, Learning Rate: 8.03e-06
2025-12-13 05:28:04 - INFO - Epoch: 6.43, Step: 8150, Train Loss: 0.0287, Learning Rate: 7.94e-06
2025-12-13 05:30:14 - INFO - Epoch: 6.47, Step: 8200, Train Loss: 0.0237, Learning Rate: 7.85e-06
2025-12-13 05:32:24 - INFO - Epoch: 6.51, Step: 8250, Train Loss: 0.0184, Learning Rate: 7.77e-06
2025-12-13 05:34:34 - INFO - Epoch: 6.55, Step: 8300, Train Loss: 0.0225, Learning Rate: 7.68e-06
2025-12-13 05:36:44 - INFO - Epoch: 6.59, Step: 8350, Train Loss: 0.0203, Learning Rate: 7.59e-06
2025-12-13 05:38:53 - INFO - Epoch: 6.62, Step: 8400, Train Loss: 0.0305, Learning Rate: 7.50e-06
2025-12-13 05:41:03 - INFO - Epoch: 6.66, Step: 8450, Train Loss: 0.0294, Learning Rate: 7.42e-06
2025-12-13 05:43:13 - INFO - Epoch: 6.70, Step: 8500, Train Loss: 0.0244, Learning Rate: 7.33e-06
2025-12-13 05:43:13 - INFO - Epoch: 6.70, Step: 8500, Eval Loss: 0.1294, Accuracy: 0.9667, F1: 0.9641
2025-12-13 05:45:23 - INFO - Epoch: 6.74, Step: 8550, Train Loss: 0.0287, Learning Rate: 7.24e-06
2025-12-13 05:47:33 - INFO - Epoch: 6.78, Step: 8600, Train Loss: 0.0236, Learning Rate: 7.15e-06
2025-12-13 05:49:42 - INFO - Epoch: 6.82, Step: 8650, Train Loss: 0.0273, Learning Rate: 7.06e-06
2025-12-13 05:51:52 - INFO - Epoch: 6.86, Step: 8700, Train Loss: 0.0261, Learning Rate: 6.98e-06
2025-12-13 05:54:02 - INFO - Epoch: 6.90, Step: 8750, Train Loss: 0.0258, Learning Rate: 6.89e-06
2025-12-13 05:56:12 - INFO - Epoch: 6.94, Step: 8800, Train Loss: 0.0311, Learning Rate: 6.80e-06
2025-12-13 05:58:22 - INFO - Epoch: 6.98, Step: 8850, Train Loss: 0.0249, Learning Rate: 6.71e-06
2025-12-13 06:00:31 - INFO - Epoch: 7.02, Step: 8900, Train Loss: 0.0324, Learning Rate: 6.63e-06
2025-12-13 06:02:41 - INFO - Epoch: 7.06, Step: 8950, Train Loss: 0.0163, Learning Rate: 6.54e-06
2025-12-13 06:04:51 - INFO - Epoch: 7.10, Step: 9000, Train Loss: 0.0197, Learning Rate: 6.45e-06
2025-12-13 06:04:51 - INFO - Epoch: 7.10, Step: 9000, Eval Loss: 0.1339, Accuracy: 0.9668, F1: 0.9644
2025-12-13 06:07:01 - INFO - Epoch: 7.14, Step: 9050, Train Loss: 0.0157, Learning Rate: 6.36e-06
2025-12-13 06:09:11 - INFO - Epoch: 7.18, Step: 9100, Train Loss: 0.0207, Learning Rate: 6.28e-06
2025-12-13 06:11:20 - INFO - Epoch: 7.22, Step: 9150, Train Loss: 0.0158, Learning Rate: 6.19e-06
2025-12-13 06:13:30 - INFO - Epoch: 7.26, Step: 9200, Train Loss: 0.0175, Learning Rate: 6.10e-06
2025-12-13 06:15:40 - INFO - Epoch: 7.29, Step: 9250, Train Loss: 0.0171, Learning Rate: 6.01e-06
2025-12-13 06:17:50 - INFO - Epoch: 7.33, Step: 9300, Train Loss: 0.0215, Learning Rate: 5.93e-06
2025-12-13 06:20:00 - INFO - Epoch: 7.37, Step: 9350, Train Loss: 0.0186, Learning Rate: 5.84e-06
2025-12-13 06:22:09 - INFO - Epoch: 7.41, Step: 9400, Train Loss: 0.0189, Learning Rate: 5.75e-06
2025-12-13 06:24:19 - INFO - Epoch: 7.45, Step: 9450, Train Loss: 0.0177, Learning Rate: 5.66e-06
2025-12-13 06:26:29 - INFO - Epoch: 7.49, Step: 9500, Train Loss: 0.0189, Learning Rate: 5.57e-06
2025-12-13 06:26:29 - INFO - Epoch: 7.49, Step: 9500, Eval Loss: 0.1447, Accuracy: 0.9655, F1: 0.9628
2025-12-13 06:28:39 - INFO - Epoch: 7.53, Step: 9550, Train Loss: 0.0185, Learning Rate: 5.49e-06
2025-12-13 06:30:49 - INFO - Epoch: 7.57, Step: 9600, Train Loss: 0.0199, Learning Rate: 5.40e-06
2025-12-13 06:32:58 - INFO - Epoch: 7.61, Step: 9650, Train Loss: 0.0204, Learning Rate: 5.31e-06
2025-12-13 06:35:08 - INFO - Epoch: 7.65, Step: 9700, Train Loss: 0.0195, Learning Rate: 5.22e-06
2025-12-13 06:37:18 - INFO - Epoch: 7.69, Step: 9750, Train Loss: 0.0171, Learning Rate: 5.14e-06
2025-12-13 06:39:28 - INFO - Epoch: 7.73, Step: 9800, Train Loss: 0.0186, Learning Rate: 5.05e-06
2025-12-13 06:41:38 - INFO - Epoch: 7.77, Step: 9850, Train Loss: 0.0188, Learning Rate: 4.96e-06
2025-12-13 06:43:47 - INFO - Epoch: 7.81, Step: 9900, Train Loss: 0.0168, Learning Rate: 4.87e-06
2025-12-13 06:45:57 - INFO - Epoch: 7.85, Step: 9950, Train Loss: 0.0178, Learning Rate: 4.79e-06
2025-12-13 06:48:07 - INFO - Epoch: 7.89, Step: 10000, Train Loss: 0.0215, Learning Rate: 4.70e-06
2025-12-13 06:48:07 - INFO - Epoch: 7.89, Step: 10000, Eval Loss: 0.1427, Accuracy: 0.9663, F1: 0.9636
2025-12-13 06:50:17 - INFO - Epoch: 7.93, Step: 10050, Train Loss: 0.0204, Learning Rate: 4.61e-06
2025-12-13 06:52:27 - INFO - Epoch: 7.97, Step: 10100, Train Loss: 0.0170, Learning Rate: 4.52e-06
2025-12-13 06:54:36 - INFO - Epoch: 8.00, Step: 10150, Train Loss: 0.0189, Learning Rate: 4.44e-06
2025-12-13 06:56:46 - INFO - Epoch: 8.04, Step: 10200, Train Loss: 0.0145, Learning Rate: 4.35e-06
2025-12-13 06:58:56 - INFO - Epoch: 8.08, Step: 10250, Train Loss: 0.0106, Learning Rate: 4.26e-06
2025-12-13 07:01:06 - INFO - Epoch: 8.12, Step: 10300, Train Loss: 0.0135, Learning Rate: 4.17e-06
2025-12-13 07:03:16 - INFO - Epoch: 8.16, Step: 10350, Train Loss: 0.0112, Learning Rate: 4.09e-06
2025-12-13 07:05:25 - INFO - Epoch: 8.20, Step: 10400, Train Loss: 0.0090, Learning Rate: 4.00e-06
2025-12-13 07:07:35 - INFO - Epoch: 8.24, Step: 10450, Train Loss: 0.0162, Learning Rate: 3.91e-06
2025-12-13 07:09:45 - INFO - Epoch: 8.28, Step: 10500, Train Loss: 0.0154, Learning Rate: 3.82e-06
2025-12-13 07:09:45 - INFO - Epoch: 8.28, Step: 10500, Eval Loss: 0.1448, Accuracy: 0.9664, F1: 0.9639
