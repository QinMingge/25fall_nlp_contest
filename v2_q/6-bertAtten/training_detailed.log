12/13/2025 23:50:20 - INFO - __main__ -   Logging to output_ft_attention/training_detailed.log
12/13/2025 23:50:20 - INFO - __main__ -   Loading data from ft_data_stratified...
12/13/2025 23:50:20 - INFO - __main__ -   Initializing BertTextAttention model...
12/13/2025 23:50:21 - WARNING - accelerate.utils.other -   Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
12/13/2025 23:50:22 - INFO - __main__ -   Starting training...
12/13/2025 23:52:16 - INFO - __main__ -   Epoch: 0.04, Step: 50, Train Loss: 2.6697, LR: 7.73e-07, Batch: 32, Speed: 2291.41ms/step
12/13/2025 23:54:03 - INFO - __main__ -   Epoch: 0.08, Step: 100, Train Loss: 2.4824, LR: 1.56e-06, Batch: 32, Speed: 2147.38ms/step
12/13/2025 23:55:52 - INFO - __main__ -   Epoch: 0.12, Step: 150, Train Loss: 2.1200, LR: 2.35e-06, Batch: 32, Speed: 2182.69ms/step
12/13/2025 23:57:41 - INFO - __main__ -   Epoch: 0.16, Step: 200, Train Loss: 1.6425, LR: 3.14e-06, Batch: 32, Speed: 2171.71ms/step
12/13/2025 23:59:31 - INFO - __main__ -   Epoch: 0.20, Step: 250, Train Loss: 1.0374, LR: 3.93e-06, Batch: 32, Speed: 2210.15ms/step
12/14/2025 00:01:22 - INFO - __main__ -   Epoch: 0.24, Step: 300, Train Loss: 0.6425, LR: 4.72e-06, Batch: 32, Speed: 2205.10ms/step
12/14/2025 00:03:11 - INFO - __main__ -   Epoch: 0.28, Step: 350, Train Loss: 0.4496, LR: 5.50e-06, Batch: 32, Speed: 2190.24ms/step
12/14/2025 00:05:01 - INFO - __main__ -   Epoch: 0.32, Step: 400, Train Loss: 0.3955, LR: 6.29e-06, Batch: 32, Speed: 2197.69ms/step
12/14/2025 00:06:49 - INFO - __main__ -   Epoch: 0.35, Step: 450, Train Loss: 0.3242, LR: 7.08e-06, Batch: 32, Speed: 2169.59ms/step
12/14/2025 00:08:39 - INFO - __main__ -   Epoch: 0.39, Step: 500, Train Loss: 0.2871, LR: 7.87e-06, Batch: 32, Speed: 2192.26ms/step
12/14/2025 00:11:38 - INFO - __main__ -   Epoch: 0.39, Step: 500, Batch: 32, Speed: N/A, Eval Loss: 0.2612, Accuracy: 0.9209, F1: 0.8908
12/14/2025 00:13:29 - INFO - __main__ -   Epoch: 0.43, Step: 550, Train Loss: 0.2403, LR: 8.66e-06, Batch: 32, Speed: 2214.98ms/step
12/14/2025 00:15:19 - INFO - __main__ -   Epoch: 0.47, Step: 600, Train Loss: 0.2431, LR: 9.45e-06, Batch: 32, Speed: 2203.59ms/step
12/14/2025 00:17:08 - INFO - __main__ -   Epoch: 0.51, Step: 650, Train Loss: 0.2227, LR: 1.02e-05, Batch: 32, Speed: 2176.35ms/step
12/14/2025 00:18:57 - INFO - __main__ -   Epoch: 0.55, Step: 700, Train Loss: 0.2345, LR: 1.10e-05, Batch: 32, Speed: 2174.67ms/step
12/14/2025 00:20:47 - INFO - __main__ -   Epoch: 0.59, Step: 750, Train Loss: 0.2161, LR: 1.18e-05, Batch: 32, Speed: 2206.18ms/step
12/14/2025 00:22:35 - INFO - __main__ -   Epoch: 0.63, Step: 800, Train Loss: 0.2157, LR: 1.26e-05, Batch: 32, Speed: 2168.73ms/step
12/14/2025 00:24:25 - INFO - __main__ -   Epoch: 0.67, Step: 850, Train Loss: 0.1904, LR: 1.34e-05, Batch: 32, Speed: 2188.66ms/step
12/14/2025 00:26:15 - INFO - __main__ -   Epoch: 0.71, Step: 900, Train Loss: 0.1936, LR: 1.42e-05, Batch: 32, Speed: 2201.09ms/step
12/14/2025 00:28:04 - INFO - __main__ -   Epoch: 0.75, Step: 950, Train Loss: 0.1646, LR: 1.50e-05, Batch: 32, Speed: 2184.85ms/step
12/14/2025 00:29:54 - INFO - __main__ -   Epoch: 0.79, Step: 1000, Train Loss: 0.1816, LR: 1.58e-05, Batch: 32, Speed: 2189.12ms/step
12/14/2025 00:32:52 - INFO - __main__ -   Epoch: 0.79, Step: 1000, Batch: 32, Speed: N/A, Eval Loss: 0.1755, Accuracy: 0.9453, F1: 0.9347
12/14/2025 00:34:42 - INFO - __main__ -   Epoch: 0.83, Step: 1050, Train Loss: 0.1666, LR: 1.65e-05, Batch: 32, Speed: 2196.96ms/step
12/14/2025 00:36:31 - INFO - __main__ -   Epoch: 0.87, Step: 1100, Train Loss: 0.1693, LR: 1.73e-05, Batch: 32, Speed: 2181.60ms/step
12/14/2025 00:38:20 - INFO - __main__ -   Epoch: 0.91, Step: 1150, Train Loss: 0.1718, LR: 1.81e-05, Batch: 32, Speed: 2185.24ms/step
12/14/2025 00:40:11 - INFO - __main__ -   Epoch: 0.95, Step: 1200, Train Loss: 0.1578, LR: 1.89e-05, Batch: 32, Speed: 2211.39ms/step
12/14/2025 00:41:59 - INFO - __main__ -   Epoch: 0.99, Step: 1250, Train Loss: 0.1666, LR: 1.97e-05, Batch: 32, Speed: 2166.50ms/step
12/14/2025 00:43:49 - INFO - __main__ -   Epoch: 1.03, Step: 1300, Train Loss: 0.1666, LR: 1.99e-05, Batch: 32, Speed: 2206.19ms/step
12/14/2025 00:45:38 - INFO - __main__ -   Epoch: 1.06, Step: 1350, Train Loss: 0.1374, LR: 1.99e-05, Batch: 32, Speed: 2174.75ms/step
12/14/2025 00:47:28 - INFO - __main__ -   Epoch: 1.10, Step: 1400, Train Loss: 0.1559, LR: 1.98e-05, Batch: 32, Speed: 2192.51ms/step
12/14/2025 00:49:17 - INFO - __main__ -   Epoch: 1.14, Step: 1450, Train Loss: 0.1378, LR: 1.97e-05, Batch: 32, Speed: 2198.61ms/step
12/14/2025 00:51:07 - INFO - __main__ -   Epoch: 1.18, Step: 1500, Train Loss: 0.1515, LR: 1.96e-05, Batch: 32, Speed: 2188.80ms/step
12/14/2025 00:54:05 - INFO - __main__ -   Epoch: 1.18, Step: 1500, Batch: 32, Speed: N/A, Eval Loss: 0.1447, Accuracy: 0.9546, F1: 0.9471
12/14/2025 00:55:56 - INFO - __main__ -   Epoch: 1.22, Step: 1550, Train Loss: 0.1389, LR: 1.95e-05, Batch: 32, Speed: 2216.36ms/step
12/14/2025 00:57:46 - INFO - __main__ -   Epoch: 1.26, Step: 1600, Train Loss: 0.1359, LR: 1.94e-05, Batch: 32, Speed: 2205.87ms/step
12/14/2025 00:59:32 - INFO - __main__ -   Epoch: 1.30, Step: 1650, Train Loss: 0.1207, LR: 1.93e-05, Batch: 32, Speed: 2114.29ms/step
12/14/2025 01:01:21 - INFO - __main__ -   Epoch: 1.34, Step: 1700, Train Loss: 0.1359, LR: 1.92e-05, Batch: 32, Speed: 2189.29ms/step
12/14/2025 01:03:11 - INFO - __main__ -   Epoch: 1.38, Step: 1750, Train Loss: 0.1332, LR: 1.92e-05, Batch: 32, Speed: 2188.01ms/step
12/14/2025 01:04:59 - INFO - __main__ -   Epoch: 1.42, Step: 1800, Train Loss: 0.1342, LR: 1.91e-05, Batch: 32, Speed: 2165.40ms/step
12/14/2025 01:06:47 - INFO - __main__ -   Epoch: 1.46, Step: 1850, Train Loss: 0.1384, LR: 1.90e-05, Batch: 32, Speed: 2164.98ms/step
12/14/2025 01:08:38 - INFO - __main__ -   Epoch: 1.50, Step: 1900, Train Loss: 0.1342, LR: 1.89e-05, Batch: 32, Speed: 2212.25ms/step
12/14/2025 01:10:27 - INFO - __main__ -   Epoch: 1.54, Step: 1950, Train Loss: 0.1384, LR: 1.88e-05, Batch: 32, Speed: 2194.82ms/step
12/14/2025 01:12:16 - INFO - __main__ -   Epoch: 1.58, Step: 2000, Train Loss: 0.1347, LR: 1.87e-05, Batch: 32, Speed: 2168.33ms/step
12/14/2025 01:15:14 - INFO - __main__ -   Epoch: 1.58, Step: 2000, Batch: 32, Speed: N/A, Eval Loss: 0.1381, Accuracy: 0.9573, F1: 0.9523
12/14/2025 01:17:04 - INFO - __main__ -   Epoch: 1.62, Step: 2050, Train Loss: 0.1236, LR: 1.86e-05, Batch: 32, Speed: 2202.18ms/step
12/14/2025 01:18:55 - INFO - __main__ -   Epoch: 1.66, Step: 2100, Train Loss: 0.1359, LR: 1.85e-05, Batch: 32, Speed: 2210.71ms/step
12/14/2025 01:20:42 - INFO - __main__ -   Epoch: 1.70, Step: 2150, Train Loss: 0.1213, LR: 1.85e-05, Batch: 32, Speed: 2149.49ms/step
12/14/2025 01:22:32 - INFO - __main__ -   Epoch: 1.74, Step: 2200, Train Loss: 0.1210, LR: 1.84e-05, Batch: 32, Speed: 2205.00ms/step
12/14/2025 01:24:21 - INFO - __main__ -   Epoch: 1.77, Step: 2250, Train Loss: 0.1317, LR: 1.83e-05, Batch: 32, Speed: 2178.94ms/step
12/14/2025 01:26:09 - INFO - __main__ -   Epoch: 1.81, Step: 2300, Train Loss: 0.1219, LR: 1.82e-05, Batch: 32, Speed: 2162.55ms/step
12/14/2025 01:28:00 - INFO - __main__ -   Epoch: 1.85, Step: 2350, Train Loss: 0.1317, LR: 1.81e-05, Batch: 32, Speed: 2201.87ms/step
12/14/2025 01:29:49 - INFO - __main__ -   Epoch: 1.89, Step: 2400, Train Loss: 0.1300, LR: 1.80e-05, Batch: 32, Speed: 2189.15ms/step
12/14/2025 01:31:38 - INFO - __main__ -   Epoch: 1.93, Step: 2450, Train Loss: 0.1197, LR: 1.79e-05, Batch: 32, Speed: 2175.28ms/step
12/14/2025 01:33:25 - INFO - __main__ -   Epoch: 1.97, Step: 2500, Train Loss: 0.1213, LR: 1.78e-05, Batch: 32, Speed: 2136.62ms/step
12/14/2025 01:36:23 - INFO - __main__ -   Epoch: 1.97, Step: 2500, Batch: 32, Speed: N/A, Eval Loss: 0.1271, Accuracy: 0.9603, F1: 0.9545
12/14/2025 01:38:13 - INFO - __main__ -   Epoch: 2.01, Step: 2550, Train Loss: 0.1228, LR: 1.78e-05, Batch: 32, Speed: 2213.86ms/step
12/14/2025 01:40:03 - INFO - __main__ -   Epoch: 2.05, Step: 2600, Train Loss: 0.0999, LR: 1.77e-05, Batch: 32, Speed: 2196.21ms/step
12/14/2025 01:41:53 - INFO - __main__ -   Epoch: 2.09, Step: 2650, Train Loss: 0.0993, LR: 1.76e-05, Batch: 32, Speed: 2198.09ms/step
12/14/2025 01:43:42 - INFO - __main__ -   Epoch: 2.13, Step: 2700, Train Loss: 0.0953, LR: 1.75e-05, Batch: 32, Speed: 2177.06ms/step
12/14/2025 01:45:32 - INFO - __main__ -   Epoch: 2.17, Step: 2750, Train Loss: 0.0857, LR: 1.74e-05, Batch: 32, Speed: 2192.86ms/step
12/14/2025 01:47:21 - INFO - __main__ -   Epoch: 2.21, Step: 2800, Train Loss: 0.0944, LR: 1.73e-05, Batch: 32, Speed: 2193.36ms/step
12/14/2025 01:49:10 - INFO - __main__ -   Epoch: 2.25, Step: 2850, Train Loss: 0.0998, LR: 1.72e-05, Batch: 32, Speed: 2184.56ms/step
12/14/2025 01:50:59 - INFO - __main__ -   Epoch: 2.29, Step: 2900, Train Loss: 0.0957, LR: 1.71e-05, Batch: 32, Speed: 2162.28ms/step
12/14/2025 01:52:47 - INFO - __main__ -   Epoch: 2.33, Step: 2950, Train Loss: 0.0881, LR: 1.71e-05, Batch: 32, Speed: 2162.38ms/step
12/14/2025 01:54:37 - INFO - __main__ -   Epoch: 2.37, Step: 3000, Train Loss: 0.1021, LR: 1.70e-05, Batch: 32, Speed: 2205.36ms/step
12/14/2025 01:57:35 - INFO - __main__ -   Epoch: 2.37, Step: 3000, Batch: 32, Speed: N/A, Eval Loss: 0.1241, Accuracy: 0.9620, F1: 0.9574
12/14/2025 01:59:26 - INFO - __main__ -   Epoch: 2.41, Step: 3050, Train Loss: 0.0977, LR: 1.69e-05, Batch: 32, Speed: 2211.09ms/step
12/14/2025 02:01:16 - INFO - __main__ -   Epoch: 2.44, Step: 3100, Train Loss: 0.0992, LR: 1.68e-05, Batch: 32, Speed: 2201.39ms/step
12/14/2025 02:03:06 - INFO - __main__ -   Epoch: 2.48, Step: 3150, Train Loss: 0.0982, LR: 1.67e-05, Batch: 32, Speed: 2198.22ms/step
12/14/2025 02:04:55 - INFO - __main__ -   Epoch: 2.52, Step: 3200, Train Loss: 0.0877, LR: 1.66e-05, Batch: 32, Speed: 2192.18ms/step
12/14/2025 02:06:45 - INFO - __main__ -   Epoch: 2.56, Step: 3250, Train Loss: 0.0974, LR: 1.65e-05, Batch: 32, Speed: 2198.28ms/step
12/14/2025 02:08:33 - INFO - __main__ -   Epoch: 2.60, Step: 3300, Train Loss: 0.0963, LR: 1.64e-05, Batch: 32, Speed: 2159.33ms/step
12/14/2025 02:10:24 - INFO - __main__ -   Epoch: 2.64, Step: 3350, Train Loss: 0.1026, LR: 1.64e-05, Batch: 32, Speed: 2213.24ms/step
12/14/2025 02:12:12 - INFO - __main__ -   Epoch: 2.68, Step: 3400, Train Loss: 0.0893, LR: 1.63e-05, Batch: 32, Speed: 2158.37ms/step
12/14/2025 02:14:00 - INFO - __main__ -   Epoch: 2.72, Step: 3450, Train Loss: 0.0944, LR: 1.62e-05, Batch: 32, Speed: 2173.84ms/step
12/14/2025 02:15:50 - INFO - __main__ -   Epoch: 2.76, Step: 3500, Train Loss: 0.0947, LR: 1.61e-05, Batch: 32, Speed: 2202.38ms/step
12/14/2025 02:18:49 - INFO - __main__ -   Epoch: 2.76, Step: 3500, Batch: 32, Speed: N/A, Eval Loss: 0.1209, Accuracy: 0.9624, F1: 0.9581
12/14/2025 02:20:38 - INFO - __main__ -   Epoch: 2.80, Step: 3550, Train Loss: 0.0922, LR: 1.60e-05, Batch: 32, Speed: 2190.91ms/step
12/14/2025 02:22:28 - INFO - __main__ -   Epoch: 2.84, Step: 3600, Train Loss: 0.0861, LR: 1.59e-05, Batch: 32, Speed: 2194.38ms/step
12/14/2025 02:24:17 - INFO - __main__ -   Epoch: 2.88, Step: 3650, Train Loss: 0.0942, LR: 1.58e-05, Batch: 32, Speed: 2182.86ms/step
12/14/2025 02:26:07 - INFO - __main__ -   Epoch: 2.92, Step: 3700, Train Loss: 0.1135, LR: 1.57e-05, Batch: 32, Speed: 2198.47ms/step
12/14/2025 02:27:56 - INFO - __main__ -   Epoch: 2.96, Step: 3750, Train Loss: 0.0842, LR: 1.57e-05, Batch: 32, Speed: 2191.04ms/step
12/14/2025 02:29:46 - INFO - __main__ -   Epoch: 3.00, Step: 3800, Train Loss: 0.0973, LR: 1.56e-05, Batch: 32, Speed: 2189.89ms/step
12/14/2025 02:31:37 - INFO - __main__ -   Epoch: 3.04, Step: 3850, Train Loss: 0.0691, LR: 1.55e-05, Batch: 32, Speed: 2216.56ms/step
12/14/2025 02:33:26 - INFO - __main__ -   Epoch: 3.08, Step: 3900, Train Loss: 0.0665, LR: 1.54e-05, Batch: 32, Speed: 2182.75ms/step
12/14/2025 02:35:14 - INFO - __main__ -   Epoch: 3.12, Step: 3950, Train Loss: 0.0777, LR: 1.53e-05, Batch: 32, Speed: 2152.61ms/step
12/14/2025 02:37:03 - INFO - __main__ -   Epoch: 3.15, Step: 4000, Train Loss: 0.0830, LR: 1.52e-05, Batch: 32, Speed: 2183.61ms/step
12/14/2025 02:40:01 - INFO - __main__ -   Epoch: 3.15, Step: 4000, Batch: 32, Speed: N/A, Eval Loss: 0.1223, Accuracy: 0.9630, F1: 0.9584
12/14/2025 02:41:51 - INFO - __main__ -   Epoch: 3.19, Step: 4050, Train Loss: 0.0701, LR: 1.51e-05, Batch: 32, Speed: 2213.06ms/step
12/14/2025 02:43:41 - INFO - __main__ -   Epoch: 3.23, Step: 4100, Train Loss: 0.0724, LR: 1.50e-05, Batch: 32, Speed: 2201.57ms/step
12/14/2025 02:45:30 - INFO - __main__ -   Epoch: 3.27, Step: 4150, Train Loss: 0.0715, LR: 1.50e-05, Batch: 32, Speed: 2175.58ms/step
12/14/2025 02:47:20 - INFO - __main__ -   Epoch: 3.31, Step: 4200, Train Loss: 0.0708, LR: 1.49e-05, Batch: 32, Speed: 2195.94ms/step
12/14/2025 02:49:09 - INFO - __main__ -   Epoch: 3.35, Step: 4250, Train Loss: 0.0756, LR: 1.48e-05, Batch: 32, Speed: 2188.18ms/step
12/14/2025 02:50:59 - INFO - __main__ -   Epoch: 3.39, Step: 4300, Train Loss: 0.0755, LR: 1.47e-05, Batch: 32, Speed: 2197.21ms/step
12/14/2025 02:52:48 - INFO - __main__ -   Epoch: 3.43, Step: 4350, Train Loss: 0.0775, LR: 1.46e-05, Batch: 32, Speed: 2182.73ms/step
12/14/2025 02:54:38 - INFO - __main__ -   Epoch: 3.47, Step: 4400, Train Loss: 0.0694, LR: 1.45e-05, Batch: 32, Speed: 2197.91ms/step
12/14/2025 02:56:29 - INFO - __main__ -   Epoch: 3.51, Step: 4450, Train Loss: 0.0704, LR: 1.44e-05, Batch: 32, Speed: 2204.18ms/step
12/14/2025 02:58:19 - INFO - __main__ -   Epoch: 3.55, Step: 4500, Train Loss: 0.0671, LR: 1.43e-05, Batch: 32, Speed: 2204.14ms/step
12/14/2025 03:01:17 - INFO - __main__ -   Epoch: 3.55, Step: 4500, Batch: 32, Speed: N/A, Eval Loss: 0.1177, Accuracy: 0.9653, F1: 0.9615
12/14/2025 03:03:03 - INFO - __main__ -   Epoch: 3.59, Step: 4550, Train Loss: 0.0800, LR: 1.42e-05, Batch: 32, Speed: 2130.07ms/step
12/14/2025 03:04:53 - INFO - __main__ -   Epoch: 3.63, Step: 4600, Train Loss: 0.0695, LR: 1.42e-05, Batch: 32, Speed: 2195.72ms/step
12/14/2025 03:06:43 - INFO - __main__ -   Epoch: 3.67, Step: 4650, Train Loss: 0.0644, LR: 1.41e-05, Batch: 32, Speed: 2194.20ms/step
12/14/2025 03:08:31 - INFO - __main__ -   Epoch: 3.71, Step: 4700, Train Loss: 0.0769, LR: 1.40e-05, Batch: 32, Speed: 2168.57ms/step
12/14/2025 03:10:18 - INFO - __main__ -   Epoch: 3.75, Step: 4750, Train Loss: 0.0785, LR: 1.39e-05, Batch: 32, Speed: 2125.67ms/step
12/14/2025 03:12:07 - INFO - __main__ -   Epoch: 3.79, Step: 4800, Train Loss: 0.0667, LR: 1.38e-05, Batch: 32, Speed: 2197.83ms/step
12/14/2025 03:13:57 - INFO - __main__ -   Epoch: 3.82, Step: 4850, Train Loss: 0.0742, LR: 1.37e-05, Batch: 32, Speed: 2183.80ms/step
12/14/2025 03:15:46 - INFO - __main__ -   Epoch: 3.86, Step: 4900, Train Loss: 0.0795, LR: 1.36e-05, Batch: 32, Speed: 2188.50ms/step
12/14/2025 03:17:36 - INFO - __main__ -   Epoch: 3.90, Step: 4950, Train Loss: 0.0624, LR: 1.35e-05, Batch: 32, Speed: 2205.07ms/step
12/14/2025 03:19:26 - INFO - __main__ -   Epoch: 3.94, Step: 5000, Train Loss: 0.0687, LR: 1.35e-05, Batch: 32, Speed: 2185.22ms/step
12/14/2025 03:22:24 - INFO - __main__ -   Epoch: 3.94, Step: 5000, Batch: 32, Speed: N/A, Eval Loss: 0.1149, Accuracy: 0.9659, F1: 0.9624
12/14/2025 03:24:13 - INFO - __main__ -   Epoch: 3.98, Step: 5050, Train Loss: 0.0737, LR: 1.34e-05, Batch: 32, Speed: 2194.50ms/step
12/14/2025 03:26:04 - INFO - __main__ -   Epoch: 4.02, Step: 5100, Train Loss: 0.0554, LR: 1.33e-05, Batch: 32, Speed: 2210.33ms/step
12/14/2025 03:27:53 - INFO - __main__ -   Epoch: 4.06, Step: 5150, Train Loss: 0.0535, LR: 1.32e-05, Batch: 32, Speed: 2182.67ms/step
12/14/2025 03:29:43 - INFO - __main__ -   Epoch: 4.10, Step: 5200, Train Loss: 0.0619, LR: 1.31e-05, Batch: 32, Speed: 2199.00ms/step
12/14/2025 03:31:33 - INFO - __main__ -   Epoch: 4.14, Step: 5250, Train Loss: 0.0587, LR: 1.30e-05, Batch: 32, Speed: 2193.63ms/step
12/14/2025 03:33:22 - INFO - __main__ -   Epoch: 4.18, Step: 5300, Train Loss: 0.0646, LR: 1.29e-05, Batch: 32, Speed: 2194.67ms/step
12/14/2025 03:35:12 - INFO - __main__ -   Epoch: 4.22, Step: 5350, Train Loss: 0.0558, LR: 1.28e-05, Batch: 32, Speed: 2185.86ms/step
12/14/2025 03:37:01 - INFO - __main__ -   Epoch: 4.26, Step: 5400, Train Loss: 0.0514, LR: 1.28e-05, Batch: 32, Speed: 2189.47ms/step
12/14/2025 03:38:50 - INFO - __main__ -   Epoch: 4.30, Step: 5450, Train Loss: 0.0628, LR: 1.27e-05, Batch: 32, Speed: 2175.44ms/step
12/14/2025 03:40:39 - INFO - __main__ -   Epoch: 4.34, Step: 5500, Train Loss: 0.0529, LR: 1.26e-05, Batch: 32, Speed: 2184.05ms/step
12/14/2025 03:43:37 - INFO - __main__ -   Epoch: 4.34, Step: 5500, Batch: 32, Speed: N/A, Eval Loss: 0.1189, Accuracy: 0.9655, F1: 0.9624
12/14/2025 03:45:27 - INFO - __main__ -   Epoch: 4.38, Step: 5550, Train Loss: 0.0564, LR: 1.25e-05, Batch: 32, Speed: 2202.56ms/step
12/14/2025 03:47:16 - INFO - __main__ -   Epoch: 4.42, Step: 5600, Train Loss: 0.0573, LR: 1.24e-05, Batch: 32, Speed: 2180.22ms/step
12/14/2025 03:49:05 - INFO - __main__ -   Epoch: 4.46, Step: 5650, Train Loss: 0.0529, LR: 1.23e-05, Batch: 32, Speed: 2171.76ms/step
12/14/2025 03:50:53 - INFO - __main__ -   Epoch: 4.50, Step: 5700, Train Loss: 0.0612, LR: 1.22e-05, Batch: 32, Speed: 2162.34ms/step
12/14/2025 03:52:42 - INFO - __main__ -   Epoch: 4.53, Step: 5750, Train Loss: 0.0540, LR: 1.21e-05, Batch: 32, Speed: 2173.26ms/step
12/14/2025 03:54:32 - INFO - __main__ -   Epoch: 4.57, Step: 5800, Train Loss: 0.0527, LR: 1.21e-05, Batch: 32, Speed: 2196.66ms/step
12/14/2025 03:56:19 - INFO - __main__ -   Epoch: 4.61, Step: 5850, Train Loss: 0.0579, LR: 1.20e-05, Batch: 32, Speed: 2149.04ms/step
12/14/2025 03:58:08 - INFO - __main__ -   Epoch: 4.65, Step: 5900, Train Loss: 0.0594, LR: 1.19e-05, Batch: 32, Speed: 2186.52ms/step
12/14/2025 03:59:56 - INFO - __main__ -   Epoch: 4.69, Step: 5950, Train Loss: 0.0505, LR: 1.18e-05, Batch: 32, Speed: 2163.86ms/step
12/14/2025 04:01:45 - INFO - __main__ -   Epoch: 4.73, Step: 6000, Train Loss: 0.0611, LR: 1.17e-05, Batch: 32, Speed: 2162.95ms/step
12/14/2025 04:04:43 - INFO - __main__ -   Epoch: 4.73, Step: 6000, Batch: 32, Speed: N/A, Eval Loss: 0.1251, Accuracy: 0.9654, F1: 0.9633
12/14/2025 04:06:33 - INFO - __main__ -   Epoch: 4.77, Step: 6050, Train Loss: 0.0534, LR: 1.16e-05, Batch: 32, Speed: 2204.22ms/step
12/14/2025 04:08:21 - INFO - __main__ -   Epoch: 4.81, Step: 6100, Train Loss: 0.0565, LR: 1.15e-05, Batch: 32, Speed: 2167.11ms/step
12/14/2025 04:10:10 - INFO - __main__ -   Epoch: 4.85, Step: 6150, Train Loss: 0.0612, LR: 1.14e-05, Batch: 32, Speed: 2174.52ms/step
12/14/2025 04:11:59 - INFO - __main__ -   Epoch: 4.89, Step: 6200, Train Loss: 0.0487, LR: 1.14e-05, Batch: 32, Speed: 2186.49ms/step
12/14/2025 04:13:49 - INFO - __main__ -   Epoch: 4.93, Step: 6250, Train Loss: 0.0557, LR: 1.13e-05, Batch: 32, Speed: 2195.43ms/step
12/14/2025 04:15:38 - INFO - __main__ -   Epoch: 4.97, Step: 6300, Train Loss: 0.0504, LR: 1.12e-05, Batch: 32, Speed: 2185.76ms/step
12/14/2025 04:17:29 - INFO - __main__ -   Epoch: 5.01, Step: 6350, Train Loss: 0.0522, LR: 1.11e-05, Batch: 32, Speed: 2208.78ms/step
12/14/2025 04:19:19 - INFO - __main__ -   Epoch: 5.05, Step: 6400, Train Loss: 0.0450, LR: 1.10e-05, Batch: 32, Speed: 2211.60ms/step
12/14/2025 04:21:09 - INFO - __main__ -   Epoch: 5.09, Step: 6450, Train Loss: 0.0400, LR: 1.09e-05, Batch: 32, Speed: 2193.98ms/step
12/14/2025 04:22:58 - INFO - __main__ -   Epoch: 5.13, Step: 6500, Train Loss: 0.0336, LR: 1.08e-05, Batch: 32, Speed: 2179.97ms/step
12/14/2025 04:25:56 - INFO - __main__ -   Epoch: 5.13, Step: 6500, Batch: 32, Speed: N/A, Eval Loss: 0.1242, Accuracy: 0.9660, F1: 0.9630
12/14/2025 04:27:46 - INFO - __main__ -   Epoch: 5.17, Step: 6550, Train Loss: 0.0437, LR: 1.07e-05, Batch: 32, Speed: 2203.14ms/step
12/14/2025 04:29:36 - INFO - __main__ -   Epoch: 5.21, Step: 6600, Train Loss: 0.0443, LR: 1.07e-05, Batch: 32, Speed: 2193.59ms/step
12/14/2025 04:31:26 - INFO - __main__ -   Epoch: 5.24, Step: 6650, Train Loss: 0.0416, LR: 1.06e-05, Batch: 32, Speed: 2198.37ms/step
12/14/2025 04:33:15 - INFO - __main__ -   Epoch: 5.28, Step: 6700, Train Loss: 0.0450, LR: 1.05e-05, Batch: 32, Speed: 2185.60ms/step
12/14/2025 04:35:05 - INFO - __main__ -   Epoch: 5.32, Step: 6750, Train Loss: 0.0427, LR: 1.04e-05, Batch: 32, Speed: 2196.33ms/step
12/14/2025 04:36:52 - INFO - __main__ -   Epoch: 5.36, Step: 6800, Train Loss: 0.0414, LR: 1.03e-05, Batch: 32, Speed: 2142.95ms/step
12/14/2025 04:38:42 - INFO - __main__ -   Epoch: 5.40, Step: 6850, Train Loss: 0.0430, LR: 1.02e-05, Batch: 32, Speed: 2203.22ms/step
12/14/2025 04:40:32 - INFO - __main__ -   Epoch: 5.44, Step: 6900, Train Loss: 0.0338, LR: 1.01e-05, Batch: 32, Speed: 2198.67ms/step
12/14/2025 04:42:20 - INFO - __main__ -   Epoch: 5.48, Step: 6950, Train Loss: 0.0427, LR: 1.00e-05, Batch: 32, Speed: 2147.79ms/step
12/14/2025 04:44:09 - INFO - __main__ -   Epoch: 5.52, Step: 7000, Train Loss: 0.0449, LR: 9.96e-06, Batch: 32, Speed: 2175.85ms/step
12/14/2025 04:47:07 - INFO - __main__ -   Epoch: 5.52, Step: 7000, Batch: 32, Speed: N/A, Eval Loss: 0.1280, Accuracy: 0.9659, F1: 0.9629
12/14/2025 04:48:57 - INFO - __main__ -   Epoch: 5.56, Step: 7050, Train Loss: 0.0481, LR: 9.87e-06, Batch: 32, Speed: 2208.00ms/step
12/14/2025 04:50:48 - INFO - __main__ -   Epoch: 5.60, Step: 7100, Train Loss: 0.0459, LR: 9.78e-06, Batch: 32, Speed: 2212.87ms/step
12/14/2025 04:52:37 - INFO - __main__ -   Epoch: 5.64, Step: 7150, Train Loss: 0.0381, LR: 9.69e-06, Batch: 32, Speed: 2191.39ms/step
12/14/2025 04:54:26 - INFO - __main__ -   Epoch: 5.68, Step: 7200, Train Loss: 0.0368, LR: 9.61e-06, Batch: 32, Speed: 2170.10ms/step
12/14/2025 04:56:14 - INFO - __main__ -   Epoch: 5.72, Step: 7250, Train Loss: 0.0404, LR: 9.52e-06, Batch: 32, Speed: 2166.07ms/step
12/14/2025 04:58:02 - INFO - __main__ -   Epoch: 5.76, Step: 7300, Train Loss: 0.0422, LR: 9.43e-06, Batch: 32, Speed: 2168.43ms/step
12/14/2025 04:59:53 - INFO - __main__ -   Epoch: 5.80, Step: 7350, Train Loss: 0.0425, LR: 9.34e-06, Batch: 32, Speed: 2209.18ms/step
12/14/2025 05:01:41 - INFO - __main__ -   Epoch: 5.84, Step: 7400, Train Loss: 0.0414, LR: 9.26e-06, Batch: 32, Speed: 2152.86ms/step
12/14/2025 05:03:29 - INFO - __main__ -   Epoch: 5.88, Step: 7450, Train Loss: 0.0422, LR: 9.17e-06, Batch: 32, Speed: 2174.50ms/step
12/14/2025 05:05:19 - INFO - __main__ -   Epoch: 5.91, Step: 7500, Train Loss: 0.0441, LR: 9.08e-06, Batch: 32, Speed: 2197.02ms/step
12/14/2025 05:08:17 - INFO - __main__ -   Epoch: 5.91, Step: 7500, Batch: 32, Speed: N/A, Eval Loss: 0.1302, Accuracy: 0.9654, F1: 0.9625
12/14/2025 05:10:08 - INFO - __main__ -   Epoch: 5.95, Step: 7550, Train Loss: 0.0395, LR: 8.99e-06, Batch: 32, Speed: 2209.77ms/step
12/14/2025 05:11:58 - INFO - __main__ -   Epoch: 5.99, Step: 7600, Train Loss: 0.0347, LR: 8.90e-06, Batch: 32, Speed: 2195.85ms/step
12/14/2025 05:13:49 - INFO - __main__ -   Epoch: 6.03, Step: 7650, Train Loss: 0.0365, LR: 8.82e-06, Batch: 32, Speed: 2225.89ms/step
12/14/2025 05:15:37 - INFO - __main__ -   Epoch: 6.07, Step: 7700, Train Loss: 0.0285, LR: 8.73e-06, Batch: 32, Speed: 2158.85ms/step
12/14/2025 05:17:27 - INFO - __main__ -   Epoch: 6.11, Step: 7750, Train Loss: 0.0258, LR: 8.64e-06, Batch: 32, Speed: 2202.49ms/step
12/14/2025 05:19:16 - INFO - __main__ -   Epoch: 6.15, Step: 7800, Train Loss: 0.0292, LR: 8.55e-06, Batch: 32, Speed: 2178.14ms/step
12/14/2025 05:21:05 - INFO - __main__ -   Epoch: 6.19, Step: 7850, Train Loss: 0.0338, LR: 8.47e-06, Batch: 32, Speed: 2192.11ms/step
12/14/2025 05:22:55 - INFO - __main__ -   Epoch: 6.23, Step: 7900, Train Loss: 0.0317, LR: 8.38e-06, Batch: 32, Speed: 2187.91ms/step
12/14/2025 05:24:44 - INFO - __main__ -   Epoch: 6.27, Step: 7950, Train Loss: 0.0326, LR: 8.29e-06, Batch: 32, Speed: 2181.82ms/step
12/14/2025 05:26:34 - INFO - __main__ -   Epoch: 6.31, Step: 8000, Train Loss: 0.0307, LR: 8.20e-06, Batch: 32, Speed: 2192.88ms/step
12/14/2025 05:29:32 - INFO - __main__ -   Epoch: 6.31, Step: 8000, Batch: 32, Speed: N/A, Eval Loss: 0.1327, Accuracy: 0.9656, F1: 0.9630
12/14/2025 05:31:22 - INFO - __main__ -   Epoch: 6.35, Step: 8050, Train Loss: 0.0324, LR: 8.12e-06, Batch: 32, Speed: 2214.01ms/step
12/14/2025 05:33:12 - INFO - __main__ -   Epoch: 6.39, Step: 8100, Train Loss: 0.0308, LR: 8.03e-06, Batch: 32, Speed: 2187.10ms/step
12/14/2025 05:35:02 - INFO - __main__ -   Epoch: 6.43, Step: 8150, Train Loss: 0.0350, LR: 7.94e-06, Batch: 32, Speed: 2195.00ms/step
12/14/2025 05:36:52 - INFO - __main__ -   Epoch: 6.47, Step: 8200, Train Loss: 0.0339, LR: 7.85e-06, Batch: 32, Speed: 2202.01ms/step
12/14/2025 05:38:40 - INFO - __main__ -   Epoch: 6.51, Step: 8250, Train Loss: 0.0284, LR: 7.77e-06, Batch: 32, Speed: 2161.11ms/step
12/14/2025 05:40:30 - INFO - __main__ -   Epoch: 6.55, Step: 8300, Train Loss: 0.0327, LR: 7.68e-06, Batch: 32, Speed: 2196.68ms/step
12/14/2025 05:42:19 - INFO - __main__ -   Epoch: 6.59, Step: 8350, Train Loss: 0.0261, LR: 7.59e-06, Batch: 32, Speed: 2196.56ms/step
12/14/2025 05:44:09 - INFO - __main__ -   Epoch: 6.62, Step: 8400, Train Loss: 0.0341, LR: 7.50e-06, Batch: 32, Speed: 2188.99ms/step
12/14/2025 05:45:59 - INFO - __main__ -   Epoch: 6.66, Step: 8450, Train Loss: 0.0344, LR: 7.42e-06, Batch: 32, Speed: 2194.08ms/step
12/14/2025 05:47:48 - INFO - __main__ -   Epoch: 6.70, Step: 8500, Train Loss: 0.0319, LR: 7.33e-06, Batch: 32, Speed: 2190.29ms/step
12/14/2025 05:50:46 - INFO - __main__ -   Epoch: 6.70, Step: 8500, Batch: 32, Speed: N/A, Eval Loss: 0.1383, Accuracy: 0.9648, F1: 0.9623
12/14/2025 05:50:47 - INFO - __main__ -   Epoch: 6.70, Step: 8500, Batch: 32, Speed: N/A
12/14/2025 05:50:47 - INFO - __main__ -   Saving final model to output_ft_attention/final_model
