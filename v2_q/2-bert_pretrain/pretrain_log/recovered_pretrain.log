2025-12-08 19:37:02 - INFO - Epoch: 0.00, Step: 10, Train Loss: 9.3141, Learning Rate: 1.42e-07
2025-12-08 19:37:13 - INFO - Epoch: 0.01, Step: 20, Train Loss: 9.3102, Learning Rate: 3.00e-07
2025-12-08 19:37:24 - INFO - Epoch: 0.01, Step: 30, Train Loss: 9.2955, Learning Rate: 4.58e-07
2025-12-08 19:37:35 - INFO - Epoch: 0.01, Step: 40, Train Loss: 9.2795, Learning Rate: 6.15e-07
2025-12-08 19:37:46 - INFO - Epoch: 0.02, Step: 50, Train Loss: 9.2565, Learning Rate: 7.73e-07
2025-12-08 19:37:57 - INFO - Epoch: 0.02, Step: 60, Train Loss: 9.2301, Learning Rate: 9.31e-07
2025-12-08 19:38:08 - INFO - Epoch: 0.02, Step: 70, Train Loss: 9.1979, Learning Rate: 1.09e-06
2025-12-08 19:38:19 - INFO - Epoch: 0.03, Step: 80, Train Loss: 9.1606, Learning Rate: 1.25e-06
2025-12-08 19:38:30 - INFO - Epoch: 0.03, Step: 90, Train Loss: 9.1161, Learning Rate: 1.40e-06
2025-12-08 19:38:41 - INFO - Epoch: 0.03, Step: 100, Train Loss: 9.0689, Learning Rate: 1.56e-06
2025-12-08 19:38:52 - INFO - Epoch: 0.03, Step: 110, Train Loss: 9.0223, Learning Rate: 1.72e-06
2025-12-08 19:39:03 - INFO - Epoch: 0.04, Step: 120, Train Loss: 8.9759, Learning Rate: 1.88e-06
2025-12-08 19:39:15 - INFO - Epoch: 0.04, Step: 130, Train Loss: 8.9180, Learning Rate: 2.04e-06
2025-12-08 19:39:26 - INFO - Epoch: 0.04, Step: 140, Train Loss: 8.8747, Learning Rate: 2.19e-06
2025-12-08 19:39:37 - INFO - Epoch: 0.05, Step: 150, Train Loss: 8.8312, Learning Rate: 2.35e-06
2025-12-08 19:39:48 - INFO - Epoch: 0.05, Step: 160, Train Loss: 8.7883, Learning Rate: 2.51e-06
2025-12-08 19:39:59 - INFO - Epoch: 0.05, Step: 170, Train Loss: 8.7494, Learning Rate: 2.67e-06
2025-12-08 19:40:10 - INFO - Epoch: 0.06, Step: 180, Train Loss: 8.7056, Learning Rate: 2.82e-06
2025-12-08 19:40:21 - INFO - Epoch: 0.06, Step: 190, Train Loss: 8.6606, Learning Rate: 2.98e-06
2025-12-08 19:40:32 - INFO - Epoch: 0.06, Step: 200, Train Loss: 8.6303, Learning Rate: 3.14e-06
2025-12-08 19:40:43 - INFO - Epoch: 0.07, Step: 210, Train Loss: 8.5888, Learning Rate: 3.30e-06
2025-12-08 19:40:54 - INFO - Epoch: 0.07, Step: 220, Train Loss: 8.5556, Learning Rate: 3.46e-06
2025-12-08 19:41:05 - INFO - Epoch: 0.07, Step: 230, Train Loss: 8.5038, Learning Rate: 3.61e-06
2025-12-08 19:41:16 - INFO - Epoch: 0.08, Step: 240, Train Loss: 8.4705, Learning Rate: 3.77e-06
2025-12-08 19:41:27 - INFO - Epoch: 0.08, Step: 250, Train Loss: 8.4354, Learning Rate: 3.93e-06
2025-12-08 19:41:39 - INFO - Epoch: 0.08, Step: 260, Train Loss: 8.3943, Learning Rate: 4.09e-06
2025-12-08 19:41:50 - INFO - Epoch: 0.09, Step: 270, Train Loss: 8.3607, Learning Rate: 4.24e-06
2025-12-08 19:42:01 - INFO - Epoch: 0.09, Step: 280, Train Loss: 8.3112, Learning Rate: 4.40e-06
2025-12-08 19:42:12 - INFO - Epoch: 0.09, Step: 290, Train Loss: 8.2782, Learning Rate: 4.56e-06
2025-12-08 19:42:23 - INFO - Epoch: 0.09, Step: 300, Train Loss: 8.2367, Learning Rate: 4.72e-06
2025-12-08 19:42:34 - INFO - Epoch: 0.10, Step: 310, Train Loss: 8.1968, Learning Rate: 4.88e-06
2025-12-08 19:42:45 - INFO - Epoch: 0.10, Step: 320, Train Loss: 8.1584, Learning Rate: 5.03e-06
2025-12-08 19:42:56 - INFO - Epoch: 0.10, Step: 330, Train Loss: 8.1150, Learning Rate: 5.19e-06
2025-12-08 19:43:07 - INFO - Epoch: 0.11, Step: 340, Train Loss: 8.0763, Learning Rate: 5.35e-06
2025-12-08 19:43:18 - INFO - Epoch: 0.11, Step: 350, Train Loss: 8.0200, Learning Rate: 5.51e-06
2025-12-08 19:43:29 - INFO - Epoch: 0.11, Step: 360, Train Loss: 7.9893, Learning Rate: 5.66e-06
2025-12-08 19:43:40 - INFO - Epoch: 0.12, Step: 370, Train Loss: 7.9471, Learning Rate: 5.82e-06
2025-12-08 19:43:51 - INFO - Epoch: 0.12, Step: 380, Train Loss: 7.8913, Learning Rate: 5.98e-06
2025-12-08 19:44:02 - INFO - Epoch: 0.12, Step: 390, Train Loss: 7.8412, Learning Rate: 6.14e-06
2025-12-08 19:44:14 - INFO - Epoch: 0.13, Step: 400, Train Loss: 7.8082, Learning Rate: 6.30e-06
2025-12-08 19:44:25 - INFO - Epoch: 0.13, Step: 410, Train Loss: 7.7642, Learning Rate: 6.45e-06
2025-12-08 19:44:36 - INFO - Epoch: 0.13, Step: 420, Train Loss: 7.7121, Learning Rate: 6.61e-06
2025-12-08 19:44:47 - INFO - Epoch: 0.14, Step: 430, Train Loss: 7.6934, Learning Rate: 6.77e-06
2025-12-08 19:44:58 - INFO - Epoch: 0.14, Step: 440, Train Loss: 7.6253, Learning Rate: 6.93e-06
2025-12-08 19:45:09 - INFO - Epoch: 0.14, Step: 450, Train Loss: 7.5886, Learning Rate: 7.08e-06
2025-12-08 19:45:20 - INFO - Epoch: 0.15, Step: 460, Train Loss: 7.5496, Learning Rate: 7.24e-06
2025-12-08 19:45:31 - INFO - Epoch: 0.15, Step: 470, Train Loss: 7.4959, Learning Rate: 7.40e-06
2025-12-08 19:45:42 - INFO - Epoch: 0.15, Step: 480, Train Loss: 7.4557, Learning Rate: 7.56e-06
2025-12-08 19:45:53 - INFO - Epoch: 0.15, Step: 490, Train Loss: 7.4449, Learning Rate: 7.72e-06
2025-12-08 19:46:04 - INFO - Epoch: 0.16, Step: 500, Train Loss: 7.3890, Learning Rate: 7.87e-06
2025-12-08 19:46:15 - INFO - Epoch: 0.16, Step: 510, Train Loss: 7.3439, Learning Rate: 8.03e-06
2025-12-08 19:46:26 - INFO - Epoch: 0.16, Step: 520, Train Loss: 7.2995, Learning Rate: 8.19e-06
2025-12-08 19:46:38 - INFO - Epoch: 0.17, Step: 530, Train Loss: 7.2695, Learning Rate: 8.35e-06
2025-12-08 19:46:49 - INFO - Epoch: 0.17, Step: 540, Train Loss: 7.2449, Learning Rate: 8.50e-06
2025-12-08 19:47:00 - INFO - Epoch: 0.17, Step: 550, Train Loss: 7.2004, Learning Rate: 8.66e-06
2025-12-08 19:47:11 - INFO - Epoch: 0.18, Step: 560, Train Loss: 7.1553, Learning Rate: 8.82e-06
2025-12-08 19:47:22 - INFO - Epoch: 0.18, Step: 570, Train Loss: 7.1208, Learning Rate: 8.98e-06
2025-12-08 19:47:33 - INFO - Epoch: 0.18, Step: 580, Train Loss: 7.1027, Learning Rate: 9.14e-06
2025-12-08 19:47:44 - INFO - Epoch: 0.19, Step: 590, Train Loss: 7.0640, Learning Rate: 9.29e-06
2025-12-08 19:47:55 - INFO - Epoch: 0.19, Step: 600, Train Loss: 7.0424, Learning Rate: 9.45e-06
2025-12-08 19:48:06 - INFO - Epoch: 0.19, Step: 610, Train Loss: 7.0039, Learning Rate: 9.61e-06
2025-12-08 19:48:17 - INFO - Epoch: 0.20, Step: 620, Train Loss: 6.9809, Learning Rate: 9.77e-06
2025-12-08 19:48:28 - INFO - Epoch: 0.20, Step: 630, Train Loss: 6.9693, Learning Rate: 9.92e-06
2025-12-08 19:48:39 - INFO - Epoch: 0.20, Step: 640, Train Loss: 6.9289, Learning Rate: 1.01e-05
2025-12-08 19:48:50 - INFO - Epoch: 0.21, Step: 650, Train Loss: 6.8936, Learning Rate: 1.02e-05
2025-12-08 19:49:01 - INFO - Epoch: 0.21, Step: 660, Train Loss: 6.8799, Learning Rate: 1.04e-05
2025-12-08 19:49:13 - INFO - Epoch: 0.21, Step: 670, Train Loss: 6.8516, Learning Rate: 1.06e-05
2025-12-08 19:49:24 - INFO - Epoch: 0.21, Step: 680, Train Loss: 6.8450, Learning Rate: 1.07e-05
2025-12-08 19:49:35 - INFO - Epoch: 0.22, Step: 690, Train Loss: 6.8221, Learning Rate: 1.09e-05
2025-12-08 19:49:46 - INFO - Epoch: 0.22, Step: 700, Train Loss: 6.7942, Learning Rate: 1.10e-05
2025-12-08 19:49:57 - INFO - Epoch: 0.22, Step: 710, Train Loss: 6.7778, Learning Rate: 1.12e-05
2025-12-08 19:50:08 - INFO - Epoch: 0.23, Step: 720, Train Loss: 6.7643, Learning Rate: 1.13e-05
2025-12-08 19:50:19 - INFO - Epoch: 0.23, Step: 730, Train Loss: 6.7365, Learning Rate: 1.15e-05
2025-12-08 19:50:30 - INFO - Epoch: 0.23, Step: 740, Train Loss: 6.7226, Learning Rate: 1.17e-05
2025-12-08 19:50:41 - INFO - Epoch: 0.24, Step: 750, Train Loss: 6.7135, Learning Rate: 1.18e-05
2025-12-08 19:50:52 - INFO - Epoch: 0.24, Step: 760, Train Loss: 6.7061, Learning Rate: 1.20e-05
2025-12-08 19:51:03 - INFO - Epoch: 0.24, Step: 770, Train Loss: 6.6616, Learning Rate: 1.21e-05
2025-12-08 19:51:14 - INFO - Epoch: 0.25, Step: 780, Train Loss: 6.6646, Learning Rate: 1.23e-05
2025-12-08 19:51:25 - INFO - Epoch: 0.25, Step: 790, Train Loss: 6.6330, Learning Rate: 1.24e-05
2025-12-08 19:51:36 - INFO - Epoch: 0.25, Step: 800, Train Loss: 6.6176, Learning Rate: 1.26e-05
2025-12-08 19:51:48 - INFO - Epoch: 0.26, Step: 810, Train Loss: 6.5959, Learning Rate: 1.28e-05
2025-12-08 19:51:59 - INFO - Epoch: 0.26, Step: 820, Train Loss: 6.5754, Learning Rate: 1.29e-05
2025-12-08 19:52:10 - INFO - Epoch: 0.26, Step: 830, Train Loss: 6.5689, Learning Rate: 1.31e-05
2025-12-08 19:52:21 - INFO - Epoch: 0.27, Step: 840, Train Loss: 6.5600, Learning Rate: 1.32e-05
2025-12-08 19:52:32 - INFO - Epoch: 0.27, Step: 850, Train Loss: 6.5607, Learning Rate: 1.34e-05
2025-12-08 19:52:43 - INFO - Epoch: 0.27, Step: 860, Train Loss: 6.5365, Learning Rate: 1.36e-05
2025-12-08 19:52:54 - INFO - Epoch: 0.27, Step: 870, Train Loss: 6.5195, Learning Rate: 1.37e-05
2025-12-08 19:53:05 - INFO - Epoch: 0.28, Step: 880, Train Loss: 6.5144, Learning Rate: 1.39e-05
2025-12-08 19:53:16 - INFO - Epoch: 0.28, Step: 890, Train Loss: 6.4991, Learning Rate: 1.40e-05
2025-12-08 19:53:27 - INFO - Epoch: 0.28, Step: 900, Train Loss: 6.4694, Learning Rate: 1.42e-05
2025-12-08 19:53:38 - INFO - Epoch: 0.29, Step: 910, Train Loss: 6.4638, Learning Rate: 1.43e-05
2025-12-08 19:53:49 - INFO - Epoch: 0.29, Step: 920, Train Loss: 6.4487, Learning Rate: 1.45e-05
2025-12-08 19:54:00 - INFO - Epoch: 0.29, Step: 930, Train Loss: 6.4337, Learning Rate: 1.47e-05
2025-12-08 19:54:12 - INFO - Epoch: 0.30, Step: 940, Train Loss: 6.4393, Learning Rate: 1.48e-05
2025-12-08 19:54:23 - INFO - Epoch: 0.30, Step: 950, Train Loss: 6.4433, Learning Rate: 1.50e-05
2025-12-08 19:54:34 - INFO - Epoch: 0.30, Step: 960, Train Loss: 6.3979, Learning Rate: 1.51e-05
2025-12-08 19:54:45 - INFO - Epoch: 0.31, Step: 970, Train Loss: 6.4346, Learning Rate: 1.53e-05
2025-12-08 19:54:56 - INFO - Epoch: 0.31, Step: 980, Train Loss: 6.3813, Learning Rate: 1.54e-05
2025-12-08 19:55:07 - INFO - Epoch: 0.31, Step: 990, Train Loss: 6.3855, Learning Rate: 1.56e-05
2025-12-08 19:55:18 - INFO - Epoch: 0.32, Step: 1000, Train Loss: 6.3786, Learning Rate: 1.58e-05
2025-12-08 19:55:29 - INFO - Epoch: 0.32, Step: 1010, Train Loss: 6.3514, Learning Rate: 1.59e-05
2025-12-08 19:55:40 - INFO - Epoch: 0.32, Step: 1020, Train Loss: 6.3554, Learning Rate: 1.61e-05
2025-12-08 19:55:51 - INFO - Epoch: 0.33, Step: 1030, Train Loss: 6.3387, Learning Rate: 1.62e-05
2025-12-08 19:56:02 - INFO - Epoch: 0.33, Step: 1040, Train Loss: 6.3193, Learning Rate: 1.64e-05
2025-12-08 19:56:13 - INFO - Epoch: 0.33, Step: 1050, Train Loss: 6.3521, Learning Rate: 1.66e-05
2025-12-08 19:56:24 - INFO - Epoch: 0.33, Step: 1060, Train Loss: 6.3379, Learning Rate: 1.67e-05
2025-12-08 19:56:35 - INFO - Epoch: 0.34, Step: 1070, Train Loss: 6.3089, Learning Rate: 1.69e-05
2025-12-08 19:56:47 - INFO - Epoch: 0.34, Step: 1080, Train Loss: 6.3033, Learning Rate: 1.70e-05
2025-12-08 19:56:58 - INFO - Epoch: 0.34, Step: 1090, Train Loss: 6.2971, Learning Rate: 1.72e-05
2025-12-08 19:57:09 - INFO - Epoch: 0.35, Step: 1100, Train Loss: 6.3019, Learning Rate: 1.73e-05
2025-12-08 19:57:20 - INFO - Epoch: 0.35, Step: 1110, Train Loss: 6.2652, Learning Rate: 1.75e-05
2025-12-08 19:57:31 - INFO - Epoch: 0.35, Step: 1120, Train Loss: 6.2759, Learning Rate: 1.77e-05
2025-12-08 19:57:42 - INFO - Epoch: 0.36, Step: 1130, Train Loss: 6.2776, Learning Rate: 1.78e-05
2025-12-08 19:57:53 - INFO - Epoch: 0.36, Step: 1140, Train Loss: 6.2678, Learning Rate: 1.80e-05
2025-12-08 19:58:04 - INFO - Epoch: 0.36, Step: 1150, Train Loss: 6.2549, Learning Rate: 1.81e-05
2025-12-08 19:58:15 - INFO - Epoch: 0.37, Step: 1160, Train Loss: 6.2420, Learning Rate: 1.83e-05
2025-12-08 19:58:26 - INFO - Epoch: 0.37, Step: 1170, Train Loss: 6.2428, Learning Rate: 1.84e-05
2025-12-08 19:58:37 - INFO - Epoch: 0.37, Step: 1180, Train Loss: 6.2481, Learning Rate: 1.86e-05
2025-12-08 19:58:48 - INFO - Epoch: 0.38, Step: 1190, Train Loss: 6.2450, Learning Rate: 1.88e-05
2025-12-08 19:58:59 - INFO - Epoch: 0.38, Step: 1200, Train Loss: 6.2161, Learning Rate: 1.89e-05
2025-12-08 19:59:11 - INFO - Epoch: 0.38, Step: 1210, Train Loss: 6.2156, Learning Rate: 1.91e-05
2025-12-08 19:59:22 - INFO - Epoch: 0.38, Step: 1220, Train Loss: 6.1918, Learning Rate: 1.92e-05
2025-12-08 19:59:33 - INFO - Epoch: 0.39, Step: 1230, Train Loss: 6.2051, Learning Rate: 1.94e-05
2025-12-08 19:59:44 - INFO - Epoch: 0.39, Step: 1240, Train Loss: 6.2206, Learning Rate: 1.95e-05
2025-12-08 19:59:55 - INFO - Epoch: 0.39, Step: 1250, Train Loss: 6.1948, Learning Rate: 1.97e-05
2025-12-08 20:00:06 - INFO - Epoch: 0.40, Step: 1260, Train Loss: 6.1861, Learning Rate: 1.99e-05
2025-12-08 20:00:17 - INFO - Epoch: 0.40, Step: 1270, Train Loss: 6.1788, Learning Rate: 2.00e-05
2025-12-08 20:00:28 - INFO - Epoch: 0.40, Step: 1280, Train Loss: 6.1865, Learning Rate: 2.02e-05
2025-12-08 20:00:39 - INFO - Epoch: 0.41, Step: 1290, Train Loss: 6.1642, Learning Rate: 2.03e-05
2025-12-08 20:00:50 - INFO - Epoch: 0.41, Step: 1300, Train Loss: 6.1872, Learning Rate: 2.05e-05
2025-12-08 20:01:01 - INFO - Epoch: 0.41, Step: 1310, Train Loss: 6.1632, Learning Rate: 2.07e-05
2025-12-08 20:01:12 - INFO - Epoch: 0.42, Step: 1320, Train Loss: 6.1712, Learning Rate: 2.08e-05
2025-12-08 20:01:23 - INFO - Epoch: 0.42, Step: 1330, Train Loss: 6.1666, Learning Rate: 2.10e-05
2025-12-08 20:01:34 - INFO - Epoch: 0.42, Step: 1340, Train Loss: 6.1597, Learning Rate: 2.11e-05
2025-12-08 20:01:46 - INFO - Epoch: 0.43, Step: 1350, Train Loss: 6.1327, Learning Rate: 2.13e-05
2025-12-08 20:01:57 - INFO - Epoch: 0.43, Step: 1360, Train Loss: 6.1305, Learning Rate: 2.14e-05
2025-12-08 20:02:08 - INFO - Epoch: 0.43, Step: 1370, Train Loss: 6.1210, Learning Rate: 2.16e-05
2025-12-08 20:02:19 - INFO - Epoch: 0.44, Step: 1380, Train Loss: 6.0973, Learning Rate: 2.18e-05
2025-12-08 20:02:30 - INFO - Epoch: 0.44, Step: 1390, Train Loss: 6.0948, Learning Rate: 2.19e-05
2025-12-08 20:02:41 - INFO - Epoch: 0.44, Step: 1400, Train Loss: 6.0961, Learning Rate: 2.21e-05
2025-12-08 20:02:52 - INFO - Epoch: 0.44, Step: 1410, Train Loss: 6.0722, Learning Rate: 2.22e-05
2025-12-08 20:03:03 - INFO - Epoch: 0.45, Step: 1420, Train Loss: 6.1216, Learning Rate: 2.24e-05
2025-12-08 20:03:14 - INFO - Epoch: 0.45, Step: 1430, Train Loss: 6.0941, Learning Rate: 2.25e-05
2025-12-08 20:03:25 - INFO - Epoch: 0.45, Step: 1440, Train Loss: 6.0714, Learning Rate: 2.27e-05
2025-12-08 20:03:36 - INFO - Epoch: 0.46, Step: 1450, Train Loss: 6.0794, Learning Rate: 2.29e-05
2025-12-08 20:03:47 - INFO - Epoch: 0.46, Step: 1460, Train Loss: 6.0981, Learning Rate: 2.30e-05
2025-12-08 20:03:58 - INFO - Epoch: 0.46, Step: 1470, Train Loss: 6.1001, Learning Rate: 2.32e-05
2025-12-08 20:04:09 - INFO - Epoch: 0.47, Step: 1480, Train Loss: 6.0731, Learning Rate: 2.33e-05
2025-12-08 20:04:21 - INFO - Epoch: 0.47, Step: 1490, Train Loss: 6.0476, Learning Rate: 2.35e-05
2025-12-08 20:04:32 - INFO - Epoch: 0.47, Step: 1500, Train Loss: 6.0645, Learning Rate: 2.37e-05
2025-12-08 20:04:43 - INFO - Epoch: 0.48, Step: 1510, Train Loss: 6.0525, Learning Rate: 2.38e-05
2025-12-08 20:04:54 - INFO - Epoch: 0.48, Step: 1520, Train Loss: 6.0446, Learning Rate: 2.40e-05
2025-12-08 20:05:05 - INFO - Epoch: 0.48, Step: 1530, Train Loss: 6.0480, Learning Rate: 2.41e-05
2025-12-08 20:05:16 - INFO - Epoch: 0.49, Step: 1540, Train Loss: 6.0364, Learning Rate: 2.43e-05
2025-12-08 20:05:27 - INFO - Epoch: 0.49, Step: 1550, Train Loss: 6.0302, Learning Rate: 2.44e-05
2025-12-08 20:05:38 - INFO - Epoch: 0.49, Step: 1560, Train Loss: 6.0411, Learning Rate: 2.46e-05
2025-12-08 20:05:49 - INFO - Epoch: 0.50, Step: 1570, Train Loss: 6.0071, Learning Rate: 2.48e-05
2025-12-08 20:06:00 - INFO - Epoch: 0.50, Step: 1580, Train Loss: 6.0211, Learning Rate: 2.49e-05
2025-12-08 20:06:11 - INFO - Epoch: 0.50, Step: 1590, Train Loss: 6.0116, Learning Rate: 2.51e-05
2025-12-08 20:06:22 - INFO - Epoch: 0.50, Step: 1600, Train Loss: 6.0079, Learning Rate: 2.52e-05
2025-12-08 20:06:33 - INFO - Epoch: 0.51, Step: 1610, Train Loss: 6.0158, Learning Rate: 2.54e-05
2025-12-08 20:06:45 - INFO - Epoch: 0.51, Step: 1620, Train Loss: 6.0205, Learning Rate: 2.55e-05
2025-12-08 20:06:56 - INFO - Epoch: 0.51, Step: 1630, Train Loss: 6.0085, Learning Rate: 2.57e-05
2025-12-08 20:07:07 - INFO - Epoch: 0.52, Step: 1640, Train Loss: 6.0259, Learning Rate: 2.59e-05
2025-12-08 20:07:18 - INFO - Epoch: 0.52, Step: 1650, Train Loss: 5.9775, Learning Rate: 2.60e-05
2025-12-08 20:07:29 - INFO - Epoch: 0.52, Step: 1660, Train Loss: 5.9656, Learning Rate: 2.62e-05
2025-12-08 20:07:40 - INFO - Epoch: 0.53, Step: 1670, Train Loss: 5.9917, Learning Rate: 2.63e-05
2025-12-08 20:07:51 - INFO - Epoch: 0.53, Step: 1680, Train Loss: 6.0053, Learning Rate: 2.65e-05
2025-12-08 20:08:02 - INFO - Epoch: 0.53, Step: 1690, Train Loss: 5.9852, Learning Rate: 2.66e-05
2025-12-08 20:08:13 - INFO - Epoch: 0.54, Step: 1700, Train Loss: 5.9789, Learning Rate: 2.68e-05
2025-12-08 20:08:24 - INFO - Epoch: 0.54, Step: 1710, Train Loss: 5.9740, Learning Rate: 2.70e-05
2025-12-08 20:08:35 - INFO - Epoch: 0.54, Step: 1720, Train Loss: 5.9461, Learning Rate: 2.71e-05
2025-12-08 20:08:46 - INFO - Epoch: 0.55, Step: 1730, Train Loss: 5.9432, Learning Rate: 2.73e-05
2025-12-08 20:08:57 - INFO - Epoch: 0.55, Step: 1740, Train Loss: 5.9788, Learning Rate: 2.74e-05
2025-12-08 20:09:08 - INFO - Epoch: 0.55, Step: 1750, Train Loss: 5.9403, Learning Rate: 2.76e-05
2025-12-08 20:09:20 - INFO - Epoch: 0.56, Step: 1760, Train Loss: 5.9544, Learning Rate: 2.78e-05
2025-12-08 20:09:31 - INFO - Epoch: 0.56, Step: 1770, Train Loss: 5.9177, Learning Rate: 2.79e-05
2025-12-08 20:09:42 - INFO - Epoch: 0.56, Step: 1780, Train Loss: 5.9580, Learning Rate: 2.81e-05
2025-12-08 20:09:53 - INFO - Epoch: 0.56, Step: 1790, Train Loss: 5.9447, Learning Rate: 2.82e-05
2025-12-08 20:10:04 - INFO - Epoch: 0.57, Step: 1800, Train Loss: 5.9538, Learning Rate: 2.84e-05
2025-12-08 20:10:15 - INFO - Epoch: 0.57, Step: 1810, Train Loss: 5.9579, Learning Rate: 2.85e-05
2025-12-08 20:10:26 - INFO - Epoch: 0.57, Step: 1820, Train Loss: 5.9231, Learning Rate: 2.87e-05
2025-12-08 20:10:37 - INFO - Epoch: 0.58, Step: 1830, Train Loss: 5.9296, Learning Rate: 2.89e-05
2025-12-08 20:10:48 - INFO - Epoch: 0.58, Step: 1840, Train Loss: 5.9285, Learning Rate: 2.90e-05
2025-12-08 20:10:59 - INFO - Epoch: 0.58, Step: 1850, Train Loss: 5.9203, Learning Rate: 2.92e-05
2025-12-08 20:11:10 - INFO - Epoch: 0.59, Step: 1860, Train Loss: 5.9255, Learning Rate: 2.93e-05
2025-12-08 20:11:21 - INFO - Epoch: 0.59, Step: 1870, Train Loss: 5.9149, Learning Rate: 2.95e-05
2025-12-08 20:11:32 - INFO - Epoch: 0.59, Step: 1880, Train Loss: 5.9128, Learning Rate: 2.96e-05
2025-12-08 20:11:44 - INFO - Epoch: 0.60, Step: 1890, Train Loss: 5.9129, Learning Rate: 2.98e-05
2025-12-08 20:11:55 - INFO - Epoch: 0.60, Step: 1900, Train Loss: 5.9325, Learning Rate: 3.00e-05
2025-12-08 20:12:06 - INFO - Epoch: 0.60, Step: 1910, Train Loss: 5.9182, Learning Rate: 3.01e-05
2025-12-08 20:12:17 - INFO - Epoch: 0.61, Step: 1920, Train Loss: 5.9255, Learning Rate: 3.03e-05
2025-12-08 20:12:28 - INFO - Epoch: 0.61, Step: 1930, Train Loss: 5.9150, Learning Rate: 3.04e-05
2025-12-08 20:12:39 - INFO - Epoch: 0.61, Step: 1940, Train Loss: 5.8692, Learning Rate: 3.06e-05
2025-12-08 20:12:50 - INFO - Epoch: 0.62, Step: 1950, Train Loss: 5.8998, Learning Rate: 3.08e-05
2025-12-08 20:13:01 - INFO - Epoch: 0.62, Step: 1960, Train Loss: 5.8860, Learning Rate: 3.09e-05
2025-12-08 20:13:12 - INFO - Epoch: 0.62, Step: 1970, Train Loss: 5.8565, Learning Rate: 3.11e-05
2025-12-08 20:13:23 - INFO - Epoch: 0.62, Step: 1980, Train Loss: 5.8669, Learning Rate: 3.12e-05
2025-12-08 20:13:34 - INFO - Epoch: 0.63, Step: 1990, Train Loss: 5.8793, Learning Rate: 3.14e-05
2025-12-08 20:13:45 - INFO - Epoch: 0.63, Step: 2000, Train Loss: 5.8502, Learning Rate: 3.15e-05
2025-12-08 20:13:56 - INFO - Epoch: 0.63, Step: 2010, Train Loss: 5.8746, Learning Rate: 3.17e-05
2025-12-08 20:14:07 - INFO - Epoch: 0.64, Step: 2020, Train Loss: 5.8738, Learning Rate: 3.19e-05
2025-12-08 20:14:19 - INFO - Epoch: 0.64, Step: 2030, Train Loss: 5.8899, Learning Rate: 3.20e-05
2025-12-08 20:14:30 - INFO - Epoch: 0.64, Step: 2040, Train Loss: 5.8630, Learning Rate: 3.22e-05
2025-12-08 20:14:41 - INFO - Epoch: 0.65, Step: 2050, Train Loss: 5.8540, Learning Rate: 3.23e-05
2025-12-08 20:14:52 - INFO - Epoch: 0.65, Step: 2060, Train Loss: 5.8624, Learning Rate: 3.25e-05
2025-12-08 20:15:03 - INFO - Epoch: 0.65, Step: 2070, Train Loss: 5.8569, Learning Rate: 3.26e-05
2025-12-08 20:15:14 - INFO - Epoch: 0.66, Step: 2080, Train Loss: 5.8600, Learning Rate: 3.28e-05
2025-12-08 20:15:25 - INFO - Epoch: 0.66, Step: 2090, Train Loss: 5.8685, Learning Rate: 3.30e-05
2025-12-08 20:15:36 - INFO - Epoch: 0.66, Step: 2100, Train Loss: 5.8454, Learning Rate: 3.31e-05
2025-12-08 20:15:47 - INFO - Epoch: 0.67, Step: 2110, Train Loss: 5.8369, Learning Rate: 3.33e-05
2025-12-08 20:15:58 - INFO - Epoch: 0.67, Step: 2120, Train Loss: 5.8198, Learning Rate: 3.34e-05
2025-12-08 20:16:09 - INFO - Epoch: 0.67, Step: 2130, Train Loss: 5.8184, Learning Rate: 3.36e-05
2025-12-08 20:16:20 - INFO - Epoch: 0.68, Step: 2140, Train Loss: 5.8439, Learning Rate: 3.37e-05
2025-12-08 20:16:31 - INFO - Epoch: 0.68, Step: 2150, Train Loss: 5.8249, Learning Rate: 3.39e-05
2025-12-08 20:16:42 - INFO - Epoch: 0.68, Step: 2160, Train Loss: 5.8404, Learning Rate: 3.41e-05
2025-12-08 20:16:54 - INFO - Epoch: 0.68, Step: 2170, Train Loss: 5.8336, Learning Rate: 3.42e-05
2025-12-08 20:17:05 - INFO - Epoch: 0.69, Step: 2180, Train Loss: 5.8565, Learning Rate: 3.44e-05
2025-12-08 20:17:16 - INFO - Epoch: 0.69, Step: 2190, Train Loss: 5.8464, Learning Rate: 3.45e-05
2025-12-08 20:17:27 - INFO - Epoch: 0.69, Step: 2200, Train Loss: 5.8529, Learning Rate: 3.47e-05
2025-12-08 20:17:38 - INFO - Epoch: 0.70, Step: 2210, Train Loss: 5.8282, Learning Rate: 3.49e-05
2025-12-08 20:17:49 - INFO - Epoch: 0.70, Step: 2220, Train Loss: 5.8262, Learning Rate: 3.50e-05
2025-12-08 20:18:00 - INFO - Epoch: 0.70, Step: 2230, Train Loss: 5.8334, Learning Rate: 3.52e-05
2025-12-08 20:18:11 - INFO - Epoch: 0.71, Step: 2240, Train Loss: 5.8161, Learning Rate: 3.53e-05
2025-12-08 20:18:22 - INFO - Epoch: 0.71, Step: 2250, Train Loss: 5.8233, Learning Rate: 3.55e-05
2025-12-08 20:18:33 - INFO - Epoch: 0.71, Step: 2260, Train Loss: 5.8337, Learning Rate: 3.56e-05
2025-12-08 20:18:44 - INFO - Epoch: 0.72, Step: 2270, Train Loss: 5.8390, Learning Rate: 3.58e-05
2025-12-08 20:18:55 - INFO - Epoch: 0.72, Step: 2280, Train Loss: 5.8290, Learning Rate: 3.60e-05
2025-12-08 20:19:06 - INFO - Epoch: 0.72, Step: 2290, Train Loss: 5.8033, Learning Rate: 3.61e-05
2025-12-08 20:19:18 - INFO - Epoch: 0.73, Step: 2300, Train Loss: 5.8194, Learning Rate: 3.63e-05
2025-12-08 20:19:29 - INFO - Epoch: 0.73, Step: 2310, Train Loss: 5.7950, Learning Rate: 3.64e-05
2025-12-08 20:19:40 - INFO - Epoch: 0.73, Step: 2320, Train Loss: 5.7990, Learning Rate: 3.66e-05
2025-12-08 20:19:51 - INFO - Epoch: 0.74, Step: 2330, Train Loss: 5.7993, Learning Rate: 3.67e-05
2025-12-08 20:20:02 - INFO - Epoch: 0.74, Step: 2340, Train Loss: 5.8220, Learning Rate: 3.69e-05
2025-12-08 20:20:13 - INFO - Epoch: 0.74, Step: 2350, Train Loss: 5.7980, Learning Rate: 3.71e-05
2025-12-08 20:20:24 - INFO - Epoch: 0.74, Step: 2360, Train Loss: 5.7953, Learning Rate: 3.72e-05
2025-12-08 20:20:35 - INFO - Epoch: 0.75, Step: 2370, Train Loss: 5.7775, Learning Rate: 3.74e-05
2025-12-08 20:20:46 - INFO - Epoch: 0.75, Step: 2380, Train Loss: 5.7887, Learning Rate: 3.75e-05
2025-12-08 20:20:57 - INFO - Epoch: 0.75, Step: 2390, Train Loss: 5.7812, Learning Rate: 3.77e-05
2025-12-08 20:21:08 - INFO - Epoch: 0.76, Step: 2400, Train Loss: 5.7897, Learning Rate: 3.79e-05
2025-12-08 20:21:19 - INFO - Epoch: 0.76, Step: 2410, Train Loss: 5.7977, Learning Rate: 3.80e-05
2025-12-08 20:21:30 - INFO - Epoch: 0.76, Step: 2420, Train Loss: 5.7858, Learning Rate: 3.82e-05
2025-12-08 20:21:41 - INFO - Epoch: 0.77, Step: 2430, Train Loss: 5.7826, Learning Rate: 3.83e-05
2025-12-08 20:21:53 - INFO - Epoch: 0.77, Step: 2440, Train Loss: 5.8025, Learning Rate: 3.85e-05
2025-12-08 20:22:04 - INFO - Epoch: 0.77, Step: 2450, Train Loss: 5.7852, Learning Rate: 3.86e-05
2025-12-08 20:22:15 - INFO - Epoch: 0.78, Step: 2460, Train Loss: 5.7911, Learning Rate: 3.88e-05
2025-12-08 20:22:26 - INFO - Epoch: 0.78, Step: 2470, Train Loss: 5.7625, Learning Rate: 3.90e-05
2025-12-08 20:22:37 - INFO - Epoch: 0.78, Step: 2480, Train Loss: 5.7920, Learning Rate: 3.91e-05
2025-12-08 20:22:48 - INFO - Epoch: 0.79, Step: 2490, Train Loss: 5.7447, Learning Rate: 3.93e-05
2025-12-08 20:22:59 - INFO - Epoch: 0.79, Step: 2500, Train Loss: 5.7738, Learning Rate: 3.94e-05
2025-12-08 20:23:10 - INFO - Epoch: 0.79, Step: 2510, Train Loss: 5.7563, Learning Rate: 3.96e-05
2025-12-08 20:23:21 - INFO - Epoch: 0.80, Step: 2520, Train Loss: 5.7679, Learning Rate: 3.97e-05
2025-12-08 20:23:32 - INFO - Epoch: 0.80, Step: 2530, Train Loss: 5.7783, Learning Rate: 3.99e-05
2025-12-08 20:23:43 - INFO - Epoch: 0.80, Step: 2540, Train Loss: 5.7576, Learning Rate: 4.01e-05
2025-12-08 20:23:54 - INFO - Epoch: 0.80, Step: 2550, Train Loss: 5.7713, Learning Rate: 4.02e-05
2025-12-08 20:24:05 - INFO - Epoch: 0.81, Step: 2560, Train Loss: 5.7583, Learning Rate: 4.04e-05
2025-12-08 20:24:17 - INFO - Epoch: 0.81, Step: 2570, Train Loss: 5.7744, Learning Rate: 4.05e-05
2025-12-08 20:24:28 - INFO - Epoch: 0.81, Step: 2580, Train Loss: 5.7859, Learning Rate: 4.07e-05
2025-12-08 20:24:39 - INFO - Epoch: 0.82, Step: 2590, Train Loss: 5.7473, Learning Rate: 4.08e-05
2025-12-08 20:24:50 - INFO - Epoch: 0.82, Step: 2600, Train Loss: 5.7796, Learning Rate: 4.10e-05
2025-12-08 20:25:01 - INFO - Epoch: 0.82, Step: 2610, Train Loss: 5.7681, Learning Rate: 4.12e-05
2025-12-08 20:25:12 - INFO - Epoch: 0.83, Step: 2620, Train Loss: 5.7811, Learning Rate: 4.13e-05
2025-12-08 20:25:23 - INFO - Epoch: 0.83, Step: 2630, Train Loss: 5.7416, Learning Rate: 4.15e-05
2025-12-08 20:25:34 - INFO - Epoch: 0.83, Step: 2640, Train Loss: 5.7643, Learning Rate: 4.16e-05
2025-12-08 20:25:45 - INFO - Epoch: 0.84, Step: 2650, Train Loss: 5.7631, Learning Rate: 4.18e-05
2025-12-08 20:25:56 - INFO - Epoch: 0.84, Step: 2660, Train Loss: 5.7371, Learning Rate: 4.20e-05
2025-12-08 20:26:07 - INFO - Epoch: 0.84, Step: 2670, Train Loss: 5.7645, Learning Rate: 4.21e-05
2025-12-08 20:26:18 - INFO - Epoch: 0.85, Step: 2680, Train Loss: 5.7249, Learning Rate: 4.23e-05
2025-12-08 20:26:29 - INFO - Epoch: 0.85, Step: 2690, Train Loss: 5.7448, Learning Rate: 4.24e-05
2025-12-08 20:26:40 - INFO - Epoch: 0.85, Step: 2700, Train Loss: 5.7602, Learning Rate: 4.26e-05
2025-12-08 20:26:52 - INFO - Epoch: 0.86, Step: 2710, Train Loss: 5.7104, Learning Rate: 4.27e-05
2025-12-08 20:27:03 - INFO - Epoch: 0.86, Step: 2720, Train Loss: 5.7542, Learning Rate: 4.29e-05
2025-12-08 20:27:14 - INFO - Epoch: 0.86, Step: 2730, Train Loss: 5.7144, Learning Rate: 4.31e-05
2025-12-08 20:27:25 - INFO - Epoch: 0.86, Step: 2740, Train Loss: 5.7310, Learning Rate: 4.32e-05
2025-12-08 20:27:36 - INFO - Epoch: 0.87, Step: 2750, Train Loss: 5.7138, Learning Rate: 4.34e-05
2025-12-08 20:27:47 - INFO - Epoch: 0.87, Step: 2760, Train Loss: 5.7486, Learning Rate: 4.35e-05
2025-12-08 20:27:58 - INFO - Epoch: 0.87, Step: 2770, Train Loss: 5.7260, Learning Rate: 4.37e-05
2025-12-08 20:28:09 - INFO - Epoch: 0.88, Step: 2780, Train Loss: 5.6920, Learning Rate: 4.38e-05
2025-12-08 20:28:20 - INFO - Epoch: 0.88, Step: 2790, Train Loss: 5.7345, Learning Rate: 4.40e-05
2025-12-08 20:28:31 - INFO - Epoch: 0.88, Step: 2800, Train Loss: 5.7022, Learning Rate: 4.42e-05
2025-12-08 20:28:42 - INFO - Epoch: 0.89, Step: 2810, Train Loss: 5.7468, Learning Rate: 4.43e-05
2025-12-08 20:28:53 - INFO - Epoch: 0.89, Step: 2820, Train Loss: 5.6847, Learning Rate: 4.45e-05
2025-12-08 20:29:04 - INFO - Epoch: 0.89, Step: 2830, Train Loss: 5.7539, Learning Rate: 4.46e-05
2025-12-08 20:29:16 - INFO - Epoch: 0.90, Step: 2840, Train Loss: 5.7543, Learning Rate: 4.48e-05
2025-12-08 20:29:27 - INFO - Epoch: 0.90, Step: 2850, Train Loss: 5.7533, Learning Rate: 4.50e-05
2025-12-08 20:29:38 - INFO - Epoch: 0.90, Step: 2860, Train Loss: 5.6635, Learning Rate: 4.51e-05
2025-12-08 20:29:49 - INFO - Epoch: 0.91, Step: 2870, Train Loss: 5.7324, Learning Rate: 4.53e-05
2025-12-08 20:30:00 - INFO - Epoch: 0.91, Step: 2880, Train Loss: 5.6850, Learning Rate: 4.54e-05
2025-12-08 20:30:11 - INFO - Epoch: 0.91, Step: 2890, Train Loss: 5.7323, Learning Rate: 4.56e-05
2025-12-08 20:30:22 - INFO - Epoch: 0.92, Step: 2900, Train Loss: 5.7526, Learning Rate: 4.57e-05
2025-12-08 20:30:33 - INFO - Epoch: 0.92, Step: 2910, Train Loss: 5.7221, Learning Rate: 4.59e-05
2025-12-08 20:30:44 - INFO - Epoch: 0.92, Step: 2920, Train Loss: 5.6991, Learning Rate: 4.61e-05
2025-12-08 20:30:55 - INFO - Epoch: 0.92, Step: 2930, Train Loss: 5.6976, Learning Rate: 4.62e-05
2025-12-08 20:31:06 - INFO - Epoch: 0.93, Step: 2940, Train Loss: 5.7233, Learning Rate: 4.64e-05
2025-12-08 20:31:17 - INFO - Epoch: 0.93, Step: 2950, Train Loss: 5.6981, Learning Rate: 4.65e-05
2025-12-08 20:31:28 - INFO - Epoch: 0.93, Step: 2960, Train Loss: 5.7234, Learning Rate: 4.67e-05
2025-12-08 20:31:39 - INFO - Epoch: 0.94, Step: 2970, Train Loss: 5.7055, Learning Rate: 4.68e-05
2025-12-08 20:31:51 - INFO - Epoch: 0.94, Step: 2980, Train Loss: 5.7307, Learning Rate: 4.70e-05
2025-12-08 20:32:02 - INFO - Epoch: 0.94, Step: 2990, Train Loss: 5.7023, Learning Rate: 4.72e-05
2025-12-08 20:32:13 - INFO - Epoch: 0.95, Step: 3000, Train Loss: 5.7158, Learning Rate: 4.73e-05
2025-12-08 20:32:24 - INFO - Epoch: 0.95, Step: 3010, Train Loss: 5.7167, Learning Rate: 4.75e-05
2025-12-08 20:32:35 - INFO - Epoch: 0.95, Step: 3020, Train Loss: 5.7361, Learning Rate: 4.76e-05
2025-12-08 20:32:46 - INFO - Epoch: 0.96, Step: 3030, Train Loss: 5.7148, Learning Rate: 4.78e-05
2025-12-08 20:32:57 - INFO - Epoch: 0.96, Step: 3040, Train Loss: 5.7142, Learning Rate: 4.79e-05
2025-12-08 20:33:08 - INFO - Epoch: 0.96, Step: 3050, Train Loss: 5.6928, Learning Rate: 4.81e-05
2025-12-08 20:33:19 - INFO - Epoch: 0.97, Step: 3060, Train Loss: 5.7074, Learning Rate: 4.83e-05
2025-12-08 20:33:30 - INFO - Epoch: 0.97, Step: 3070, Train Loss: 5.6856, Learning Rate: 4.84e-05
2025-12-08 20:33:41 - INFO - Epoch: 0.97, Step: 3080, Train Loss: 5.6876, Learning Rate: 4.86e-05
2025-12-08 20:33:52 - INFO - Epoch: 0.98, Step: 3090, Train Loss: 5.7288, Learning Rate: 4.87e-05
2025-12-08 20:34:03 - INFO - Epoch: 0.98, Step: 3100, Train Loss: 5.7194, Learning Rate: 4.89e-05
2025-12-08 20:34:14 - INFO - Epoch: 0.98, Step: 3110, Train Loss: 5.7186, Learning Rate: 4.91e-05
2025-12-08 20:34:26 - INFO - Epoch: 0.98, Step: 3120, Train Loss: 5.6891, Learning Rate: 4.92e-05
2025-12-08 20:34:37 - INFO - Epoch: 0.99, Step: 3130, Train Loss: 5.7052, Learning Rate: 4.94e-05
2025-12-08 20:34:48 - INFO - Epoch: 0.99, Step: 3140, Train Loss: 5.7005, Learning Rate: 4.95e-05
2025-12-08 20:34:59 - INFO - Epoch: 0.99, Step: 3150, Train Loss: 5.6565, Learning Rate: 4.97e-05
2025-12-08 20:35:10 - INFO - Epoch: 1.00, Step: 3160, Train Loss: 5.7242, Learning Rate: 4.98e-05
2025-12-08 20:35:21 - INFO - Epoch: 1.00, Step: 3170, Train Loss: 5.6915, Learning Rate: 5.00e-05
2025-12-08 20:35:32 - INFO - Epoch: 1.00, Step: 3180, Train Loss: 5.6333, Learning Rate: 5.02e-05
2025-12-08 20:35:43 - INFO - Epoch: 1.01, Step: 3190, Train Loss: 5.6844, Learning Rate: 5.03e-05
2025-12-08 20:35:54 - INFO - Epoch: 1.01, Step: 3200, Train Loss: 5.6859, Learning Rate: 5.05e-05
2025-12-08 20:36:05 - INFO - Epoch: 1.01, Step: 3210, Train Loss: 5.6934, Learning Rate: 5.06e-05
2025-12-08 20:36:16 - INFO - Epoch: 1.02, Step: 3220, Train Loss: 5.6939, Learning Rate: 5.08e-05
2025-12-08 20:36:27 - INFO - Epoch: 1.02, Step: 3230, Train Loss: 5.6748, Learning Rate: 5.09e-05
2025-12-08 20:36:38 - INFO - Epoch: 1.02, Step: 3240, Train Loss: 5.6727, Learning Rate: 5.11e-05
2025-12-08 20:36:50 - INFO - Epoch: 1.03, Step: 3250, Train Loss: 5.6945, Learning Rate: 5.13e-05
2025-12-08 20:37:01 - INFO - Epoch: 1.03, Step: 3260, Train Loss: 5.6798, Learning Rate: 5.14e-05
2025-12-08 20:37:12 - INFO - Epoch: 1.03, Step: 3270, Train Loss: 5.6998, Learning Rate: 5.16e-05
2025-12-08 20:37:23 - INFO - Epoch: 1.04, Step: 3280, Train Loss: 5.6933, Learning Rate: 5.17e-05
2025-12-08 20:37:34 - INFO - Epoch: 1.04, Step: 3290, Train Loss: 5.6506, Learning Rate: 5.19e-05
2025-12-08 20:37:45 - INFO - Epoch: 1.04, Step: 3300, Train Loss: 5.6672, Learning Rate: 5.21e-05
2025-12-08 20:37:56 - INFO - Epoch: 1.04, Step: 3310, Train Loss: 5.6754, Learning Rate: 5.22e-05
2025-12-08 20:38:07 - INFO - Epoch: 1.05, Step: 3320, Train Loss: 5.7027, Learning Rate: 5.24e-05
2025-12-08 20:38:18 - INFO - Epoch: 1.05, Step: 3330, Train Loss: 5.6865, Learning Rate: 5.25e-05
2025-12-08 20:38:29 - INFO - Epoch: 1.05, Step: 3340, Train Loss: 5.6819, Learning Rate: 5.27e-05
2025-12-08 20:38:40 - INFO - Epoch: 1.06, Step: 3350, Train Loss: 5.6778, Learning Rate: 5.28e-05
2025-12-08 20:38:51 - INFO - Epoch: 1.06, Step: 3360, Train Loss: 5.6931, Learning Rate: 5.30e-05
2025-12-08 20:39:02 - INFO - Epoch: 1.06, Step: 3370, Train Loss: 5.6749, Learning Rate: 5.32e-05
2025-12-08 20:39:13 - INFO - Epoch: 1.07, Step: 3380, Train Loss: 5.6834, Learning Rate: 5.33e-05
2025-12-08 20:39:25 - INFO - Epoch: 1.07, Step: 3390, Train Loss: 5.6652, Learning Rate: 5.35e-05
2025-12-08 20:39:36 - INFO - Epoch: 1.07, Step: 3400, Train Loss: 5.6846, Learning Rate: 5.36e-05
2025-12-08 20:39:47 - INFO - Epoch: 1.08, Step: 3410, Train Loss: 5.6780, Learning Rate: 5.38e-05
2025-12-08 20:39:58 - INFO - Epoch: 1.08, Step: 3420, Train Loss: 5.6700, Learning Rate: 5.39e-05
2025-12-08 20:40:09 - INFO - Epoch: 1.08, Step: 3430, Train Loss: 5.6448, Learning Rate: 5.41e-05
2025-12-08 20:40:20 - INFO - Epoch: 1.09, Step: 3440, Train Loss: 5.6723, Learning Rate: 5.43e-05
2025-12-08 20:40:31 - INFO - Epoch: 1.09, Step: 3450, Train Loss: 5.6774, Learning Rate: 5.44e-05
2025-12-08 20:40:42 - INFO - Epoch: 1.09, Step: 3460, Train Loss: 5.6313, Learning Rate: 5.46e-05
2025-12-08 20:40:53 - INFO - Epoch: 1.09, Step: 3470, Train Loss: 5.6467, Learning Rate: 5.47e-05
2025-12-08 20:41:04 - INFO - Epoch: 1.10, Step: 3480, Train Loss: 5.6307, Learning Rate: 5.49e-05
2025-12-08 20:41:15 - INFO - Epoch: 1.10, Step: 3490, Train Loss: 5.6603, Learning Rate: 5.50e-05
2025-12-08 20:41:26 - INFO - Epoch: 1.10, Step: 3500, Train Loss: 5.6650, Learning Rate: 5.52e-05
2025-12-08 20:41:37 - INFO - Epoch: 1.11, Step: 3510, Train Loss: 5.6836, Learning Rate: 5.54e-05
2025-12-08 20:41:49 - INFO - Epoch: 1.11, Step: 3520, Train Loss: 5.6636, Learning Rate: 5.55e-05
2025-12-08 20:42:00 - INFO - Epoch: 1.11, Step: 3530, Train Loss: 5.6249, Learning Rate: 5.57e-05
2025-12-08 20:42:11 - INFO - Epoch: 1.12, Step: 3540, Train Loss: 5.6657, Learning Rate: 5.58e-05
2025-12-08 20:42:22 - INFO - Epoch: 1.12, Step: 3550, Train Loss: 5.6473, Learning Rate: 5.60e-05
2025-12-08 20:42:33 - INFO - Epoch: 1.12, Step: 3560, Train Loss: 5.6491, Learning Rate: 5.62e-05
2025-12-08 20:42:44 - INFO - Epoch: 1.13, Step: 3570, Train Loss: 5.6622, Learning Rate: 5.63e-05
2025-12-08 20:42:55 - INFO - Epoch: 1.13, Step: 3580, Train Loss: 5.6210, Learning Rate: 5.65e-05
2025-12-08 20:43:06 - INFO - Epoch: 1.13, Step: 3590, Train Loss: 5.6413, Learning Rate: 5.66e-05
2025-12-08 20:43:17 - INFO - Epoch: 1.14, Step: 3600, Train Loss: 5.6777, Learning Rate: 5.68e-05
2025-12-08 20:43:28 - INFO - Epoch: 1.14, Step: 3610, Train Loss: 5.6509, Learning Rate: 5.69e-05
2025-12-08 20:43:39 - INFO - Epoch: 1.14, Step: 3620, Train Loss: 5.6419, Learning Rate: 5.71e-05
2025-12-08 20:43:50 - INFO - Epoch: 1.15, Step: 3630, Train Loss: 5.6576, Learning Rate: 5.73e-05
2025-12-08 20:44:01 - INFO - Epoch: 1.15, Step: 3640, Train Loss: 5.6153, Learning Rate: 5.74e-05
2025-12-08 20:44:12 - INFO - Epoch: 1.15, Step: 3650, Train Loss: 5.6578, Learning Rate: 5.76e-05
2025-12-08 20:44:24 - INFO - Epoch: 1.15, Step: 3660, Train Loss: 5.6249, Learning Rate: 5.77e-05
2025-12-08 20:44:35 - INFO - Epoch: 1.16, Step: 3670, Train Loss: 5.6544, Learning Rate: 5.79e-05
2025-12-08 20:44:46 - INFO - Epoch: 1.16, Step: 3680, Train Loss: 5.6663, Learning Rate: 5.80e-05
2025-12-08 20:44:57 - INFO - Epoch: 1.16, Step: 3690, Train Loss: 5.6309, Learning Rate: 5.82e-05
2025-12-08 20:45:08 - INFO - Epoch: 1.17, Step: 3700, Train Loss: 5.6528, Learning Rate: 5.84e-05
2025-12-08 20:45:19 - INFO - Epoch: 1.17, Step: 3710, Train Loss: 5.6396, Learning Rate: 5.85e-05
2025-12-08 20:45:30 - INFO - Epoch: 1.17, Step: 3720, Train Loss: 5.6389, Learning Rate: 5.87e-05
2025-12-08 20:45:41 - INFO - Epoch: 1.18, Step: 3730, Train Loss: 5.6496, Learning Rate: 5.88e-05
2025-12-08 20:45:52 - INFO - Epoch: 1.18, Step: 3740, Train Loss: 5.6611, Learning Rate: 5.90e-05
2025-12-08 20:46:03 - INFO - Epoch: 1.18, Step: 3750, Train Loss: 5.6633, Learning Rate: 5.92e-05
2025-12-08 20:46:14 - INFO - Epoch: 1.19, Step: 3760, Train Loss: 5.6452, Learning Rate: 5.93e-05
2025-12-08 20:46:25 - INFO - Epoch: 1.19, Step: 3770, Train Loss: 5.6305, Learning Rate: 5.95e-05
2025-12-08 20:46:36 - INFO - Epoch: 1.19, Step: 3780, Train Loss: 5.6514, Learning Rate: 5.96e-05
2025-12-08 20:46:47 - INFO - Epoch: 1.20, Step: 3790, Train Loss: 5.6353, Learning Rate: 5.98e-05
2025-12-08 20:46:59 - INFO - Epoch: 1.20, Step: 3800, Train Loss: 5.6382, Learning Rate: 5.99e-05
2025-12-08 20:47:10 - INFO - Epoch: 1.20, Step: 3810, Train Loss: 5.6369, Learning Rate: 6.01e-05
2025-12-08 20:47:21 - INFO - Epoch: 1.21, Step: 3820, Train Loss: 5.6342, Learning Rate: 6.03e-05
2025-12-08 20:47:32 - INFO - Epoch: 1.21, Step: 3830, Train Loss: 5.6211, Learning Rate: 6.04e-05
2025-12-08 20:47:43 - INFO - Epoch: 1.21, Step: 3840, Train Loss: 5.6500, Learning Rate: 6.06e-05
2025-12-08 20:47:54 - INFO - Epoch: 1.21, Step: 3850, Train Loss: 5.6279, Learning Rate: 6.07e-05
2025-12-08 20:48:05 - INFO - Epoch: 1.22, Step: 3860, Train Loss: 5.5977, Learning Rate: 6.09e-05
2025-12-08 20:48:16 - INFO - Epoch: 1.22, Step: 3870, Train Loss: 5.6404, Learning Rate: 6.10e-05
2025-12-08 20:48:27 - INFO - Epoch: 1.22, Step: 3880, Train Loss: 5.6521, Learning Rate: 6.12e-05
2025-12-08 20:48:38 - INFO - Epoch: 1.23, Step: 3890, Train Loss: 5.6330, Learning Rate: 6.14e-05
2025-12-08 20:48:49 - INFO - Epoch: 1.23, Step: 3900, Train Loss: 5.6451, Learning Rate: 6.15e-05
2025-12-08 20:49:00 - INFO - Epoch: 1.23, Step: 3910, Train Loss: 5.6471, Learning Rate: 6.17e-05
2025-12-08 20:49:11 - INFO - Epoch: 1.24, Step: 3920, Train Loss: 5.5932, Learning Rate: 6.18e-05
2025-12-08 20:49:23 - INFO - Epoch: 1.24, Step: 3930, Train Loss: 5.6397, Learning Rate: 6.20e-05
2025-12-08 20:49:34 - INFO - Epoch: 1.24, Step: 3940, Train Loss: 5.6288, Learning Rate: 6.21e-05
2025-12-08 20:49:45 - INFO - Epoch: 1.25, Step: 3950, Train Loss: 5.6446, Learning Rate: 6.23e-05
2025-12-08 20:49:56 - INFO - Epoch: 1.25, Step: 3960, Train Loss: 5.6576, Learning Rate: 6.25e-05
2025-12-08 20:50:07 - INFO - Epoch: 1.25, Step: 3970, Train Loss: 5.6269, Learning Rate: 6.26e-05
2025-12-08 20:50:18 - INFO - Epoch: 1.26, Step: 3980, Train Loss: 5.6242, Learning Rate: 6.28e-05
2025-12-08 20:50:29 - INFO - Epoch: 1.26, Step: 3990, Train Loss: 5.5759, Learning Rate: 6.29e-05
2025-12-08 20:50:40 - INFO - Epoch: 1.26, Step: 4000, Train Loss: 5.6406, Learning Rate: 6.31e-05
2025-12-08 20:50:51 - INFO - Epoch: 1.27, Step: 4010, Train Loss: 5.6363, Learning Rate: 6.33e-05
2025-12-08 20:51:02 - INFO - Epoch: 1.27, Step: 4020, Train Loss: 5.6295, Learning Rate: 6.34e-05
2025-12-08 20:51:13 - INFO - Epoch: 1.27, Step: 4030, Train Loss: 5.5993, Learning Rate: 6.36e-05
2025-12-08 20:51:24 - INFO - Epoch: 1.27, Step: 4040, Train Loss: 5.6156, Learning Rate: 6.37e-05
2025-12-08 20:51:35 - INFO - Epoch: 1.28, Step: 4050, Train Loss: 5.6174, Learning Rate: 6.39e-05
2025-12-08 20:51:46 - INFO - Epoch: 1.28, Step: 4060, Train Loss: 5.6402, Learning Rate: 6.40e-05
2025-12-08 20:51:58 - INFO - Epoch: 1.28, Step: 4070, Train Loss: 5.6193, Learning Rate: 6.42e-05
2025-12-08 20:52:09 - INFO - Epoch: 1.29, Step: 4080, Train Loss: 5.6116, Learning Rate: 6.44e-05
2025-12-08 20:52:20 - INFO - Epoch: 1.29, Step: 4090, Train Loss: 5.6092, Learning Rate: 6.45e-05
2025-12-08 20:52:31 - INFO - Epoch: 1.29, Step: 4100, Train Loss: 5.5869, Learning Rate: 6.47e-05
2025-12-08 20:52:42 - INFO - Epoch: 1.30, Step: 4110, Train Loss: 5.6204, Learning Rate: 6.48e-05
2025-12-08 20:52:53 - INFO - Epoch: 1.30, Step: 4120, Train Loss: 5.6119, Learning Rate: 6.50e-05
2025-12-08 20:53:04 - INFO - Epoch: 1.30, Step: 4130, Train Loss: 5.5842, Learning Rate: 6.51e-05
2025-12-08 20:53:15 - INFO - Epoch: 1.31, Step: 4140, Train Loss: 5.6299, Learning Rate: 6.53e-05
2025-12-08 20:53:26 - INFO - Epoch: 1.31, Step: 4150, Train Loss: 5.5877, Learning Rate: 6.55e-05
2025-12-08 20:53:37 - INFO - Epoch: 1.31, Step: 4160, Train Loss: 5.5892, Learning Rate: 6.56e-05
2025-12-08 20:53:48 - INFO - Epoch: 1.32, Step: 4170, Train Loss: 5.6148, Learning Rate: 6.58e-05
2025-12-08 20:53:59 - INFO - Epoch: 1.32, Step: 4180, Train Loss: 5.6467, Learning Rate: 6.59e-05
2025-12-08 20:54:10 - INFO - Epoch: 1.32, Step: 4190, Train Loss: 5.6164, Learning Rate: 6.61e-05
2025-12-08 20:54:22 - INFO - Epoch: 1.33, Step: 4200, Train Loss: 5.6045, Learning Rate: 6.63e-05
2025-12-08 20:54:33 - INFO - Epoch: 1.33, Step: 4210, Train Loss: 5.6258, Learning Rate: 6.64e-05
2025-12-08 20:54:44 - INFO - Epoch: 1.33, Step: 4220, Train Loss: 5.6303, Learning Rate: 6.66e-05
2025-12-08 20:54:55 - INFO - Epoch: 1.33, Step: 4230, Train Loss: 5.6146, Learning Rate: 6.67e-05
2025-12-08 20:55:06 - INFO - Epoch: 1.34, Step: 4240, Train Loss: 5.6010, Learning Rate: 6.69e-05
2025-12-08 20:55:17 - INFO - Epoch: 1.34, Step: 4250, Train Loss: 5.5905, Learning Rate: 6.70e-05
2025-12-08 20:55:28 - INFO - Epoch: 1.34, Step: 4260, Train Loss: 5.6202, Learning Rate: 6.72e-05
2025-12-08 20:55:39 - INFO - Epoch: 1.35, Step: 4270, Train Loss: 5.6049, Learning Rate: 6.74e-05
2025-12-08 20:55:50 - INFO - Epoch: 1.35, Step: 4280, Train Loss: 5.6287, Learning Rate: 6.75e-05
2025-12-08 20:56:01 - INFO - Epoch: 1.35, Step: 4290, Train Loss: 5.6221, Learning Rate: 6.77e-05
2025-12-08 20:56:12 - INFO - Epoch: 1.36, Step: 4300, Train Loss: 5.6085, Learning Rate: 6.78e-05
2025-12-08 20:56:23 - INFO - Epoch: 1.36, Step: 4310, Train Loss: 5.5941, Learning Rate: 6.80e-05
2025-12-08 20:56:34 - INFO - Epoch: 1.36, Step: 4320, Train Loss: 5.6065, Learning Rate: 6.81e-05
2025-12-08 20:56:45 - INFO - Epoch: 1.37, Step: 4330, Train Loss: 5.6141, Learning Rate: 6.83e-05
2025-12-08 20:56:57 - INFO - Epoch: 1.37, Step: 4340, Train Loss: 5.6107, Learning Rate: 6.85e-05
2025-12-08 20:57:08 - INFO - Epoch: 1.37, Step: 4350, Train Loss: 5.6231, Learning Rate: 6.86e-05
2025-12-08 20:57:19 - INFO - Epoch: 1.38, Step: 4360, Train Loss: 5.5887, Learning Rate: 6.88e-05
2025-12-08 20:57:30 - INFO - Epoch: 1.38, Step: 4370, Train Loss: 5.5913, Learning Rate: 6.89e-05
2025-12-08 20:57:41 - INFO - Epoch: 1.38, Step: 4380, Train Loss: 5.6013, Learning Rate: 6.91e-05
2025-12-08 20:57:52 - INFO - Epoch: 1.39, Step: 4390, Train Loss: 5.5944, Learning Rate: 6.92e-05
2025-12-08 20:58:03 - INFO - Epoch: 1.39, Step: 4400, Train Loss: 5.5932, Learning Rate: 6.94e-05
2025-12-08 20:58:14 - INFO - Epoch: 1.39, Step: 4410, Train Loss: 5.5963, Learning Rate: 6.96e-05
2025-12-08 20:58:25 - INFO - Epoch: 1.39, Step: 4420, Train Loss: 5.6011, Learning Rate: 6.97e-05
2025-12-08 20:58:36 - INFO - Epoch: 1.40, Step: 4430, Train Loss: 5.5874, Learning Rate: 6.99e-05
2025-12-08 20:58:47 - INFO - Epoch: 1.40, Step: 4440, Train Loss: 5.5803, Learning Rate: 7.00e-05
2025-12-08 20:58:58 - INFO - Epoch: 1.40, Step: 4450, Train Loss: 5.5723, Learning Rate: 7.02e-05
2025-12-08 20:59:09 - INFO - Epoch: 1.41, Step: 4460, Train Loss: 5.5843, Learning Rate: 7.04e-05
2025-12-08 20:59:20 - INFO - Epoch: 1.41, Step: 4470, Train Loss: 5.5918, Learning Rate: 7.05e-05
2025-12-08 20:59:32 - INFO - Epoch: 1.41, Step: 4480, Train Loss: 5.5961, Learning Rate: 7.07e-05
2025-12-08 20:59:43 - INFO - Epoch: 1.42, Step: 4490, Train Loss: 5.5899, Learning Rate: 7.08e-05
2025-12-08 20:59:54 - INFO - Epoch: 1.42, Step: 4500, Train Loss: 5.5626, Learning Rate: 7.10e-05
2025-12-08 21:00:05 - INFO - Epoch: 1.42, Step: 4510, Train Loss: 5.5747, Learning Rate: 7.11e-05
2025-12-08 21:00:16 - INFO - Epoch: 1.43, Step: 4520, Train Loss: 5.5944, Learning Rate: 7.13e-05
2025-12-08 21:00:27 - INFO - Epoch: 1.43, Step: 4530, Train Loss: 5.5717, Learning Rate: 7.15e-05
2025-12-08 21:00:38 - INFO - Epoch: 1.43, Step: 4540, Train Loss: 5.5947, Learning Rate: 7.16e-05
2025-12-08 21:00:49 - INFO - Epoch: 1.44, Step: 4550, Train Loss: 5.5877, Learning Rate: 7.18e-05
2025-12-08 21:01:00 - INFO - Epoch: 1.44, Step: 4560, Train Loss: 5.5648, Learning Rate: 7.19e-05
2025-12-08 21:01:11 - INFO - Epoch: 1.44, Step: 4570, Train Loss: 5.5897, Learning Rate: 7.21e-05
2025-12-08 21:01:22 - INFO - Epoch: 1.45, Step: 4580, Train Loss: 5.5791, Learning Rate: 7.22e-05
2025-12-08 21:01:33 - INFO - Epoch: 1.45, Step: 4590, Train Loss: 5.5747, Learning Rate: 7.24e-05
2025-12-08 21:01:44 - INFO - Epoch: 1.45, Step: 4600, Train Loss: 5.5447, Learning Rate: 7.26e-05
2025-12-08 21:01:56 - INFO - Epoch: 1.45, Step: 4610, Train Loss: 5.5644, Learning Rate: 7.27e-05
2025-12-08 21:02:07 - INFO - Epoch: 1.46, Step: 4620, Train Loss: 5.5768, Learning Rate: 7.29e-05
2025-12-08 21:02:18 - INFO - Epoch: 1.46, Step: 4630, Train Loss: 5.6089, Learning Rate: 7.30e-05
2025-12-08 21:02:29 - INFO - Epoch: 1.46, Step: 4640, Train Loss: 5.5884, Learning Rate: 7.32e-05
2025-12-08 21:02:40 - INFO - Epoch: 1.47, Step: 4650, Train Loss: 5.5773, Learning Rate: 7.34e-05
2025-12-08 21:02:51 - INFO - Epoch: 1.47, Step: 4660, Train Loss: 5.5687, Learning Rate: 7.35e-05
2025-12-08 21:03:02 - INFO - Epoch: 1.47, Step: 4670, Train Loss: 5.5789, Learning Rate: 7.37e-05
2025-12-08 21:03:13 - INFO - Epoch: 1.48, Step: 4680, Train Loss: 5.5713, Learning Rate: 7.38e-05
2025-12-08 21:03:24 - INFO - Epoch: 1.48, Step: 4690, Train Loss: 5.5947, Learning Rate: 7.40e-05
2025-12-08 21:03:35 - INFO - Epoch: 1.48, Step: 4700, Train Loss: 5.5844, Learning Rate: 7.41e-05
2025-12-08 21:03:46 - INFO - Epoch: 1.49, Step: 4710, Train Loss: 5.5753, Learning Rate: 7.43e-05
2025-12-08 21:03:57 - INFO - Epoch: 1.49, Step: 4720, Train Loss: 5.5961, Learning Rate: 7.45e-05
2025-12-08 21:04:08 - INFO - Epoch: 1.49, Step: 4730, Train Loss: 5.5657, Learning Rate: 7.46e-05
2025-12-08 21:04:19 - INFO - Epoch: 1.50, Step: 4740, Train Loss: 5.6053, Learning Rate: 7.48e-05
2025-12-08 21:04:31 - INFO - Epoch: 1.50, Step: 4750, Train Loss: 5.5455, Learning Rate: 7.49e-05
2025-12-08 21:04:42 - INFO - Epoch: 1.50, Step: 4760, Train Loss: 5.5586, Learning Rate: 7.51e-05
2025-12-08 21:04:53 - INFO - Epoch: 1.51, Step: 4770, Train Loss: 5.5356, Learning Rate: 7.52e-05
2025-12-08 21:05:04 - INFO - Epoch: 1.51, Step: 4780, Train Loss: 5.5739, Learning Rate: 7.54e-05
2025-12-08 21:05:15 - INFO - Epoch: 1.51, Step: 4790, Train Loss: 5.5949, Learning Rate: 7.56e-05
2025-12-08 21:05:26 - INFO - Epoch: 1.51, Step: 4800, Train Loss: 5.5494, Learning Rate: 7.57e-05
2025-12-08 21:05:37 - INFO - Epoch: 1.52, Step: 4810, Train Loss: 5.5712, Learning Rate: 7.59e-05
2025-12-08 21:05:48 - INFO - Epoch: 1.52, Step: 4820, Train Loss: 5.5556, Learning Rate: 7.60e-05
2025-12-08 21:05:59 - INFO - Epoch: 1.52, Step: 4830, Train Loss: 5.5365, Learning Rate: 7.62e-05
2025-12-08 21:06:10 - INFO - Epoch: 1.53, Step: 4840, Train Loss: 5.5458, Learning Rate: 7.63e-05
2025-12-08 21:06:21 - INFO - Epoch: 1.53, Step: 4850, Train Loss: 5.5526, Learning Rate: 7.65e-05
2025-12-08 21:06:32 - INFO - Epoch: 1.53, Step: 4860, Train Loss: 5.5509, Learning Rate: 7.67e-05
2025-12-08 21:06:43 - INFO - Epoch: 1.54, Step: 4870, Train Loss: 5.5470, Learning Rate: 7.68e-05
2025-12-08 21:06:55 - INFO - Epoch: 1.54, Step: 4880, Train Loss: 5.5885, Learning Rate: 7.70e-05
2025-12-08 21:07:06 - INFO - Epoch: 1.54, Step: 4890, Train Loss: 5.5418, Learning Rate: 7.71e-05
2025-12-08 21:07:17 - INFO - Epoch: 1.55, Step: 4900, Train Loss: 5.5850, Learning Rate: 7.73e-05
2025-12-08 21:07:28 - INFO - Epoch: 1.55, Step: 4910, Train Loss: 5.5613, Learning Rate: 7.75e-05
2025-12-08 21:07:39 - INFO - Epoch: 1.55, Step: 4920, Train Loss: 5.5649, Learning Rate: 7.76e-05
2025-12-08 21:07:50 - INFO - Epoch: 1.56, Step: 4930, Train Loss: 5.5553, Learning Rate: 7.78e-05
2025-12-08 21:08:01 - INFO - Epoch: 1.56, Step: 4940, Train Loss: 5.5652, Learning Rate: 7.79e-05
2025-12-08 21:08:12 - INFO - Epoch: 1.56, Step: 4950, Train Loss: 5.5550, Learning Rate: 7.81e-05
2025-12-08 21:08:23 - INFO - Epoch: 1.57, Step: 4960, Train Loss: 5.5489, Learning Rate: 7.82e-05
2025-12-08 21:08:34 - INFO - Epoch: 1.57, Step: 4970, Train Loss: 5.5548, Learning Rate: 7.84e-05
2025-12-08 21:08:45 - INFO - Epoch: 1.57, Step: 4980, Train Loss: 5.5702, Learning Rate: 7.86e-05
2025-12-08 21:08:56 - INFO - Epoch: 1.57, Step: 4990, Train Loss: 5.5598, Learning Rate: 7.87e-05
2025-12-08 21:09:07 - INFO - Epoch: 1.58, Step: 5000, Train Loss: 5.5765, Learning Rate: 7.89e-05
2025-12-08 21:09:18 - INFO - Epoch: 1.58, Step: 5010, Train Loss: 5.5693, Learning Rate: 7.90e-05
2025-12-08 21:09:30 - INFO - Epoch: 1.58, Step: 5020, Train Loss: 5.5701, Learning Rate: 7.92e-05
2025-12-08 21:09:41 - INFO - Epoch: 1.59, Step: 5030, Train Loss: 5.5709, Learning Rate: 7.93e-05
2025-12-08 21:09:52 - INFO - Epoch: 1.59, Step: 5040, Train Loss: 5.5288, Learning Rate: 7.95e-05
2025-12-08 21:10:03 - INFO - Epoch: 1.59, Step: 5050, Train Loss: 5.5399, Learning Rate: 7.97e-05
2025-12-08 21:10:14 - INFO - Epoch: 1.60, Step: 5060, Train Loss: 5.5558, Learning Rate: 7.98e-05
2025-12-08 21:10:25 - INFO - Epoch: 1.60, Step: 5070, Train Loss: 5.5713, Learning Rate: 8.00e-05
2025-12-08 21:10:36 - INFO - Epoch: 1.60, Step: 5080, Train Loss: 5.5759, Learning Rate: 8.01e-05
2025-12-08 21:10:47 - INFO - Epoch: 1.61, Step: 5090, Train Loss: 5.5483, Learning Rate: 8.03e-05
2025-12-08 21:10:58 - INFO - Epoch: 1.61, Step: 5100, Train Loss: 5.5572, Learning Rate: 8.05e-05
2025-12-08 21:11:09 - INFO - Epoch: 1.61, Step: 5110, Train Loss: 5.5611, Learning Rate: 8.06e-05
2025-12-08 21:11:20 - INFO - Epoch: 1.62, Step: 5120, Train Loss: 5.5593, Learning Rate: 8.08e-05
2025-12-08 21:11:31 - INFO - Epoch: 1.62, Step: 5130, Train Loss: 5.5877, Learning Rate: 8.09e-05
2025-12-08 21:11:42 - INFO - Epoch: 1.62, Step: 5140, Train Loss: 5.5180, Learning Rate: 8.11e-05
2025-12-08 21:11:54 - INFO - Epoch: 1.63, Step: 5150, Train Loss: 5.5594, Learning Rate: 8.12e-05
2025-12-08 21:12:05 - INFO - Epoch: 1.63, Step: 5160, Train Loss: 5.5383, Learning Rate: 8.14e-05
2025-12-08 21:12:16 - INFO - Epoch: 1.63, Step: 5170, Train Loss: 5.5367, Learning Rate: 8.16e-05
2025-12-08 21:12:27 - INFO - Epoch: 1.63, Step: 5180, Train Loss: 5.5561, Learning Rate: 8.17e-05
2025-12-08 21:12:38 - INFO - Epoch: 1.64, Step: 5190, Train Loss: 5.5384, Learning Rate: 8.19e-05
2025-12-08 21:12:49 - INFO - Epoch: 1.64, Step: 5200, Train Loss: 5.5177, Learning Rate: 8.20e-05
2025-12-08 21:13:00 - INFO - Epoch: 1.64, Step: 5210, Train Loss: 5.5332, Learning Rate: 8.22e-05
2025-12-08 21:13:11 - INFO - Epoch: 1.65, Step: 5220, Train Loss: 5.5294, Learning Rate: 8.23e-05
2025-12-08 21:13:22 - INFO - Epoch: 1.65, Step: 5230, Train Loss: 5.5788, Learning Rate: 8.25e-05
2025-12-08 21:13:33 - INFO - Epoch: 1.65, Step: 5240, Train Loss: 5.4991, Learning Rate: 8.27e-05
2025-12-08 21:13:44 - INFO - Epoch: 1.66, Step: 5250, Train Loss: 5.5623, Learning Rate: 8.28e-05
2025-12-08 21:13:55 - INFO - Epoch: 1.66, Step: 5260, Train Loss: 5.5291, Learning Rate: 8.30e-05
2025-12-08 21:14:06 - INFO - Epoch: 1.66, Step: 5270, Train Loss: 5.5655, Learning Rate: 8.31e-05
2025-12-08 21:14:17 - INFO - Epoch: 1.67, Step: 5280, Train Loss: 5.5574, Learning Rate: 8.33e-05
2025-12-08 21:14:29 - INFO - Epoch: 1.67, Step: 5290, Train Loss: 5.5391, Learning Rate: 8.34e-05
2025-12-08 21:14:40 - INFO - Epoch: 1.67, Step: 5300, Train Loss: 5.5261, Learning Rate: 8.36e-05
2025-12-08 21:14:51 - INFO - Epoch: 1.68, Step: 5310, Train Loss: 5.5276, Learning Rate: 8.38e-05
2025-12-08 21:15:02 - INFO - Epoch: 1.68, Step: 5320, Train Loss: 5.5344, Learning Rate: 8.39e-05
2025-12-08 21:15:13 - INFO - Epoch: 1.68, Step: 5330, Train Loss: 5.5437, Learning Rate: 8.41e-05
2025-12-08 21:15:24 - INFO - Epoch: 1.69, Step: 5340, Train Loss: 5.5392, Learning Rate: 8.42e-05
2025-12-08 21:15:35 - INFO - Epoch: 1.69, Step: 5350, Train Loss: 5.5088, Learning Rate: 8.44e-05
2025-12-08 21:15:46 - INFO - Epoch: 1.69, Step: 5360, Train Loss: 5.5161, Learning Rate: 8.46e-05
2025-12-08 21:15:57 - INFO - Epoch: 1.69, Step: 5370, Train Loss: 5.5239, Learning Rate: 8.47e-05
2025-12-08 21:16:08 - INFO - Epoch: 1.70, Step: 5380, Train Loss: 5.5260, Learning Rate: 8.49e-05
2025-12-08 21:16:19 - INFO - Epoch: 1.70, Step: 5390, Train Loss: 5.5290, Learning Rate: 8.50e-05
2025-12-08 21:16:30 - INFO - Epoch: 1.70, Step: 5400, Train Loss: 5.5055, Learning Rate: 8.52e-05
2025-12-08 21:16:41 - INFO - Epoch: 1.71, Step: 5410, Train Loss: 5.4954, Learning Rate: 8.53e-05
2025-12-08 21:16:52 - INFO - Epoch: 1.71, Step: 5420, Train Loss: 5.4992, Learning Rate: 8.55e-05
2025-12-08 21:17:04 - INFO - Epoch: 1.71, Step: 5430, Train Loss: 5.4886, Learning Rate: 8.57e-05
2025-12-08 21:17:15 - INFO - Epoch: 1.72, Step: 5440, Train Loss: 5.5519, Learning Rate: 8.58e-05
2025-12-08 21:17:26 - INFO - Epoch: 1.72, Step: 5450, Train Loss: 5.5322, Learning Rate: 8.60e-05
2025-12-08 21:17:37 - INFO - Epoch: 1.72, Step: 5460, Train Loss: 5.5276, Learning Rate: 8.61e-05
2025-12-08 21:17:48 - INFO - Epoch: 1.73, Step: 5470, Train Loss: 5.5216, Learning Rate: 8.63e-05
2025-12-08 21:17:59 - INFO - Epoch: 1.73, Step: 5480, Train Loss: 5.5202, Learning Rate: 8.64e-05
2025-12-08 21:18:10 - INFO - Epoch: 1.73, Step: 5490, Train Loss: 5.4932, Learning Rate: 8.66e-05
2025-12-08 21:18:21 - INFO - Epoch: 1.74, Step: 5500, Train Loss: 5.5382, Learning Rate: 8.68e-05
2025-12-08 21:18:32 - INFO - Epoch: 1.74, Step: 5510, Train Loss: 5.5243, Learning Rate: 8.69e-05
2025-12-08 21:18:43 - INFO - Epoch: 1.74, Step: 5520, Train Loss: 5.5078, Learning Rate: 8.71e-05
2025-12-08 21:18:54 - INFO - Epoch: 1.75, Step: 5530, Train Loss: 5.5694, Learning Rate: 8.72e-05
2025-12-08 21:19:05 - INFO - Epoch: 1.75, Step: 5540, Train Loss: 5.5156, Learning Rate: 8.74e-05
2025-12-08 21:19:16 - INFO - Epoch: 1.75, Step: 5550, Train Loss: 5.5303, Learning Rate: 8.76e-05
2025-12-08 21:19:28 - INFO - Epoch: 1.75, Step: 5560, Train Loss: 5.5286, Learning Rate: 8.77e-05
2025-12-08 21:19:39 - INFO - Epoch: 1.76, Step: 5570, Train Loss: 5.5144, Learning Rate: 8.79e-05
2025-12-08 21:19:50 - INFO - Epoch: 1.76, Step: 5580, Train Loss: 5.4979, Learning Rate: 8.80e-05
2025-12-08 21:20:01 - INFO - Epoch: 1.76, Step: 5590, Train Loss: 5.4976, Learning Rate: 8.82e-05
2025-12-08 21:20:12 - INFO - Epoch: 1.77, Step: 5600, Train Loss: 5.5280, Learning Rate: 8.83e-05
2025-12-08 21:20:23 - INFO - Epoch: 1.77, Step: 5610, Train Loss: 5.5063, Learning Rate: 8.85e-05
2025-12-08 21:20:34 - INFO - Epoch: 1.77, Step: 5620, Train Loss: 5.5079, Learning Rate: 8.87e-05
2025-12-08 21:20:45 - INFO - Epoch: 1.78, Step: 5630, Train Loss: 5.4900, Learning Rate: 8.88e-05
2025-12-08 21:20:56 - INFO - Epoch: 1.78, Step: 5640, Train Loss: 5.5403, Learning Rate: 8.90e-05
2025-12-08 21:21:07 - INFO - Epoch: 1.78, Step: 5650, Train Loss: 5.5131, Learning Rate: 8.91e-05
2025-12-08 21:21:18 - INFO - Epoch: 1.79, Step: 5660, Train Loss: 5.4962, Learning Rate: 8.93e-05
2025-12-08 21:21:29 - INFO - Epoch: 1.79, Step: 5670, Train Loss: 5.5318, Learning Rate: 8.94e-05
2025-12-08 21:21:40 - INFO - Epoch: 1.79, Step: 5680, Train Loss: 5.5154, Learning Rate: 8.96e-05
2025-12-08 21:21:51 - INFO - Epoch: 1.80, Step: 5690, Train Loss: 5.5126, Learning Rate: 8.98e-05
2025-12-08 21:22:03 - INFO - Epoch: 1.80, Step: 5700, Train Loss: 5.4686, Learning Rate: 8.99e-05
2025-12-08 21:22:14 - INFO - Epoch: 1.80, Step: 5710, Train Loss: 5.5085, Learning Rate: 9.01e-05
2025-12-08 21:22:25 - INFO - Epoch: 1.80, Step: 5720, Train Loss: 5.5109, Learning Rate: 9.02e-05
2025-12-08 21:22:36 - INFO - Epoch: 1.81, Step: 5730, Train Loss: 5.5036, Learning Rate: 9.04e-05
2025-12-08 21:22:47 - INFO - Epoch: 1.81, Step: 5740, Train Loss: 5.5197, Learning Rate: 9.05e-05
2025-12-08 21:22:58 - INFO - Epoch: 1.81, Step: 5750, Train Loss: 5.4835, Learning Rate: 9.07e-05
2025-12-08 21:23:09 - INFO - Epoch: 1.82, Step: 5760, Train Loss: 5.4951, Learning Rate: 9.09e-05
2025-12-08 21:23:20 - INFO - Epoch: 1.82, Step: 5770, Train Loss: 5.5021, Learning Rate: 9.10e-05
2025-12-08 21:23:31 - INFO - Epoch: 1.82, Step: 5780, Train Loss: 5.4703, Learning Rate: 9.12e-05
2025-12-08 21:23:42 - INFO - Epoch: 1.83, Step: 5790, Train Loss: 5.5131, Learning Rate: 9.13e-05
2025-12-08 21:23:53 - INFO - Epoch: 1.83, Step: 5800, Train Loss: 5.4838, Learning Rate: 9.15e-05
2025-12-08 21:24:04 - INFO - Epoch: 1.83, Step: 5810, Train Loss: 5.4981, Learning Rate: 9.17e-05
2025-12-08 21:24:15 - INFO - Epoch: 1.84, Step: 5820, Train Loss: 5.4954, Learning Rate: 9.18e-05
2025-12-08 21:24:27 - INFO - Epoch: 1.84, Step: 5830, Train Loss: 5.4675, Learning Rate: 9.20e-05
2025-12-08 21:24:38 - INFO - Epoch: 1.84, Step: 5840, Train Loss: 5.4946, Learning Rate: 9.21e-05
2025-12-08 21:24:49 - INFO - Epoch: 1.85, Step: 5850, Train Loss: 5.4687, Learning Rate: 9.23e-05
2025-12-08 21:25:00 - INFO - Epoch: 1.85, Step: 5860, Train Loss: 5.5039, Learning Rate: 9.24e-05
2025-12-08 21:25:11 - INFO - Epoch: 1.85, Step: 5870, Train Loss: 5.4740, Learning Rate: 9.26e-05
2025-12-08 21:25:22 - INFO - Epoch: 1.86, Step: 5880, Train Loss: 5.4526, Learning Rate: 9.28e-05
2025-12-08 21:25:33 - INFO - Epoch: 1.86, Step: 5890, Train Loss: 5.4887, Learning Rate: 9.29e-05
2025-12-08 21:25:44 - INFO - Epoch: 1.86, Step: 5900, Train Loss: 5.4649, Learning Rate: 9.31e-05
2025-12-08 21:25:55 - INFO - Epoch: 1.86, Step: 5910, Train Loss: 5.4750, Learning Rate: 9.32e-05
2025-12-08 21:26:06 - INFO - Epoch: 1.87, Step: 5920, Train Loss: 5.4817, Learning Rate: 9.34e-05
2025-12-08 21:26:17 - INFO - Epoch: 1.87, Step: 5930, Train Loss: 5.5089, Learning Rate: 9.35e-05
2025-12-08 21:26:28 - INFO - Epoch: 1.87, Step: 5940, Train Loss: 5.4652, Learning Rate: 9.37e-05
2025-12-08 21:26:39 - INFO - Epoch: 1.88, Step: 5950, Train Loss: 5.4884, Learning Rate: 9.39e-05
2025-12-08 21:26:50 - INFO - Epoch: 1.88, Step: 5960, Train Loss: 5.4852, Learning Rate: 9.40e-05
2025-12-08 21:27:02 - INFO - Epoch: 1.88, Step: 5970, Train Loss: 5.4894, Learning Rate: 9.42e-05
2025-12-08 21:27:13 - INFO - Epoch: 1.89, Step: 5980, Train Loss: 5.4878, Learning Rate: 9.43e-05
2025-12-08 21:27:24 - INFO - Epoch: 1.89, Step: 5990, Train Loss: 5.4691, Learning Rate: 9.45e-05
2025-12-08 21:27:35 - INFO - Epoch: 1.89, Step: 6000, Train Loss: 5.4712, Learning Rate: 9.47e-05
2025-12-08 21:27:46 - INFO - Epoch: 1.90, Step: 6010, Train Loss: 5.4949, Learning Rate: 9.48e-05
2025-12-08 21:27:57 - INFO - Epoch: 1.90, Step: 6020, Train Loss: 5.4798, Learning Rate: 9.50e-05
2025-12-08 21:28:08 - INFO - Epoch: 1.90, Step: 6030, Train Loss: 5.4881, Learning Rate: 9.51e-05
2025-12-08 21:28:19 - INFO - Epoch: 1.91, Step: 6040, Train Loss: 5.4565, Learning Rate: 9.53e-05
2025-12-08 21:28:30 - INFO - Epoch: 1.91, Step: 6050, Train Loss: 5.4567, Learning Rate: 9.54e-05
2025-12-08 21:28:41 - INFO - Epoch: 1.91, Step: 6060, Train Loss: 5.5004, Learning Rate: 9.56e-05
2025-12-08 21:28:52 - INFO - Epoch: 1.92, Step: 6070, Train Loss: 5.4517, Learning Rate: 9.58e-05
2025-12-08 21:29:03 - INFO - Epoch: 1.92, Step: 6080, Train Loss: 5.4629, Learning Rate: 9.59e-05
2025-12-08 21:29:14 - INFO - Epoch: 1.92, Step: 6090, Train Loss: 5.4964, Learning Rate: 9.61e-05
2025-12-08 21:29:25 - INFO - Epoch: 1.92, Step: 6100, Train Loss: 5.4554, Learning Rate: 9.62e-05
2025-12-08 21:29:37 - INFO - Epoch: 1.93, Step: 6110, Train Loss: 5.4502, Learning Rate: 9.64e-05
2025-12-08 21:29:48 - INFO - Epoch: 1.93, Step: 6120, Train Loss: 5.4753, Learning Rate: 9.65e-05
2025-12-08 21:29:59 - INFO - Epoch: 1.93, Step: 6130, Train Loss: 5.4724, Learning Rate: 9.67e-05
2025-12-08 21:30:10 - INFO - Epoch: 1.94, Step: 6140, Train Loss: 5.4618, Learning Rate: 9.69e-05
2025-12-08 21:30:21 - INFO - Epoch: 1.94, Step: 6150, Train Loss: 5.4626, Learning Rate: 9.70e-05
2025-12-08 21:30:32 - INFO - Epoch: 1.94, Step: 6160, Train Loss: 5.4458, Learning Rate: 9.72e-05
2025-12-08 21:30:43 - INFO - Epoch: 1.95, Step: 6170, Train Loss: 5.4873, Learning Rate: 9.73e-05
2025-12-08 21:30:54 - INFO - Epoch: 1.95, Step: 6180, Train Loss: 5.4583, Learning Rate: 9.75e-05
2025-12-08 21:31:05 - INFO - Epoch: 1.95, Step: 6190, Train Loss: 5.4720, Learning Rate: 9.76e-05
2025-12-08 21:31:16 - INFO - Epoch: 1.96, Step: 6200, Train Loss: 5.4737, Learning Rate: 9.78e-05
2025-12-08 21:31:27 - INFO - Epoch: 1.96, Step: 6210, Train Loss: 5.4288, Learning Rate: 9.80e-05
2025-12-08 21:31:38 - INFO - Epoch: 1.96, Step: 6220, Train Loss: 5.4709, Learning Rate: 9.81e-05
2025-12-08 21:31:49 - INFO - Epoch: 1.97, Step: 6230, Train Loss: 5.4752, Learning Rate: 9.83e-05
2025-12-08 21:32:01 - INFO - Epoch: 1.97, Step: 6240, Train Loss: 5.4539, Learning Rate: 9.84e-05
2025-12-08 21:32:12 - INFO - Epoch: 1.97, Step: 6250, Train Loss: 5.4673, Learning Rate: 9.86e-05
2025-12-08 21:32:23 - INFO - Epoch: 1.98, Step: 6260, Train Loss: 5.4754, Learning Rate: 9.88e-05
2025-12-08 21:32:34 - INFO - Epoch: 1.98, Step: 6270, Train Loss: 5.4598, Learning Rate: 9.89e-05
2025-12-08 21:32:45 - INFO - Epoch: 1.98, Step: 6280, Train Loss: 5.4668, Learning Rate: 9.91e-05
2025-12-08 21:32:56 - INFO - Epoch: 1.98, Step: 6290, Train Loss: 5.4744, Learning Rate: 9.92e-05
2025-12-08 21:33:07 - INFO - Epoch: 1.99, Step: 6300, Train Loss: 5.4769, Learning Rate: 9.94e-05
2025-12-08 21:33:18 - INFO - Epoch: 1.99, Step: 6310, Train Loss: 5.4371, Learning Rate: 9.95e-05
2025-12-08 21:33:29 - INFO - Epoch: 1.99, Step: 6320, Train Loss: 5.4136, Learning Rate: 9.97e-05
2025-12-08 21:33:40 - INFO - Epoch: 2.00, Step: 6330, Train Loss: 5.4501, Learning Rate: 9.99e-05
2025-12-08 21:33:51 - INFO - Epoch: 2.00, Step: 6340, Train Loss: 5.4615, Learning Rate: 1.00e-04
2025-12-08 21:34:02 - INFO - Epoch: 2.00, Step: 6350, Train Loss: 5.4202, Learning Rate: 1.00e-04
2025-12-08 21:34:13 - INFO - Epoch: 2.01, Step: 6360, Train Loss: 5.4621, Learning Rate: 1.00e-04
2025-12-08 21:34:24 - INFO - Epoch: 2.01, Step: 6370, Train Loss: 5.4633, Learning Rate: 1.00e-04
2025-12-08 21:34:36 - INFO - Epoch: 2.01, Step: 6380, Train Loss: 5.4419, Learning Rate: 1.00e-04
2025-12-08 21:34:47 - INFO - Epoch: 2.02, Step: 6390, Train Loss: 5.4539, Learning Rate: 1.00e-04
2025-12-08 21:34:58 - INFO - Epoch: 2.02, Step: 6400, Train Loss: 5.4497, Learning Rate: 9.99e-05
2025-12-08 21:35:09 - INFO - Epoch: 2.02, Step: 6410, Train Loss: 5.4477, Learning Rate: 9.99e-05
2025-12-08 21:35:20 - INFO - Epoch: 2.03, Step: 6420, Train Loss: 5.4524, Learning Rate: 9.99e-05
2025-12-08 21:35:31 - INFO - Epoch: 2.03, Step: 6430, Train Loss: 5.4379, Learning Rate: 9.99e-05
2025-12-08 21:35:42 - INFO - Epoch: 2.03, Step: 6440, Train Loss: 5.4344, Learning Rate: 9.99e-05
2025-12-08 21:35:53 - INFO - Epoch: 2.04, Step: 6450, Train Loss: 5.4382, Learning Rate: 9.99e-05
2025-12-08 21:36:04 - INFO - Epoch: 2.04, Step: 6460, Train Loss: 5.4073, Learning Rate: 9.99e-05
2025-12-08 21:36:15 - INFO - Epoch: 2.04, Step: 6470, Train Loss: 5.4517, Learning Rate: 9.99e-05
2025-12-08 21:36:26 - INFO - Epoch: 2.04, Step: 6480, Train Loss: 5.4487, Learning Rate: 9.99e-05
2025-12-08 21:36:37 - INFO - Epoch: 2.05, Step: 6490, Train Loss: 5.4409, Learning Rate: 9.99e-05
2025-12-08 21:36:49 - INFO - Epoch: 2.05, Step: 6500, Train Loss: 5.4094, Learning Rate: 9.99e-05
2025-12-08 21:37:00 - INFO - Epoch: 2.05, Step: 6510, Train Loss: 5.4297, Learning Rate: 9.99e-05
2025-12-08 21:37:11 - INFO - Epoch: 2.06, Step: 6520, Train Loss: 5.4184, Learning Rate: 9.98e-05
2025-12-08 21:37:22 - INFO - Epoch: 2.06, Step: 6530, Train Loss: 5.4378, Learning Rate: 9.98e-05
2025-12-08 21:37:33 - INFO - Epoch: 2.06, Step: 6540, Train Loss: 5.4226, Learning Rate: 9.98e-05
2025-12-08 21:37:44 - INFO - Epoch: 2.07, Step: 6550, Train Loss: 5.3808, Learning Rate: 9.98e-05
2025-12-08 21:37:55 - INFO - Epoch: 2.07, Step: 6560, Train Loss: 5.4457, Learning Rate: 9.98e-05
2025-12-08 21:38:06 - INFO - Epoch: 2.07, Step: 6570, Train Loss: 5.4126, Learning Rate: 9.98e-05
2025-12-08 21:38:17 - INFO - Epoch: 2.08, Step: 6580, Train Loss: 5.4427, Learning Rate: 9.98e-05
2025-12-08 21:38:28 - INFO - Epoch: 2.08, Step: 6590, Train Loss: 5.4371, Learning Rate: 9.98e-05
2025-12-08 21:38:39 - INFO - Epoch: 2.08, Step: 6600, Train Loss: 5.4411, Learning Rate: 9.98e-05
2025-12-08 21:38:50 - INFO - Epoch: 2.09, Step: 6610, Train Loss: 5.4232, Learning Rate: 9.98e-05
2025-12-08 21:39:01 - INFO - Epoch: 2.09, Step: 6620, Train Loss: 5.4247, Learning Rate: 9.98e-05
2025-12-08 21:39:13 - INFO - Epoch: 2.09, Step: 6630, Train Loss: 5.3782, Learning Rate: 9.98e-05
2025-12-08 21:39:24 - INFO - Epoch: 2.10, Step: 6640, Train Loss: 5.3875, Learning Rate: 9.98e-05
2025-12-08 21:39:35 - INFO - Epoch: 2.10, Step: 6650, Train Loss: 5.3882, Learning Rate: 9.97e-05
2025-12-08 21:39:46 - INFO - Epoch: 2.10, Step: 6660, Train Loss: 5.3931, Learning Rate: 9.97e-05
2025-12-08 21:39:57 - INFO - Epoch: 2.10, Step: 6670, Train Loss: 5.4116, Learning Rate: 9.97e-05
2025-12-08 21:40:08 - INFO - Epoch: 2.11, Step: 6680, Train Loss: 5.3920, Learning Rate: 9.97e-05
2025-12-08 21:40:19 - INFO - Epoch: 2.11, Step: 6690, Train Loss: 5.4197, Learning Rate: 9.97e-05
2025-12-08 21:40:30 - INFO - Epoch: 2.11, Step: 6700, Train Loss: 5.3926, Learning Rate: 9.97e-05
2025-12-08 21:40:41 - INFO - Epoch: 2.12, Step: 6710, Train Loss: 5.4104, Learning Rate: 9.97e-05
2025-12-08 21:40:52 - INFO - Epoch: 2.12, Step: 6720, Train Loss: 5.3891, Learning Rate: 9.97e-05
2025-12-08 21:41:03 - INFO - Epoch: 2.12, Step: 6730, Train Loss: 5.4074, Learning Rate: 9.97e-05
2025-12-08 21:41:14 - INFO - Epoch: 2.13, Step: 6740, Train Loss: 5.3502, Learning Rate: 9.97e-05
2025-12-08 21:41:25 - INFO - Epoch: 2.13, Step: 6750, Train Loss: 5.3990, Learning Rate: 9.97e-05
2025-12-08 21:41:37 - INFO - Epoch: 2.13, Step: 6760, Train Loss: 5.3813, Learning Rate: 9.97e-05
2025-12-08 21:41:48 - INFO - Epoch: 2.14, Step: 6770, Train Loss: 5.4007, Learning Rate: 9.96e-05
2025-12-08 21:41:59 - INFO - Epoch: 2.14, Step: 6780, Train Loss: 5.3608, Learning Rate: 9.96e-05
2025-12-08 21:42:10 - INFO - Epoch: 2.14, Step: 6790, Train Loss: 5.3804, Learning Rate: 9.96e-05
2025-12-08 21:42:21 - INFO - Epoch: 2.15, Step: 6800, Train Loss: 5.3455, Learning Rate: 9.96e-05
2025-12-08 21:42:32 - INFO - Epoch: 2.15, Step: 6810, Train Loss: 5.3461, Learning Rate: 9.96e-05
2025-12-08 21:42:43 - INFO - Epoch: 2.15, Step: 6820, Train Loss: 5.4009, Learning Rate: 9.96e-05
2025-12-08 21:42:54 - INFO - Epoch: 2.16, Step: 6830, Train Loss: 5.3679, Learning Rate: 9.96e-05
2025-12-08 21:43:05 - INFO - Epoch: 2.16, Step: 6840, Train Loss: 5.3599, Learning Rate: 9.96e-05
2025-12-08 21:43:16 - INFO - Epoch: 2.16, Step: 6850, Train Loss: 5.3551, Learning Rate: 9.96e-05
2025-12-08 21:43:27 - INFO - Epoch: 2.16, Step: 6860, Train Loss: 5.3849, Learning Rate: 9.96e-05
2025-12-08 21:43:38 - INFO - Epoch: 2.17, Step: 6870, Train Loss: 5.3687, Learning Rate: 9.96e-05
2025-12-08 21:43:49 - INFO - Epoch: 2.17, Step: 6880, Train Loss: 5.3462, Learning Rate: 9.96e-05
2025-12-08 21:44:01 - INFO - Epoch: 2.17, Step: 6890, Train Loss: 5.3630, Learning Rate: 9.95e-05
2025-12-08 21:44:12 - INFO - Epoch: 2.18, Step: 6900, Train Loss: 5.3445, Learning Rate: 9.95e-05
2025-12-08 21:44:23 - INFO - Epoch: 2.18, Step: 6910, Train Loss: 5.3653, Learning Rate: 9.95e-05
2025-12-08 21:44:34 - INFO - Epoch: 2.18, Step: 6920, Train Loss: 5.3522, Learning Rate: 9.95e-05
2025-12-08 21:44:45 - INFO - Epoch: 2.19, Step: 6930, Train Loss: 5.3367, Learning Rate: 9.95e-05
2025-12-08 21:44:56 - INFO - Epoch: 2.19, Step: 6940, Train Loss: 5.3794, Learning Rate: 9.95e-05
2025-12-08 21:45:07 - INFO - Epoch: 2.19, Step: 6950, Train Loss: 5.3291, Learning Rate: 9.95e-05
2025-12-08 21:45:18 - INFO - Epoch: 2.20, Step: 6960, Train Loss: 5.3015, Learning Rate: 9.95e-05
2025-12-08 21:45:29 - INFO - Epoch: 2.20, Step: 6970, Train Loss: 5.3409, Learning Rate: 9.95e-05
2025-12-08 21:45:40 - INFO - Epoch: 2.20, Step: 6980, Train Loss: 5.3373, Learning Rate: 9.95e-05
2025-12-08 21:45:51 - INFO - Epoch: 2.21, Step: 6990, Train Loss: 5.3287, Learning Rate: 9.95e-05
2025-12-08 21:46:02 - INFO - Epoch: 2.21, Step: 7000, Train Loss: 5.3188, Learning Rate: 9.95e-05
2025-12-08 21:46:13 - INFO - Epoch: 2.21, Step: 7010, Train Loss: 5.3360, Learning Rate: 9.94e-05
2025-12-08 21:46:25 - INFO - Epoch: 2.22, Step: 7020, Train Loss: 5.3257, Learning Rate: 9.94e-05
2025-12-08 21:46:36 - INFO - Epoch: 2.22, Step: 7030, Train Loss: 5.3117, Learning Rate: 9.94e-05
2025-12-08 21:46:47 - INFO - Epoch: 2.22, Step: 7040, Train Loss: 5.2693, Learning Rate: 9.94e-05
2025-12-08 21:46:58 - INFO - Epoch: 2.22, Step: 7050, Train Loss: 5.2839, Learning Rate: 9.94e-05
2025-12-08 21:47:09 - INFO - Epoch: 2.23, Step: 7060, Train Loss: 5.3070, Learning Rate: 9.94e-05
2025-12-08 21:47:20 - INFO - Epoch: 2.23, Step: 7070, Train Loss: 5.3186, Learning Rate: 9.94e-05
2025-12-08 21:47:31 - INFO - Epoch: 2.23, Step: 7080, Train Loss: 5.2912, Learning Rate: 9.94e-05
2025-12-08 21:47:42 - INFO - Epoch: 2.24, Step: 7090, Train Loss: 5.3053, Learning Rate: 9.94e-05
2025-12-08 21:47:53 - INFO - Epoch: 2.24, Step: 7100, Train Loss: 5.2591, Learning Rate: 9.94e-05
2025-12-08 21:48:04 - INFO - Epoch: 2.24, Step: 7110, Train Loss: 5.2835, Learning Rate: 9.94e-05
2025-12-08 21:48:15 - INFO - Epoch: 2.25, Step: 7120, Train Loss: 5.2965, Learning Rate: 9.94e-05
2025-12-08 21:48:26 - INFO - Epoch: 2.25, Step: 7130, Train Loss: 5.2448, Learning Rate: 9.93e-05
2025-12-08 21:48:37 - INFO - Epoch: 2.25, Step: 7140, Train Loss: 5.2400, Learning Rate: 9.93e-05
2025-12-08 21:48:49 - INFO - Epoch: 2.26, Step: 7150, Train Loss: 5.2817, Learning Rate: 9.93e-05
2025-12-08 21:49:00 - INFO - Epoch: 2.26, Step: 7160, Train Loss: 5.2655, Learning Rate: 9.93e-05
2025-12-08 21:49:11 - INFO - Epoch: 2.26, Step: 7170, Train Loss: 5.2662, Learning Rate: 9.93e-05
2025-12-08 21:49:22 - INFO - Epoch: 2.27, Step: 7180, Train Loss: 5.2008, Learning Rate: 9.93e-05
2025-12-08 21:49:33 - INFO - Epoch: 2.27, Step: 7190, Train Loss: 5.2311, Learning Rate: 9.93e-05
2025-12-08 21:49:44 - INFO - Epoch: 2.27, Step: 7200, Train Loss: 5.2458, Learning Rate: 9.93e-05
2025-12-08 21:49:55 - INFO - Epoch: 2.28, Step: 7210, Train Loss: 5.1690, Learning Rate: 9.93e-05
2025-12-08 21:50:06 - INFO - Epoch: 2.28, Step: 7220, Train Loss: 5.2050, Learning Rate: 9.93e-05
2025-12-08 21:50:17 - INFO - Epoch: 2.28, Step: 7230, Train Loss: 5.2524, Learning Rate: 9.93e-05
2025-12-08 21:50:28 - INFO - Epoch: 2.28, Step: 7240, Train Loss: 5.2183, Learning Rate: 9.93e-05
2025-12-08 21:50:39 - INFO - Epoch: 2.29, Step: 7250, Train Loss: 5.1977, Learning Rate: 9.92e-05
2025-12-08 21:50:50 - INFO - Epoch: 2.29, Step: 7260, Train Loss: 5.1853, Learning Rate: 9.92e-05
2025-12-08 21:51:01 - INFO - Epoch: 2.29, Step: 7270, Train Loss: 5.1811, Learning Rate: 9.92e-05
2025-12-08 21:51:13 - INFO - Epoch: 2.30, Step: 7280, Train Loss: 5.1683, Learning Rate: 9.92e-05
2025-12-08 21:51:24 - INFO - Epoch: 2.30, Step: 7290, Train Loss: 5.1653, Learning Rate: 9.92e-05
2025-12-08 21:51:35 - INFO - Epoch: 2.30, Step: 7300, Train Loss: 5.1783, Learning Rate: 9.92e-05
2025-12-08 21:51:46 - INFO - Epoch: 2.31, Step: 7310, Train Loss: 5.1324, Learning Rate: 9.92e-05
2025-12-08 21:51:57 - INFO - Epoch: 2.31, Step: 7320, Train Loss: 5.1609, Learning Rate: 9.92e-05
2025-12-08 21:52:08 - INFO - Epoch: 2.31, Step: 7330, Train Loss: 5.1326, Learning Rate: 9.92e-05
2025-12-08 21:52:19 - INFO - Epoch: 2.32, Step: 7340, Train Loss: 5.1648, Learning Rate: 9.92e-05
2025-12-08 21:52:30 - INFO - Epoch: 2.32, Step: 7350, Train Loss: 5.1088, Learning Rate: 9.92e-05
2025-12-08 21:52:41 - INFO - Epoch: 2.32, Step: 7360, Train Loss: 5.1218, Learning Rate: 9.92e-05
2025-12-08 21:52:52 - INFO - Epoch: 2.33, Step: 7370, Train Loss: 5.1204, Learning Rate: 9.91e-05
2025-12-08 21:53:03 - INFO - Epoch: 2.33, Step: 7380, Train Loss: 5.1353, Learning Rate: 9.91e-05
2025-12-08 21:53:14 - INFO - Epoch: 2.33, Step: 7390, Train Loss: 5.0788, Learning Rate: 9.91e-05
2025-12-08 21:53:26 - INFO - Epoch: 2.34, Step: 7400, Train Loss: 5.0734, Learning Rate: 9.91e-05
2025-12-08 21:53:37 - INFO - Epoch: 2.34, Step: 7410, Train Loss: 5.0562, Learning Rate: 9.91e-05
2025-12-08 21:53:48 - INFO - Epoch: 2.34, Step: 7420, Train Loss: 5.0728, Learning Rate: 9.91e-05
2025-12-08 21:53:59 - INFO - Epoch: 2.34, Step: 7430, Train Loss: 5.0444, Learning Rate: 9.91e-05
2025-12-08 21:54:10 - INFO - Epoch: 2.35, Step: 7440, Train Loss: 5.0392, Learning Rate: 9.91e-05
2025-12-08 21:54:21 - INFO - Epoch: 2.35, Step: 7450, Train Loss: 5.0631, Learning Rate: 9.91e-05
2025-12-08 21:54:32 - INFO - Epoch: 2.35, Step: 7460, Train Loss: 5.0655, Learning Rate: 9.91e-05
2025-12-08 21:54:43 - INFO - Epoch: 2.36, Step: 7470, Train Loss: 5.0548, Learning Rate: 9.91e-05
2025-12-08 21:54:54 - INFO - Epoch: 2.36, Step: 7480, Train Loss: 5.0758, Learning Rate: 9.91e-05
2025-12-08 21:55:05 - INFO - Epoch: 2.36, Step: 7490, Train Loss: 5.0167, Learning Rate: 9.90e-05
2025-12-08 21:55:16 - INFO - Epoch: 2.37, Step: 7500, Train Loss: 5.0097, Learning Rate: 9.90e-05
2025-12-08 21:55:27 - INFO - Epoch: 2.37, Step: 7510, Train Loss: 4.9973, Learning Rate: 9.90e-05
2025-12-08 21:55:38 - INFO - Epoch: 2.37, Step: 7520, Train Loss: 4.9406, Learning Rate: 9.90e-05
2025-12-08 21:55:50 - INFO - Epoch: 2.38, Step: 7530, Train Loss: 4.9448, Learning Rate: 9.90e-05
2025-12-08 21:56:01 - INFO - Epoch: 2.38, Step: 7540, Train Loss: 4.9889, Learning Rate: 9.90e-05
2025-12-08 21:56:12 - INFO - Epoch: 2.38, Step: 7550, Train Loss: 4.9365, Learning Rate: 9.90e-05
2025-12-08 21:56:23 - INFO - Epoch: 2.39, Step: 7560, Train Loss: 4.9580, Learning Rate: 9.90e-05
2025-12-08 21:56:34 - INFO - Epoch: 2.39, Step: 7570, Train Loss: 4.9493, Learning Rate: 9.90e-05
2025-12-08 21:56:45 - INFO - Epoch: 2.39, Step: 7580, Train Loss: 4.9509, Learning Rate: 9.90e-05
2025-12-08 21:56:56 - INFO - Epoch: 2.40, Step: 7590, Train Loss: 4.9390, Learning Rate: 9.90e-05
2025-12-08 21:57:07 - INFO - Epoch: 2.40, Step: 7600, Train Loss: 4.9244, Learning Rate: 9.90e-05
2025-12-08 21:57:18 - INFO - Epoch: 2.40, Step: 7610, Train Loss: 4.9173, Learning Rate: 9.89e-05
2025-12-08 21:57:29 - INFO - Epoch: 2.40, Step: 7620, Train Loss: 4.8903, Learning Rate: 9.89e-05
2025-12-08 21:57:40 - INFO - Epoch: 2.41, Step: 7630, Train Loss: 4.9050, Learning Rate: 9.89e-05
2025-12-08 21:57:51 - INFO - Epoch: 2.41, Step: 7640, Train Loss: 4.9013, Learning Rate: 9.89e-05
2025-12-08 21:58:02 - INFO - Epoch: 2.41, Step: 7650, Train Loss: 4.8400, Learning Rate: 9.89e-05
2025-12-08 21:58:14 - INFO - Epoch: 2.42, Step: 7660, Train Loss: 4.8968, Learning Rate: 9.89e-05
2025-12-08 21:58:25 - INFO - Epoch: 2.42, Step: 7670, Train Loss: 4.8647, Learning Rate: 9.89e-05
2025-12-08 21:58:36 - INFO - Epoch: 2.42, Step: 7680, Train Loss: 4.8881, Learning Rate: 9.89e-05
2025-12-08 21:58:47 - INFO - Epoch: 2.43, Step: 7690, Train Loss: 4.8481, Learning Rate: 9.89e-05
2025-12-08 21:58:58 - INFO - Epoch: 2.43, Step: 7700, Train Loss: 4.8550, Learning Rate: 9.89e-05
2025-12-08 21:59:09 - INFO - Epoch: 2.43, Step: 7710, Train Loss: 4.8634, Learning Rate: 9.89e-05
2025-12-08 21:59:20 - INFO - Epoch: 2.44, Step: 7720, Train Loss: 4.8768, Learning Rate: 9.89e-05
2025-12-08 21:59:31 - INFO - Epoch: 2.44, Step: 7730, Train Loss: 4.8549, Learning Rate: 9.88e-05
2025-12-08 21:59:42 - INFO - Epoch: 2.44, Step: 7740, Train Loss: 4.8280, Learning Rate: 9.88e-05
2025-12-08 21:59:53 - INFO - Epoch: 2.45, Step: 7750, Train Loss: 4.8082, Learning Rate: 9.88e-05
2025-12-08 22:00:04 - INFO - Epoch: 2.45, Step: 7760, Train Loss: 4.7952, Learning Rate: 9.88e-05
2025-12-08 22:00:15 - INFO - Epoch: 2.45, Step: 7770, Train Loss: 4.7961, Learning Rate: 9.88e-05
2025-12-08 22:00:26 - INFO - Epoch: 2.46, Step: 7780, Train Loss: 4.7784, Learning Rate: 9.88e-05
2025-12-08 22:00:38 - INFO - Epoch: 2.46, Step: 7790, Train Loss: 4.7762, Learning Rate: 9.88e-05
2025-12-08 22:00:49 - INFO - Epoch: 2.46, Step: 7800, Train Loss: 4.7842, Learning Rate: 9.88e-05
2025-12-08 22:01:00 - INFO - Epoch: 2.46, Step: 7810, Train Loss: 4.7796, Learning Rate: 9.88e-05
2025-12-08 22:01:11 - INFO - Epoch: 2.47, Step: 7820, Train Loss: 4.7340, Learning Rate: 9.88e-05
2025-12-08 22:01:22 - INFO - Epoch: 2.47, Step: 7830, Train Loss: 4.7498, Learning Rate: 9.88e-05
2025-12-08 22:01:33 - INFO - Epoch: 2.47, Step: 7840, Train Loss: 4.7378, Learning Rate: 9.88e-05
2025-12-08 22:01:44 - INFO - Epoch: 2.48, Step: 7850, Train Loss: 4.7601, Learning Rate: 9.87e-05
2025-12-08 22:01:55 - INFO - Epoch: 2.48, Step: 7860, Train Loss: 4.7394, Learning Rate: 9.87e-05
2025-12-08 22:02:06 - INFO - Epoch: 2.48, Step: 7870, Train Loss: 4.6983, Learning Rate: 9.87e-05
2025-12-08 22:02:17 - INFO - Epoch: 2.49, Step: 7880, Train Loss: 4.7330, Learning Rate: 9.87e-05
2025-12-08 22:02:28 - INFO - Epoch: 2.49, Step: 7890, Train Loss: 4.6975, Learning Rate: 9.87e-05
2025-12-08 22:02:39 - INFO - Epoch: 2.49, Step: 7900, Train Loss: 4.7155, Learning Rate: 9.87e-05
2025-12-08 22:02:50 - INFO - Epoch: 2.50, Step: 7910, Train Loss: 4.7071, Learning Rate: 9.87e-05
2025-12-08 22:03:02 - INFO - Epoch: 2.50, Step: 7920, Train Loss: 4.6885, Learning Rate: 9.87e-05
2025-12-08 22:03:13 - INFO - Epoch: 2.50, Step: 7930, Train Loss: 4.6934, Learning Rate: 9.87e-05
2025-12-08 22:03:24 - INFO - Epoch: 2.51, Step: 7940, Train Loss: 4.6908, Learning Rate: 9.87e-05
2025-12-08 22:03:35 - INFO - Epoch: 2.51, Step: 7950, Train Loss: 4.6315, Learning Rate: 9.87e-05
2025-12-08 22:03:46 - INFO - Epoch: 2.51, Step: 7960, Train Loss: 4.6101, Learning Rate: 9.87e-05
2025-12-08 22:03:57 - INFO - Epoch: 2.51, Step: 7970, Train Loss: 4.5810, Learning Rate: 9.86e-05
2025-12-08 22:04:08 - INFO - Epoch: 2.52, Step: 7980, Train Loss: 4.6496, Learning Rate: 9.86e-05
2025-12-08 22:04:19 - INFO - Epoch: 2.52, Step: 7990, Train Loss: 4.6256, Learning Rate: 9.86e-05
2025-12-08 22:04:30 - INFO - Epoch: 2.52, Step: 8000, Train Loss: 4.6265, Learning Rate: 9.86e-05
2025-12-08 22:04:41 - INFO - Epoch: 2.53, Step: 8010, Train Loss: 4.6565, Learning Rate: 9.86e-05
2025-12-08 22:04:52 - INFO - Epoch: 2.53, Step: 8020, Train Loss: 4.5653, Learning Rate: 9.86e-05
2025-12-08 22:05:03 - INFO - Epoch: 2.53, Step: 8030, Train Loss: 4.6133, Learning Rate: 9.86e-05
2025-12-08 22:05:14 - INFO - Epoch: 2.54, Step: 8040, Train Loss: 4.6114, Learning Rate: 9.86e-05
2025-12-08 22:05:26 - INFO - Epoch: 2.54, Step: 8050, Train Loss: 4.5546, Learning Rate: 9.86e-05
2025-12-08 22:05:37 - INFO - Epoch: 2.54, Step: 8060, Train Loss: 4.5454, Learning Rate: 9.86e-05
2025-12-08 22:05:48 - INFO - Epoch: 2.55, Step: 8070, Train Loss: 4.5126, Learning Rate: 9.86e-05
2025-12-08 22:05:59 - INFO - Epoch: 2.55, Step: 8080, Train Loss: 4.5453, Learning Rate: 9.86e-05
2025-12-08 22:06:10 - INFO - Epoch: 2.55, Step: 8090, Train Loss: 4.5739, Learning Rate: 9.85e-05
2025-12-08 22:06:21 - INFO - Epoch: 2.56, Step: 8100, Train Loss: 4.5059, Learning Rate: 9.85e-05
2025-12-08 22:06:32 - INFO - Epoch: 2.56, Step: 8110, Train Loss: 4.5206, Learning Rate: 9.85e-05
2025-12-08 22:06:43 - INFO - Epoch: 2.56, Step: 8120, Train Loss: 4.5459, Learning Rate: 9.85e-05
2025-12-08 22:06:54 - INFO - Epoch: 2.57, Step: 8130, Train Loss: 4.5002, Learning Rate: 9.85e-05
2025-12-08 22:07:05 - INFO - Epoch: 2.57, Step: 8140, Train Loss: 4.5250, Learning Rate: 9.85e-05
2025-12-08 22:07:16 - INFO - Epoch: 2.57, Step: 8150, Train Loss: 4.5380, Learning Rate: 9.85e-05
2025-12-08 22:07:27 - INFO - Epoch: 2.57, Step: 8160, Train Loss: 4.4510, Learning Rate: 9.85e-05
2025-12-08 22:07:38 - INFO - Epoch: 2.58, Step: 8170, Train Loss: 4.5061, Learning Rate: 9.85e-05
2025-12-08 22:07:50 - INFO - Epoch: 2.58, Step: 8180, Train Loss: 4.4910, Learning Rate: 9.85e-05
2025-12-08 22:08:01 - INFO - Epoch: 2.58, Step: 8190, Train Loss: 4.4857, Learning Rate: 9.85e-05
2025-12-08 22:08:12 - INFO - Epoch: 2.59, Step: 8200, Train Loss: 4.4688, Learning Rate: 9.85e-05
2025-12-08 22:08:23 - INFO - Epoch: 2.59, Step: 8210, Train Loss: 4.4584, Learning Rate: 9.84e-05
2025-12-08 22:08:34 - INFO - Epoch: 2.59, Step: 8220, Train Loss: 4.4384, Learning Rate: 9.84e-05
2025-12-08 22:08:45 - INFO - Epoch: 2.60, Step: 8230, Train Loss: 4.4417, Learning Rate: 9.84e-05
2025-12-08 22:08:56 - INFO - Epoch: 2.60, Step: 8240, Train Loss: 4.4318, Learning Rate: 9.84e-05
2025-12-08 22:09:07 - INFO - Epoch: 2.60, Step: 8250, Train Loss: 4.4013, Learning Rate: 9.84e-05
2025-12-08 22:09:18 - INFO - Epoch: 2.61, Step: 8260, Train Loss: 4.4507, Learning Rate: 9.84e-05
2025-12-08 22:09:29 - INFO - Epoch: 2.61, Step: 8270, Train Loss: 4.4067, Learning Rate: 9.84e-05
2025-12-08 22:09:40 - INFO - Epoch: 2.61, Step: 8280, Train Loss: 4.4096, Learning Rate: 9.84e-05
2025-12-08 22:09:51 - INFO - Epoch: 2.62, Step: 8290, Train Loss: 4.4215, Learning Rate: 9.84e-05
2025-12-08 22:10:03 - INFO - Epoch: 2.62, Step: 8300, Train Loss: 4.4081, Learning Rate: 9.84e-05
2025-12-08 22:10:14 - INFO - Epoch: 2.62, Step: 8310, Train Loss: 4.3957, Learning Rate: 9.84e-05
2025-12-08 22:10:25 - INFO - Epoch: 2.63, Step: 8320, Train Loss: 4.3660, Learning Rate: 9.84e-05
2025-12-08 22:10:36 - INFO - Epoch: 2.63, Step: 8330, Train Loss: 4.3844, Learning Rate: 9.83e-05
2025-12-08 22:10:47 - INFO - Epoch: 2.63, Step: 8340, Train Loss: 4.3786, Learning Rate: 9.83e-05
2025-12-08 22:10:58 - INFO - Epoch: 2.63, Step: 8350, Train Loss: 4.3741, Learning Rate: 9.83e-05
2025-12-08 22:11:09 - INFO - Epoch: 2.64, Step: 8360, Train Loss: 4.3791, Learning Rate: 9.83e-05
2025-12-08 22:11:20 - INFO - Epoch: 2.64, Step: 8370, Train Loss: 4.3480, Learning Rate: 9.83e-05
2025-12-08 22:11:31 - INFO - Epoch: 2.64, Step: 8380, Train Loss: 4.3550, Learning Rate: 9.83e-05
2025-12-08 22:11:42 - INFO - Epoch: 2.65, Step: 8390, Train Loss: 4.2996, Learning Rate: 9.83e-05
2025-12-08 22:11:53 - INFO - Epoch: 2.65, Step: 8400, Train Loss: 4.3369, Learning Rate: 9.83e-05
2025-12-08 22:12:04 - INFO - Epoch: 2.65, Step: 8410, Train Loss: 4.3287, Learning Rate: 9.83e-05
2025-12-08 22:12:15 - INFO - Epoch: 2.66, Step: 8420, Train Loss: 4.3358, Learning Rate: 9.83e-05
2025-12-08 22:12:27 - INFO - Epoch: 2.66, Step: 8430, Train Loss: 4.3548, Learning Rate: 9.83e-05
2025-12-08 22:12:38 - INFO - Epoch: 2.66, Step: 8440, Train Loss: 4.3049, Learning Rate: 9.83e-05
2025-12-08 22:12:49 - INFO - Epoch: 2.67, Step: 8450, Train Loss: 4.3420, Learning Rate: 9.82e-05
2025-12-08 22:13:00 - INFO - Epoch: 2.67, Step: 8460, Train Loss: 4.2842, Learning Rate: 9.82e-05
2025-12-08 22:13:11 - INFO - Epoch: 2.67, Step: 8470, Train Loss: 4.2980, Learning Rate: 9.82e-05
2025-12-08 22:13:22 - INFO - Epoch: 2.68, Step: 8480, Train Loss: 4.2800, Learning Rate: 9.82e-05
2025-12-08 22:13:33 - INFO - Epoch: 2.68, Step: 8490, Train Loss: 4.2472, Learning Rate: 9.82e-05
2025-12-08 22:13:44 - INFO - Epoch: 2.68, Step: 8500, Train Loss: 4.2488, Learning Rate: 9.82e-05
2025-12-08 22:13:55 - INFO - Epoch: 2.69, Step: 8510, Train Loss: 4.2620, Learning Rate: 9.82e-05
2025-12-08 22:14:06 - INFO - Epoch: 2.69, Step: 8520, Train Loss: 4.3261, Learning Rate: 9.82e-05
2025-12-08 22:14:17 - INFO - Epoch: 2.69, Step: 8530, Train Loss: 4.2418, Learning Rate: 9.82e-05
2025-12-08 22:14:28 - INFO - Epoch: 2.69, Step: 8540, Train Loss: 4.2655, Learning Rate: 9.82e-05
2025-12-08 22:14:39 - INFO - Epoch: 2.70, Step: 8550, Train Loss: 4.2739, Learning Rate: 9.82e-05
2025-12-08 22:14:51 - INFO - Epoch: 2.70, Step: 8560, Train Loss: 4.2495, Learning Rate: 9.82e-05
2025-12-08 22:15:02 - INFO - Epoch: 2.70, Step: 8570, Train Loss: 4.2446, Learning Rate: 9.81e-05
2025-12-08 22:15:13 - INFO - Epoch: 2.71, Step: 8580, Train Loss: 4.2780, Learning Rate: 9.81e-05
2025-12-08 22:15:24 - INFO - Epoch: 2.71, Step: 8590, Train Loss: 4.2332, Learning Rate: 9.81e-05
2025-12-08 22:15:35 - INFO - Epoch: 2.71, Step: 8600, Train Loss: 4.2041, Learning Rate: 9.81e-05
2025-12-08 22:15:46 - INFO - Epoch: 2.72, Step: 8610, Train Loss: 4.2229, Learning Rate: 9.81e-05
2025-12-08 22:15:57 - INFO - Epoch: 2.72, Step: 8620, Train Loss: 4.1634, Learning Rate: 9.81e-05
2025-12-08 22:16:08 - INFO - Epoch: 2.72, Step: 8630, Train Loss: 4.2023, Learning Rate: 9.81e-05
2025-12-08 22:16:19 - INFO - Epoch: 2.73, Step: 8640, Train Loss: 4.2146, Learning Rate: 9.81e-05
2025-12-08 22:16:30 - INFO - Epoch: 2.73, Step: 8650, Train Loss: 4.1905, Learning Rate: 9.81e-05
2025-12-08 22:16:41 - INFO - Epoch: 2.73, Step: 8660, Train Loss: 4.2012, Learning Rate: 9.81e-05
2025-12-08 22:16:52 - INFO - Epoch: 2.74, Step: 8670, Train Loss: 4.1491, Learning Rate: 9.81e-05
2025-12-08 22:17:03 - INFO - Epoch: 2.74, Step: 8680, Train Loss: 4.1518, Learning Rate: 9.81e-05
2025-12-08 22:17:15 - INFO - Epoch: 2.74, Step: 8690, Train Loss: 4.1688, Learning Rate: 9.80e-05
2025-12-08 22:17:26 - INFO - Epoch: 2.75, Step: 8700, Train Loss: 4.1817, Learning Rate: 9.80e-05
2025-12-08 22:17:37 - INFO - Epoch: 2.75, Step: 8710, Train Loss: 4.1614, Learning Rate: 9.80e-05
2025-12-08 22:17:48 - INFO - Epoch: 2.75, Step: 8720, Train Loss: 4.1354, Learning Rate: 9.80e-05
2025-12-08 22:17:59 - INFO - Epoch: 2.75, Step: 8730, Train Loss: 4.1713, Learning Rate: 9.80e-05
2025-12-08 22:18:10 - INFO - Epoch: 2.76, Step: 8740, Train Loss: 4.1586, Learning Rate: 9.80e-05
2025-12-08 22:18:21 - INFO - Epoch: 2.76, Step: 8750, Train Loss: 4.1796, Learning Rate: 9.80e-05
2025-12-08 22:18:32 - INFO - Epoch: 2.76, Step: 8760, Train Loss: 4.1423, Learning Rate: 9.80e-05
2025-12-08 22:18:43 - INFO - Epoch: 2.77, Step: 8770, Train Loss: 4.1293, Learning Rate: 9.80e-05
2025-12-08 22:18:54 - INFO - Epoch: 2.77, Step: 8780, Train Loss: 4.1066, Learning Rate: 9.80e-05
2025-12-08 22:19:05 - INFO - Epoch: 2.77, Step: 8790, Train Loss: 4.1508, Learning Rate: 9.80e-05
2025-12-08 22:19:16 - INFO - Epoch: 2.78, Step: 8800, Train Loss: 4.1336, Learning Rate: 9.80e-05
2025-12-08 22:19:27 - INFO - Epoch: 2.78, Step: 8810, Train Loss: 4.1061, Learning Rate: 9.79e-05
2025-12-08 22:19:39 - INFO - Epoch: 2.78, Step: 8820, Train Loss: 4.0559, Learning Rate: 9.79e-05
2025-12-08 22:19:50 - INFO - Epoch: 2.79, Step: 8830, Train Loss: 4.1246, Learning Rate: 9.79e-05
2025-12-08 22:20:01 - INFO - Epoch: 2.79, Step: 8840, Train Loss: 4.0857, Learning Rate: 9.79e-05
2025-12-08 22:20:12 - INFO - Epoch: 2.79, Step: 8850, Train Loss: 4.1017, Learning Rate: 9.79e-05
2025-12-08 22:20:23 - INFO - Epoch: 2.80, Step: 8860, Train Loss: 4.1187, Learning Rate: 9.79e-05
2025-12-08 22:20:34 - INFO - Epoch: 2.80, Step: 8870, Train Loss: 4.0931, Learning Rate: 9.79e-05
2025-12-08 22:20:45 - INFO - Epoch: 2.80, Step: 8880, Train Loss: 4.0831, Learning Rate: 9.79e-05
2025-12-08 22:20:56 - INFO - Epoch: 2.81, Step: 8890, Train Loss: 4.0575, Learning Rate: 9.79e-05
2025-12-08 22:21:07 - INFO - Epoch: 2.81, Step: 8900, Train Loss: 4.0664, Learning Rate: 9.79e-05
2025-12-08 22:21:18 - INFO - Epoch: 2.81, Step: 8910, Train Loss: 4.0609, Learning Rate: 9.79e-05
2025-12-08 22:21:29 - INFO - Epoch: 2.81, Step: 8920, Train Loss: 4.0726, Learning Rate: 9.79e-05
2025-12-08 22:21:40 - INFO - Epoch: 2.82, Step: 8930, Train Loss: 4.0717, Learning Rate: 9.78e-05
2025-12-08 22:21:51 - INFO - Epoch: 2.82, Step: 8940, Train Loss: 4.0287, Learning Rate: 9.78e-05
2025-12-08 22:22:03 - INFO - Epoch: 2.82, Step: 8950, Train Loss: 4.0112, Learning Rate: 9.78e-05
2025-12-08 22:22:14 - INFO - Epoch: 2.83, Step: 8960, Train Loss: 4.0430, Learning Rate: 9.78e-05
2025-12-08 22:22:25 - INFO - Epoch: 2.83, Step: 8970, Train Loss: 4.0321, Learning Rate: 9.78e-05
2025-12-08 22:22:36 - INFO - Epoch: 2.83, Step: 8980, Train Loss: 4.0364, Learning Rate: 9.78e-05
2025-12-08 22:22:47 - INFO - Epoch: 2.84, Step: 8990, Train Loss: 4.0687, Learning Rate: 9.78e-05
2025-12-08 22:22:58 - INFO - Epoch: 2.84, Step: 9000, Train Loss: 4.0463, Learning Rate: 9.78e-05
2025-12-08 22:23:09 - INFO - Epoch: 2.84, Step: 9010, Train Loss: 4.0665, Learning Rate: 9.78e-05
2025-12-08 22:23:20 - INFO - Epoch: 2.85, Step: 9020, Train Loss: 4.0141, Learning Rate: 9.78e-05
2025-12-08 22:23:31 - INFO - Epoch: 2.85, Step: 9030, Train Loss: 3.9904, Learning Rate: 9.78e-05
2025-12-08 22:23:42 - INFO - Epoch: 2.85, Step: 9040, Train Loss: 4.0151, Learning Rate: 9.78e-05
2025-12-08 22:23:53 - INFO - Epoch: 2.86, Step: 9050, Train Loss: 4.0032, Learning Rate: 9.77e-05
2025-12-08 22:24:04 - INFO - Epoch: 2.86, Step: 9060, Train Loss: 3.9857, Learning Rate: 9.77e-05
2025-12-08 22:24:15 - INFO - Epoch: 2.86, Step: 9070, Train Loss: 3.9444, Learning Rate: 9.77e-05
2025-12-08 22:24:27 - INFO - Epoch: 2.87, Step: 9080, Train Loss: 3.9857, Learning Rate: 9.77e-05
2025-12-08 22:24:38 - INFO - Epoch: 2.87, Step: 9090, Train Loss: 4.0056, Learning Rate: 9.77e-05
2025-12-08 22:24:49 - INFO - Epoch: 2.87, Step: 9100, Train Loss: 3.9485, Learning Rate: 9.77e-05
2025-12-08 22:25:00 - INFO - Epoch: 2.87, Step: 9110, Train Loss: 4.0061, Learning Rate: 9.77e-05
2025-12-08 22:25:11 - INFO - Epoch: 2.88, Step: 9120, Train Loss: 3.9761, Learning Rate: 9.77e-05
2025-12-08 22:25:22 - INFO - Epoch: 2.88, Step: 9130, Train Loss: 3.9564, Learning Rate: 9.77e-05
2025-12-08 22:25:33 - INFO - Epoch: 2.88, Step: 9140, Train Loss: 3.9570, Learning Rate: 9.77e-05
2025-12-08 22:25:44 - INFO - Epoch: 2.89, Step: 9150, Train Loss: 3.9614, Learning Rate: 9.77e-05
2025-12-08 22:25:55 - INFO - Epoch: 2.89, Step: 9160, Train Loss: 3.9569, Learning Rate: 9.77e-05
2025-12-08 22:26:06 - INFO - Epoch: 2.89, Step: 9170, Train Loss: 3.9210, Learning Rate: 9.76e-05
2025-12-08 22:26:17 - INFO - Epoch: 2.90, Step: 9180, Train Loss: 3.9388, Learning Rate: 9.76e-05
2025-12-08 22:26:28 - INFO - Epoch: 2.90, Step: 9190, Train Loss: 3.9542, Learning Rate: 9.76e-05
2025-12-08 22:26:40 - INFO - Epoch: 2.90, Step: 9200, Train Loss: 3.9656, Learning Rate: 9.76e-05
2025-12-08 22:26:51 - INFO - Epoch: 2.91, Step: 9210, Train Loss: 3.9281, Learning Rate: 9.76e-05
2025-12-08 22:27:02 - INFO - Epoch: 2.91, Step: 9220, Train Loss: 3.8901, Learning Rate: 9.76e-05
2025-12-08 22:27:13 - INFO - Epoch: 2.91, Step: 9230, Train Loss: 3.9315, Learning Rate: 9.76e-05
2025-12-08 22:27:24 - INFO - Epoch: 2.92, Step: 9240, Train Loss: 3.9143, Learning Rate: 9.76e-05
2025-12-08 22:27:35 - INFO - Epoch: 2.92, Step: 9250, Train Loss: 3.8782, Learning Rate: 9.76e-05
2025-12-08 22:27:46 - INFO - Epoch: 2.92, Step: 9260, Train Loss: 3.9021, Learning Rate: 9.76e-05
2025-12-08 22:27:57 - INFO - Epoch: 2.93, Step: 9270, Train Loss: 3.9185, Learning Rate: 9.76e-05
2025-12-08 22:28:08 - INFO - Epoch: 2.93, Step: 9280, Train Loss: 3.8979, Learning Rate: 9.76e-05
2025-12-08 22:28:19 - INFO - Epoch: 2.93, Step: 9290, Train Loss: 3.8939, Learning Rate: 9.75e-05
2025-12-08 22:28:30 - INFO - Epoch: 2.93, Step: 9300, Train Loss: 3.8616, Learning Rate: 9.75e-05
2025-12-08 22:28:41 - INFO - Epoch: 2.94, Step: 9310, Train Loss: 3.8224, Learning Rate: 9.75e-05
2025-12-08 22:28:52 - INFO - Epoch: 2.94, Step: 9320, Train Loss: 3.8188, Learning Rate: 9.75e-05
2025-12-08 22:29:04 - INFO - Epoch: 2.94, Step: 9330, Train Loss: 3.8198, Learning Rate: 9.75e-05
2025-12-08 22:29:15 - INFO - Epoch: 2.95, Step: 9340, Train Loss: 3.8321, Learning Rate: 9.75e-05
2025-12-08 22:29:26 - INFO - Epoch: 2.95, Step: 9350, Train Loss: 3.9033, Learning Rate: 9.75e-05
2025-12-08 22:29:37 - INFO - Epoch: 2.95, Step: 9360, Train Loss: 3.8467, Learning Rate: 9.75e-05
2025-12-08 22:29:48 - INFO - Epoch: 2.96, Step: 9370, Train Loss: 3.8207, Learning Rate: 9.75e-05
2025-12-08 22:29:59 - INFO - Epoch: 2.96, Step: 9380, Train Loss: 3.8606, Learning Rate: 9.75e-05
2025-12-08 22:30:10 - INFO - Epoch: 2.96, Step: 9390, Train Loss: 3.8357, Learning Rate: 9.75e-05
2025-12-08 22:30:21 - INFO - Epoch: 2.97, Step: 9400, Train Loss: 3.8428, Learning Rate: 9.75e-05
2025-12-08 22:30:32 - INFO - Epoch: 2.97, Step: 9410, Train Loss: 3.8556, Learning Rate: 9.74e-05
2025-12-08 22:30:43 - INFO - Epoch: 2.97, Step: 9420, Train Loss: 3.8258, Learning Rate: 9.74e-05
2025-12-08 22:30:54 - INFO - Epoch: 2.98, Step: 9430, Train Loss: 3.8034, Learning Rate: 9.74e-05
2025-12-08 22:31:05 - INFO - Epoch: 2.98, Step: 9440, Train Loss: 3.8137, Learning Rate: 9.74e-05
2025-12-08 22:31:16 - INFO - Epoch: 2.98, Step: 9450, Train Loss: 3.7680, Learning Rate: 9.74e-05
2025-12-08 22:31:28 - INFO - Epoch: 2.99, Step: 9460, Train Loss: 3.7897, Learning Rate: 9.74e-05
2025-12-08 22:31:39 - INFO - Epoch: 2.99, Step: 9470, Train Loss: 3.7969, Learning Rate: 9.74e-05
2025-12-08 22:31:50 - INFO - Epoch: 2.99, Step: 9480, Train Loss: 3.7511, Learning Rate: 9.74e-05
2025-12-08 22:32:01 - INFO - Epoch: 2.99, Step: 9490, Train Loss: 3.7773, Learning Rate: 9.74e-05
2025-12-08 22:32:12 - INFO - Epoch: 3.00, Step: 9500, Train Loss: 3.7778, Learning Rate: 9.74e-05
2025-12-08 22:32:23 - INFO - Epoch: 3.00, Step: 9510, Train Loss: 3.7695, Learning Rate: 9.74e-05
2025-12-08 22:32:34 - INFO - Epoch: 3.00, Step: 9520, Train Loss: 3.7854, Learning Rate: 9.74e-05
2025-12-08 22:32:45 - INFO - Epoch: 3.01, Step: 9530, Train Loss: 3.7425, Learning Rate: 9.74e-05
2025-12-08 22:32:56 - INFO - Epoch: 3.01, Step: 9540, Train Loss: 3.7478, Learning Rate: 9.73e-05
2025-12-08 22:33:07 - INFO - Epoch: 3.01, Step: 9550, Train Loss: 3.7648, Learning Rate: 9.73e-05
2025-12-08 22:33:18 - INFO - Epoch: 3.02, Step: 9560, Train Loss: 3.7965, Learning Rate: 9.73e-05
2025-12-08 22:33:29 - INFO - Epoch: 3.02, Step: 9570, Train Loss: 3.7284, Learning Rate: 9.73e-05
2025-12-08 22:33:40 - INFO - Epoch: 3.02, Step: 9580, Train Loss: 3.7372, Learning Rate: 9.73e-05
2025-12-08 22:33:52 - INFO - Epoch: 3.03, Step: 9590, Train Loss: 3.7125, Learning Rate: 9.73e-05
2025-12-08 22:34:03 - INFO - Epoch: 3.03, Step: 9600, Train Loss: 3.7779, Learning Rate: 9.73e-05
2025-12-08 22:34:14 - INFO - Epoch: 3.03, Step: 9610, Train Loss: 3.6912, Learning Rate: 9.73e-05
2025-12-08 22:34:25 - INFO - Epoch: 3.04, Step: 9620, Train Loss: 3.7020, Learning Rate: 9.73e-05
2025-12-08 22:34:36 - INFO - Epoch: 3.04, Step: 9630, Train Loss: 3.7025, Learning Rate: 9.73e-05
2025-12-08 22:34:47 - INFO - Epoch: 3.04, Step: 9640, Train Loss: 3.6978, Learning Rate: 9.73e-05
2025-12-08 22:34:58 - INFO - Epoch: 3.05, Step: 9650, Train Loss: 3.7148, Learning Rate: 9.73e-05
2025-12-08 22:35:09 - INFO - Epoch: 3.05, Step: 9660, Train Loss: 3.7013, Learning Rate: 9.72e-05
2025-12-08 22:35:20 - INFO - Epoch: 3.05, Step: 9670, Train Loss: 3.6826, Learning Rate: 9.72e-05
2025-12-08 22:35:31 - INFO - Epoch: 3.05, Step: 9680, Train Loss: 3.6683, Learning Rate: 9.72e-05
2025-12-08 22:35:42 - INFO - Epoch: 3.06, Step: 9690, Train Loss: 3.6765, Learning Rate: 9.72e-05
2025-12-08 22:35:53 - INFO - Epoch: 3.06, Step: 9700, Train Loss: 3.6739, Learning Rate: 9.72e-05
2025-12-08 22:36:04 - INFO - Epoch: 3.06, Step: 9710, Train Loss: 3.6321, Learning Rate: 9.72e-05
2025-12-08 22:36:16 - INFO - Epoch: 3.07, Step: 9720, Train Loss: 3.6495, Learning Rate: 9.72e-05
2025-12-08 22:36:27 - INFO - Epoch: 3.07, Step: 9730, Train Loss: 3.5924, Learning Rate: 9.72e-05
2025-12-08 22:36:38 - INFO - Epoch: 3.07, Step: 9740, Train Loss: 3.6643, Learning Rate: 9.72e-05
2025-12-08 22:36:49 - INFO - Epoch: 3.08, Step: 9750, Train Loss: 3.6704, Learning Rate: 9.72e-05
2025-12-08 22:37:00 - INFO - Epoch: 3.08, Step: 9760, Train Loss: 3.6502, Learning Rate: 9.72e-05
2025-12-08 22:37:11 - INFO - Epoch: 3.08, Step: 9770, Train Loss: 3.6231, Learning Rate: 9.72e-05
2025-12-08 22:37:22 - INFO - Epoch: 3.09, Step: 9780, Train Loss: 3.6079, Learning Rate: 9.71e-05
2025-12-08 22:37:33 - INFO - Epoch: 3.09, Step: 9790, Train Loss: 3.6515, Learning Rate: 9.71e-05
2025-12-08 22:37:44 - INFO - Epoch: 3.09, Step: 9800, Train Loss: 3.6115, Learning Rate: 9.71e-05
2025-12-08 22:37:55 - INFO - Epoch: 3.10, Step: 9810, Train Loss: 3.6093, Learning Rate: 9.71e-05
2025-12-08 22:38:06 - INFO - Epoch: 3.10, Step: 9820, Train Loss: 3.6076, Learning Rate: 9.71e-05
2025-12-08 22:38:17 - INFO - Epoch: 3.10, Step: 9830, Train Loss: 3.5885, Learning Rate: 9.71e-05
2025-12-08 22:38:28 - INFO - Epoch: 3.11, Step: 9840, Train Loss: 3.5841, Learning Rate: 9.71e-05
2025-12-08 22:38:40 - INFO - Epoch: 3.11, Step: 9850, Train Loss: 3.5773, Learning Rate: 9.71e-05
2025-12-08 22:38:51 - INFO - Epoch: 3.11, Step: 9860, Train Loss: 3.5939, Learning Rate: 9.71e-05
2025-12-08 22:39:02 - INFO - Epoch: 3.11, Step: 9870, Train Loss: 3.5785, Learning Rate: 9.71e-05
2025-12-08 22:39:13 - INFO - Epoch: 3.12, Step: 9880, Train Loss: 3.5804, Learning Rate: 9.71e-05
2025-12-08 22:39:24 - INFO - Epoch: 3.12, Step: 9890, Train Loss: 3.5742, Learning Rate: 9.71e-05
2025-12-08 22:39:35 - INFO - Epoch: 3.12, Step: 9900, Train Loss: 3.5508, Learning Rate: 9.70e-05
2025-12-08 22:39:46 - INFO - Epoch: 3.13, Step: 9910, Train Loss: 3.5791, Learning Rate: 9.70e-05
2025-12-08 22:39:57 - INFO - Epoch: 3.13, Step: 9920, Train Loss: 3.5418, Learning Rate: 9.70e-05
2025-12-08 22:40:08 - INFO - Epoch: 3.13, Step: 9930, Train Loss: 3.5567, Learning Rate: 9.70e-05
2025-12-08 22:40:19 - INFO - Epoch: 3.14, Step: 9940, Train Loss: 3.5691, Learning Rate: 9.70e-05
2025-12-08 22:40:30 - INFO - Epoch: 3.14, Step: 9950, Train Loss: 3.5207, Learning Rate: 9.70e-05
2025-12-08 22:40:41 - INFO - Epoch: 3.14, Step: 9960, Train Loss: 3.5029, Learning Rate: 9.70e-05
2025-12-08 22:40:53 - INFO - Epoch: 3.15, Step: 9970, Train Loss: 3.5679, Learning Rate: 9.70e-05
2025-12-08 22:41:04 - INFO - Epoch: 3.15, Step: 9980, Train Loss: 3.5741, Learning Rate: 9.70e-05
2025-12-08 22:41:15 - INFO - Epoch: 3.15, Step: 9990, Train Loss: 3.5562, Learning Rate: 9.70e-05
2025-12-08 22:41:26 - INFO - Epoch: 3.16, Step: 10000, Train Loss: 3.5163, Learning Rate: 9.70e-05
2025-12-08 22:41:37 - INFO - Epoch: 3.16, Step: 10010, Train Loss: 3.5365, Learning Rate: 9.70e-05
2025-12-08 22:41:48 - INFO - Epoch: 3.16, Step: 10020, Train Loss: 3.5407, Learning Rate: 9.69e-05
2025-12-08 22:41:59 - INFO - Epoch: 3.17, Step: 10030, Train Loss: 3.4999, Learning Rate: 9.69e-05
2025-12-08 22:42:10 - INFO - Epoch: 3.17, Step: 10040, Train Loss: 3.5660, Learning Rate: 9.69e-05
2025-12-08 22:42:21 - INFO - Epoch: 3.17, Step: 10050, Train Loss: 3.5586, Learning Rate: 9.69e-05
2025-12-08 22:42:32 - INFO - Epoch: 3.17, Step: 10060, Train Loss: 3.4942, Learning Rate: 9.69e-05
2025-12-08 22:42:43 - INFO - Epoch: 3.18, Step: 10070, Train Loss: 3.5195, Learning Rate: 9.69e-05
2025-12-08 22:42:54 - INFO - Epoch: 3.18, Step: 10080, Train Loss: 3.5235, Learning Rate: 9.69e-05
2025-12-08 22:43:05 - INFO - Epoch: 3.18, Step: 10090, Train Loss: 3.4807, Learning Rate: 9.69e-05
2025-12-08 22:43:17 - INFO - Epoch: 3.19, Step: 10100, Train Loss: 3.5136, Learning Rate: 9.69e-05
2025-12-08 22:43:28 - INFO - Epoch: 3.19, Step: 10110, Train Loss: 3.4950, Learning Rate: 9.69e-05
2025-12-08 22:43:39 - INFO - Epoch: 3.19, Step: 10120, Train Loss: 3.4630, Learning Rate: 9.69e-05
2025-12-08 22:43:50 - INFO - Epoch: 3.20, Step: 10130, Train Loss: 3.4464, Learning Rate: 9.69e-05
2025-12-08 22:44:01 - INFO - Epoch: 3.20, Step: 10140, Train Loss: 3.4728, Learning Rate: 9.68e-05
2025-12-08 22:44:12 - INFO - Epoch: 3.20, Step: 10150, Train Loss: 3.4827, Learning Rate: 9.68e-05
2025-12-08 22:44:23 - INFO - Epoch: 3.21, Step: 10160, Train Loss: 3.5044, Learning Rate: 9.68e-05
2025-12-08 22:44:34 - INFO - Epoch: 3.21, Step: 10170, Train Loss: 3.4146, Learning Rate: 9.68e-05
2025-12-08 22:44:45 - INFO - Epoch: 3.21, Step: 10180, Train Loss: 3.4155, Learning Rate: 9.68e-05
2025-12-08 22:44:56 - INFO - Epoch: 3.22, Step: 10190, Train Loss: 3.3959, Learning Rate: 9.68e-05
2025-12-08 22:45:07 - INFO - Epoch: 3.22, Step: 10200, Train Loss: 3.4420, Learning Rate: 9.68e-05
2025-12-08 22:45:18 - INFO - Epoch: 3.22, Step: 10210, Train Loss: 3.4234, Learning Rate: 9.68e-05
2025-12-08 22:45:29 - INFO - Epoch: 3.22, Step: 10220, Train Loss: 3.4331, Learning Rate: 9.68e-05
2025-12-08 22:45:41 - INFO - Epoch: 3.23, Step: 10230, Train Loss: 3.4184, Learning Rate: 9.68e-05
2025-12-08 22:45:52 - INFO - Epoch: 3.23, Step: 10240, Train Loss: 3.5129, Learning Rate: 9.68e-05
2025-12-08 22:46:03 - INFO - Epoch: 3.23, Step: 10250, Train Loss: 3.4688, Learning Rate: 9.68e-05
2025-12-08 22:46:14 - INFO - Epoch: 3.24, Step: 10260, Train Loss: 3.3933, Learning Rate: 9.67e-05
2025-12-08 22:46:25 - INFO - Epoch: 3.24, Step: 10270, Train Loss: 3.4759, Learning Rate: 9.67e-05
2025-12-08 22:46:36 - INFO - Epoch: 3.24, Step: 10280, Train Loss: 3.4095, Learning Rate: 9.67e-05
2025-12-08 22:46:47 - INFO - Epoch: 3.25, Step: 10290, Train Loss: 3.3879, Learning Rate: 9.67e-05
2025-12-08 22:46:58 - INFO - Epoch: 3.25, Step: 10300, Train Loss: 3.4462, Learning Rate: 9.67e-05
2025-12-08 22:47:09 - INFO - Epoch: 3.25, Step: 10310, Train Loss: 3.4113, Learning Rate: 9.67e-05
2025-12-08 22:47:20 - INFO - Epoch: 3.26, Step: 10320, Train Loss: 3.3893, Learning Rate: 9.67e-05
2025-12-08 22:47:31 - INFO - Epoch: 3.26, Step: 10330, Train Loss: 3.3979, Learning Rate: 9.67e-05
2025-12-08 22:47:42 - INFO - Epoch: 3.26, Step: 10340, Train Loss: 3.4037, Learning Rate: 9.67e-05
2025-12-08 22:47:53 - INFO - Epoch: 3.27, Step: 10350, Train Loss: 3.4266, Learning Rate: 9.67e-05
2025-12-08 22:48:05 - INFO - Epoch: 3.27, Step: 10360, Train Loss: 3.3837, Learning Rate: 9.67e-05
2025-12-08 22:48:16 - INFO - Epoch: 3.27, Step: 10370, Train Loss: 3.3958, Learning Rate: 9.67e-05
2025-12-08 22:48:27 - INFO - Epoch: 3.28, Step: 10380, Train Loss: 3.3710, Learning Rate: 9.66e-05
2025-12-08 22:48:38 - INFO - Epoch: 3.28, Step: 10390, Train Loss: 3.3732, Learning Rate: 9.66e-05
2025-12-08 22:48:49 - INFO - Epoch: 3.28, Step: 10400, Train Loss: 3.3979, Learning Rate: 9.66e-05
2025-12-08 22:49:00 - INFO - Epoch: 3.28, Step: 10410, Train Loss: 3.3907, Learning Rate: 9.66e-05
2025-12-08 22:49:11 - INFO - Epoch: 3.29, Step: 10420, Train Loss: 3.3600, Learning Rate: 9.66e-05
2025-12-08 22:49:22 - INFO - Epoch: 3.29, Step: 10430, Train Loss: 3.3480, Learning Rate: 9.66e-05
2025-12-08 22:49:33 - INFO - Epoch: 3.29, Step: 10440, Train Loss: 3.3929, Learning Rate: 9.66e-05
2025-12-08 22:49:44 - INFO - Epoch: 3.30, Step: 10450, Train Loss: 3.3548, Learning Rate: 9.66e-05
2025-12-08 22:49:55 - INFO - Epoch: 3.30, Step: 10460, Train Loss: 3.3327, Learning Rate: 9.66e-05
2025-12-08 22:50:06 - INFO - Epoch: 3.30, Step: 10470, Train Loss: 3.3797, Learning Rate: 9.66e-05
2025-12-08 22:50:17 - INFO - Epoch: 3.31, Step: 10480, Train Loss: 3.3803, Learning Rate: 9.66e-05
2025-12-08 22:50:29 - INFO - Epoch: 3.31, Step: 10490, Train Loss: 3.3483, Learning Rate: 9.66e-05
2025-12-08 22:50:40 - INFO - Epoch: 3.31, Step: 10500, Train Loss: 3.3463, Learning Rate: 9.65e-05
2025-12-08 22:50:51 - INFO - Epoch: 3.32, Step: 10510, Train Loss: 3.3274, Learning Rate: 9.65e-05
2025-12-08 22:51:02 - INFO - Epoch: 3.32, Step: 10520, Train Loss: 3.3252, Learning Rate: 9.65e-05
2025-12-08 22:51:13 - INFO - Epoch: 3.32, Step: 10530, Train Loss: 3.3031, Learning Rate: 9.65e-05
2025-12-08 22:51:24 - INFO - Epoch: 3.33, Step: 10540, Train Loss: 3.2894, Learning Rate: 9.65e-05
2025-12-08 22:51:35 - INFO - Epoch: 3.33, Step: 10550, Train Loss: 3.3070, Learning Rate: 9.65e-05
2025-12-08 22:51:46 - INFO - Epoch: 3.33, Step: 10560, Train Loss: 3.3216, Learning Rate: 9.65e-05
2025-12-08 22:51:57 - INFO - Epoch: 3.34, Step: 10570, Train Loss: 3.2955, Learning Rate: 9.65e-05
2025-12-08 22:52:08 - INFO - Epoch: 3.34, Step: 10580, Train Loss: 3.2956, Learning Rate: 9.65e-05
2025-12-08 22:52:19 - INFO - Epoch: 3.34, Step: 10590, Train Loss: 3.2778, Learning Rate: 9.65e-05
2025-12-08 22:52:30 - INFO - Epoch: 3.34, Step: 10600, Train Loss: 3.2966, Learning Rate: 9.65e-05
2025-12-08 22:52:42 - INFO - Epoch: 3.35, Step: 10610, Train Loss: 3.2677, Learning Rate: 9.65e-05
2025-12-08 22:52:53 - INFO - Epoch: 3.35, Step: 10620, Train Loss: 3.2728, Learning Rate: 9.64e-05
2025-12-08 22:53:04 - INFO - Epoch: 3.35, Step: 10630, Train Loss: 3.2710, Learning Rate: 9.64e-05
2025-12-08 22:53:15 - INFO - Epoch: 3.36, Step: 10640, Train Loss: 3.2417, Learning Rate: 9.64e-05
2025-12-08 22:53:26 - INFO - Epoch: 3.36, Step: 10650, Train Loss: 3.2609, Learning Rate: 9.64e-05
2025-12-08 22:53:37 - INFO - Epoch: 3.36, Step: 10660, Train Loss: 3.2587, Learning Rate: 9.64e-05
2025-12-08 22:53:48 - INFO - Epoch: 3.37, Step: 10670, Train Loss: 3.2452, Learning Rate: 9.64e-05
2025-12-08 22:53:59 - INFO - Epoch: 3.37, Step: 10680, Train Loss: 3.2612, Learning Rate: 9.64e-05
2025-12-08 22:54:10 - INFO - Epoch: 3.37, Step: 10690, Train Loss: 3.2456, Learning Rate: 9.64e-05
2025-12-08 22:54:21 - INFO - Epoch: 3.38, Step: 10700, Train Loss: 3.2266, Learning Rate: 9.64e-05
2025-12-08 22:54:32 - INFO - Epoch: 3.38, Step: 10710, Train Loss: 3.2670, Learning Rate: 9.64e-05
2025-12-08 22:54:43 - INFO - Epoch: 3.38, Step: 10720, Train Loss: 3.2336, Learning Rate: 9.64e-05
2025-12-08 22:54:54 - INFO - Epoch: 3.39, Step: 10730, Train Loss: 3.2344, Learning Rate: 9.64e-05
2025-12-08 22:55:06 - INFO - Epoch: 3.39, Step: 10740, Train Loss: 3.2236, Learning Rate: 9.63e-05
2025-12-08 22:55:17 - INFO - Epoch: 3.39, Step: 10750, Train Loss: 3.2526, Learning Rate: 9.63e-05
2025-12-08 22:55:28 - INFO - Epoch: 3.40, Step: 10760, Train Loss: 3.2212, Learning Rate: 9.63e-05
2025-12-08 22:55:39 - INFO - Epoch: 3.40, Step: 10770, Train Loss: 3.2155, Learning Rate: 9.63e-05
2025-12-08 22:55:50 - INFO - Epoch: 3.40, Step: 10780, Train Loss: 3.2410, Learning Rate: 9.63e-05
2025-12-08 22:56:01 - INFO - Epoch: 3.40, Step: 10790, Train Loss: 3.1586, Learning Rate: 9.63e-05
2025-12-08 22:56:12 - INFO - Epoch: 3.41, Step: 10800, Train Loss: 3.2407, Learning Rate: 9.63e-05
2025-12-08 22:56:23 - INFO - Epoch: 3.41, Step: 10810, Train Loss: 3.1607, Learning Rate: 9.63e-05
2025-12-08 22:56:34 - INFO - Epoch: 3.41, Step: 10820, Train Loss: 3.1734, Learning Rate: 9.63e-05
2025-12-08 22:56:45 - INFO - Epoch: 3.42, Step: 10830, Train Loss: 3.2190, Learning Rate: 9.63e-05
2025-12-08 22:56:56 - INFO - Epoch: 3.42, Step: 10840, Train Loss: 3.2198, Learning Rate: 9.63e-05
2025-12-08 22:57:07 - INFO - Epoch: 3.42, Step: 10850, Train Loss: 3.1656, Learning Rate: 9.63e-05
2025-12-08 22:57:18 - INFO - Epoch: 3.43, Step: 10860, Train Loss: 3.1497, Learning Rate: 9.62e-05
2025-12-08 22:57:30 - INFO - Epoch: 3.43, Step: 10870, Train Loss: 3.1315, Learning Rate: 9.62e-05
2025-12-08 22:57:41 - INFO - Epoch: 3.43, Step: 10880, Train Loss: 3.1610, Learning Rate: 9.62e-05
2025-12-08 22:57:52 - INFO - Epoch: 3.44, Step: 10890, Train Loss: 3.2035, Learning Rate: 9.62e-05
2025-12-08 22:58:03 - INFO - Epoch: 3.44, Step: 10900, Train Loss: 3.1279, Learning Rate: 9.62e-05
2025-12-08 22:58:14 - INFO - Epoch: 3.44, Step: 10910, Train Loss: 3.1743, Learning Rate: 9.62e-05
2025-12-08 22:58:25 - INFO - Epoch: 3.45, Step: 10920, Train Loss: 3.1636, Learning Rate: 9.62e-05
2025-12-08 22:58:36 - INFO - Epoch: 3.45, Step: 10930, Train Loss: 3.1437, Learning Rate: 9.62e-05
2025-12-08 22:58:47 - INFO - Epoch: 3.45, Step: 10940, Train Loss: 3.1113, Learning Rate: 9.62e-05
2025-12-08 22:58:58 - INFO - Epoch: 3.46, Step: 10950, Train Loss: 3.1358, Learning Rate: 9.62e-05
2025-12-08 22:59:09 - INFO - Epoch: 3.46, Step: 10960, Train Loss: 3.1130, Learning Rate: 9.62e-05
2025-12-08 22:59:20 - INFO - Epoch: 3.46, Step: 10970, Train Loss: 3.1322, Learning Rate: 9.62e-05
2025-12-08 22:59:31 - INFO - Epoch: 3.46, Step: 10980, Train Loss: 3.1246, Learning Rate: 9.61e-05
2025-12-08 22:59:42 - INFO - Epoch: 3.47, Step: 10990, Train Loss: 3.0872, Learning Rate: 9.61e-05
2025-12-08 22:59:54 - INFO - Epoch: 3.47, Step: 11000, Train Loss: 3.1019, Learning Rate: 9.61e-05
2025-12-08 23:00:05 - INFO - Epoch: 3.47, Step: 11010, Train Loss: 3.1283, Learning Rate: 9.61e-05
2025-12-08 23:00:16 - INFO - Epoch: 3.48, Step: 11020, Train Loss: 3.1312, Learning Rate: 9.61e-05
2025-12-08 23:00:27 - INFO - Epoch: 3.48, Step: 11030, Train Loss: 3.0843, Learning Rate: 9.61e-05
2025-12-08 23:00:38 - INFO - Epoch: 3.48, Step: 11040, Train Loss: 3.1230, Learning Rate: 9.61e-05
2025-12-08 23:00:49 - INFO - Epoch: 3.49, Step: 11050, Train Loss: 3.1093, Learning Rate: 9.61e-05
2025-12-08 23:01:00 - INFO - Epoch: 3.49, Step: 11060, Train Loss: 3.0670, Learning Rate: 9.61e-05
2025-12-08 23:01:11 - INFO - Epoch: 3.49, Step: 11070, Train Loss: 3.1194, Learning Rate: 9.61e-05
2025-12-08 23:01:22 - INFO - Epoch: 3.50, Step: 11080, Train Loss: 3.0425, Learning Rate: 9.61e-05
2025-12-08 23:01:33 - INFO - Epoch: 3.50, Step: 11090, Train Loss: 3.1232, Learning Rate: 9.61e-05
2025-12-08 23:01:44 - INFO - Epoch: 3.50, Step: 11100, Train Loss: 3.0674, Learning Rate: 9.60e-05
2025-12-08 23:01:55 - INFO - Epoch: 3.51, Step: 11110, Train Loss: 3.0610, Learning Rate: 9.60e-05
2025-12-08 23:02:07 - INFO - Epoch: 3.51, Step: 11120, Train Loss: 3.0700, Learning Rate: 9.60e-05
2025-12-08 23:02:18 - INFO - Epoch: 3.51, Step: 11130, Train Loss: 3.0462, Learning Rate: 9.60e-05
2025-12-08 23:02:29 - INFO - Epoch: 3.52, Step: 11140, Train Loss: 3.0901, Learning Rate: 9.60e-05
2025-12-08 23:02:40 - INFO - Epoch: 3.52, Step: 11150, Train Loss: 3.0492, Learning Rate: 9.60e-05
2025-12-08 23:02:51 - INFO - Epoch: 3.52, Step: 11160, Train Loss: 3.0838, Learning Rate: 9.60e-05
2025-12-08 23:03:02 - INFO - Epoch: 3.52, Step: 11170, Train Loss: 3.0427, Learning Rate: 9.60e-05
2025-12-08 23:03:13 - INFO - Epoch: 3.53, Step: 11180, Train Loss: 3.0401, Learning Rate: 9.60e-05
2025-12-08 23:03:24 - INFO - Epoch: 3.53, Step: 11190, Train Loss: 3.0516, Learning Rate: 9.60e-05
2025-12-08 23:03:35 - INFO - Epoch: 3.53, Step: 11200, Train Loss: 3.0189, Learning Rate: 9.60e-05
2025-12-08 23:03:46 - INFO - Epoch: 3.54, Step: 11210, Train Loss: 3.0131, Learning Rate: 9.60e-05
2025-12-08 23:03:57 - INFO - Epoch: 3.54, Step: 11220, Train Loss: 3.0058, Learning Rate: 9.59e-05
2025-12-08 23:04:08 - INFO - Epoch: 3.54, Step: 11230, Train Loss: 3.0090, Learning Rate: 9.59e-05
2025-12-08 23:04:19 - INFO - Epoch: 3.55, Step: 11240, Train Loss: 3.0160, Learning Rate: 9.59e-05
2025-12-08 23:04:31 - INFO - Epoch: 3.55, Step: 11250, Train Loss: 2.9779, Learning Rate: 9.59e-05
2025-12-08 23:04:42 - INFO - Epoch: 3.55, Step: 11260, Train Loss: 3.0062, Learning Rate: 9.59e-05
2025-12-08 23:04:53 - INFO - Epoch: 3.56, Step: 11270, Train Loss: 2.9920, Learning Rate: 9.59e-05
2025-12-08 23:05:04 - INFO - Epoch: 3.56, Step: 11280, Train Loss: 3.0222, Learning Rate: 9.59e-05
2025-12-08 23:05:15 - INFO - Epoch: 3.56, Step: 11290, Train Loss: 2.9700, Learning Rate: 9.59e-05
2025-12-08 23:05:26 - INFO - Epoch: 3.57, Step: 11300, Train Loss: 3.0396, Learning Rate: 9.59e-05
2025-12-08 23:05:37 - INFO - Epoch: 3.57, Step: 11310, Train Loss: 2.9864, Learning Rate: 9.59e-05
2025-12-08 23:05:48 - INFO - Epoch: 3.57, Step: 11320, Train Loss: 2.9689, Learning Rate: 9.59e-05
2025-12-08 23:05:59 - INFO - Epoch: 3.58, Step: 11330, Train Loss: 2.9769, Learning Rate: 9.59e-05
2025-12-08 23:06:10 - INFO - Epoch: 3.58, Step: 11340, Train Loss: 2.9595, Learning Rate: 9.58e-05
2025-12-08 23:06:21 - INFO - Epoch: 3.58, Step: 11350, Train Loss: 2.9644, Learning Rate: 9.58e-05
2025-12-08 23:06:32 - INFO - Epoch: 3.58, Step: 11360, Train Loss: 2.9433, Learning Rate: 9.58e-05
2025-12-08 23:06:43 - INFO - Epoch: 3.59, Step: 11370, Train Loss: 2.9814, Learning Rate: 9.58e-05
2025-12-08 23:06:55 - INFO - Epoch: 3.59, Step: 11380, Train Loss: 2.9409, Learning Rate: 9.58e-05
2025-12-08 23:07:06 - INFO - Epoch: 3.59, Step: 11390, Train Loss: 2.9739, Learning Rate: 9.58e-05
2025-12-08 23:07:17 - INFO - Epoch: 3.60, Step: 11400, Train Loss: 2.9324, Learning Rate: 9.58e-05
2025-12-08 23:07:28 - INFO - Epoch: 3.60, Step: 11410, Train Loss: 2.9777, Learning Rate: 9.58e-05
2025-12-08 23:07:39 - INFO - Epoch: 3.60, Step: 11420, Train Loss: 2.9247, Learning Rate: 9.58e-05
2025-12-08 23:07:50 - INFO - Epoch: 3.61, Step: 11430, Train Loss: 2.9210, Learning Rate: 9.58e-05
2025-12-08 23:08:01 - INFO - Epoch: 3.61, Step: 11440, Train Loss: 2.9576, Learning Rate: 9.58e-05
2025-12-08 23:08:12 - INFO - Epoch: 3.61, Step: 11450, Train Loss: 2.9328, Learning Rate: 9.58e-05
2025-12-08 23:08:23 - INFO - Epoch: 3.62, Step: 11460, Train Loss: 2.9748, Learning Rate: 9.57e-05
2025-12-08 23:08:34 - INFO - Epoch: 3.62, Step: 11470, Train Loss: 2.9440, Learning Rate: 9.57e-05
2025-12-08 23:08:45 - INFO - Epoch: 3.62, Step: 11480, Train Loss: 2.9043, Learning Rate: 9.57e-05
2025-12-08 23:08:56 - INFO - Epoch: 3.63, Step: 11490, Train Loss: 2.9057, Learning Rate: 9.57e-05
2025-12-08 23:09:07 - INFO - Epoch: 3.63, Step: 11500, Train Loss: 2.9406, Learning Rate: 9.57e-05
2025-12-08 23:09:19 - INFO - Epoch: 3.63, Step: 11510, Train Loss: 2.8966, Learning Rate: 9.57e-05
2025-12-08 23:09:30 - INFO - Epoch: 3.64, Step: 11520, Train Loss: 2.9124, Learning Rate: 9.57e-05
2025-12-08 23:09:41 - INFO - Epoch: 3.64, Step: 11530, Train Loss: 2.8821, Learning Rate: 9.57e-05
2025-12-08 23:09:52 - INFO - Epoch: 3.64, Step: 11540, Train Loss: 2.9343, Learning Rate: 9.57e-05
2025-12-08 23:10:03 - INFO - Epoch: 3.64, Step: 11550, Train Loss: 2.8899, Learning Rate: 9.57e-05
2025-12-08 23:10:14 - INFO - Epoch: 3.65, Step: 11560, Train Loss: 2.9337, Learning Rate: 9.57e-05
2025-12-08 23:10:25 - INFO - Epoch: 3.65, Step: 11570, Train Loss: 2.8869, Learning Rate: 9.57e-05
2025-12-08 23:10:36 - INFO - Epoch: 3.65, Step: 11580, Train Loss: 2.9035, Learning Rate: 9.56e-05
2025-12-08 23:10:47 - INFO - Epoch: 3.66, Step: 11590, Train Loss: 2.8831, Learning Rate: 9.56e-05
2025-12-08 23:10:58 - INFO - Epoch: 3.66, Step: 11600, Train Loss: 2.9469, Learning Rate: 9.56e-05
2025-12-08 23:11:09 - INFO - Epoch: 3.66, Step: 11610, Train Loss: 2.8389, Learning Rate: 9.56e-05
2025-12-08 23:11:20 - INFO - Epoch: 3.67, Step: 11620, Train Loss: 2.8743, Learning Rate: 9.56e-05
2025-12-08 23:11:31 - INFO - Epoch: 3.67, Step: 11630, Train Loss: 2.8627, Learning Rate: 9.56e-05
2025-12-08 23:11:43 - INFO - Epoch: 3.67, Step: 11640, Train Loss: 2.8628, Learning Rate: 9.56e-05
2025-12-08 23:11:54 - INFO - Epoch: 3.68, Step: 11650, Train Loss: 2.8819, Learning Rate: 9.56e-05
2025-12-08 23:12:05 - INFO - Epoch: 3.68, Step: 11660, Train Loss: 2.8676, Learning Rate: 9.56e-05
2025-12-08 23:12:16 - INFO - Epoch: 3.68, Step: 11670, Train Loss: 2.8874, Learning Rate: 9.56e-05
2025-12-08 23:12:27 - INFO - Epoch: 3.69, Step: 11680, Train Loss: 2.8767, Learning Rate: 9.56e-05
2025-12-08 23:12:38 - INFO - Epoch: 3.69, Step: 11690, Train Loss: 2.8361, Learning Rate: 9.56e-05
2025-12-08 23:12:49 - INFO - Epoch: 3.69, Step: 11700, Train Loss: 2.8724, Learning Rate: 9.55e-05
2025-12-08 23:13:00 - INFO - Epoch: 3.70, Step: 11710, Train Loss: 2.8867, Learning Rate: 9.55e-05
2025-12-08 23:13:11 - INFO - Epoch: 3.70, Step: 11720, Train Loss: 2.8812, Learning Rate: 9.55e-05
2025-12-08 23:13:22 - INFO - Epoch: 3.70, Step: 11730, Train Loss: 2.8262, Learning Rate: 9.55e-05
2025-12-08 23:13:33 - INFO - Epoch: 3.70, Step: 11740, Train Loss: 2.8068, Learning Rate: 9.55e-05
2025-12-08 23:13:44 - INFO - Epoch: 3.71, Step: 11750, Train Loss: 2.8648, Learning Rate: 9.55e-05
2025-12-08 23:13:56 - INFO - Epoch: 3.71, Step: 11760, Train Loss: 2.8022, Learning Rate: 9.55e-05
2025-12-08 23:14:07 - INFO - Epoch: 3.71, Step: 11770, Train Loss: 2.7953, Learning Rate: 9.55e-05
2025-12-08 23:14:18 - INFO - Epoch: 3.72, Step: 11780, Train Loss: 2.8518, Learning Rate: 9.55e-05
2025-12-08 23:14:29 - INFO - Epoch: 3.72, Step: 11790, Train Loss: 2.8197, Learning Rate: 9.55e-05
2025-12-08 23:14:40 - INFO - Epoch: 3.72, Step: 11800, Train Loss: 2.8541, Learning Rate: 9.55e-05
2025-12-08 23:14:51 - INFO - Epoch: 3.73, Step: 11810, Train Loss: 2.8227, Learning Rate: 9.55e-05
2025-12-08 23:15:02 - INFO - Epoch: 3.73, Step: 11820, Train Loss: 2.8186, Learning Rate: 9.54e-05
2025-12-08 23:15:13 - INFO - Epoch: 3.73, Step: 11830, Train Loss: 2.8165, Learning Rate: 9.54e-05
2025-12-08 23:15:24 - INFO - Epoch: 3.74, Step: 11840, Train Loss: 2.7837, Learning Rate: 9.54e-05
2025-12-08 23:15:35 - INFO - Epoch: 3.74, Step: 11850, Train Loss: 2.7618, Learning Rate: 9.54e-05
2025-12-08 23:15:46 - INFO - Epoch: 3.74, Step: 11860, Train Loss: 2.8448, Learning Rate: 9.54e-05
2025-12-08 23:15:57 - INFO - Epoch: 3.75, Step: 11870, Train Loss: 2.8179, Learning Rate: 9.54e-05
2025-12-08 23:16:08 - INFO - Epoch: 3.75, Step: 11880, Train Loss: 2.8205, Learning Rate: 9.54e-05
2025-12-08 23:16:20 - INFO - Epoch: 3.75, Step: 11890, Train Loss: 2.8200, Learning Rate: 9.54e-05
2025-12-08 23:16:31 - INFO - Epoch: 3.76, Step: 11900, Train Loss: 2.8002, Learning Rate: 9.54e-05
2025-12-08 23:16:42 - INFO - Epoch: 3.76, Step: 11910, Train Loss: 2.7808, Learning Rate: 9.54e-05
2025-12-08 23:16:53 - INFO - Epoch: 3.76, Step: 11920, Train Loss: 2.8156, Learning Rate: 9.54e-05
2025-12-08 23:17:04 - INFO - Epoch: 3.76, Step: 11930, Train Loss: 2.8130, Learning Rate: 9.54e-05
2025-12-08 23:17:15 - INFO - Epoch: 3.77, Step: 11940, Train Loss: 2.8029, Learning Rate: 9.53e-05
2025-12-08 23:17:26 - INFO - Epoch: 3.77, Step: 11950, Train Loss: 2.7749, Learning Rate: 9.53e-05
2025-12-08 23:17:37 - INFO - Epoch: 3.77, Step: 11960, Train Loss: 2.7899, Learning Rate: 9.53e-05
2025-12-08 23:17:48 - INFO - Epoch: 3.78, Step: 11970, Train Loss: 2.7984, Learning Rate: 9.53e-05
2025-12-08 23:17:59 - INFO - Epoch: 3.78, Step: 11980, Train Loss: 2.7864, Learning Rate: 9.53e-05
2025-12-08 23:18:10 - INFO - Epoch: 3.78, Step: 11990, Train Loss: 2.8036, Learning Rate: 9.53e-05
2025-12-08 23:18:21 - INFO - Epoch: 3.79, Step: 12000, Train Loss: 2.7609, Learning Rate: 9.53e-05
2025-12-08 23:18:32 - INFO - Epoch: 3.79, Step: 12010, Train Loss: 2.7541, Learning Rate: 9.53e-05
2025-12-08 23:18:44 - INFO - Epoch: 3.79, Step: 12020, Train Loss: 2.8094, Learning Rate: 9.53e-05
2025-12-08 23:18:55 - INFO - Epoch: 3.80, Step: 12030, Train Loss: 2.8130, Learning Rate: 9.53e-05
2025-12-08 23:19:06 - INFO - Epoch: 3.80, Step: 12040, Train Loss: 2.7454, Learning Rate: 9.53e-05
2025-12-08 23:19:17 - INFO - Epoch: 3.80, Step: 12050, Train Loss: 2.7750, Learning Rate: 9.53e-05
2025-12-08 23:19:28 - INFO - Epoch: 3.81, Step: 12060, Train Loss: 2.7143, Learning Rate: 9.52e-05
2025-12-08 23:19:39 - INFO - Epoch: 3.81, Step: 12070, Train Loss: 2.7750, Learning Rate: 9.52e-05
2025-12-08 23:19:50 - INFO - Epoch: 3.81, Step: 12080, Train Loss: 2.7709, Learning Rate: 9.52e-05
2025-12-08 23:20:01 - INFO - Epoch: 3.82, Step: 12090, Train Loss: 2.7443, Learning Rate: 9.52e-05
2025-12-08 23:20:12 - INFO - Epoch: 3.82, Step: 12100, Train Loss: 2.7028, Learning Rate: 9.52e-05
2025-12-08 23:20:23 - INFO - Epoch: 3.82, Step: 12110, Train Loss: 2.7590, Learning Rate: 9.52e-05
2025-12-08 23:20:34 - INFO - Epoch: 3.82, Step: 12120, Train Loss: 2.7449, Learning Rate: 9.52e-05
2025-12-08 23:20:45 - INFO - Epoch: 3.83, Step: 12130, Train Loss: 2.7122, Learning Rate: 9.52e-05
2025-12-08 23:20:56 - INFO - Epoch: 3.83, Step: 12140, Train Loss: 2.6889, Learning Rate: 9.52e-05
2025-12-08 23:21:08 - INFO - Epoch: 3.83, Step: 12150, Train Loss: 2.7382, Learning Rate: 9.52e-05
2025-12-08 23:21:19 - INFO - Epoch: 3.84, Step: 12160, Train Loss: 2.7483, Learning Rate: 9.52e-05
2025-12-08 23:21:30 - INFO - Epoch: 3.84, Step: 12170, Train Loss: 2.7013, Learning Rate: 9.52e-05
2025-12-08 23:21:41 - INFO - Epoch: 3.84, Step: 12180, Train Loss: 2.7416, Learning Rate: 9.51e-05
2025-12-08 23:21:52 - INFO - Epoch: 3.85, Step: 12190, Train Loss: 2.7066, Learning Rate: 9.51e-05
2025-12-08 23:22:03 - INFO - Epoch: 3.85, Step: 12200, Train Loss: 2.7126, Learning Rate: 9.51e-05
2025-12-08 23:22:14 - INFO - Epoch: 3.85, Step: 12210, Train Loss: 2.7119, Learning Rate: 9.51e-05
2025-12-08 23:22:25 - INFO - Epoch: 3.86, Step: 12220, Train Loss: 2.6973, Learning Rate: 9.51e-05
2025-12-08 23:22:36 - INFO - Epoch: 3.86, Step: 12230, Train Loss: 2.7474, Learning Rate: 9.51e-05
2025-12-08 23:22:47 - INFO - Epoch: 3.86, Step: 12240, Train Loss: 2.7426, Learning Rate: 9.51e-05
2025-12-08 23:22:58 - INFO - Epoch: 3.87, Step: 12250, Train Loss: 2.7248, Learning Rate: 9.51e-05
2025-12-08 23:23:09 - INFO - Epoch: 3.87, Step: 12260, Train Loss: 2.7294, Learning Rate: 9.51e-05
2025-12-08 23:23:20 - INFO - Epoch: 3.87, Step: 12270, Train Loss: 2.6933, Learning Rate: 9.51e-05
2025-12-08 23:23:32 - INFO - Epoch: 3.88, Step: 12280, Train Loss: 2.6731, Learning Rate: 9.51e-05
2025-12-08 23:23:43 - INFO - Epoch: 3.88, Step: 12290, Train Loss: 2.7145, Learning Rate: 9.51e-05
2025-12-08 23:23:54 - INFO - Epoch: 3.88, Step: 12300, Train Loss: 2.6796, Learning Rate: 9.50e-05
2025-12-08 23:24:05 - INFO - Epoch: 3.88, Step: 12310, Train Loss: 2.6789, Learning Rate: 9.50e-05
2025-12-08 23:24:16 - INFO - Epoch: 3.89, Step: 12320, Train Loss: 2.7090, Learning Rate: 9.50e-05
2025-12-08 23:24:27 - INFO - Epoch: 3.89, Step: 12330, Train Loss: 2.6728, Learning Rate: 9.50e-05
2025-12-08 23:24:38 - INFO - Epoch: 3.89, Step: 12340, Train Loss: 2.6638, Learning Rate: 9.50e-05
2025-12-08 23:24:49 - INFO - Epoch: 3.90, Step: 12350, Train Loss: 2.7080, Learning Rate: 9.50e-05
2025-12-08 23:25:00 - INFO - Epoch: 3.90, Step: 12360, Train Loss: 2.6858, Learning Rate: 9.50e-05
2025-12-08 23:25:11 - INFO - Epoch: 3.90, Step: 12370, Train Loss: 2.6830, Learning Rate: 9.50e-05
2025-12-08 23:25:22 - INFO - Epoch: 3.91, Step: 12380, Train Loss: 2.6413, Learning Rate: 9.50e-05
2025-12-08 23:25:33 - INFO - Epoch: 3.91, Step: 12390, Train Loss: 2.6928, Learning Rate: 9.50e-05
2025-12-08 23:25:45 - INFO - Epoch: 3.91, Step: 12400, Train Loss: 2.6568, Learning Rate: 9.50e-05
2025-12-08 23:25:56 - INFO - Epoch: 3.92, Step: 12410, Train Loss: 2.6434, Learning Rate: 9.50e-05
2025-12-08 23:26:07 - INFO - Epoch: 3.92, Step: 12420, Train Loss: 2.6547, Learning Rate: 9.50e-05
2025-12-08 23:26:18 - INFO - Epoch: 3.92, Step: 12430, Train Loss: 2.6560, Learning Rate: 9.49e-05
2025-12-08 23:26:29 - INFO - Epoch: 3.93, Step: 12440, Train Loss: 2.6982, Learning Rate: 9.49e-05
2025-12-08 23:26:40 - INFO - Epoch: 3.93, Step: 12450, Train Loss: 2.6464, Learning Rate: 9.49e-05
2025-12-08 23:26:51 - INFO - Epoch: 3.93, Step: 12460, Train Loss: 2.6643, Learning Rate: 9.49e-05
2025-12-08 23:27:02 - INFO - Epoch: 3.93, Step: 12470, Train Loss: 2.6422, Learning Rate: 9.49e-05
2025-12-08 23:27:13 - INFO - Epoch: 3.94, Step: 12480, Train Loss: 2.6454, Learning Rate: 9.49e-05
2025-12-08 23:27:24 - INFO - Epoch: 3.94, Step: 12490, Train Loss: 2.6519, Learning Rate: 9.49e-05
2025-12-08 23:27:35 - INFO - Epoch: 3.94, Step: 12500, Train Loss: 2.6130, Learning Rate: 9.49e-05
2025-12-08 23:27:46 - INFO - Epoch: 3.95, Step: 12510, Train Loss: 2.6011, Learning Rate: 9.49e-05
2025-12-08 23:27:57 - INFO - Epoch: 3.95, Step: 12520, Train Loss: 2.6317, Learning Rate: 9.49e-05
2025-12-08 23:28:09 - INFO - Epoch: 3.95, Step: 12530, Train Loss: 2.6766, Learning Rate: 9.49e-05
2025-12-08 23:28:20 - INFO - Epoch: 3.96, Step: 12540, Train Loss: 2.6657, Learning Rate: 9.49e-05
2025-12-08 23:28:31 - INFO - Epoch: 3.96, Step: 12550, Train Loss: 2.6712, Learning Rate: 9.48e-05
2025-12-08 23:28:42 - INFO - Epoch: 3.96, Step: 12560, Train Loss: 2.6013, Learning Rate: 9.48e-05
2025-12-08 23:28:53 - INFO - Epoch: 3.97, Step: 12570, Train Loss: 2.5972, Learning Rate: 9.48e-05
2025-12-08 23:29:04 - INFO - Epoch: 3.97, Step: 12580, Train Loss: 2.6528, Learning Rate: 9.48e-05
2025-12-08 23:29:15 - INFO - Epoch: 3.97, Step: 12590, Train Loss: 2.6360, Learning Rate: 9.48e-05
2025-12-08 23:29:26 - INFO - Epoch: 3.98, Step: 12600, Train Loss: 2.6326, Learning Rate: 9.48e-05
2025-12-08 23:29:37 - INFO - Epoch: 3.98, Step: 12610, Train Loss: 2.6328, Learning Rate: 9.48e-05
2025-12-08 23:29:48 - INFO - Epoch: 3.98, Step: 12620, Train Loss: 2.6670, Learning Rate: 9.48e-05
2025-12-08 23:29:59 - INFO - Epoch: 3.99, Step: 12630, Train Loss: 2.6027, Learning Rate: 9.48e-05
2025-12-08 23:30:10 - INFO - Epoch: 3.99, Step: 12640, Train Loss: 2.6188, Learning Rate: 9.48e-05
2025-12-08 23:30:21 - INFO - Epoch: 3.99, Step: 12650, Train Loss: 2.6092, Learning Rate: 9.48e-05
2025-12-08 23:30:33 - INFO - Epoch: 3.99, Step: 12660, Train Loss: 2.5933, Learning Rate: 9.48e-05
2025-12-08 23:30:44 - INFO - Epoch: 4.00, Step: 12670, Train Loss: 2.6334, Learning Rate: 9.47e-05
2025-12-08 23:30:55 - INFO - Epoch: 4.00, Step: 12680, Train Loss: 2.6189, Learning Rate: 9.47e-05
2025-12-08 23:31:06 - INFO - Epoch: 4.00, Step: 12690, Train Loss: 2.6206, Learning Rate: 9.47e-05
2025-12-08 23:31:17 - INFO - Epoch: 4.01, Step: 12700, Train Loss: 2.5984, Learning Rate: 9.47e-05
2025-12-08 23:31:28 - INFO - Epoch: 4.01, Step: 12710, Train Loss: 2.5874, Learning Rate: 9.47e-05
2025-12-08 23:31:39 - INFO - Epoch: 4.01, Step: 12720, Train Loss: 2.5501, Learning Rate: 9.47e-05
2025-12-08 23:31:50 - INFO - Epoch: 4.02, Step: 12730, Train Loss: 2.5535, Learning Rate: 9.47e-05
2025-12-08 23:32:01 - INFO - Epoch: 4.02, Step: 12740, Train Loss: 2.5688, Learning Rate: 9.47e-05
2025-12-08 23:32:12 - INFO - Epoch: 4.02, Step: 12750, Train Loss: 2.5568, Learning Rate: 9.47e-05
2025-12-08 23:32:23 - INFO - Epoch: 4.03, Step: 12760, Train Loss: 2.5694, Learning Rate: 9.47e-05
2025-12-08 23:32:34 - INFO - Epoch: 4.03, Step: 12770, Train Loss: 2.6206, Learning Rate: 9.47e-05
2025-12-08 23:32:46 - INFO - Epoch: 4.03, Step: 12780, Train Loss: 2.5870, Learning Rate: 9.47e-05
2025-12-08 23:32:57 - INFO - Epoch: 4.04, Step: 12790, Train Loss: 2.6113, Learning Rate: 9.46e-05
2025-12-08 23:33:08 - INFO - Epoch: 4.04, Step: 12800, Train Loss: 2.6297, Learning Rate: 9.46e-05
2025-12-08 23:33:19 - INFO - Epoch: 4.04, Step: 12810, Train Loss: 2.6081, Learning Rate: 9.46e-05
2025-12-08 23:33:30 - INFO - Epoch: 4.05, Step: 12820, Train Loss: 2.5835, Learning Rate: 9.46e-05
2025-12-08 23:33:41 - INFO - Epoch: 4.05, Step: 12830, Train Loss: 2.6049, Learning Rate: 9.46e-05
2025-12-08 23:33:52 - INFO - Epoch: 4.05, Step: 12840, Train Loss: 2.6337, Learning Rate: 9.46e-05
2025-12-08 23:34:03 - INFO - Epoch: 4.05, Step: 12850, Train Loss: 2.5721, Learning Rate: 9.46e-05
2025-12-08 23:34:14 - INFO - Epoch: 4.06, Step: 12860, Train Loss: 2.5939, Learning Rate: 9.46e-05
2025-12-08 23:34:25 - INFO - Epoch: 4.06, Step: 12870, Train Loss: 2.5920, Learning Rate: 9.46e-05
2025-12-08 23:34:36 - INFO - Epoch: 4.06, Step: 12880, Train Loss: 2.5919, Learning Rate: 9.46e-05
2025-12-08 23:34:47 - INFO - Epoch: 4.07, Step: 12890, Train Loss: 2.5529, Learning Rate: 9.46e-05
2025-12-08 23:34:58 - INFO - Epoch: 4.07, Step: 12900, Train Loss: 2.5654, Learning Rate: 9.46e-05
2025-12-08 23:35:10 - INFO - Epoch: 4.07, Step: 12910, Train Loss: 2.5836, Learning Rate: 9.45e-05
2025-12-08 23:35:21 - INFO - Epoch: 4.08, Step: 12920, Train Loss: 2.5646, Learning Rate: 9.45e-05
2025-12-08 23:35:32 - INFO - Epoch: 4.08, Step: 12930, Train Loss: 2.5692, Learning Rate: 9.45e-05
2025-12-08 23:35:43 - INFO - Epoch: 4.08, Step: 12940, Train Loss: 2.5605, Learning Rate: 9.45e-05
2025-12-08 23:35:54 - INFO - Epoch: 4.09, Step: 12950, Train Loss: 2.5728, Learning Rate: 9.45e-05
2025-12-08 23:36:05 - INFO - Epoch: 4.09, Step: 12960, Train Loss: 2.5739, Learning Rate: 9.45e-05
2025-12-08 23:36:16 - INFO - Epoch: 4.09, Step: 12970, Train Loss: 2.5394, Learning Rate: 9.45e-05
2025-12-08 23:36:27 - INFO - Epoch: 4.10, Step: 12980, Train Loss: 2.4882, Learning Rate: 9.45e-05
2025-12-08 23:36:38 - INFO - Epoch: 4.10, Step: 12990, Train Loss: 2.5661, Learning Rate: 9.45e-05
2025-12-08 23:36:49 - INFO - Epoch: 4.10, Step: 13000, Train Loss: 2.5600, Learning Rate: 9.45e-05
2025-12-08 23:37:00 - INFO - Epoch: 4.11, Step: 13010, Train Loss: 2.5381, Learning Rate: 9.45e-05
2025-12-08 23:37:11 - INFO - Epoch: 4.11, Step: 13020, Train Loss: 2.5434, Learning Rate: 9.45e-05
2025-12-08 23:37:23 - INFO - Epoch: 4.11, Step: 13030, Train Loss: 2.5662, Learning Rate: 9.44e-05
2025-12-08 23:37:34 - INFO - Epoch: 4.11, Step: 13040, Train Loss: 2.5392, Learning Rate: 9.44e-05
2025-12-08 23:37:45 - INFO - Epoch: 4.12, Step: 13050, Train Loss: 2.5291, Learning Rate: 9.44e-05
2025-12-08 23:37:56 - INFO - Epoch: 4.12, Step: 13060, Train Loss: 2.5509, Learning Rate: 9.44e-05
2025-12-08 23:38:07 - INFO - Epoch: 4.12, Step: 13070, Train Loss: 2.5286, Learning Rate: 9.44e-05
2025-12-08 23:38:18 - INFO - Epoch: 4.13, Step: 13080, Train Loss: 2.5625, Learning Rate: 9.44e-05
2025-12-08 23:38:29 - INFO - Epoch: 4.13, Step: 13090, Train Loss: 2.5144, Learning Rate: 9.44e-05
2025-12-08 23:38:40 - INFO - Epoch: 4.13, Step: 13100, Train Loss: 2.5114, Learning Rate: 9.44e-05
2025-12-08 23:38:51 - INFO - Epoch: 4.14, Step: 13110, Train Loss: 2.5726, Learning Rate: 9.44e-05
2025-12-08 23:39:02 - INFO - Epoch: 4.14, Step: 13120, Train Loss: 2.5669, Learning Rate: 9.44e-05
2025-12-08 23:39:13 - INFO - Epoch: 4.14, Step: 13130, Train Loss: 2.5422, Learning Rate: 9.44e-05
2025-12-08 23:39:24 - INFO - Epoch: 4.15, Step: 13140, Train Loss: 2.5335, Learning Rate: 9.44e-05
2025-12-08 23:39:35 - INFO - Epoch: 4.15, Step: 13150, Train Loss: 2.5171, Learning Rate: 9.43e-05
2025-12-08 23:39:47 - INFO - Epoch: 4.15, Step: 13160, Train Loss: 2.4929, Learning Rate: 9.43e-05
2025-12-08 23:39:58 - INFO - Epoch: 4.16, Step: 13170, Train Loss: 2.5160, Learning Rate: 9.43e-05
2025-12-08 23:40:09 - INFO - Epoch: 4.16, Step: 13180, Train Loss: 2.5081, Learning Rate: 9.43e-05
2025-12-08 23:40:20 - INFO - Epoch: 4.16, Step: 13190, Train Loss: 2.5383, Learning Rate: 9.43e-05
2025-12-08 23:40:31 - INFO - Epoch: 4.17, Step: 13200, Train Loss: 2.5005, Learning Rate: 9.43e-05
2025-12-08 23:40:42 - INFO - Epoch: 4.17, Step: 13210, Train Loss: 2.5727, Learning Rate: 9.43e-05
2025-12-08 23:40:53 - INFO - Epoch: 4.17, Step: 13220, Train Loss: 2.5414, Learning Rate: 9.43e-05
2025-12-08 23:41:04 - INFO - Epoch: 4.17, Step: 13230, Train Loss: 2.5656, Learning Rate: 9.43e-05
2025-12-08 23:41:15 - INFO - Epoch: 4.18, Step: 13240, Train Loss: 2.4978, Learning Rate: 9.43e-05
2025-12-08 23:41:26 - INFO - Epoch: 4.18, Step: 13250, Train Loss: 2.4840, Learning Rate: 9.43e-05
2025-12-08 23:41:37 - INFO - Epoch: 4.18, Step: 13260, Train Loss: 2.5108, Learning Rate: 9.43e-05
2025-12-08 23:41:48 - INFO - Epoch: 4.19, Step: 13270, Train Loss: 2.4931, Learning Rate: 9.42e-05
2025-12-08 23:42:00 - INFO - Epoch: 4.19, Step: 13280, Train Loss: 2.5295, Learning Rate: 9.42e-05
2025-12-08 23:42:11 - INFO - Epoch: 4.19, Step: 13290, Train Loss: 2.5586, Learning Rate: 9.42e-05
2025-12-08 23:42:22 - INFO - Epoch: 4.20, Step: 13300, Train Loss: 2.5189, Learning Rate: 9.42e-05
2025-12-08 23:42:33 - INFO - Epoch: 4.20, Step: 13310, Train Loss: 2.4695, Learning Rate: 9.42e-05
2025-12-08 23:42:44 - INFO - Epoch: 4.20, Step: 13320, Train Loss: 2.4911, Learning Rate: 9.42e-05
2025-12-08 23:42:55 - INFO - Epoch: 4.21, Step: 13330, Train Loss: 2.4939, Learning Rate: 9.42e-05
2025-12-08 23:43:06 - INFO - Epoch: 4.21, Step: 13340, Train Loss: 2.4662, Learning Rate: 9.42e-05
2025-12-08 23:43:17 - INFO - Epoch: 4.21, Step: 13350, Train Loss: 2.5313, Learning Rate: 9.42e-05
2025-12-08 23:43:28 - INFO - Epoch: 4.22, Step: 13360, Train Loss: 2.4322, Learning Rate: 9.42e-05
2025-12-08 23:43:39 - INFO - Epoch: 4.22, Step: 13370, Train Loss: 2.4795, Learning Rate: 9.42e-05
2025-12-08 23:43:50 - INFO - Epoch: 4.22, Step: 13380, Train Loss: 2.4957, Learning Rate: 9.42e-05
2025-12-08 23:44:01 - INFO - Epoch: 4.23, Step: 13390, Train Loss: 2.4682, Learning Rate: 9.41e-05
2025-12-08 23:44:12 - INFO - Epoch: 4.23, Step: 13400, Train Loss: 2.4755, Learning Rate: 9.41e-05
2025-12-08 23:44:24 - INFO - Epoch: 4.23, Step: 13410, Train Loss: 2.4722, Learning Rate: 9.41e-05
2025-12-08 23:44:35 - INFO - Epoch: 4.23, Step: 13420, Train Loss: 2.4904, Learning Rate: 9.41e-05
2025-12-08 23:44:46 - INFO - Epoch: 4.24, Step: 13430, Train Loss: 2.4581, Learning Rate: 9.41e-05
2025-12-08 23:44:57 - INFO - Epoch: 4.24, Step: 13440, Train Loss: 2.4710, Learning Rate: 9.41e-05
2025-12-08 23:45:08 - INFO - Epoch: 4.24, Step: 13450, Train Loss: 2.4741, Learning Rate: 9.41e-05
2025-12-08 23:45:19 - INFO - Epoch: 4.25, Step: 13460, Train Loss: 2.4545, Learning Rate: 9.41e-05
2025-12-08 23:45:30 - INFO - Epoch: 4.25, Step: 13470, Train Loss: 2.4936, Learning Rate: 9.41e-05
2025-12-08 23:45:41 - INFO - Epoch: 4.25, Step: 13480, Train Loss: 2.4977, Learning Rate: 9.41e-05
2025-12-08 23:45:52 - INFO - Epoch: 4.26, Step: 13490, Train Loss: 2.4690, Learning Rate: 9.41e-05
2025-12-08 23:46:03 - INFO - Epoch: 4.26, Step: 13500, Train Loss: 2.5277, Learning Rate: 9.41e-05
2025-12-08 23:46:14 - INFO - Epoch: 4.26, Step: 13510, Train Loss: 2.4647, Learning Rate: 9.40e-05
2025-12-08 23:46:25 - INFO - Epoch: 4.27, Step: 13520, Train Loss: 2.5027, Learning Rate: 9.40e-05
2025-12-08 23:46:37 - INFO - Epoch: 4.27, Step: 13530, Train Loss: 2.4581, Learning Rate: 9.40e-05
2025-12-08 23:46:48 - INFO - Epoch: 4.27, Step: 13540, Train Loss: 2.4889, Learning Rate: 9.40e-05
2025-12-08 23:46:59 - INFO - Epoch: 4.28, Step: 13550, Train Loss: 2.4640, Learning Rate: 9.40e-05
2025-12-08 23:47:10 - INFO - Epoch: 4.28, Step: 13560, Train Loss: 2.4411, Learning Rate: 9.40e-05
2025-12-08 23:47:21 - INFO - Epoch: 4.28, Step: 13570, Train Loss: 2.4253, Learning Rate: 9.40e-05
2025-12-08 23:47:32 - INFO - Epoch: 4.29, Step: 13580, Train Loss: 2.4566, Learning Rate: 9.40e-05
2025-12-08 23:47:43 - INFO - Epoch: 4.29, Step: 13590, Train Loss: 2.4909, Learning Rate: 9.40e-05
2025-12-08 23:47:54 - INFO - Epoch: 4.29, Step: 13600, Train Loss: 2.4368, Learning Rate: 9.40e-05
2025-12-08 23:48:05 - INFO - Epoch: 4.29, Step: 13610, Train Loss: 2.5054, Learning Rate: 9.40e-05
2025-12-08 23:48:16 - INFO - Epoch: 4.30, Step: 13620, Train Loss: 2.4768, Learning Rate: 9.40e-05
2025-12-08 23:48:27 - INFO - Epoch: 4.30, Step: 13630, Train Loss: 2.4453, Learning Rate: 9.39e-05
2025-12-08 23:48:38 - INFO - Epoch: 4.30, Step: 13640, Train Loss: 2.4733, Learning Rate: 9.39e-05
2025-12-08 23:48:49 - INFO - Epoch: 4.31, Step: 13650, Train Loss: 2.4620, Learning Rate: 9.39e-05
2025-12-08 23:49:01 - INFO - Epoch: 4.31, Step: 13660, Train Loss: 2.4661, Learning Rate: 9.39e-05
2025-12-08 23:49:12 - INFO - Epoch: 4.31, Step: 13670, Train Loss: 2.4278, Learning Rate: 9.39e-05
2025-12-08 23:49:23 - INFO - Epoch: 4.32, Step: 13680, Train Loss: 2.4602, Learning Rate: 9.39e-05
2025-12-08 23:49:34 - INFO - Epoch: 4.32, Step: 13690, Train Loss: 2.4132, Learning Rate: 9.39e-05
2025-12-08 23:49:45 - INFO - Epoch: 4.32, Step: 13700, Train Loss: 2.4763, Learning Rate: 9.39e-05
2025-12-08 23:49:56 - INFO - Epoch: 4.33, Step: 13710, Train Loss: 2.4467, Learning Rate: 9.39e-05
2025-12-08 23:50:07 - INFO - Epoch: 4.33, Step: 13720, Train Loss: 2.4683, Learning Rate: 9.39e-05
2025-12-08 23:50:18 - INFO - Epoch: 4.33, Step: 13730, Train Loss: 2.4241, Learning Rate: 9.39e-05
2025-12-08 23:50:29 - INFO - Epoch: 4.34, Step: 13740, Train Loss: 2.4401, Learning Rate: 9.39e-05
2025-12-08 23:50:40 - INFO - Epoch: 4.34, Step: 13750, Train Loss: 2.5005, Learning Rate: 9.38e-05
2025-12-08 23:50:51 - INFO - Epoch: 4.34, Step: 13760, Train Loss: 2.4469, Learning Rate: 9.38e-05
2025-12-08 23:51:02 - INFO - Epoch: 4.35, Step: 13770, Train Loss: 2.3875, Learning Rate: 9.38e-05
2025-12-08 23:51:14 - INFO - Epoch: 4.35, Step: 13780, Train Loss: 2.4149, Learning Rate: 9.38e-05
2025-12-08 23:51:25 - INFO - Epoch: 4.35, Step: 13790, Train Loss: 2.4014, Learning Rate: 9.38e-05
2025-12-08 23:51:36 - INFO - Epoch: 4.35, Step: 13800, Train Loss: 2.4121, Learning Rate: 9.38e-05
2025-12-08 23:51:47 - INFO - Epoch: 4.36, Step: 13810, Train Loss: 2.4093, Learning Rate: 9.38e-05
2025-12-08 23:51:58 - INFO - Epoch: 4.36, Step: 13820, Train Loss: 2.4161, Learning Rate: 9.38e-05
2025-12-08 23:52:09 - INFO - Epoch: 4.36, Step: 13830, Train Loss: 2.4068, Learning Rate: 9.38e-05
2025-12-08 23:52:20 - INFO - Epoch: 4.37, Step: 13840, Train Loss: 2.4235, Learning Rate: 9.38e-05
2025-12-08 23:52:31 - INFO - Epoch: 4.37, Step: 13850, Train Loss: 2.4408, Learning Rate: 9.38e-05
2025-12-08 23:52:42 - INFO - Epoch: 4.37, Step: 13860, Train Loss: 2.4356, Learning Rate: 9.38e-05
2025-12-08 23:52:53 - INFO - Epoch: 4.38, Step: 13870, Train Loss: 2.3909, Learning Rate: 9.37e-05
2025-12-08 23:53:04 - INFO - Epoch: 4.38, Step: 13880, Train Loss: 2.4399, Learning Rate: 9.37e-05
2025-12-08 23:53:15 - INFO - Epoch: 4.38, Step: 13890, Train Loss: 2.3600, Learning Rate: 9.37e-05
2025-12-08 23:53:26 - INFO - Epoch: 4.39, Step: 13900, Train Loss: 2.3951, Learning Rate: 9.37e-05
2025-12-08 23:53:38 - INFO - Epoch: 4.39, Step: 13910, Train Loss: 2.4560, Learning Rate: 9.37e-05
2025-12-08 23:53:49 - INFO - Epoch: 4.39, Step: 13920, Train Loss: 2.3758, Learning Rate: 9.37e-05
2025-12-08 23:54:00 - INFO - Epoch: 4.40, Step: 13930, Train Loss: 2.4256, Learning Rate: 9.37e-05
2025-12-08 23:54:11 - INFO - Epoch: 4.40, Step: 13940, Train Loss: 2.3814, Learning Rate: 9.37e-05
2025-12-08 23:54:22 - INFO - Epoch: 4.40, Step: 13950, Train Loss: 2.4018, Learning Rate: 9.37e-05
2025-12-08 23:54:33 - INFO - Epoch: 4.41, Step: 13960, Train Loss: 2.4650, Learning Rate: 9.37e-05
2025-12-08 23:54:44 - INFO - Epoch: 4.41, Step: 13970, Train Loss: 2.3847, Learning Rate: 9.37e-05
2025-12-08 23:54:55 - INFO - Epoch: 4.41, Step: 13980, Train Loss: 2.3765, Learning Rate: 9.37e-05
2025-12-08 23:55:06 - INFO - Epoch: 4.41, Step: 13990, Train Loss: 2.3577, Learning Rate: 9.36e-05
2025-12-08 23:55:17 - INFO - Epoch: 4.42, Step: 14000, Train Loss: 2.3923, Learning Rate: 9.36e-05
2025-12-08 23:55:28 - INFO - Epoch: 4.42, Step: 14010, Train Loss: 2.3690, Learning Rate: 9.36e-05
2025-12-08 23:55:39 - INFO - Epoch: 4.42, Step: 14020, Train Loss: 2.4256, Learning Rate: 9.36e-05
2025-12-08 23:55:51 - INFO - Epoch: 4.43, Step: 14030, Train Loss: 2.3819, Learning Rate: 9.36e-05
2025-12-08 23:56:02 - INFO - Epoch: 4.43, Step: 14040, Train Loss: 2.4029, Learning Rate: 9.36e-05
2025-12-08 23:56:13 - INFO - Epoch: 4.43, Step: 14050, Train Loss: 2.4131, Learning Rate: 9.36e-05
2025-12-08 23:56:24 - INFO - Epoch: 4.44, Step: 14060, Train Loss: 2.4156, Learning Rate: 9.36e-05
2025-12-08 23:56:35 - INFO - Epoch: 4.44, Step: 14070, Train Loss: 2.3729, Learning Rate: 9.36e-05
2025-12-08 23:56:46 - INFO - Epoch: 4.44, Step: 14080, Train Loss: 2.3477, Learning Rate: 9.36e-05
2025-12-08 23:56:57 - INFO - Epoch: 4.45, Step: 14090, Train Loss: 2.4085, Learning Rate: 9.36e-05
2025-12-08 23:57:08 - INFO - Epoch: 4.45, Step: 14100, Train Loss: 2.3978, Learning Rate: 9.36e-05
2025-12-08 23:57:19 - INFO - Epoch: 4.45, Step: 14110, Train Loss: 2.3657, Learning Rate: 9.35e-05
2025-12-08 23:57:30 - INFO - Epoch: 4.46, Step: 14120, Train Loss: 2.3465, Learning Rate: 9.35e-05
2025-12-08 23:57:41 - INFO - Epoch: 4.46, Step: 14130, Train Loss: 2.3976, Learning Rate: 9.35e-05
2025-12-08 23:57:52 - INFO - Epoch: 4.46, Step: 14140, Train Loss: 2.3709, Learning Rate: 9.35e-05
2025-12-08 23:58:03 - INFO - Epoch: 4.47, Step: 14150, Train Loss: 2.3417, Learning Rate: 9.35e-05
2025-12-08 23:58:15 - INFO - Epoch: 4.47, Step: 14160, Train Loss: 2.3697, Learning Rate: 9.35e-05
2025-12-08 23:58:26 - INFO - Epoch: 4.47, Step: 14170, Train Loss: 2.3837, Learning Rate: 9.35e-05
2025-12-08 23:58:37 - INFO - Epoch: 4.47, Step: 14180, Train Loss: 2.3739, Learning Rate: 9.35e-05
2025-12-08 23:58:48 - INFO - Epoch: 4.48, Step: 14190, Train Loss: 2.3902, Learning Rate: 9.35e-05
2025-12-08 23:58:59 - INFO - Epoch: 4.48, Step: 14200, Train Loss: 2.3715, Learning Rate: 9.35e-05
2025-12-08 23:59:10 - INFO - Epoch: 4.48, Step: 14210, Train Loss: 2.3800, Learning Rate: 9.35e-05
2025-12-08 23:59:21 - INFO - Epoch: 4.49, Step: 14220, Train Loss: 2.4130, Learning Rate: 9.35e-05
2025-12-08 23:59:32 - INFO - Epoch: 4.49, Step: 14230, Train Loss: 2.3955, Learning Rate: 9.34e-05
2025-12-08 23:59:43 - INFO - Epoch: 4.49, Step: 14240, Train Loss: 2.3125, Learning Rate: 9.34e-05
2025-12-08 23:59:54 - INFO - Epoch: 4.50, Step: 14250, Train Loss: 2.3602, Learning Rate: 9.34e-05
2025-12-09 00:00:05 - INFO - Epoch: 4.50, Step: 14260, Train Loss: 2.3658, Learning Rate: 9.34e-05
2025-12-09 00:00:16 - INFO - Epoch: 4.50, Step: 14270, Train Loss: 2.3536, Learning Rate: 9.34e-05
2025-12-09 00:00:28 - INFO - Epoch: 4.51, Step: 14280, Train Loss: 2.3605, Learning Rate: 9.34e-05
2025-12-09 00:00:39 - INFO - Epoch: 4.51, Step: 14290, Train Loss: 2.3603, Learning Rate: 9.34e-05
2025-12-09 00:00:50 - INFO - Epoch: 4.51, Step: 14300, Train Loss: 2.4068, Learning Rate: 9.34e-05
2025-12-09 00:01:01 - INFO - Epoch: 4.52, Step: 14310, Train Loss: 2.3232, Learning Rate: 9.34e-05
2025-12-09 00:01:12 - INFO - Epoch: 4.52, Step: 14320, Train Loss: 2.3568, Learning Rate: 9.34e-05
2025-12-09 00:01:23 - INFO - Epoch: 4.52, Step: 14330, Train Loss: 2.3517, Learning Rate: 9.34e-05
2025-12-09 00:01:34 - INFO - Epoch: 4.53, Step: 14340, Train Loss: 2.3457, Learning Rate: 9.34e-05
2025-12-09 00:01:45 - INFO - Epoch: 4.53, Step: 14350, Train Loss: 2.3242, Learning Rate: 9.33e-05
2025-12-09 00:01:56 - INFO - Epoch: 4.53, Step: 14360, Train Loss: 2.3804, Learning Rate: 9.33e-05
2025-12-09 00:02:07 - INFO - Epoch: 4.53, Step: 14370, Train Loss: 2.3520, Learning Rate: 9.33e-05
2025-12-09 00:02:18 - INFO - Epoch: 4.54, Step: 14380, Train Loss: 2.3458, Learning Rate: 9.33e-05
2025-12-09 00:02:29 - INFO - Epoch: 4.54, Step: 14390, Train Loss: 2.3575, Learning Rate: 9.33e-05
2025-12-09 00:02:40 - INFO - Epoch: 4.54, Step: 14400, Train Loss: 2.3608, Learning Rate: 9.33e-05
2025-12-09 00:02:52 - INFO - Epoch: 4.55, Step: 14410, Train Loss: 2.3352, Learning Rate: 9.33e-05
2025-12-09 00:03:03 - INFO - Epoch: 4.55, Step: 14420, Train Loss: 2.3398, Learning Rate: 9.33e-05
2025-12-09 00:03:14 - INFO - Epoch: 4.55, Step: 14430, Train Loss: 2.3437, Learning Rate: 9.33e-05
2025-12-09 00:03:25 - INFO - Epoch: 4.56, Step: 14440, Train Loss: 2.3341, Learning Rate: 9.33e-05
2025-12-09 00:03:36 - INFO - Epoch: 4.56, Step: 14450, Train Loss: 2.3539, Learning Rate: 9.33e-05
2025-12-09 00:03:47 - INFO - Epoch: 4.56, Step: 14460, Train Loss: 2.3381, Learning Rate: 9.33e-05
2025-12-09 00:03:58 - INFO - Epoch: 4.57, Step: 14470, Train Loss: 2.3141, Learning Rate: 9.32e-05
2025-12-09 00:04:09 - INFO - Epoch: 4.57, Step: 14480, Train Loss: 2.2902, Learning Rate: 9.32e-05
2025-12-09 00:04:20 - INFO - Epoch: 4.57, Step: 14490, Train Loss: 2.3150, Learning Rate: 9.32e-05
2025-12-09 00:04:31 - INFO - Epoch: 4.58, Step: 14500, Train Loss: 2.3360, Learning Rate: 9.32e-05
2025-12-09 00:04:42 - INFO - Epoch: 4.58, Step: 14510, Train Loss: 2.3778, Learning Rate: 9.32e-05
2025-12-09 00:04:53 - INFO - Epoch: 4.58, Step: 14520, Train Loss: 2.3239, Learning Rate: 9.32e-05
2025-12-09 00:05:05 - INFO - Epoch: 4.59, Step: 14530, Train Loss: 2.3285, Learning Rate: 9.32e-05
2025-12-09 00:05:16 - INFO - Epoch: 4.59, Step: 14540, Train Loss: 2.3214, Learning Rate: 9.32e-05
2025-12-09 00:05:27 - INFO - Epoch: 4.59, Step: 14550, Train Loss: 2.2889, Learning Rate: 9.32e-05
2025-12-09 00:05:38 - INFO - Epoch: 4.59, Step: 14560, Train Loss: 2.3280, Learning Rate: 9.32e-05
2025-12-09 00:05:49 - INFO - Epoch: 4.60, Step: 14570, Train Loss: 2.3460, Learning Rate: 9.32e-05
2025-12-09 00:06:00 - INFO - Epoch: 4.60, Step: 14580, Train Loss: 2.3179, Learning Rate: 9.32e-05
2025-12-09 00:06:11 - INFO - Epoch: 4.60, Step: 14590, Train Loss: 2.3347, Learning Rate: 9.31e-05
2025-12-09 00:06:22 - INFO - Epoch: 4.61, Step: 14600, Train Loss: 2.3473, Learning Rate: 9.31e-05
2025-12-09 00:06:33 - INFO - Epoch: 4.61, Step: 14610, Train Loss: 2.3129, Learning Rate: 9.31e-05
2025-12-09 00:06:44 - INFO - Epoch: 4.61, Step: 14620, Train Loss: 2.3087, Learning Rate: 9.31e-05
2025-12-09 00:06:55 - INFO - Epoch: 4.62, Step: 14630, Train Loss: 2.3553, Learning Rate: 9.31e-05
2025-12-09 00:07:06 - INFO - Epoch: 4.62, Step: 14640, Train Loss: 2.3437, Learning Rate: 9.31e-05
2025-12-09 00:07:18 - INFO - Epoch: 4.62, Step: 14650, Train Loss: 2.3094, Learning Rate: 9.31e-05
2025-12-09 00:07:29 - INFO - Epoch: 4.63, Step: 14660, Train Loss: 2.3097, Learning Rate: 9.31e-05
2025-12-09 00:07:40 - INFO - Epoch: 4.63, Step: 14670, Train Loss: 2.3137, Learning Rate: 9.31e-05
2025-12-09 00:07:51 - INFO - Epoch: 4.63, Step: 14680, Train Loss: 2.2907, Learning Rate: 9.31e-05
2025-12-09 00:08:02 - INFO - Epoch: 4.64, Step: 14690, Train Loss: 2.2772, Learning Rate: 9.31e-05
2025-12-09 00:08:13 - INFO - Epoch: 4.64, Step: 14700, Train Loss: 2.3090, Learning Rate: 9.31e-05
2025-12-09 00:08:24 - INFO - Epoch: 4.64, Step: 14710, Train Loss: 2.3169, Learning Rate: 9.30e-05
2025-12-09 00:08:35 - INFO - Epoch: 4.64, Step: 14720, Train Loss: 2.2985, Learning Rate: 9.30e-05
2025-12-09 00:08:46 - INFO - Epoch: 4.65, Step: 14730, Train Loss: 2.2953, Learning Rate: 9.30e-05
2025-12-09 00:08:57 - INFO - Epoch: 4.65, Step: 14740, Train Loss: 2.2924, Learning Rate: 9.30e-05
2025-12-09 00:09:08 - INFO - Epoch: 4.65, Step: 14750, Train Loss: 2.3263, Learning Rate: 9.30e-05
2025-12-09 00:09:19 - INFO - Epoch: 4.66, Step: 14760, Train Loss: 2.2728, Learning Rate: 9.30e-05
2025-12-09 00:09:30 - INFO - Epoch: 4.66, Step: 14770, Train Loss: 2.3037, Learning Rate: 9.30e-05
2025-12-09 00:09:42 - INFO - Epoch: 4.66, Step: 14780, Train Loss: 2.2806, Learning Rate: 9.30e-05
2025-12-09 00:09:53 - INFO - Epoch: 4.67, Step: 14790, Train Loss: 2.2840, Learning Rate: 9.30e-05
2025-12-09 00:10:04 - INFO - Epoch: 4.67, Step: 14800, Train Loss: 2.3126, Learning Rate: 9.30e-05
2025-12-09 00:10:15 - INFO - Epoch: 4.67, Step: 14810, Train Loss: 2.2533, Learning Rate: 9.30e-05
2025-12-09 00:10:26 - INFO - Epoch: 4.68, Step: 14820, Train Loss: 2.3030, Learning Rate: 9.30e-05
2025-12-09 00:10:37 - INFO - Epoch: 4.68, Step: 14830, Train Loss: 2.3251, Learning Rate: 9.29e-05
2025-12-09 00:10:48 - INFO - Epoch: 4.68, Step: 14840, Train Loss: 2.2877, Learning Rate: 9.29e-05
2025-12-09 00:10:59 - INFO - Epoch: 4.69, Step: 14850, Train Loss: 2.2519, Learning Rate: 9.29e-05
2025-12-09 00:11:10 - INFO - Epoch: 4.69, Step: 14860, Train Loss: 2.2863, Learning Rate: 9.29e-05
2025-12-09 00:11:21 - INFO - Epoch: 4.69, Step: 14870, Train Loss: 2.2852, Learning Rate: 9.29e-05
2025-12-09 00:11:32 - INFO - Epoch: 4.70, Step: 14880, Train Loss: 2.3209, Learning Rate: 9.29e-05
2025-12-09 00:11:43 - INFO - Epoch: 4.70, Step: 14890, Train Loss: 2.3263, Learning Rate: 9.29e-05
2025-12-09 00:11:55 - INFO - Epoch: 4.70, Step: 14900, Train Loss: 2.3283, Learning Rate: 9.29e-05
2025-12-09 00:12:06 - INFO - Epoch: 4.70, Step: 14910, Train Loss: 2.2461, Learning Rate: 9.29e-05
2025-12-09 00:12:17 - INFO - Epoch: 4.71, Step: 14920, Train Loss: 2.2944, Learning Rate: 9.29e-05
2025-12-09 00:12:28 - INFO - Epoch: 4.71, Step: 14930, Train Loss: 2.2639, Learning Rate: 9.29e-05
2025-12-09 00:12:39 - INFO - Epoch: 4.71, Step: 14940, Train Loss: 2.3070, Learning Rate: 9.29e-05
2025-12-09 00:12:50 - INFO - Epoch: 4.72, Step: 14950, Train Loss: 2.2840, Learning Rate: 9.28e-05
2025-12-09 00:13:01 - INFO - Epoch: 4.72, Step: 14960, Train Loss: 2.2519, Learning Rate: 9.28e-05
2025-12-09 00:13:12 - INFO - Epoch: 4.72, Step: 14970, Train Loss: 2.2738, Learning Rate: 9.28e-05
2025-12-09 00:13:23 - INFO - Epoch: 4.73, Step: 14980, Train Loss: 2.2581, Learning Rate: 9.28e-05
2025-12-09 00:13:34 - INFO - Epoch: 4.73, Step: 14990, Train Loss: 2.2819, Learning Rate: 9.28e-05
2025-12-09 00:13:45 - INFO - Epoch: 4.73, Step: 15000, Train Loss: 2.2841, Learning Rate: 9.28e-05
2025-12-09 00:13:56 - INFO - Epoch: 4.74, Step: 15010, Train Loss: 2.2781, Learning Rate: 9.28e-05
2025-12-09 00:14:07 - INFO - Epoch: 4.74, Step: 15020, Train Loss: 2.2974, Learning Rate: 9.28e-05
2025-12-09 00:14:19 - INFO - Epoch: 4.74, Step: 15030, Train Loss: 2.2933, Learning Rate: 9.28e-05
2025-12-09 00:14:30 - INFO - Epoch: 4.75, Step: 15040, Train Loss: 2.2950, Learning Rate: 9.28e-05
2025-12-09 00:14:41 - INFO - Epoch: 4.75, Step: 15050, Train Loss: 2.2719, Learning Rate: 9.28e-05
2025-12-09 00:14:52 - INFO - Epoch: 4.75, Step: 15060, Train Loss: 2.2618, Learning Rate: 9.28e-05
2025-12-09 00:15:03 - INFO - Epoch: 4.76, Step: 15070, Train Loss: 2.2457, Learning Rate: 9.27e-05
2025-12-09 00:15:14 - INFO - Epoch: 4.76, Step: 15080, Train Loss: 2.2749, Learning Rate: 9.27e-05
2025-12-09 00:15:25 - INFO - Epoch: 4.76, Step: 15090, Train Loss: 2.2710, Learning Rate: 9.27e-05
2025-12-09 00:15:36 - INFO - Epoch: 4.76, Step: 15100, Train Loss: 2.2532, Learning Rate: 9.27e-05
2025-12-09 00:15:47 - INFO - Epoch: 4.77, Step: 15110, Train Loss: 2.2456, Learning Rate: 9.27e-05
2025-12-09 00:15:58 - INFO - Epoch: 4.77, Step: 15120, Train Loss: 2.2866, Learning Rate: 9.27e-05
2025-12-09 00:16:09 - INFO - Epoch: 4.77, Step: 15130, Train Loss: 2.2478, Learning Rate: 9.27e-05
2025-12-09 00:16:20 - INFO - Epoch: 4.78, Step: 15140, Train Loss: 2.2869, Learning Rate: 9.27e-05
2025-12-09 00:16:32 - INFO - Epoch: 4.78, Step: 15150, Train Loss: 2.2700, Learning Rate: 9.27e-05
2025-12-09 00:16:43 - INFO - Epoch: 4.78, Step: 15160, Train Loss: 2.2900, Learning Rate: 9.27e-05
2025-12-09 00:16:54 - INFO - Epoch: 4.79, Step: 15170, Train Loss: 2.2457, Learning Rate: 9.27e-05
2025-12-09 00:17:05 - INFO - Epoch: 4.79, Step: 15180, Train Loss: 2.2355, Learning Rate: 9.27e-05
2025-12-09 00:17:16 - INFO - Epoch: 4.79, Step: 15190, Train Loss: 2.2695, Learning Rate: 9.27e-05
2025-12-09 00:17:27 - INFO - Epoch: 4.80, Step: 15200, Train Loss: 2.2582, Learning Rate: 9.26e-05
2025-12-09 00:17:38 - INFO - Epoch: 4.80, Step: 15210, Train Loss: 2.2235, Learning Rate: 9.26e-05
2025-12-09 00:17:49 - INFO - Epoch: 4.80, Step: 15220, Train Loss: 2.2604, Learning Rate: 9.26e-05
2025-12-09 00:18:00 - INFO - Epoch: 4.81, Step: 15230, Train Loss: 2.2899, Learning Rate: 9.26e-05
2025-12-09 00:18:11 - INFO - Epoch: 4.81, Step: 15240, Train Loss: 2.2584, Learning Rate: 9.26e-05
2025-12-09 00:18:22 - INFO - Epoch: 4.81, Step: 15250, Train Loss: 2.2501, Learning Rate: 9.26e-05
2025-12-09 00:18:33 - INFO - Epoch: 4.82, Step: 15260, Train Loss: 2.2201, Learning Rate: 9.26e-05
2025-12-09 00:18:44 - INFO - Epoch: 4.82, Step: 15270, Train Loss: 2.2021, Learning Rate: 9.26e-05
2025-12-09 00:18:56 - INFO - Epoch: 4.82, Step: 15280, Train Loss: 2.2280, Learning Rate: 9.26e-05
2025-12-09 00:19:07 - INFO - Epoch: 4.82, Step: 15290, Train Loss: 2.2543, Learning Rate: 9.26e-05
2025-12-09 00:19:18 - INFO - Epoch: 4.83, Step: 15300, Train Loss: 2.2179, Learning Rate: 9.26e-05
2025-12-09 00:19:29 - INFO - Epoch: 4.83, Step: 15310, Train Loss: 2.2350, Learning Rate: 9.26e-05
2025-12-09 00:19:40 - INFO - Epoch: 4.83, Step: 15320, Train Loss: 2.2791, Learning Rate: 9.25e-05
2025-12-09 00:19:51 - INFO - Epoch: 4.84, Step: 15330, Train Loss: 2.2286, Learning Rate: 9.25e-05
2025-12-09 00:20:02 - INFO - Epoch: 4.84, Step: 15340, Train Loss: 2.2561, Learning Rate: 9.25e-05
2025-12-09 00:20:13 - INFO - Epoch: 4.84, Step: 15350, Train Loss: 2.2482, Learning Rate: 9.25e-05
2025-12-09 00:20:24 - INFO - Epoch: 4.85, Step: 15360, Train Loss: 2.2329, Learning Rate: 9.25e-05
2025-12-09 00:20:35 - INFO - Epoch: 4.85, Step: 15370, Train Loss: 2.2150, Learning Rate: 9.25e-05
2025-12-09 00:20:46 - INFO - Epoch: 4.85, Step: 15380, Train Loss: 2.2208, Learning Rate: 9.25e-05
2025-12-09 00:20:57 - INFO - Epoch: 4.86, Step: 15390, Train Loss: 2.2082, Learning Rate: 9.25e-05
2025-12-09 00:21:09 - INFO - Epoch: 4.86, Step: 15400, Train Loss: 2.2252, Learning Rate: 9.25e-05
2025-12-09 00:21:20 - INFO - Epoch: 4.86, Step: 15410, Train Loss: 2.2484, Learning Rate: 9.25e-05
2025-12-09 00:21:31 - INFO - Epoch: 4.87, Step: 15420, Train Loss: 2.2287, Learning Rate: 9.25e-05
2025-12-09 00:21:42 - INFO - Epoch: 4.87, Step: 15430, Train Loss: 2.2933, Learning Rate: 9.25e-05
2025-12-09 00:21:53 - INFO - Epoch: 4.87, Step: 15440, Train Loss: 2.1695, Learning Rate: 9.24e-05
2025-12-09 00:22:04 - INFO - Epoch: 4.88, Step: 15450, Train Loss: 2.2476, Learning Rate: 9.24e-05
2025-12-09 00:22:15 - INFO - Epoch: 4.88, Step: 15460, Train Loss: 2.2808, Learning Rate: 9.24e-05
2025-12-09 00:22:26 - INFO - Epoch: 4.88, Step: 15470, Train Loss: 2.2262, Learning Rate: 9.24e-05
2025-12-09 00:22:37 - INFO - Epoch: 4.88, Step: 15480, Train Loss: 2.2704, Learning Rate: 9.24e-05
2025-12-09 00:22:48 - INFO - Epoch: 4.89, Step: 15490, Train Loss: 2.2287, Learning Rate: 9.24e-05
2025-12-09 00:22:59 - INFO - Epoch: 4.89, Step: 15500, Train Loss: 2.2319, Learning Rate: 9.24e-05
2025-12-09 00:23:10 - INFO - Epoch: 4.89, Step: 15510, Train Loss: 2.2583, Learning Rate: 9.24e-05
2025-12-09 00:23:21 - INFO - Epoch: 4.90, Step: 15520, Train Loss: 2.1897, Learning Rate: 9.24e-05
2025-12-09 00:23:33 - INFO - Epoch: 4.90, Step: 15530, Train Loss: 2.2125, Learning Rate: 9.24e-05
2025-12-09 00:23:44 - INFO - Epoch: 4.90, Step: 15540, Train Loss: 2.2429, Learning Rate: 9.24e-05
2025-12-09 00:23:55 - INFO - Epoch: 4.91, Step: 15550, Train Loss: 2.2132, Learning Rate: 9.24e-05
2025-12-09 00:24:06 - INFO - Epoch: 4.91, Step: 15560, Train Loss: 2.2451, Learning Rate: 9.23e-05
2025-12-09 00:24:17 - INFO - Epoch: 4.91, Step: 15570, Train Loss: 2.2481, Learning Rate: 9.23e-05
2025-12-09 00:24:28 - INFO - Epoch: 4.92, Step: 15580, Train Loss: 2.2430, Learning Rate: 9.23e-05
2025-12-09 00:24:39 - INFO - Epoch: 4.92, Step: 15590, Train Loss: 2.2245, Learning Rate: 9.23e-05
2025-12-09 00:24:50 - INFO - Epoch: 4.92, Step: 15600, Train Loss: 2.2346, Learning Rate: 9.23e-05
2025-12-09 00:25:01 - INFO - Epoch: 4.93, Step: 15610, Train Loss: 2.2187, Learning Rate: 9.23e-05
2025-12-09 00:25:12 - INFO - Epoch: 4.93, Step: 15620, Train Loss: 2.1835, Learning Rate: 9.23e-05
2025-12-09 00:25:23 - INFO - Epoch: 4.93, Step: 15630, Train Loss: 2.2167, Learning Rate: 9.23e-05
2025-12-09 00:25:34 - INFO - Epoch: 4.94, Step: 15640, Train Loss: 2.2246, Learning Rate: 9.23e-05
2025-12-09 00:25:46 - INFO - Epoch: 4.94, Step: 15650, Train Loss: 2.2201, Learning Rate: 9.23e-05
2025-12-09 00:25:57 - INFO - Epoch: 4.94, Step: 15660, Train Loss: 2.2139, Learning Rate: 9.23e-05
2025-12-09 00:26:08 - INFO - Epoch: 4.94, Step: 15670, Train Loss: 2.2446, Learning Rate: 9.23e-05
2025-12-09 00:26:19 - INFO - Epoch: 4.95, Step: 15680, Train Loss: 2.2679, Learning Rate: 9.22e-05
2025-12-09 00:26:30 - INFO - Epoch: 4.95, Step: 15690, Train Loss: 2.2344, Learning Rate: 9.22e-05
2025-12-09 00:26:41 - INFO - Epoch: 4.95, Step: 15700, Train Loss: 2.1607, Learning Rate: 9.22e-05
2025-12-09 00:26:52 - INFO - Epoch: 4.96, Step: 15710, Train Loss: 2.2148, Learning Rate: 9.22e-05
2025-12-09 00:27:03 - INFO - Epoch: 4.96, Step: 15720, Train Loss: 2.2095, Learning Rate: 9.22e-05
2025-12-09 00:27:14 - INFO - Epoch: 4.96, Step: 15730, Train Loss: 2.1705, Learning Rate: 9.22e-05
2025-12-09 00:27:25 - INFO - Epoch: 4.97, Step: 15740, Train Loss: 2.1893, Learning Rate: 9.22e-05
2025-12-09 00:27:36 - INFO - Epoch: 4.97, Step: 15750, Train Loss: 2.1688, Learning Rate: 9.22e-05
2025-12-09 00:27:47 - INFO - Epoch: 4.97, Step: 15760, Train Loss: 2.2275, Learning Rate: 9.22e-05
2025-12-09 00:27:58 - INFO - Epoch: 4.98, Step: 15770, Train Loss: 2.2244, Learning Rate: 9.22e-05
2025-12-09 00:28:10 - INFO - Epoch: 4.98, Step: 15780, Train Loss: 2.1839, Learning Rate: 9.22e-05
2025-12-09 00:28:21 - INFO - Epoch: 4.98, Step: 15790, Train Loss: 2.2345, Learning Rate: 9.22e-05
2025-12-09 00:28:32 - INFO - Epoch: 4.99, Step: 15800, Train Loss: 2.1993, Learning Rate: 9.21e-05
2025-12-09 00:28:43 - INFO - Epoch: 4.99, Step: 15810, Train Loss: 2.2376, Learning Rate: 9.21e-05
2025-12-09 00:28:54 - INFO - Epoch: 4.99, Step: 15820, Train Loss: 2.1861, Learning Rate: 9.21e-05
2025-12-09 00:29:05 - INFO - Epoch: 5.00, Step: 15830, Train Loss: 2.1983, Learning Rate: 9.21e-05
2025-12-09 00:29:16 - INFO - Epoch: 5.00, Step: 15840, Train Loss: 2.1987, Learning Rate: 9.21e-05
2025-12-09 00:29:27 - INFO - Epoch: 5.00, Step: 15850, Train Loss: 2.1560, Learning Rate: 9.21e-05
2025-12-09 00:29:38 - INFO - Epoch: 5.00, Step: 15860, Train Loss: 2.1832, Learning Rate: 9.21e-05
2025-12-09 00:29:49 - INFO - Epoch: 5.01, Step: 15870, Train Loss: 2.2333, Learning Rate: 9.21e-05
2025-12-09 00:30:00 - INFO - Epoch: 5.01, Step: 15880, Train Loss: 2.2069, Learning Rate: 9.21e-05
2025-12-09 00:30:11 - INFO - Epoch: 5.01, Step: 15890, Train Loss: 2.1971, Learning Rate: 9.21e-05
2025-12-09 00:30:23 - INFO - Epoch: 5.02, Step: 15900, Train Loss: 2.1860, Learning Rate: 9.21e-05
2025-12-09 00:30:34 - INFO - Epoch: 5.02, Step: 15910, Train Loss: 2.1996, Learning Rate: 9.21e-05
2025-12-09 00:30:45 - INFO - Epoch: 5.02, Step: 15920, Train Loss: 2.1947, Learning Rate: 9.20e-05
2025-12-09 00:30:56 - INFO - Epoch: 5.03, Step: 15930, Train Loss: 2.1896, Learning Rate: 9.20e-05
2025-12-09 00:31:07 - INFO - Epoch: 5.03, Step: 15940, Train Loss: 2.1787, Learning Rate: 9.20e-05
2025-12-09 00:31:18 - INFO - Epoch: 5.03, Step: 15950, Train Loss: 2.1822, Learning Rate: 9.20e-05
2025-12-09 00:31:29 - INFO - Epoch: 5.04, Step: 15960, Train Loss: 2.1838, Learning Rate: 9.20e-05
2025-12-09 00:31:40 - INFO - Epoch: 5.04, Step: 15970, Train Loss: 2.2038, Learning Rate: 9.20e-05
2025-12-09 00:31:51 - INFO - Epoch: 5.04, Step: 15980, Train Loss: 2.1849, Learning Rate: 9.20e-05
2025-12-09 00:32:02 - INFO - Epoch: 5.05, Step: 15990, Train Loss: 2.1610, Learning Rate: 9.20e-05
2025-12-09 00:32:13 - INFO - Epoch: 5.05, Step: 16000, Train Loss: 2.1712, Learning Rate: 9.20e-05
2025-12-09 00:32:24 - INFO - Epoch: 5.05, Step: 16010, Train Loss: 2.1868, Learning Rate: 9.20e-05
2025-12-09 00:32:35 - INFO - Epoch: 5.06, Step: 16020, Train Loss: 2.1991, Learning Rate: 9.20e-05
2025-12-09 00:32:47 - INFO - Epoch: 5.06, Step: 16030, Train Loss: 2.1716, Learning Rate: 9.20e-05
2025-12-09 00:32:58 - INFO - Epoch: 5.06, Step: 16040, Train Loss: 2.1409, Learning Rate: 9.19e-05
2025-12-09 00:33:09 - INFO - Epoch: 5.06, Step: 16050, Train Loss: 2.1701, Learning Rate: 9.19e-05
2025-12-09 00:33:20 - INFO - Epoch: 5.07, Step: 16060, Train Loss: 2.1696, Learning Rate: 9.19e-05
2025-12-09 00:33:31 - INFO - Epoch: 5.07, Step: 16070, Train Loss: 2.1913, Learning Rate: 9.19e-05
2025-12-09 00:33:42 - INFO - Epoch: 5.07, Step: 16080, Train Loss: 2.1664, Learning Rate: 9.19e-05
2025-12-09 00:33:53 - INFO - Epoch: 5.08, Step: 16090, Train Loss: 2.1916, Learning Rate: 9.19e-05
2025-12-09 00:34:04 - INFO - Epoch: 5.08, Step: 16100, Train Loss: 2.1160, Learning Rate: 9.19e-05
2025-12-09 00:34:15 - INFO - Epoch: 5.08, Step: 16110, Train Loss: 2.1497, Learning Rate: 9.19e-05
2025-12-09 00:34:26 - INFO - Epoch: 5.09, Step: 16120, Train Loss: 2.1975, Learning Rate: 9.19e-05
2025-12-09 00:34:37 - INFO - Epoch: 5.09, Step: 16130, Train Loss: 2.1537, Learning Rate: 9.19e-05
2025-12-09 00:34:48 - INFO - Epoch: 5.09, Step: 16140, Train Loss: 2.1867, Learning Rate: 9.19e-05
2025-12-09 00:34:59 - INFO - Epoch: 5.10, Step: 16150, Train Loss: 2.1395, Learning Rate: 9.19e-05
2025-12-09 00:35:11 - INFO - Epoch: 5.10, Step: 16160, Train Loss: 2.1539, Learning Rate: 9.18e-05
2025-12-09 00:35:22 - INFO - Epoch: 5.10, Step: 16170, Train Loss: 2.1370, Learning Rate: 9.18e-05
2025-12-09 00:35:33 - INFO - Epoch: 5.11, Step: 16180, Train Loss: 2.1632, Learning Rate: 9.18e-05
2025-12-09 00:35:44 - INFO - Epoch: 5.11, Step: 16190, Train Loss: 2.2044, Learning Rate: 9.18e-05
2025-12-09 00:35:55 - INFO - Epoch: 5.11, Step: 16200, Train Loss: 2.1489, Learning Rate: 9.18e-05
2025-12-09 00:36:06 - INFO - Epoch: 5.12, Step: 16210, Train Loss: 2.1752, Learning Rate: 9.18e-05
2025-12-09 00:36:17 - INFO - Epoch: 5.12, Step: 16220, Train Loss: 2.1690, Learning Rate: 9.18e-05
2025-12-09 00:36:28 - INFO - Epoch: 5.12, Step: 16230, Train Loss: 2.1662, Learning Rate: 9.18e-05
2025-12-09 00:36:39 - INFO - Epoch: 5.12, Step: 16240, Train Loss: 2.1516, Learning Rate: 9.18e-05
2025-12-09 00:36:50 - INFO - Epoch: 5.13, Step: 16250, Train Loss: 2.1710, Learning Rate: 9.18e-05
2025-12-09 00:37:01 - INFO - Epoch: 5.13, Step: 16260, Train Loss: 2.1974, Learning Rate: 9.18e-05
2025-12-09 00:37:12 - INFO - Epoch: 5.13, Step: 16270, Train Loss: 2.1742, Learning Rate: 9.18e-05
2025-12-09 00:37:23 - INFO - Epoch: 5.14, Step: 16280, Train Loss: 2.1647, Learning Rate: 9.17e-05
2025-12-09 00:37:35 - INFO - Epoch: 5.14, Step: 16290, Train Loss: 2.1315, Learning Rate: 9.17e-05
2025-12-09 00:37:46 - INFO - Epoch: 5.14, Step: 16300, Train Loss: 2.1439, Learning Rate: 9.17e-05
2025-12-09 00:37:57 - INFO - Epoch: 5.15, Step: 16310, Train Loss: 2.1438, Learning Rate: 9.17e-05
2025-12-09 00:38:08 - INFO - Epoch: 5.15, Step: 16320, Train Loss: 2.1658, Learning Rate: 9.17e-05
2025-12-09 00:38:19 - INFO - Epoch: 5.15, Step: 16330, Train Loss: 2.1717, Learning Rate: 9.17e-05
2025-12-09 00:38:30 - INFO - Epoch: 5.16, Step: 16340, Train Loss: 2.1357, Learning Rate: 9.17e-05
2025-12-09 00:38:41 - INFO - Epoch: 5.16, Step: 16350, Train Loss: 2.1335, Learning Rate: 9.17e-05
2025-12-09 00:38:52 - INFO - Epoch: 5.16, Step: 16360, Train Loss: 2.1665, Learning Rate: 9.17e-05
2025-12-09 00:39:03 - INFO - Epoch: 5.17, Step: 16370, Train Loss: 2.1778, Learning Rate: 9.17e-05
2025-12-09 00:39:14 - INFO - Epoch: 5.17, Step: 16380, Train Loss: 2.1705, Learning Rate: 9.17e-05
2025-12-09 00:39:25 - INFO - Epoch: 5.17, Step: 16390, Train Loss: 2.1463, Learning Rate: 9.17e-05
2025-12-09 00:39:36 - INFO - Epoch: 5.18, Step: 16400, Train Loss: 2.1683, Learning Rate: 9.16e-05
2025-12-09 00:39:48 - INFO - Epoch: 5.18, Step: 16410, Train Loss: 2.1733, Learning Rate: 9.16e-05
2025-12-09 00:39:59 - INFO - Epoch: 5.18, Step: 16420, Train Loss: 2.1547, Learning Rate: 9.16e-05
2025-12-09 00:40:10 - INFO - Epoch: 5.18, Step: 16430, Train Loss: 2.1541, Learning Rate: 9.16e-05
2025-12-09 00:40:21 - INFO - Epoch: 5.19, Step: 16440, Train Loss: 2.1532, Learning Rate: 9.16e-05
2025-12-09 00:40:32 - INFO - Epoch: 5.19, Step: 16450, Train Loss: 2.1556, Learning Rate: 9.16e-05
2025-12-09 00:40:43 - INFO - Epoch: 5.19, Step: 16460, Train Loss: 2.1604, Learning Rate: 9.16e-05
2025-12-09 00:40:54 - INFO - Epoch: 5.20, Step: 16470, Train Loss: 2.1892, Learning Rate: 9.16e-05
2025-12-09 00:41:05 - INFO - Epoch: 5.20, Step: 16480, Train Loss: 2.1634, Learning Rate: 9.16e-05
2025-12-09 00:41:16 - INFO - Epoch: 5.20, Step: 16490, Train Loss: 2.1169, Learning Rate: 9.16e-05
2025-12-09 00:41:27 - INFO - Epoch: 5.21, Step: 16500, Train Loss: 2.1690, Learning Rate: 9.16e-05
2025-12-09 00:41:38 - INFO - Epoch: 5.21, Step: 16510, Train Loss: 2.1279, Learning Rate: 9.16e-05
2025-12-09 00:41:49 - INFO - Epoch: 5.21, Step: 16520, Train Loss: 2.1248, Learning Rate: 9.15e-05
2025-12-09 00:42:00 - INFO - Epoch: 5.22, Step: 16530, Train Loss: 2.1358, Learning Rate: 9.15e-05
2025-12-09 00:42:12 - INFO - Epoch: 5.22, Step: 16540, Train Loss: 2.1837, Learning Rate: 9.15e-05
2025-12-09 00:42:23 - INFO - Epoch: 5.22, Step: 16550, Train Loss: 2.1516, Learning Rate: 9.15e-05
2025-12-09 00:42:34 - INFO - Epoch: 5.23, Step: 16560, Train Loss: 2.1163, Learning Rate: 9.15e-05
2025-12-09 00:42:45 - INFO - Epoch: 5.23, Step: 16570, Train Loss: 2.1261, Learning Rate: 9.15e-05
2025-12-09 00:42:56 - INFO - Epoch: 5.23, Step: 16580, Train Loss: 2.1227, Learning Rate: 9.15e-05
2025-12-09 00:43:07 - INFO - Epoch: 5.24, Step: 16590, Train Loss: 2.1705, Learning Rate: 9.15e-05
2025-12-09 00:43:18 - INFO - Epoch: 5.24, Step: 16600, Train Loss: 2.0972, Learning Rate: 9.15e-05
2025-12-09 00:43:29 - INFO - Epoch: 5.24, Step: 16610, Train Loss: 2.0934, Learning Rate: 9.15e-05
2025-12-09 00:43:40 - INFO - Epoch: 5.24, Step: 16620, Train Loss: 2.1109, Learning Rate: 9.15e-05
2025-12-09 00:43:51 - INFO - Epoch: 5.25, Step: 16630, Train Loss: 2.0878, Learning Rate: 9.15e-05
2025-12-09 00:44:02 - INFO - Epoch: 5.25, Step: 16640, Train Loss: 2.1385, Learning Rate: 9.14e-05
2025-12-09 00:44:13 - INFO - Epoch: 5.25, Step: 16650, Train Loss: 2.1793, Learning Rate: 9.14e-05
2025-12-09 00:44:24 - INFO - Epoch: 5.26, Step: 16660, Train Loss: 2.1304, Learning Rate: 9.14e-05
2025-12-09 00:44:36 - INFO - Epoch: 5.26, Step: 16670, Train Loss: 2.1308, Learning Rate: 9.14e-05
2025-12-09 00:44:47 - INFO - Epoch: 5.26, Step: 16680, Train Loss: 2.1156, Learning Rate: 9.14e-05
2025-12-09 00:44:58 - INFO - Epoch: 5.27, Step: 16690, Train Loss: 2.1323, Learning Rate: 9.14e-05
2025-12-09 00:45:09 - INFO - Epoch: 5.27, Step: 16700, Train Loss: 2.0963, Learning Rate: 9.14e-05
2025-12-09 00:45:20 - INFO - Epoch: 5.27, Step: 16710, Train Loss: 2.1283, Learning Rate: 9.14e-05
2025-12-09 00:45:31 - INFO - Epoch: 5.28, Step: 16720, Train Loss: 2.1328, Learning Rate: 9.14e-05
2025-12-09 00:45:42 - INFO - Epoch: 5.28, Step: 16730, Train Loss: 2.1263, Learning Rate: 9.14e-05
2025-12-09 00:45:53 - INFO - Epoch: 5.28, Step: 16740, Train Loss: 2.1175, Learning Rate: 9.14e-05
2025-12-09 00:46:04 - INFO - Epoch: 5.29, Step: 16750, Train Loss: 2.1660, Learning Rate: 9.14e-05
2025-12-09 00:46:15 - INFO - Epoch: 5.29, Step: 16760, Train Loss: 2.0986, Learning Rate: 9.13e-05
2025-12-09 00:46:26 - INFO - Epoch: 5.29, Step: 16770, Train Loss: 2.0972, Learning Rate: 9.13e-05
2025-12-09 00:46:37 - INFO - Epoch: 5.30, Step: 16780, Train Loss: 2.1220, Learning Rate: 9.13e-05
2025-12-09 00:46:48 - INFO - Epoch: 5.30, Step: 16790, Train Loss: 2.1224, Learning Rate: 9.13e-05
2025-12-09 00:47:00 - INFO - Epoch: 5.30, Step: 16800, Train Loss: 2.1087, Learning Rate: 9.13e-05
2025-12-09 00:47:11 - INFO - Epoch: 5.30, Step: 16810, Train Loss: 2.1540, Learning Rate: 9.13e-05
2025-12-09 00:47:22 - INFO - Epoch: 5.31, Step: 16820, Train Loss: 2.0982, Learning Rate: 9.13e-05
2025-12-09 00:47:33 - INFO - Epoch: 5.31, Step: 16830, Train Loss: 2.1175, Learning Rate: 9.13e-05
2025-12-09 00:47:44 - INFO - Epoch: 5.31, Step: 16840, Train Loss: 2.1238, Learning Rate: 9.13e-05
2025-12-09 00:47:55 - INFO - Epoch: 5.32, Step: 16850, Train Loss: 2.1028, Learning Rate: 9.13e-05
2025-12-09 00:48:06 - INFO - Epoch: 5.32, Step: 16860, Train Loss: 2.0809, Learning Rate: 9.13e-05
2025-12-09 00:48:17 - INFO - Epoch: 5.32, Step: 16870, Train Loss: 2.1229, Learning Rate: 9.13e-05
2025-12-09 00:48:28 - INFO - Epoch: 5.33, Step: 16880, Train Loss: 2.1184, Learning Rate: 9.12e-05
2025-12-09 00:48:39 - INFO - Epoch: 5.33, Step: 16890, Train Loss: 2.1407, Learning Rate: 9.12e-05
2025-12-09 00:48:50 - INFO - Epoch: 5.33, Step: 16900, Train Loss: 2.1119, Learning Rate: 9.12e-05
2025-12-09 00:49:01 - INFO - Epoch: 5.34, Step: 16910, Train Loss: 2.1189, Learning Rate: 9.12e-05
2025-12-09 00:49:13 - INFO - Epoch: 5.34, Step: 16920, Train Loss: 2.0921, Learning Rate: 9.12e-05
2025-12-09 00:49:24 - INFO - Epoch: 5.34, Step: 16930, Train Loss: 2.0776, Learning Rate: 9.12e-05
2025-12-09 00:49:35 - INFO - Epoch: 5.35, Step: 16940, Train Loss: 2.1022, Learning Rate: 9.12e-05
2025-12-09 00:49:46 - INFO - Epoch: 5.35, Step: 16950, Train Loss: 2.1160, Learning Rate: 9.12e-05
2025-12-09 00:49:57 - INFO - Epoch: 5.35, Step: 16960, Train Loss: 2.1366, Learning Rate: 9.12e-05
2025-12-09 00:50:08 - INFO - Epoch: 5.36, Step: 16970, Train Loss: 2.1094, Learning Rate: 9.12e-05
2025-12-09 00:50:19 - INFO - Epoch: 5.36, Step: 16980, Train Loss: 2.0833, Learning Rate: 9.12e-05
2025-12-09 00:50:30 - INFO - Epoch: 5.36, Step: 16990, Train Loss: 2.1027, Learning Rate: 9.12e-05
2025-12-09 00:50:41 - INFO - Epoch: 5.36, Step: 17000, Train Loss: 2.1148, Learning Rate: 9.11e-05
2025-12-09 00:50:52 - INFO - Epoch: 5.37, Step: 17010, Train Loss: 2.0682, Learning Rate: 9.11e-05
2025-12-09 00:51:03 - INFO - Epoch: 5.37, Step: 17020, Train Loss: 2.1369, Learning Rate: 9.11e-05
2025-12-09 00:51:14 - INFO - Epoch: 5.37, Step: 17030, Train Loss: 2.0934, Learning Rate: 9.11e-05
2025-12-09 00:51:25 - INFO - Epoch: 5.38, Step: 17040, Train Loss: 2.0956, Learning Rate: 9.11e-05
2025-12-09 00:51:37 - INFO - Epoch: 5.38, Step: 17050, Train Loss: 2.0945, Learning Rate: 9.11e-05
2025-12-09 00:51:48 - INFO - Epoch: 5.38, Step: 17060, Train Loss: 2.0881, Learning Rate: 9.11e-05
2025-12-09 00:51:59 - INFO - Epoch: 5.39, Step: 17070, Train Loss: 2.0505, Learning Rate: 9.11e-05
2025-12-09 00:52:10 - INFO - Epoch: 5.39, Step: 17080, Train Loss: 2.0693, Learning Rate: 9.11e-05
2025-12-09 00:52:21 - INFO - Epoch: 5.39, Step: 17090, Train Loss: 2.1346, Learning Rate: 9.11e-05
2025-12-09 00:52:32 - INFO - Epoch: 5.40, Step: 17100, Train Loss: 2.0856, Learning Rate: 9.11e-05
2025-12-09 00:52:43 - INFO - Epoch: 5.40, Step: 17110, Train Loss: 2.0986, Learning Rate: 9.11e-05
2025-12-09 00:52:54 - INFO - Epoch: 5.40, Step: 17120, Train Loss: 2.1506, Learning Rate: 9.10e-05
2025-12-09 00:53:05 - INFO - Epoch: 5.41, Step: 17130, Train Loss: 2.1442, Learning Rate: 9.10e-05
2025-12-09 00:53:16 - INFO - Epoch: 5.41, Step: 17140, Train Loss: 2.1123, Learning Rate: 9.10e-05
2025-12-09 00:53:27 - INFO - Epoch: 5.41, Step: 17150, Train Loss: 2.0834, Learning Rate: 9.10e-05
2025-12-09 00:53:38 - INFO - Epoch: 5.41, Step: 17160, Train Loss: 2.1012, Learning Rate: 9.10e-05
2025-12-09 00:53:49 - INFO - Epoch: 5.42, Step: 17170, Train Loss: 2.1261, Learning Rate: 9.10e-05
2025-12-09 00:54:01 - INFO - Epoch: 5.42, Step: 17180, Train Loss: 2.0866, Learning Rate: 9.10e-05
2025-12-09 00:54:12 - INFO - Epoch: 5.42, Step: 17190, Train Loss: 2.0881, Learning Rate: 9.10e-05
2025-12-09 00:54:23 - INFO - Epoch: 5.43, Step: 17200, Train Loss: 2.0906, Learning Rate: 9.10e-05
2025-12-09 00:54:34 - INFO - Epoch: 5.43, Step: 17210, Train Loss: 2.0829, Learning Rate: 9.10e-05
2025-12-09 00:54:45 - INFO - Epoch: 5.43, Step: 17220, Train Loss: 2.0860, Learning Rate: 9.10e-05
2025-12-09 00:54:56 - INFO - Epoch: 5.44, Step: 17230, Train Loss: 2.1184, Learning Rate: 9.10e-05
2025-12-09 00:55:07 - INFO - Epoch: 5.44, Step: 17240, Train Loss: 2.0647, Learning Rate: 9.09e-05
2025-12-09 00:55:18 - INFO - Epoch: 5.44, Step: 17250, Train Loss: 2.1303, Learning Rate: 9.09e-05
2025-12-09 00:55:29 - INFO - Epoch: 5.45, Step: 17260, Train Loss: 2.0765, Learning Rate: 9.09e-05
2025-12-09 00:55:40 - INFO - Epoch: 5.45, Step: 17270, Train Loss: 2.0968, Learning Rate: 9.09e-05
2025-12-09 00:55:51 - INFO - Epoch: 5.45, Step: 17280, Train Loss: 2.0710, Learning Rate: 9.09e-05
2025-12-09 00:56:02 - INFO - Epoch: 5.46, Step: 17290, Train Loss: 2.0662, Learning Rate: 9.09e-05
2025-12-09 00:56:14 - INFO - Epoch: 5.46, Step: 17300, Train Loss: 2.0643, Learning Rate: 9.09e-05
2025-12-09 00:56:25 - INFO - Epoch: 5.46, Step: 17310, Train Loss: 2.0853, Learning Rate: 9.09e-05
2025-12-09 00:56:36 - INFO - Epoch: 5.47, Step: 17320, Train Loss: 2.0879, Learning Rate: 9.09e-05
2025-12-09 00:56:47 - INFO - Epoch: 5.47, Step: 17330, Train Loss: 2.0834, Learning Rate: 9.09e-05
2025-12-09 00:56:58 - INFO - Epoch: 5.47, Step: 17340, Train Loss: 2.0769, Learning Rate: 9.09e-05
2025-12-09 00:57:09 - INFO - Epoch: 5.47, Step: 17350, Train Loss: 2.0927, Learning Rate: 9.09e-05
2025-12-09 00:57:20 - INFO - Epoch: 5.48, Step: 17360, Train Loss: 2.0468, Learning Rate: 9.08e-05
2025-12-09 00:57:31 - INFO - Epoch: 5.48, Step: 17370, Train Loss: 2.1036, Learning Rate: 9.08e-05
2025-12-09 00:57:42 - INFO - Epoch: 5.48, Step: 17380, Train Loss: 2.0964, Learning Rate: 9.08e-05
2025-12-09 00:57:53 - INFO - Epoch: 5.49, Step: 17390, Train Loss: 2.0591, Learning Rate: 9.08e-05
2025-12-09 00:58:04 - INFO - Epoch: 5.49, Step: 17400, Train Loss: 2.0520, Learning Rate: 9.08e-05
2025-12-09 00:58:15 - INFO - Epoch: 5.49, Step: 17410, Train Loss: 2.0923, Learning Rate: 9.08e-05
2025-12-09 00:58:26 - INFO - Epoch: 5.50, Step: 17420, Train Loss: 2.0833, Learning Rate: 9.08e-05
2025-12-09 00:58:38 - INFO - Epoch: 5.50, Step: 17430, Train Loss: 2.0665, Learning Rate: 9.08e-05
2025-12-09 00:58:49 - INFO - Epoch: 5.50, Step: 17440, Train Loss: 2.0878, Learning Rate: 9.08e-05
2025-12-09 00:59:00 - INFO - Epoch: 5.51, Step: 17450, Train Loss: 2.0765, Learning Rate: 9.08e-05
2025-12-09 00:59:11 - INFO - Epoch: 5.51, Step: 17460, Train Loss: 2.0489, Learning Rate: 9.08e-05
2025-12-09 00:59:22 - INFO - Epoch: 5.51, Step: 17470, Train Loss: 2.1107, Learning Rate: 9.08e-05
2025-12-09 00:59:33 - INFO - Epoch: 5.52, Step: 17480, Train Loss: 2.0811, Learning Rate: 9.07e-05
2025-12-09 00:59:44 - INFO - Epoch: 5.52, Step: 17490, Train Loss: 2.0220, Learning Rate: 9.07e-05
2025-12-09 00:59:55 - INFO - Epoch: 5.52, Step: 17500, Train Loss: 2.0648, Learning Rate: 9.07e-05
2025-12-09 01:00:06 - INFO - Epoch: 5.53, Step: 17510, Train Loss: 2.0903, Learning Rate: 9.07e-05
2025-12-09 01:00:17 - INFO - Epoch: 5.53, Step: 17520, Train Loss: 2.0488, Learning Rate: 9.07e-05
2025-12-09 01:00:28 - INFO - Epoch: 5.53, Step: 17530, Train Loss: 2.0514, Learning Rate: 9.07e-05
2025-12-09 01:00:39 - INFO - Epoch: 5.53, Step: 17540, Train Loss: 2.0843, Learning Rate: 9.07e-05
2025-12-09 01:00:50 - INFO - Epoch: 5.54, Step: 17550, Train Loss: 2.0376, Learning Rate: 9.07e-05
2025-12-09 01:01:02 - INFO - Epoch: 5.54, Step: 17560, Train Loss: 2.0305, Learning Rate: 9.07e-05
2025-12-09 01:01:13 - INFO - Epoch: 5.54, Step: 17570, Train Loss: 2.0940, Learning Rate: 9.07e-05
2025-12-09 01:01:24 - INFO - Epoch: 5.55, Step: 17580, Train Loss: 2.0625, Learning Rate: 9.07e-05
2025-12-09 01:01:35 - INFO - Epoch: 5.55, Step: 17590, Train Loss: 2.0498, Learning Rate: 9.07e-05
2025-12-09 01:01:46 - INFO - Epoch: 5.55, Step: 17600, Train Loss: 2.0795, Learning Rate: 9.06e-05
2025-12-09 01:01:57 - INFO - Epoch: 5.56, Step: 17610, Train Loss: 2.0498, Learning Rate: 9.06e-05
2025-12-09 01:02:08 - INFO - Epoch: 5.56, Step: 17620, Train Loss: 2.1002, Learning Rate: 9.06e-05
2025-12-09 01:02:19 - INFO - Epoch: 5.56, Step: 17630, Train Loss: 2.0657, Learning Rate: 9.06e-05
2025-12-09 01:02:30 - INFO - Epoch: 5.57, Step: 17640, Train Loss: 2.0677, Learning Rate: 9.06e-05
2025-12-09 01:02:41 - INFO - Epoch: 5.57, Step: 17650, Train Loss: 2.0613, Learning Rate: 9.06e-05
2025-12-09 01:02:52 - INFO - Epoch: 5.57, Step: 17660, Train Loss: 2.0586, Learning Rate: 9.06e-05
2025-12-09 01:03:03 - INFO - Epoch: 5.58, Step: 17670, Train Loss: 2.0414, Learning Rate: 9.06e-05
2025-12-09 01:03:14 - INFO - Epoch: 5.58, Step: 17680, Train Loss: 2.0970, Learning Rate: 9.06e-05
2025-12-09 01:03:26 - INFO - Epoch: 5.58, Step: 17690, Train Loss: 2.0706, Learning Rate: 9.06e-05
2025-12-09 01:03:37 - INFO - Epoch: 5.59, Step: 17700, Train Loss: 2.0093, Learning Rate: 9.06e-05
2025-12-09 01:03:48 - INFO - Epoch: 5.59, Step: 17710, Train Loss: 2.0872, Learning Rate: 9.06e-05
2025-12-09 01:03:59 - INFO - Epoch: 5.59, Step: 17720, Train Loss: 2.0089, Learning Rate: 9.05e-05
2025-12-09 01:04:10 - INFO - Epoch: 5.59, Step: 17730, Train Loss: 2.0734, Learning Rate: 9.05e-05
2025-12-09 01:04:21 - INFO - Epoch: 5.60, Step: 17740, Train Loss: 2.0301, Learning Rate: 9.05e-05
2025-12-09 01:04:32 - INFO - Epoch: 5.60, Step: 17750, Train Loss: 2.0294, Learning Rate: 9.05e-05
2025-12-09 01:04:43 - INFO - Epoch: 5.60, Step: 17760, Train Loss: 2.0347, Learning Rate: 9.05e-05
2025-12-09 01:04:54 - INFO - Epoch: 5.61, Step: 17770, Train Loss: 2.0554, Learning Rate: 9.05e-05
2025-12-09 01:05:05 - INFO - Epoch: 5.61, Step: 17780, Train Loss: 2.0638, Learning Rate: 9.05e-05
2025-12-09 01:05:16 - INFO - Epoch: 5.61, Step: 17790, Train Loss: 2.0443, Learning Rate: 9.05e-05
2025-12-09 01:05:27 - INFO - Epoch: 5.62, Step: 17800, Train Loss: 2.0772, Learning Rate: 9.05e-05
2025-12-09 01:05:39 - INFO - Epoch: 5.62, Step: 17810, Train Loss: 2.0121, Learning Rate: 9.05e-05
2025-12-09 01:05:50 - INFO - Epoch: 5.62, Step: 17820, Train Loss: 2.0211, Learning Rate: 9.05e-05
2025-12-09 01:06:01 - INFO - Epoch: 5.63, Step: 17830, Train Loss: 2.0429, Learning Rate: 9.05e-05
2025-12-09 01:06:12 - INFO - Epoch: 5.63, Step: 17840, Train Loss: 2.0134, Learning Rate: 9.04e-05
2025-12-09 01:06:23 - INFO - Epoch: 5.63, Step: 17850, Train Loss: 2.0458, Learning Rate: 9.04e-05
2025-12-09 01:06:34 - INFO - Epoch: 5.64, Step: 17860, Train Loss: 2.0639, Learning Rate: 9.04e-05
2025-12-09 01:06:45 - INFO - Epoch: 5.64, Step: 17870, Train Loss: 2.0196, Learning Rate: 9.04e-05
2025-12-09 01:06:56 - INFO - Epoch: 5.64, Step: 17880, Train Loss: 2.0461, Learning Rate: 9.04e-05
2025-12-09 01:07:07 - INFO - Epoch: 5.65, Step: 17890, Train Loss: 2.0530, Learning Rate: 9.04e-05
2025-12-09 01:07:18 - INFO - Epoch: 5.65, Step: 17900, Train Loss: 2.0422, Learning Rate: 9.04e-05
2025-12-09 01:07:29 - INFO - Epoch: 5.65, Step: 17910, Train Loss: 2.0446, Learning Rate: 9.04e-05
2025-12-09 01:07:40 - INFO - Epoch: 5.65, Step: 17920, Train Loss: 2.0066, Learning Rate: 9.04e-05
2025-12-09 01:07:51 - INFO - Epoch: 5.66, Step: 17930, Train Loss: 2.0728, Learning Rate: 9.04e-05
2025-12-09 01:08:03 - INFO - Epoch: 5.66, Step: 17940, Train Loss: 2.0120, Learning Rate: 9.04e-05
2025-12-09 01:08:14 - INFO - Epoch: 5.66, Step: 17950, Train Loss: 2.0572, Learning Rate: 9.04e-05
2025-12-09 01:08:25 - INFO - Epoch: 5.67, Step: 17960, Train Loss: 2.0413, Learning Rate: 9.03e-05
2025-12-09 01:08:36 - INFO - Epoch: 5.67, Step: 17970, Train Loss: 2.0268, Learning Rate: 9.03e-05
2025-12-09 01:08:47 - INFO - Epoch: 5.67, Step: 17980, Train Loss: 2.0044, Learning Rate: 9.03e-05
2025-12-09 01:08:58 - INFO - Epoch: 5.68, Step: 17990, Train Loss: 2.0501, Learning Rate: 9.03e-05
2025-12-09 01:09:09 - INFO - Epoch: 5.68, Step: 18000, Train Loss: 2.0470, Learning Rate: 9.03e-05
2025-12-09 01:09:20 - INFO - Epoch: 5.68, Step: 18010, Train Loss: 2.0289, Learning Rate: 9.03e-05
2025-12-09 01:09:31 - INFO - Epoch: 5.69, Step: 18020, Train Loss: 2.0350, Learning Rate: 9.03e-05
2025-12-09 01:09:42 - INFO - Epoch: 5.69, Step: 18030, Train Loss: 2.0743, Learning Rate: 9.03e-05
2025-12-09 01:09:53 - INFO - Epoch: 5.69, Step: 18040, Train Loss: 2.0119, Learning Rate: 9.03e-05
2025-12-09 01:10:04 - INFO - Epoch: 5.70, Step: 18050, Train Loss: 2.0072, Learning Rate: 9.03e-05
2025-12-09 01:10:15 - INFO - Epoch: 5.70, Step: 18060, Train Loss: 2.1029, Learning Rate: 9.03e-05
2025-12-09 01:10:27 - INFO - Epoch: 5.70, Step: 18070, Train Loss: 2.0199, Learning Rate: 9.03e-05
2025-12-09 01:10:38 - INFO - Epoch: 5.71, Step: 18080, Train Loss: 2.0451, Learning Rate: 9.03e-05
2025-12-09 01:10:49 - INFO - Epoch: 5.71, Step: 18090, Train Loss: 2.0154, Learning Rate: 9.02e-05
2025-12-09 01:11:00 - INFO - Epoch: 5.71, Step: 18100, Train Loss: 2.0109, Learning Rate: 9.02e-05
2025-12-09 01:11:11 - INFO - Epoch: 5.71, Step: 18110, Train Loss: 2.0873, Learning Rate: 9.02e-05
2025-12-09 01:11:22 - INFO - Epoch: 5.72, Step: 18120, Train Loss: 2.0372, Learning Rate: 9.02e-05
2025-12-09 01:11:33 - INFO - Epoch: 5.72, Step: 18130, Train Loss: 2.0082, Learning Rate: 9.02e-05
2025-12-09 01:11:44 - INFO - Epoch: 5.72, Step: 18140, Train Loss: 2.0359, Learning Rate: 9.02e-05
2025-12-09 01:11:55 - INFO - Epoch: 5.73, Step: 18150, Train Loss: 2.0177, Learning Rate: 9.02e-05
2025-12-09 01:12:06 - INFO - Epoch: 5.73, Step: 18160, Train Loss: 2.0326, Learning Rate: 9.02e-05
2025-12-09 01:12:17 - INFO - Epoch: 5.73, Step: 18170, Train Loss: 2.0334, Learning Rate: 9.02e-05
2025-12-09 01:12:28 - INFO - Epoch: 5.74, Step: 18180, Train Loss: 2.0457, Learning Rate: 9.02e-05
2025-12-09 01:12:39 - INFO - Epoch: 5.74, Step: 18190, Train Loss: 2.0553, Learning Rate: 9.02e-05
2025-12-09 01:12:51 - INFO - Epoch: 5.74, Step: 18200, Train Loss: 2.0199, Learning Rate: 9.02e-05
2025-12-09 01:13:02 - INFO - Epoch: 5.75, Step: 18210, Train Loss: 2.0423, Learning Rate: 9.01e-05
2025-12-09 01:13:13 - INFO - Epoch: 5.75, Step: 18220, Train Loss: 2.0162, Learning Rate: 9.01e-05
2025-12-09 01:13:24 - INFO - Epoch: 5.75, Step: 18230, Train Loss: 2.0466, Learning Rate: 9.01e-05
2025-12-09 01:13:35 - INFO - Epoch: 5.76, Step: 18240, Train Loss: 2.0200, Learning Rate: 9.01e-05
2025-12-09 01:13:46 - INFO - Epoch: 5.76, Step: 18250, Train Loss: 2.0409, Learning Rate: 9.01e-05
2025-12-09 01:13:57 - INFO - Epoch: 5.76, Step: 18260, Train Loss: 2.0124, Learning Rate: 9.01e-05
2025-12-09 01:14:08 - INFO - Epoch: 5.77, Step: 18270, Train Loss: 2.0059, Learning Rate: 9.01e-05
2025-12-09 01:14:19 - INFO - Epoch: 5.77, Step: 18280, Train Loss: 2.0447, Learning Rate: 9.01e-05
2025-12-09 01:14:30 - INFO - Epoch: 5.77, Step: 18290, Train Loss: 1.9992, Learning Rate: 9.01e-05
2025-12-09 01:14:41 - INFO - Epoch: 5.77, Step: 18300, Train Loss: 2.0702, Learning Rate: 9.01e-05
2025-12-09 01:14:52 - INFO - Epoch: 5.78, Step: 18310, Train Loss: 2.0234, Learning Rate: 9.01e-05
2025-12-09 01:15:04 - INFO - Epoch: 5.78, Step: 18320, Train Loss: 2.0025, Learning Rate: 9.01e-05
2025-12-09 01:15:15 - INFO - Epoch: 5.78, Step: 18330, Train Loss: 1.9868, Learning Rate: 9.00e-05
2025-12-09 01:15:26 - INFO - Epoch: 5.79, Step: 18340, Train Loss: 2.0443, Learning Rate: 9.00e-05
2025-12-09 01:15:37 - INFO - Epoch: 5.79, Step: 18350, Train Loss: 2.0129, Learning Rate: 9.00e-05
2025-12-09 01:15:48 - INFO - Epoch: 5.79, Step: 18360, Train Loss: 2.0059, Learning Rate: 9.00e-05
2025-12-09 01:15:59 - INFO - Epoch: 5.80, Step: 18370, Train Loss: 1.9931, Learning Rate: 9.00e-05
2025-12-09 01:16:10 - INFO - Epoch: 5.80, Step: 18380, Train Loss: 1.9906, Learning Rate: 9.00e-05
2025-12-09 01:16:21 - INFO - Epoch: 5.80, Step: 18390, Train Loss: 1.9762, Learning Rate: 9.00e-05
2025-12-09 01:16:32 - INFO - Epoch: 5.81, Step: 18400, Train Loss: 1.9964, Learning Rate: 9.00e-05
2025-12-09 01:16:43 - INFO - Epoch: 5.81, Step: 18410, Train Loss: 2.0256, Learning Rate: 9.00e-05
2025-12-09 01:16:54 - INFO - Epoch: 5.81, Step: 18420, Train Loss: 2.0017, Learning Rate: 9.00e-05
2025-12-09 01:17:05 - INFO - Epoch: 5.82, Step: 18430, Train Loss: 2.0372, Learning Rate: 9.00e-05
2025-12-09 01:17:16 - INFO - Epoch: 5.82, Step: 18440, Train Loss: 2.0290, Learning Rate: 9.00e-05
2025-12-09 01:17:28 - INFO - Epoch: 5.82, Step: 18450, Train Loss: 2.0080, Learning Rate: 8.99e-05
2025-12-09 01:17:39 - INFO - Epoch: 5.83, Step: 18460, Train Loss: 2.0111, Learning Rate: 8.99e-05
2025-12-09 01:17:50 - INFO - Epoch: 5.83, Step: 18470, Train Loss: 2.0253, Learning Rate: 8.99e-05
2025-12-09 01:18:01 - INFO - Epoch: 5.83, Step: 18480, Train Loss: 1.9990, Learning Rate: 8.99e-05
2025-12-09 01:18:12 - INFO - Epoch: 5.83, Step: 18490, Train Loss: 1.9775, Learning Rate: 8.99e-05
2025-12-09 01:18:23 - INFO - Epoch: 5.84, Step: 18500, Train Loss: 1.9687, Learning Rate: 8.99e-05
2025-12-09 01:18:34 - INFO - Epoch: 5.84, Step: 18510, Train Loss: 2.0147, Learning Rate: 8.99e-05
2025-12-09 01:18:45 - INFO - Epoch: 5.84, Step: 18520, Train Loss: 2.0553, Learning Rate: 8.99e-05
2025-12-09 01:18:56 - INFO - Epoch: 5.85, Step: 18530, Train Loss: 2.0225, Learning Rate: 8.99e-05
2025-12-09 01:19:07 - INFO - Epoch: 5.85, Step: 18540, Train Loss: 2.0144, Learning Rate: 8.99e-05
2025-12-09 01:19:18 - INFO - Epoch: 5.85, Step: 18550, Train Loss: 1.9945, Learning Rate: 8.99e-05
2025-12-09 01:19:29 - INFO - Epoch: 5.86, Step: 18560, Train Loss: 1.9722, Learning Rate: 8.99e-05
2025-12-09 01:19:40 - INFO - Epoch: 5.86, Step: 18570, Train Loss: 1.9767, Learning Rate: 8.98e-05
2025-12-09 01:19:52 - INFO - Epoch: 5.86, Step: 18580, Train Loss: 2.0266, Learning Rate: 8.98e-05
2025-12-09 01:20:03 - INFO - Epoch: 5.87, Step: 18590, Train Loss: 1.9968, Learning Rate: 8.98e-05
2025-12-09 01:20:14 - INFO - Epoch: 5.87, Step: 18600, Train Loss: 1.9720, Learning Rate: 8.98e-05
2025-12-09 01:20:25 - INFO - Epoch: 5.87, Step: 18610, Train Loss: 2.0121, Learning Rate: 8.98e-05
2025-12-09 01:20:36 - INFO - Epoch: 5.88, Step: 18620, Train Loss: 2.0192, Learning Rate: 8.98e-05
2025-12-09 01:20:47 - INFO - Epoch: 5.88, Step: 18630, Train Loss: 2.0194, Learning Rate: 8.98e-05
2025-12-09 01:20:58 - INFO - Epoch: 5.88, Step: 18640, Train Loss: 1.9796, Learning Rate: 8.98e-05
2025-12-09 01:21:09 - INFO - Epoch: 5.89, Step: 18650, Train Loss: 1.9742, Learning Rate: 8.98e-05
2025-12-09 01:21:20 - INFO - Epoch: 5.89, Step: 18660, Train Loss: 2.0221, Learning Rate: 8.98e-05
2025-12-09 01:21:31 - INFO - Epoch: 5.89, Step: 18670, Train Loss: 1.9951, Learning Rate: 8.98e-05
2025-12-09 01:21:42 - INFO - Epoch: 5.89, Step: 18680, Train Loss: 2.0286, Learning Rate: 8.98e-05
2025-12-09 01:21:53 - INFO - Epoch: 5.90, Step: 18690, Train Loss: 1.9677, Learning Rate: 8.97e-05
2025-12-09 01:22:04 - INFO - Epoch: 5.90, Step: 18700, Train Loss: 1.9929, Learning Rate: 8.97e-05
2025-12-09 01:22:16 - INFO - Epoch: 5.90, Step: 18710, Train Loss: 2.0529, Learning Rate: 8.97e-05
2025-12-09 01:22:27 - INFO - Epoch: 5.91, Step: 18720, Train Loss: 1.9721, Learning Rate: 8.97e-05
2025-12-09 01:22:38 - INFO - Epoch: 5.91, Step: 18730, Train Loss: 1.9913, Learning Rate: 8.97e-05
2025-12-09 01:22:49 - INFO - Epoch: 5.91, Step: 18740, Train Loss: 1.9822, Learning Rate: 8.97e-05
2025-12-09 01:23:00 - INFO - Epoch: 5.92, Step: 18750, Train Loss: 2.0076, Learning Rate: 8.97e-05
2025-12-09 01:23:11 - INFO - Epoch: 5.92, Step: 18760, Train Loss: 2.0348, Learning Rate: 8.97e-05
2025-12-09 01:23:22 - INFO - Epoch: 5.92, Step: 18770, Train Loss: 1.9812, Learning Rate: 8.97e-05
2025-12-09 01:23:33 - INFO - Epoch: 5.93, Step: 18780, Train Loss: 2.0509, Learning Rate: 8.97e-05
2025-12-09 01:23:44 - INFO - Epoch: 5.93, Step: 18790, Train Loss: 1.9698, Learning Rate: 8.97e-05
2025-12-09 01:23:55 - INFO - Epoch: 5.93, Step: 18800, Train Loss: 1.9844, Learning Rate: 8.97e-05
2025-12-09 01:24:06 - INFO - Epoch: 5.94, Step: 18810, Train Loss: 1.9725, Learning Rate: 8.96e-05
2025-12-09 01:24:17 - INFO - Epoch: 5.94, Step: 18820, Train Loss: 1.9714, Learning Rate: 8.96e-05
2025-12-09 01:24:29 - INFO - Epoch: 5.94, Step: 18830, Train Loss: 1.9974, Learning Rate: 8.96e-05
2025-12-09 01:24:40 - INFO - Epoch: 5.95, Step: 18840, Train Loss: 1.9654, Learning Rate: 8.96e-05
2025-12-09 01:24:51 - INFO - Epoch: 5.95, Step: 18850, Train Loss: 1.9675, Learning Rate: 8.96e-05
2025-12-09 01:25:02 - INFO - Epoch: 5.95, Step: 18860, Train Loss: 1.9946, Learning Rate: 8.96e-05
2025-12-09 01:25:13 - INFO - Epoch: 5.95, Step: 18870, Train Loss: 1.9663, Learning Rate: 8.96e-05
2025-12-09 01:25:24 - INFO - Epoch: 5.96, Step: 18880, Train Loss: 1.9740, Learning Rate: 8.96e-05
2025-12-09 01:25:35 - INFO - Epoch: 5.96, Step: 18890, Train Loss: 1.9638, Learning Rate: 8.96e-05
2025-12-09 01:25:46 - INFO - Epoch: 5.96, Step: 18900, Train Loss: 2.0277, Learning Rate: 8.96e-05
2025-12-09 01:25:57 - INFO - Epoch: 5.97, Step: 18910, Train Loss: 1.9518, Learning Rate: 8.96e-05
2025-12-09 01:26:08 - INFO - Epoch: 5.97, Step: 18920, Train Loss: 2.0267, Learning Rate: 8.96e-05
2025-12-09 01:26:19 - INFO - Epoch: 5.97, Step: 18930, Train Loss: 2.0199, Learning Rate: 8.95e-05
2025-12-09 01:26:30 - INFO - Epoch: 5.98, Step: 18940, Train Loss: 1.9717, Learning Rate: 8.95e-05
2025-12-09 01:26:41 - INFO - Epoch: 5.98, Step: 18950, Train Loss: 1.9718, Learning Rate: 8.95e-05
2025-12-09 01:26:53 - INFO - Epoch: 5.98, Step: 18960, Train Loss: 2.0023, Learning Rate: 8.95e-05
2025-12-09 01:27:04 - INFO - Epoch: 5.99, Step: 18970, Train Loss: 2.0135, Learning Rate: 8.95e-05
2025-12-09 01:27:15 - INFO - Epoch: 5.99, Step: 18980, Train Loss: 1.9869, Learning Rate: 8.95e-05
2025-12-09 01:27:26 - INFO - Epoch: 5.99, Step: 18990, Train Loss: 1.9390, Learning Rate: 8.95e-05
2025-12-09 01:27:37 - INFO - Epoch: 6.00, Step: 19000, Train Loss: 1.9790, Learning Rate: 8.95e-05
2025-12-09 01:27:48 - INFO - Epoch: 6.00, Step: 19010, Train Loss: 1.9455, Learning Rate: 8.95e-05
2025-12-09 01:27:59 - INFO - Epoch: 6.00, Step: 19020, Train Loss: 1.9617, Learning Rate: 8.95e-05
2025-12-09 01:28:10 - INFO - Epoch: 6.01, Step: 19030, Train Loss: 1.9476, Learning Rate: 8.95e-05
2025-12-09 01:28:21 - INFO - Epoch: 6.01, Step: 19040, Train Loss: 2.0130, Learning Rate: 8.95e-05
2025-12-09 01:28:32 - INFO - Epoch: 6.01, Step: 19050, Train Loss: 1.9661, Learning Rate: 8.94e-05
2025-12-09 01:28:43 - INFO - Epoch: 6.01, Step: 19060, Train Loss: 1.9678, Learning Rate: 8.94e-05
2025-12-09 01:28:54 - INFO - Epoch: 6.02, Step: 19070, Train Loss: 1.9861, Learning Rate: 8.94e-05
2025-12-09 01:29:05 - INFO - Epoch: 6.02, Step: 19080, Train Loss: 2.0082, Learning Rate: 8.94e-05
2025-12-09 01:29:17 - INFO - Epoch: 6.02, Step: 19090, Train Loss: 1.9771, Learning Rate: 8.94e-05
2025-12-09 01:29:28 - INFO - Epoch: 6.03, Step: 19100, Train Loss: 1.9842, Learning Rate: 8.94e-05
2025-12-09 01:29:39 - INFO - Epoch: 6.03, Step: 19110, Train Loss: 2.0182, Learning Rate: 8.94e-05
2025-12-09 01:29:50 - INFO - Epoch: 6.03, Step: 19120, Train Loss: 1.9731, Learning Rate: 8.94e-05
2025-12-09 01:30:01 - INFO - Epoch: 6.04, Step: 19130, Train Loss: 1.9430, Learning Rate: 8.94e-05
2025-12-09 01:30:12 - INFO - Epoch: 6.04, Step: 19140, Train Loss: 1.9877, Learning Rate: 8.94e-05
2025-12-09 01:30:23 - INFO - Epoch: 6.04, Step: 19150, Train Loss: 1.9874, Learning Rate: 8.94e-05
2025-12-09 01:30:34 - INFO - Epoch: 6.05, Step: 19160, Train Loss: 1.9625, Learning Rate: 8.94e-05
2025-12-09 01:30:45 - INFO - Epoch: 6.05, Step: 19170, Train Loss: 1.9896, Learning Rate: 8.93e-05
2025-12-09 01:30:56 - INFO - Epoch: 6.05, Step: 19180, Train Loss: 1.9593, Learning Rate: 8.93e-05
2025-12-09 01:31:07 - INFO - Epoch: 6.06, Step: 19190, Train Loss: 1.9677, Learning Rate: 8.93e-05
2025-12-09 01:31:18 - INFO - Epoch: 6.06, Step: 19200, Train Loss: 1.9898, Learning Rate: 8.93e-05
2025-12-09 01:31:29 - INFO - Epoch: 6.06, Step: 19210, Train Loss: 1.9504, Learning Rate: 8.93e-05
2025-12-09 01:31:41 - INFO - Epoch: 6.07, Step: 19220, Train Loss: 1.9316, Learning Rate: 8.93e-05
2025-12-09 01:31:52 - INFO - Epoch: 6.07, Step: 19230, Train Loss: 2.0312, Learning Rate: 8.93e-05
2025-12-09 01:32:03 - INFO - Epoch: 6.07, Step: 19240, Train Loss: 2.0082, Learning Rate: 8.93e-05
2025-12-09 01:32:14 - INFO - Epoch: 6.07, Step: 19250, Train Loss: 1.9611, Learning Rate: 8.93e-05
2025-12-09 01:32:25 - INFO - Epoch: 6.08, Step: 19260, Train Loss: 1.9892, Learning Rate: 8.93e-05
2025-12-09 01:32:36 - INFO - Epoch: 6.08, Step: 19270, Train Loss: 1.9497, Learning Rate: 8.93e-05
2025-12-09 01:32:47 - INFO - Epoch: 6.08, Step: 19280, Train Loss: 1.9886, Learning Rate: 8.93e-05
2025-12-09 01:32:58 - INFO - Epoch: 6.09, Step: 19290, Train Loss: 1.9764, Learning Rate: 8.92e-05
2025-12-09 01:33:09 - INFO - Epoch: 6.09, Step: 19300, Train Loss: 1.9300, Learning Rate: 8.92e-05
2025-12-09 01:33:20 - INFO - Epoch: 6.09, Step: 19310, Train Loss: 1.9518, Learning Rate: 8.92e-05
2025-12-09 01:33:31 - INFO - Epoch: 6.10, Step: 19320, Train Loss: 1.9796, Learning Rate: 8.92e-05
2025-12-09 01:33:42 - INFO - Epoch: 6.10, Step: 19330, Train Loss: 1.9577, Learning Rate: 8.92e-05
2025-12-09 01:33:54 - INFO - Epoch: 6.10, Step: 19340, Train Loss: 1.9406, Learning Rate: 8.92e-05
2025-12-09 01:34:05 - INFO - Epoch: 6.11, Step: 19350, Train Loss: 1.9422, Learning Rate: 8.92e-05
2025-12-09 01:34:16 - INFO - Epoch: 6.11, Step: 19360, Train Loss: 1.9567, Learning Rate: 8.92e-05
2025-12-09 01:34:27 - INFO - Epoch: 6.11, Step: 19370, Train Loss: 1.9848, Learning Rate: 8.92e-05
2025-12-09 01:34:38 - INFO - Epoch: 6.12, Step: 19380, Train Loss: 1.9941, Learning Rate: 8.92e-05
2025-12-09 01:34:49 - INFO - Epoch: 6.12, Step: 19390, Train Loss: 1.9393, Learning Rate: 8.92e-05
2025-12-09 01:35:00 - INFO - Epoch: 6.12, Step: 19400, Train Loss: 1.9554, Learning Rate: 8.92e-05
2025-12-09 01:35:11 - INFO - Epoch: 6.12, Step: 19410, Train Loss: 1.9635, Learning Rate: 8.91e-05
2025-12-09 01:35:22 - INFO - Epoch: 6.13, Step: 19420, Train Loss: 2.0063, Learning Rate: 8.91e-05
2025-12-09 01:35:33 - INFO - Epoch: 6.13, Step: 19430, Train Loss: 1.9908, Learning Rate: 8.91e-05
2025-12-09 01:35:44 - INFO - Epoch: 6.13, Step: 19440, Train Loss: 1.9550, Learning Rate: 8.91e-05
2025-12-09 01:35:55 - INFO - Epoch: 6.14, Step: 19450, Train Loss: 1.9656, Learning Rate: 8.91e-05
2025-12-09 01:36:06 - INFO - Epoch: 6.14, Step: 19460, Train Loss: 1.9571, Learning Rate: 8.91e-05
2025-12-09 01:36:18 - INFO - Epoch: 6.14, Step: 19470, Train Loss: 1.9381, Learning Rate: 8.91e-05
2025-12-09 01:36:29 - INFO - Epoch: 6.15, Step: 19480, Train Loss: 1.9656, Learning Rate: 8.91e-05
2025-12-09 01:36:40 - INFO - Epoch: 6.15, Step: 19490, Train Loss: 1.9695, Learning Rate: 8.91e-05
2025-12-09 01:36:51 - INFO - Epoch: 6.15, Step: 19500, Train Loss: 1.9757, Learning Rate: 8.91e-05
2025-12-09 01:37:02 - INFO - Epoch: 6.16, Step: 19510, Train Loss: 1.9750, Learning Rate: 8.91e-05
2025-12-09 01:37:13 - INFO - Epoch: 6.16, Step: 19520, Train Loss: 1.9173, Learning Rate: 8.91e-05
2025-12-09 01:37:24 - INFO - Epoch: 6.16, Step: 19530, Train Loss: 1.9381, Learning Rate: 8.90e-05
2025-12-09 01:37:35 - INFO - Epoch: 6.17, Step: 19540, Train Loss: 1.9356, Learning Rate: 8.90e-05
2025-12-09 01:37:46 - INFO - Epoch: 6.17, Step: 19550, Train Loss: 1.9821, Learning Rate: 8.90e-05
2025-12-09 01:37:57 - INFO - Epoch: 6.17, Step: 19560, Train Loss: 1.9936, Learning Rate: 8.90e-05
2025-12-09 01:38:08 - INFO - Epoch: 6.18, Step: 19570, Train Loss: 1.9631, Learning Rate: 8.90e-05
2025-12-09 01:38:19 - INFO - Epoch: 6.18, Step: 19580, Train Loss: 1.9335, Learning Rate: 8.90e-05
2025-12-09 01:38:30 - INFO - Epoch: 6.18, Step: 19590, Train Loss: 1.9047, Learning Rate: 8.90e-05
2025-12-09 01:38:42 - INFO - Epoch: 6.18, Step: 19600, Train Loss: 1.9665, Learning Rate: 8.90e-05
2025-12-09 01:38:53 - INFO - Epoch: 6.19, Step: 19610, Train Loss: 1.9703, Learning Rate: 8.90e-05
2025-12-09 01:39:04 - INFO - Epoch: 6.19, Step: 19620, Train Loss: 1.9095, Learning Rate: 8.90e-05
2025-12-09 01:39:15 - INFO - Epoch: 6.19, Step: 19630, Train Loss: 1.9405, Learning Rate: 8.90e-05
2025-12-09 01:39:26 - INFO - Epoch: 6.20, Step: 19640, Train Loss: 1.9466, Learning Rate: 8.90e-05
2025-12-09 01:39:37 - INFO - Epoch: 6.20, Step: 19650, Train Loss: 1.9447, Learning Rate: 8.89e-05
2025-12-09 01:39:48 - INFO - Epoch: 6.20, Step: 19660, Train Loss: 1.9524, Learning Rate: 8.89e-05
2025-12-09 01:39:59 - INFO - Epoch: 6.21, Step: 19670, Train Loss: 1.9473, Learning Rate: 8.89e-05
2025-12-09 01:40:10 - INFO - Epoch: 6.21, Step: 19680, Train Loss: 1.9613, Learning Rate: 8.89e-05
2025-12-09 01:40:21 - INFO - Epoch: 6.21, Step: 19690, Train Loss: 1.9425, Learning Rate: 8.89e-05
2025-12-09 01:40:32 - INFO - Epoch: 6.22, Step: 19700, Train Loss: 1.9613, Learning Rate: 8.89e-05
2025-12-09 01:40:43 - INFO - Epoch: 6.22, Step: 19710, Train Loss: 1.9390, Learning Rate: 8.89e-05
2025-12-09 01:40:55 - INFO - Epoch: 6.22, Step: 19720, Train Loss: 1.9217, Learning Rate: 8.89e-05
2025-12-09 01:41:06 - INFO - Epoch: 6.23, Step: 19730, Train Loss: 1.9638, Learning Rate: 8.89e-05
2025-12-09 01:41:17 - INFO - Epoch: 6.23, Step: 19740, Train Loss: 1.8980, Learning Rate: 8.89e-05
2025-12-09 01:41:28 - INFO - Epoch: 6.23, Step: 19750, Train Loss: 1.9533, Learning Rate: 8.89e-05
2025-12-09 01:41:39 - INFO - Epoch: 6.24, Step: 19760, Train Loss: 1.9557, Learning Rate: 8.89e-05
2025-12-09 01:41:50 - INFO - Epoch: 6.24, Step: 19770, Train Loss: 1.9273, Learning Rate: 8.88e-05
2025-12-09 01:42:01 - INFO - Epoch: 6.24, Step: 19780, Train Loss: 1.9650, Learning Rate: 8.88e-05
2025-12-09 01:42:12 - INFO - Epoch: 6.24, Step: 19790, Train Loss: 1.9439, Learning Rate: 8.88e-05
2025-12-09 01:42:23 - INFO - Epoch: 6.25, Step: 19800, Train Loss: 1.9006, Learning Rate: 8.88e-05
2025-12-09 01:42:34 - INFO - Epoch: 6.25, Step: 19810, Train Loss: 1.9627, Learning Rate: 8.88e-05
2025-12-09 01:42:45 - INFO - Epoch: 6.25, Step: 19820, Train Loss: 1.9269, Learning Rate: 8.88e-05
2025-12-09 01:42:56 - INFO - Epoch: 6.26, Step: 19830, Train Loss: 1.9557, Learning Rate: 8.88e-05
2025-12-09 01:43:07 - INFO - Epoch: 6.26, Step: 19840, Train Loss: 1.9693, Learning Rate: 8.88e-05
2025-12-09 01:43:19 - INFO - Epoch: 6.26, Step: 19850, Train Loss: 1.8860, Learning Rate: 8.88e-05
2025-12-09 01:43:30 - INFO - Epoch: 6.27, Step: 19860, Train Loss: 1.9161, Learning Rate: 8.88e-05
2025-12-09 01:43:41 - INFO - Epoch: 6.27, Step: 19870, Train Loss: 1.9740, Learning Rate: 8.88e-05
2025-12-09 01:43:52 - INFO - Epoch: 6.27, Step: 19880, Train Loss: 1.9622, Learning Rate: 8.88e-05
2025-12-09 01:44:03 - INFO - Epoch: 6.28, Step: 19890, Train Loss: 1.9533, Learning Rate: 8.87e-05
2025-12-09 01:44:14 - INFO - Epoch: 6.28, Step: 19900, Train Loss: 1.9077, Learning Rate: 8.87e-05
2025-12-09 01:44:25 - INFO - Epoch: 6.28, Step: 19910, Train Loss: 1.9097, Learning Rate: 8.87e-05
2025-12-09 01:44:36 - INFO - Epoch: 6.29, Step: 19920, Train Loss: 1.9288, Learning Rate: 8.87e-05
2025-12-09 01:44:47 - INFO - Epoch: 6.29, Step: 19930, Train Loss: 1.9425, Learning Rate: 8.87e-05
2025-12-09 01:44:58 - INFO - Epoch: 6.29, Step: 19940, Train Loss: 1.9064, Learning Rate: 8.87e-05
2025-12-09 01:45:09 - INFO - Epoch: 6.30, Step: 19950, Train Loss: 1.9520, Learning Rate: 8.87e-05
2025-12-09 01:45:20 - INFO - Epoch: 6.30, Step: 19960, Train Loss: 1.9476, Learning Rate: 8.87e-05
2025-12-09 01:45:31 - INFO - Epoch: 6.30, Step: 19970, Train Loss: 1.8919, Learning Rate: 8.87e-05
2025-12-09 01:45:43 - INFO - Epoch: 6.30, Step: 19980, Train Loss: 1.9022, Learning Rate: 8.87e-05
2025-12-09 01:45:54 - INFO - Epoch: 6.31, Step: 19990, Train Loss: 1.9455, Learning Rate: 8.87e-05
2025-12-09 01:46:05 - INFO - Epoch: 6.31, Step: 20000, Train Loss: 1.8890, Learning Rate: 8.87e-05
2025-12-09 01:46:16 - INFO - Epoch: 6.31, Step: 20010, Train Loss: 1.9271, Learning Rate: 8.86e-05
2025-12-09 01:46:27 - INFO - Epoch: 6.32, Step: 20020, Train Loss: 1.9225, Learning Rate: 8.86e-05
2025-12-09 01:46:38 - INFO - Epoch: 6.32, Step: 20030, Train Loss: 1.8964, Learning Rate: 8.86e-05
2025-12-09 01:46:49 - INFO - Epoch: 6.32, Step: 20040, Train Loss: 1.9492, Learning Rate: 8.86e-05
2025-12-09 01:47:00 - INFO - Epoch: 6.33, Step: 20050, Train Loss: 1.9233, Learning Rate: 8.86e-05
2025-12-09 01:47:11 - INFO - Epoch: 6.33, Step: 20060, Train Loss: 1.9264, Learning Rate: 8.86e-05
2025-12-09 01:47:22 - INFO - Epoch: 6.33, Step: 20070, Train Loss: 1.9427, Learning Rate: 8.86e-05
2025-12-09 01:47:33 - INFO - Epoch: 6.34, Step: 20080, Train Loss: 1.9403, Learning Rate: 8.86e-05
2025-12-09 01:47:44 - INFO - Epoch: 6.34, Step: 20090, Train Loss: 1.9044, Learning Rate: 8.86e-05
2025-12-09 01:47:56 - INFO - Epoch: 6.34, Step: 20100, Train Loss: 1.8995, Learning Rate: 8.86e-05
2025-12-09 01:48:07 - INFO - Epoch: 6.35, Step: 20110, Train Loss: 1.9061, Learning Rate: 8.86e-05
2025-12-09 01:48:18 - INFO - Epoch: 6.35, Step: 20120, Train Loss: 1.8837, Learning Rate: 8.86e-05
2025-12-09 01:48:29 - INFO - Epoch: 6.35, Step: 20130, Train Loss: 1.9620, Learning Rate: 8.85e-05
2025-12-09 01:48:40 - INFO - Epoch: 6.36, Step: 20140, Train Loss: 1.9029, Learning Rate: 8.85e-05
2025-12-09 01:48:51 - INFO - Epoch: 6.36, Step: 20150, Train Loss: 1.9354, Learning Rate: 8.85e-05
2025-12-09 01:49:02 - INFO - Epoch: 6.36, Step: 20160, Train Loss: 1.9570, Learning Rate: 8.85e-05
2025-12-09 01:49:13 - INFO - Epoch: 6.36, Step: 20170, Train Loss: 1.9379, Learning Rate: 8.85e-05
2025-12-09 01:49:24 - INFO - Epoch: 6.37, Step: 20180, Train Loss: 1.8806, Learning Rate: 8.85e-05
2025-12-09 01:49:35 - INFO - Epoch: 6.37, Step: 20190, Train Loss: 1.9069, Learning Rate: 8.85e-05
2025-12-09 01:49:46 - INFO - Epoch: 6.37, Step: 20200, Train Loss: 1.8987, Learning Rate: 8.85e-05
2025-12-09 01:49:57 - INFO - Epoch: 6.38, Step: 20210, Train Loss: 1.9409, Learning Rate: 8.85e-05
2025-12-09 01:50:08 - INFO - Epoch: 6.38, Step: 20220, Train Loss: 1.8904, Learning Rate: 8.85e-05
2025-12-09 01:50:20 - INFO - Epoch: 6.38, Step: 20230, Train Loss: 1.9290, Learning Rate: 8.85e-05
2025-12-09 01:50:31 - INFO - Epoch: 6.39, Step: 20240, Train Loss: 1.8921, Learning Rate: 8.85e-05
2025-12-09 01:50:42 - INFO - Epoch: 6.39, Step: 20250, Train Loss: 1.9082, Learning Rate: 8.84e-05
2025-12-09 01:50:53 - INFO - Epoch: 6.39, Step: 20260, Train Loss: 1.8959, Learning Rate: 8.84e-05
2025-12-09 01:51:04 - INFO - Epoch: 6.40, Step: 20270, Train Loss: 1.8817, Learning Rate: 8.84e-05
2025-12-09 01:51:15 - INFO - Epoch: 6.40, Step: 20280, Train Loss: 1.8970, Learning Rate: 8.84e-05
2025-12-09 01:51:26 - INFO - Epoch: 6.40, Step: 20290, Train Loss: 1.9452, Learning Rate: 8.84e-05
2025-12-09 01:51:37 - INFO - Epoch: 6.41, Step: 20300, Train Loss: 1.9217, Learning Rate: 8.84e-05
2025-12-09 01:51:48 - INFO - Epoch: 6.41, Step: 20310, Train Loss: 1.9284, Learning Rate: 8.84e-05
2025-12-09 01:51:59 - INFO - Epoch: 6.41, Step: 20320, Train Loss: 1.9203, Learning Rate: 8.84e-05
2025-12-09 01:52:10 - INFO - Epoch: 6.42, Step: 20330, Train Loss: 1.8981, Learning Rate: 8.84e-05
2025-12-09 01:52:21 - INFO - Epoch: 6.42, Step: 20340, Train Loss: 1.9013, Learning Rate: 8.84e-05
2025-12-09 01:52:32 - INFO - Epoch: 6.42, Step: 20350, Train Loss: 1.9164, Learning Rate: 8.84e-05
2025-12-09 01:52:44 - INFO - Epoch: 6.42, Step: 20360, Train Loss: 1.9224, Learning Rate: 8.84e-05
2025-12-09 01:52:55 - INFO - Epoch: 6.43, Step: 20370, Train Loss: 1.8904, Learning Rate: 8.83e-05
2025-12-09 01:53:06 - INFO - Epoch: 6.43, Step: 20380, Train Loss: 1.9329, Learning Rate: 8.83e-05
2025-12-09 01:53:17 - INFO - Epoch: 6.43, Step: 20390, Train Loss: 1.8926, Learning Rate: 8.83e-05
2025-12-09 01:53:28 - INFO - Epoch: 6.44, Step: 20400, Train Loss: 1.9065, Learning Rate: 8.83e-05
2025-12-09 01:53:39 - INFO - Epoch: 6.44, Step: 20410, Train Loss: 1.9346, Learning Rate: 8.83e-05
2025-12-09 01:53:50 - INFO - Epoch: 6.44, Step: 20420, Train Loss: 1.9076, Learning Rate: 8.83e-05
2025-12-09 01:54:01 - INFO - Epoch: 6.45, Step: 20430, Train Loss: 1.9262, Learning Rate: 8.83e-05
2025-12-09 01:54:12 - INFO - Epoch: 6.45, Step: 20440, Train Loss: 1.9284, Learning Rate: 8.83e-05
2025-12-09 01:54:23 - INFO - Epoch: 6.45, Step: 20450, Train Loss: 1.9375, Learning Rate: 8.83e-05
2025-12-09 01:54:34 - INFO - Epoch: 6.46, Step: 20460, Train Loss: 1.9225, Learning Rate: 8.83e-05
2025-12-09 01:54:45 - INFO - Epoch: 6.46, Step: 20470, Train Loss: 1.9224, Learning Rate: 8.83e-05
2025-12-09 01:54:57 - INFO - Epoch: 6.46, Step: 20480, Train Loss: 1.9290, Learning Rate: 8.83e-05
2025-12-09 01:55:08 - INFO - Epoch: 6.47, Step: 20490, Train Loss: 1.8540, Learning Rate: 8.82e-05
2025-12-09 01:55:19 - INFO - Epoch: 6.47, Step: 20500, Train Loss: 1.9226, Learning Rate: 8.82e-05
2025-12-09 01:55:30 - INFO - Epoch: 6.47, Step: 20510, Train Loss: 1.8885, Learning Rate: 8.82e-05
2025-12-09 01:55:41 - INFO - Epoch: 6.48, Step: 20520, Train Loss: 1.9150, Learning Rate: 8.82e-05
2025-12-09 01:55:52 - INFO - Epoch: 6.48, Step: 20530, Train Loss: 1.9018, Learning Rate: 8.82e-05
2025-12-09 01:56:03 - INFO - Epoch: 6.48, Step: 20540, Train Loss: 1.9124, Learning Rate: 8.82e-05
2025-12-09 01:56:14 - INFO - Epoch: 6.48, Step: 20550, Train Loss: 1.9305, Learning Rate: 8.82e-05
2025-12-09 01:56:25 - INFO - Epoch: 6.49, Step: 20560, Train Loss: 1.9065, Learning Rate: 8.82e-05
2025-12-09 01:56:36 - INFO - Epoch: 6.49, Step: 20570, Train Loss: 1.8920, Learning Rate: 8.82e-05
2025-12-09 01:56:47 - INFO - Epoch: 6.49, Step: 20580, Train Loss: 1.8923, Learning Rate: 8.82e-05
2025-12-09 01:56:58 - INFO - Epoch: 6.50, Step: 20590, Train Loss: 1.8722, Learning Rate: 8.82e-05
2025-12-09 01:57:09 - INFO - Epoch: 6.50, Step: 20600, Train Loss: 1.9302, Learning Rate: 8.82e-05
2025-12-09 01:57:21 - INFO - Epoch: 6.50, Step: 20610, Train Loss: 1.9113, Learning Rate: 8.81e-05
2025-12-09 01:57:32 - INFO - Epoch: 6.51, Step: 20620, Train Loss: 1.8949, Learning Rate: 8.81e-05
2025-12-09 01:57:43 - INFO - Epoch: 6.51, Step: 20630, Train Loss: 1.9114, Learning Rate: 8.81e-05
2025-12-09 01:57:54 - INFO - Epoch: 6.51, Step: 20640, Train Loss: 1.8838, Learning Rate: 8.81e-05
2025-12-09 01:58:05 - INFO - Epoch: 6.52, Step: 20650, Train Loss: 1.9157, Learning Rate: 8.81e-05
2025-12-09 01:58:16 - INFO - Epoch: 6.52, Step: 20660, Train Loss: 1.8851, Learning Rate: 8.81e-05
2025-12-09 01:58:27 - INFO - Epoch: 6.52, Step: 20670, Train Loss: 1.8906, Learning Rate: 8.81e-05
2025-12-09 01:58:38 - INFO - Epoch: 6.53, Step: 20680, Train Loss: 1.9036, Learning Rate: 8.81e-05
2025-12-09 01:58:49 - INFO - Epoch: 6.53, Step: 20690, Train Loss: 1.9090, Learning Rate: 8.81e-05
2025-12-09 01:59:00 - INFO - Epoch: 6.53, Step: 20700, Train Loss: 1.9087, Learning Rate: 8.81e-05
2025-12-09 01:59:11 - INFO - Epoch: 6.54, Step: 20710, Train Loss: 1.8759, Learning Rate: 8.81e-05
2025-12-09 01:59:22 - INFO - Epoch: 6.54, Step: 20720, Train Loss: 1.9051, Learning Rate: 8.81e-05
2025-12-09 01:59:33 - INFO - Epoch: 6.54, Step: 20730, Train Loss: 1.9229, Learning Rate: 8.80e-05
2025-12-09 01:59:45 - INFO - Epoch: 6.54, Step: 20740, Train Loss: 1.8891, Learning Rate: 8.80e-05
2025-12-09 01:59:56 - INFO - Epoch: 6.55, Step: 20750, Train Loss: 1.8874, Learning Rate: 8.80e-05
2025-12-09 02:00:07 - INFO - Epoch: 6.55, Step: 20760, Train Loss: 1.9121, Learning Rate: 8.80e-05
2025-12-09 02:00:18 - INFO - Epoch: 6.55, Step: 20770, Train Loss: 1.8893, Learning Rate: 8.80e-05
2025-12-09 02:00:29 - INFO - Epoch: 6.56, Step: 20780, Train Loss: 1.8800, Learning Rate: 8.80e-05
2025-12-09 02:00:40 - INFO - Epoch: 6.56, Step: 20790, Train Loss: 1.9440, Learning Rate: 8.80e-05
2025-12-09 02:00:51 - INFO - Epoch: 6.56, Step: 20800, Train Loss: 1.8391, Learning Rate: 8.80e-05
2025-12-09 02:01:02 - INFO - Epoch: 6.57, Step: 20810, Train Loss: 1.8771, Learning Rate: 8.80e-05
2025-12-09 02:01:13 - INFO - Epoch: 6.57, Step: 20820, Train Loss: 1.8924, Learning Rate: 8.80e-05
2025-12-09 02:01:24 - INFO - Epoch: 6.57, Step: 20830, Train Loss: 1.9035, Learning Rate: 8.80e-05
2025-12-09 02:01:35 - INFO - Epoch: 6.58, Step: 20840, Train Loss: 1.9252, Learning Rate: 8.80e-05
2025-12-09 02:01:46 - INFO - Epoch: 6.58, Step: 20850, Train Loss: 1.8761, Learning Rate: 8.79e-05
2025-12-09 02:01:58 - INFO - Epoch: 6.58, Step: 20860, Train Loss: 1.8460, Learning Rate: 8.79e-05
2025-12-09 02:02:09 - INFO - Epoch: 6.59, Step: 20870, Train Loss: 1.8954, Learning Rate: 8.79e-05
2025-12-09 02:02:20 - INFO - Epoch: 6.59, Step: 20880, Train Loss: 1.8917, Learning Rate: 8.79e-05
2025-12-09 02:02:31 - INFO - Epoch: 6.59, Step: 20890, Train Loss: 1.8691, Learning Rate: 8.79e-05
2025-12-09 02:02:42 - INFO - Epoch: 6.60, Step: 20900, Train Loss: 1.8711, Learning Rate: 8.79e-05
2025-12-09 02:02:53 - INFO - Epoch: 6.60, Step: 20910, Train Loss: 1.9299, Learning Rate: 8.79e-05
2025-12-09 02:03:04 - INFO - Epoch: 6.60, Step: 20920, Train Loss: 1.8947, Learning Rate: 8.79e-05
2025-12-09 02:03:15 - INFO - Epoch: 6.60, Step: 20930, Train Loss: 1.9178, Learning Rate: 8.79e-05
2025-12-09 02:03:26 - INFO - Epoch: 6.61, Step: 20940, Train Loss: 1.9005, Learning Rate: 8.79e-05
2025-12-09 02:03:37 - INFO - Epoch: 6.61, Step: 20950, Train Loss: 1.9159, Learning Rate: 8.79e-05
2025-12-09 02:03:48 - INFO - Epoch: 6.61, Step: 20960, Train Loss: 1.8818, Learning Rate: 8.79e-05
2025-12-09 02:03:59 - INFO - Epoch: 6.62, Step: 20970, Train Loss: 1.8669, Learning Rate: 8.79e-05
2025-12-09 02:04:10 - INFO - Epoch: 6.62, Step: 20980, Train Loss: 1.9331, Learning Rate: 8.78e-05
2025-12-09 02:04:22 - INFO - Epoch: 6.62, Step: 20990, Train Loss: 1.8656, Learning Rate: 8.78e-05
2025-12-09 02:04:33 - INFO - Epoch: 6.63, Step: 21000, Train Loss: 1.8700, Learning Rate: 8.78e-05
2025-12-09 02:04:44 - INFO - Epoch: 6.63, Step: 21010, Train Loss: 1.8656, Learning Rate: 8.78e-05
2025-12-09 02:04:55 - INFO - Epoch: 6.63, Step: 21020, Train Loss: 1.8783, Learning Rate: 8.78e-05
2025-12-09 02:05:06 - INFO - Epoch: 6.64, Step: 21030, Train Loss: 1.9067, Learning Rate: 8.78e-05
2025-12-09 02:05:17 - INFO - Epoch: 6.64, Step: 21040, Train Loss: 1.8579, Learning Rate: 8.78e-05
2025-12-09 02:05:28 - INFO - Epoch: 6.64, Step: 21050, Train Loss: 1.8507, Learning Rate: 8.78e-05
2025-12-09 02:05:39 - INFO - Epoch: 6.65, Step: 21060, Train Loss: 1.8513, Learning Rate: 8.78e-05
2025-12-09 02:05:50 - INFO - Epoch: 6.65, Step: 21070, Train Loss: 1.8738, Learning Rate: 8.78e-05
2025-12-09 02:06:01 - INFO - Epoch: 6.65, Step: 21080, Train Loss: 1.8942, Learning Rate: 8.78e-05
2025-12-09 02:06:12 - INFO - Epoch: 6.66, Step: 21090, Train Loss: 1.8782, Learning Rate: 8.78e-05
2025-12-09 02:06:23 - INFO - Epoch: 6.66, Step: 21100, Train Loss: 1.8433, Learning Rate: 8.77e-05
2025-12-09 02:06:34 - INFO - Epoch: 6.66, Step: 21110, Train Loss: 1.8505, Learning Rate: 8.77e-05
2025-12-09 02:06:46 - INFO - Epoch: 6.66, Step: 21120, Train Loss: 1.8852, Learning Rate: 8.77e-05
2025-12-09 02:06:57 - INFO - Epoch: 6.67, Step: 21130, Train Loss: 1.9233, Learning Rate: 8.77e-05
2025-12-09 02:07:08 - INFO - Epoch: 6.67, Step: 21140, Train Loss: 1.8496, Learning Rate: 8.77e-05
2025-12-09 02:07:19 - INFO - Epoch: 6.67, Step: 21150, Train Loss: 1.8330, Learning Rate: 8.77e-05
2025-12-09 02:07:30 - INFO - Epoch: 6.68, Step: 21160, Train Loss: 1.8805, Learning Rate: 8.77e-05
2025-12-09 02:07:41 - INFO - Epoch: 6.68, Step: 21170, Train Loss: 1.8929, Learning Rate: 8.77e-05
2025-12-09 02:07:52 - INFO - Epoch: 6.68, Step: 21180, Train Loss: 1.8622, Learning Rate: 8.77e-05
2025-12-09 02:08:03 - INFO - Epoch: 6.69, Step: 21190, Train Loss: 1.8967, Learning Rate: 8.77e-05
2025-12-09 02:08:14 - INFO - Epoch: 6.69, Step: 21200, Train Loss: 1.8562, Learning Rate: 8.77e-05
2025-12-09 02:08:25 - INFO - Epoch: 6.69, Step: 21210, Train Loss: 1.8680, Learning Rate: 8.77e-05
2025-12-09 02:08:36 - INFO - Epoch: 6.70, Step: 21220, Train Loss: 1.9028, Learning Rate: 8.76e-05
2025-12-09 02:08:47 - INFO - Epoch: 6.70, Step: 21230, Train Loss: 1.8567, Learning Rate: 8.76e-05
2025-12-09 02:08:59 - INFO - Epoch: 6.70, Step: 21240, Train Loss: 1.8991, Learning Rate: 8.76e-05
2025-12-09 02:09:10 - INFO - Epoch: 6.71, Step: 21250, Train Loss: 1.8998, Learning Rate: 8.76e-05
2025-12-09 02:09:21 - INFO - Epoch: 6.71, Step: 21260, Train Loss: 1.8453, Learning Rate: 8.76e-05
2025-12-09 02:09:32 - INFO - Epoch: 6.71, Step: 21270, Train Loss: 1.8442, Learning Rate: 8.76e-05
2025-12-09 02:09:43 - INFO - Epoch: 6.72, Step: 21280, Train Loss: 1.8973, Learning Rate: 8.76e-05
2025-12-09 02:09:54 - INFO - Epoch: 6.72, Step: 21290, Train Loss: 1.8599, Learning Rate: 8.76e-05
2025-12-09 02:10:05 - INFO - Epoch: 6.72, Step: 21300, Train Loss: 1.8678, Learning Rate: 8.76e-05
2025-12-09 02:10:16 - INFO - Epoch: 6.72, Step: 21310, Train Loss: 1.8057, Learning Rate: 8.76e-05
2025-12-09 02:10:27 - INFO - Epoch: 6.73, Step: 21320, Train Loss: 1.8370, Learning Rate: 8.76e-05
2025-12-09 02:10:38 - INFO - Epoch: 6.73, Step: 21330, Train Loss: 1.8411, Learning Rate: 8.76e-05
2025-12-09 02:10:49 - INFO - Epoch: 6.73, Step: 21340, Train Loss: 1.9482, Learning Rate: 8.75e-05
2025-12-09 02:11:00 - INFO - Epoch: 6.74, Step: 21350, Train Loss: 1.8997, Learning Rate: 8.75e-05
2025-12-09 02:11:11 - INFO - Epoch: 6.74, Step: 21360, Train Loss: 1.8690, Learning Rate: 8.75e-05
2025-12-09 02:11:23 - INFO - Epoch: 6.74, Step: 21370, Train Loss: 1.9048, Learning Rate: 8.75e-05
2025-12-09 02:11:34 - INFO - Epoch: 6.75, Step: 21380, Train Loss: 1.8762, Learning Rate: 8.75e-05
2025-12-09 02:11:45 - INFO - Epoch: 6.75, Step: 21390, Train Loss: 1.8626, Learning Rate: 8.75e-05
2025-12-09 02:11:56 - INFO - Epoch: 6.75, Step: 21400, Train Loss: 1.8314, Learning Rate: 8.75e-05
2025-12-09 02:12:07 - INFO - Epoch: 6.76, Step: 21410, Train Loss: 1.8365, Learning Rate: 8.75e-05
2025-12-09 02:12:18 - INFO - Epoch: 6.76, Step: 21420, Train Loss: 1.8418, Learning Rate: 8.75e-05
2025-12-09 02:12:29 - INFO - Epoch: 6.76, Step: 21430, Train Loss: 1.8610, Learning Rate: 8.75e-05
2025-12-09 02:12:40 - INFO - Epoch: 6.77, Step: 21440, Train Loss: 1.8362, Learning Rate: 8.75e-05
2025-12-09 02:12:51 - INFO - Epoch: 6.77, Step: 21450, Train Loss: 1.8746, Learning Rate: 8.75e-05
2025-12-09 02:13:02 - INFO - Epoch: 6.77, Step: 21460, Train Loss: 1.8706, Learning Rate: 8.74e-05
2025-12-09 02:13:13 - INFO - Epoch: 6.78, Step: 21470, Train Loss: 1.8578, Learning Rate: 8.74e-05
2025-12-09 02:13:24 - INFO - Epoch: 6.78, Step: 21480, Train Loss: 1.8156, Learning Rate: 8.74e-05
2025-12-09 02:13:35 - INFO - Epoch: 6.78, Step: 21490, Train Loss: 1.9037, Learning Rate: 8.74e-05
2025-12-09 02:13:47 - INFO - Epoch: 6.78, Step: 21500, Train Loss: 1.8939, Learning Rate: 8.74e-05
2025-12-09 02:13:58 - INFO - Epoch: 6.79, Step: 21510, Train Loss: 1.8595, Learning Rate: 8.74e-05
2025-12-09 02:14:09 - INFO - Epoch: 6.79, Step: 21520, Train Loss: 1.8923, Learning Rate: 8.74e-05
2025-12-09 02:14:20 - INFO - Epoch: 6.79, Step: 21530, Train Loss: 1.9046, Learning Rate: 8.74e-05
2025-12-09 02:14:31 - INFO - Epoch: 6.80, Step: 21540, Train Loss: 1.8698, Learning Rate: 8.74e-05
2025-12-09 02:14:42 - INFO - Epoch: 6.80, Step: 21550, Train Loss: 1.8424, Learning Rate: 8.74e-05
2025-12-09 02:14:53 - INFO - Epoch: 6.80, Step: 21560, Train Loss: 1.8453, Learning Rate: 8.74e-05
2025-12-09 02:15:04 - INFO - Epoch: 6.81, Step: 21570, Train Loss: 1.8566, Learning Rate: 8.74e-05
2025-12-09 02:15:15 - INFO - Epoch: 6.81, Step: 21580, Train Loss: 1.8066, Learning Rate: 8.73e-05
2025-12-09 02:15:26 - INFO - Epoch: 6.81, Step: 21590, Train Loss: 1.8845, Learning Rate: 8.73e-05
2025-12-09 02:15:37 - INFO - Epoch: 6.82, Step: 21600, Train Loss: 1.8937, Learning Rate: 8.73e-05
2025-12-09 02:15:48 - INFO - Epoch: 6.82, Step: 21610, Train Loss: 1.8535, Learning Rate: 8.73e-05
2025-12-09 02:16:00 - INFO - Epoch: 6.82, Step: 21620, Train Loss: 1.8756, Learning Rate: 8.73e-05
2025-12-09 02:16:11 - INFO - Epoch: 6.83, Step: 21630, Train Loss: 1.8911, Learning Rate: 8.73e-05
2025-12-09 02:16:22 - INFO - Epoch: 6.83, Step: 21640, Train Loss: 1.8528, Learning Rate: 8.73e-05
2025-12-09 02:16:33 - INFO - Epoch: 6.83, Step: 21650, Train Loss: 1.8398, Learning Rate: 8.73e-05
2025-12-09 02:16:44 - INFO - Epoch: 6.83, Step: 21660, Train Loss: 1.8350, Learning Rate: 8.73e-05
2025-12-09 02:16:55 - INFO - Epoch: 6.84, Step: 21670, Train Loss: 1.8182, Learning Rate: 8.73e-05
2025-12-09 02:17:06 - INFO - Epoch: 6.84, Step: 21680, Train Loss: 1.8689, Learning Rate: 8.73e-05
2025-12-09 02:17:17 - INFO - Epoch: 6.84, Step: 21690, Train Loss: 1.8857, Learning Rate: 8.73e-05
2025-12-09 02:17:28 - INFO - Epoch: 6.85, Step: 21700, Train Loss: 1.8639, Learning Rate: 8.72e-05
2025-12-09 02:17:39 - INFO - Epoch: 6.85, Step: 21710, Train Loss: 1.8580, Learning Rate: 8.72e-05
2025-12-09 02:17:50 - INFO - Epoch: 6.85, Step: 21720, Train Loss: 1.8737, Learning Rate: 8.72e-05
2025-12-09 02:18:01 - INFO - Epoch: 6.86, Step: 21730, Train Loss: 1.8689, Learning Rate: 8.72e-05
2025-12-09 02:18:12 - INFO - Epoch: 6.86, Step: 21740, Train Loss: 1.8275, Learning Rate: 8.72e-05
2025-12-09 02:18:24 - INFO - Epoch: 6.86, Step: 21750, Train Loss: 1.8375, Learning Rate: 8.72e-05
2025-12-09 02:18:35 - INFO - Epoch: 6.87, Step: 21760, Train Loss: 1.8653, Learning Rate: 8.72e-05
2025-12-09 02:18:46 - INFO - Epoch: 6.87, Step: 21770, Train Loss: 1.8989, Learning Rate: 8.72e-05
2025-12-09 02:18:57 - INFO - Epoch: 6.87, Step: 21780, Train Loss: 1.8653, Learning Rate: 8.72e-05
2025-12-09 02:19:08 - INFO - Epoch: 6.88, Step: 21790, Train Loss: 1.8576, Learning Rate: 8.72e-05
2025-12-09 02:19:19 - INFO - Epoch: 6.88, Step: 21800, Train Loss: 1.8690, Learning Rate: 8.72e-05
2025-12-09 02:19:30 - INFO - Epoch: 6.88, Step: 21810, Train Loss: 1.8285, Learning Rate: 8.72e-05
2025-12-09 02:19:41 - INFO - Epoch: 6.89, Step: 21820, Train Loss: 1.8405, Learning Rate: 8.71e-05
2025-12-09 02:19:52 - INFO - Epoch: 6.89, Step: 21830, Train Loss: 1.8639, Learning Rate: 8.71e-05
2025-12-09 02:20:03 - INFO - Epoch: 6.89, Step: 21840, Train Loss: 1.8221, Learning Rate: 8.71e-05
2025-12-09 02:20:14 - INFO - Epoch: 6.89, Step: 21850, Train Loss: 1.8271, Learning Rate: 8.71e-05
2025-12-09 02:20:25 - INFO - Epoch: 6.90, Step: 21860, Train Loss: 1.8503, Learning Rate: 8.71e-05
2025-12-09 02:20:36 - INFO - Epoch: 6.90, Step: 21870, Train Loss: 1.8539, Learning Rate: 8.71e-05
2025-12-09 02:20:48 - INFO - Epoch: 6.90, Step: 21880, Train Loss: 1.8485, Learning Rate: 8.71e-05
2025-12-09 02:20:59 - INFO - Epoch: 6.91, Step: 21890, Train Loss: 1.8640, Learning Rate: 8.71e-05
2025-12-09 02:21:10 - INFO - Epoch: 6.91, Step: 21900, Train Loss: 1.8057, Learning Rate: 8.71e-05
2025-12-09 02:21:21 - INFO - Epoch: 6.91, Step: 21910, Train Loss: 1.8263, Learning Rate: 8.71e-05
2025-12-09 02:21:32 - INFO - Epoch: 6.92, Step: 21920, Train Loss: 1.8496, Learning Rate: 8.71e-05
2025-12-09 02:21:43 - INFO - Epoch: 6.92, Step: 21930, Train Loss: 1.8125, Learning Rate: 8.71e-05
2025-12-09 02:21:54 - INFO - Epoch: 6.92, Step: 21940, Train Loss: 1.8331, Learning Rate: 8.70e-05
2025-12-09 02:22:05 - INFO - Epoch: 6.93, Step: 21950, Train Loss: 1.8557, Learning Rate: 8.70e-05
2025-12-09 02:22:16 - INFO - Epoch: 6.93, Step: 21960, Train Loss: 1.8573, Learning Rate: 8.70e-05
2025-12-09 02:22:27 - INFO - Epoch: 6.93, Step: 21970, Train Loss: 1.8271, Learning Rate: 8.70e-05
2025-12-09 02:22:38 - INFO - Epoch: 6.94, Step: 21980, Train Loss: 1.8548, Learning Rate: 8.70e-05
2025-12-09 02:22:49 - INFO - Epoch: 6.94, Step: 21990, Train Loss: 1.8480, Learning Rate: 8.70e-05
2025-12-09 02:23:01 - INFO - Epoch: 6.94, Step: 22000, Train Loss: 1.8139, Learning Rate: 8.70e-05
2025-12-09 02:23:12 - INFO - Epoch: 6.95, Step: 22010, Train Loss: 1.8644, Learning Rate: 8.70e-05
2025-12-09 02:23:23 - INFO - Epoch: 6.95, Step: 22020, Train Loss: 1.8370, Learning Rate: 8.70e-05
2025-12-09 02:23:34 - INFO - Epoch: 6.95, Step: 22030, Train Loss: 1.8681, Learning Rate: 8.70e-05
2025-12-09 02:23:45 - INFO - Epoch: 6.95, Step: 22040, Train Loss: 1.8215, Learning Rate: 8.70e-05
2025-12-09 02:23:56 - INFO - Epoch: 6.96, Step: 22050, Train Loss: 1.8393, Learning Rate: 8.70e-05
2025-12-09 02:24:07 - INFO - Epoch: 6.96, Step: 22060, Train Loss: 1.8052, Learning Rate: 8.69e-05
2025-12-09 02:24:18 - INFO - Epoch: 6.96, Step: 22070, Train Loss: 1.8586, Learning Rate: 8.69e-05
2025-12-09 02:24:29 - INFO - Epoch: 6.97, Step: 22080, Train Loss: 1.7969, Learning Rate: 8.69e-05
2025-12-09 02:24:40 - INFO - Epoch: 6.97, Step: 22090, Train Loss: 1.9044, Learning Rate: 8.69e-05
2025-12-09 02:24:51 - INFO - Epoch: 6.97, Step: 22100, Train Loss: 1.8474, Learning Rate: 8.69e-05
2025-12-09 02:25:02 - INFO - Epoch: 6.98, Step: 22110, Train Loss: 1.8221, Learning Rate: 8.69e-05
2025-12-09 02:25:13 - INFO - Epoch: 6.98, Step: 22120, Train Loss: 1.8291, Learning Rate: 8.69e-05
2025-12-09 02:25:25 - INFO - Epoch: 6.98, Step: 22130, Train Loss: 1.7974, Learning Rate: 8.69e-05
2025-12-09 02:25:36 - INFO - Epoch: 6.99, Step: 22140, Train Loss: 1.8884, Learning Rate: 8.69e-05
2025-12-09 02:25:47 - INFO - Epoch: 6.99, Step: 22150, Train Loss: 1.8724, Learning Rate: 8.69e-05
2025-12-09 02:25:58 - INFO - Epoch: 6.99, Step: 22160, Train Loss: 1.8532, Learning Rate: 8.69e-05
2025-12-09 02:26:09 - INFO - Epoch: 7.00, Step: 22170, Train Loss: 1.8125, Learning Rate: 8.69e-05
2025-12-09 02:26:20 - INFO - Epoch: 7.00, Step: 22180, Train Loss: 1.8354, Learning Rate: 8.68e-05
2025-12-09 02:26:31 - INFO - Epoch: 7.00, Step: 22190, Train Loss: 1.8328, Learning Rate: 8.68e-05
2025-12-09 02:26:42 - INFO - Epoch: 7.01, Step: 22200, Train Loss: 1.8031, Learning Rate: 8.68e-05
2025-12-09 02:26:53 - INFO - Epoch: 7.01, Step: 22210, Train Loss: 1.8244, Learning Rate: 8.68e-05
2025-12-09 02:27:04 - INFO - Epoch: 7.01, Step: 22220, Train Loss: 1.8009, Learning Rate: 8.68e-05
2025-12-09 02:27:15 - INFO - Epoch: 7.01, Step: 22230, Train Loss: 1.8413, Learning Rate: 8.68e-05
2025-12-09 02:27:26 - INFO - Epoch: 7.02, Step: 22240, Train Loss: 1.8014, Learning Rate: 8.68e-05
2025-12-09 02:27:38 - INFO - Epoch: 7.02, Step: 22250, Train Loss: 1.8413, Learning Rate: 8.68e-05
2025-12-09 02:27:49 - INFO - Epoch: 7.02, Step: 22260, Train Loss: 1.8387, Learning Rate: 8.68e-05
2025-12-09 02:28:00 - INFO - Epoch: 7.03, Step: 22270, Train Loss: 1.8319, Learning Rate: 8.68e-05
2025-12-09 02:28:11 - INFO - Epoch: 7.03, Step: 22280, Train Loss: 1.8392, Learning Rate: 8.68e-05
2025-12-09 02:28:22 - INFO - Epoch: 7.03, Step: 22290, Train Loss: 1.8432, Learning Rate: 8.68e-05
2025-12-09 02:28:33 - INFO - Epoch: 7.04, Step: 22300, Train Loss: 1.8463, Learning Rate: 8.67e-05
2025-12-09 02:28:44 - INFO - Epoch: 7.04, Step: 22310, Train Loss: 1.8265, Learning Rate: 8.67e-05
2025-12-09 02:28:55 - INFO - Epoch: 7.04, Step: 22320, Train Loss: 1.8182, Learning Rate: 8.67e-05
2025-12-09 02:29:06 - INFO - Epoch: 7.05, Step: 22330, Train Loss: 1.8244, Learning Rate: 8.67e-05
2025-12-09 02:29:17 - INFO - Epoch: 7.05, Step: 22340, Train Loss: 1.8300, Learning Rate: 8.67e-05
2025-12-09 02:29:28 - INFO - Epoch: 7.05, Step: 22350, Train Loss: 1.8560, Learning Rate: 8.67e-05
2025-12-09 02:29:39 - INFO - Epoch: 7.06, Step: 22360, Train Loss: 1.8738, Learning Rate: 8.67e-05
2025-12-09 02:29:50 - INFO - Epoch: 7.06, Step: 22370, Train Loss: 1.8016, Learning Rate: 8.67e-05
2025-12-09 02:30:02 - INFO - Epoch: 7.06, Step: 22380, Train Loss: 1.8368, Learning Rate: 8.67e-05
2025-12-09 02:30:13 - INFO - Epoch: 7.07, Step: 22390, Train Loss: 1.8003, Learning Rate: 8.67e-05
2025-12-09 02:30:24 - INFO - Epoch: 7.07, Step: 22400, Train Loss: 1.8316, Learning Rate: 8.67e-05
2025-12-09 02:30:35 - INFO - Epoch: 7.07, Step: 22410, Train Loss: 1.8401, Learning Rate: 8.67e-05
2025-12-09 02:30:46 - INFO - Epoch: 7.07, Step: 22420, Train Loss: 1.8070, Learning Rate: 8.66e-05
2025-12-09 02:30:57 - INFO - Epoch: 7.08, Step: 22430, Train Loss: 1.8183, Learning Rate: 8.66e-05
2025-12-09 02:31:08 - INFO - Epoch: 7.08, Step: 22440, Train Loss: 1.7781, Learning Rate: 8.66e-05
2025-12-09 02:31:19 - INFO - Epoch: 7.08, Step: 22450, Train Loss: 1.8132, Learning Rate: 8.66e-05
2025-12-09 02:31:30 - INFO - Epoch: 7.09, Step: 22460, Train Loss: 1.8308, Learning Rate: 8.66e-05
2025-12-09 02:31:41 - INFO - Epoch: 7.09, Step: 22470, Train Loss: 1.8319, Learning Rate: 8.66e-05
2025-12-09 02:31:52 - INFO - Epoch: 7.09, Step: 22480, Train Loss: 1.8190, Learning Rate: 8.66e-05
2025-12-09 02:32:03 - INFO - Epoch: 7.10, Step: 22490, Train Loss: 1.8220, Learning Rate: 8.66e-05
2025-12-09 02:32:15 - INFO - Epoch: 7.10, Step: 22500, Train Loss: 1.8209, Learning Rate: 8.66e-05
2025-12-09 02:32:26 - INFO - Epoch: 7.10, Step: 22510, Train Loss: 1.8155, Learning Rate: 8.66e-05
2025-12-09 02:32:37 - INFO - Epoch: 7.11, Step: 22520, Train Loss: 1.8156, Learning Rate: 8.66e-05
2025-12-09 02:32:48 - INFO - Epoch: 7.11, Step: 22530, Train Loss: 1.8315, Learning Rate: 8.66e-05
2025-12-09 02:32:59 - INFO - Epoch: 7.11, Step: 22540, Train Loss: 1.8270, Learning Rate: 8.65e-05
2025-12-09 02:33:10 - INFO - Epoch: 7.12, Step: 22550, Train Loss: 1.8679, Learning Rate: 8.65e-05
2025-12-09 02:33:21 - INFO - Epoch: 7.12, Step: 22560, Train Loss: 1.8467, Learning Rate: 8.65e-05
2025-12-09 02:33:32 - INFO - Epoch: 7.12, Step: 22570, Train Loss: 1.8563, Learning Rate: 8.65e-05
2025-12-09 02:33:43 - INFO - Epoch: 7.13, Step: 22580, Train Loss: 1.8436, Learning Rate: 8.65e-05
2025-12-09 02:33:54 - INFO - Epoch: 7.13, Step: 22590, Train Loss: 1.7943, Learning Rate: 8.65e-05
2025-12-09 02:34:05 - INFO - Epoch: 7.13, Step: 22600, Train Loss: 1.8341, Learning Rate: 8.65e-05
2025-12-09 02:34:16 - INFO - Epoch: 7.13, Step: 22610, Train Loss: 1.8076, Learning Rate: 8.65e-05
2025-12-09 02:34:28 - INFO - Epoch: 7.14, Step: 22620, Train Loss: 1.8414, Learning Rate: 8.65e-05
2025-12-09 02:34:39 - INFO - Epoch: 7.14, Step: 22630, Train Loss: 1.8267, Learning Rate: 8.65e-05
2025-12-09 02:34:50 - INFO - Epoch: 7.14, Step: 22640, Train Loss: 1.8256, Learning Rate: 8.65e-05
2025-12-09 02:35:01 - INFO - Epoch: 7.15, Step: 22650, Train Loss: 1.8190, Learning Rate: 8.65e-05
2025-12-09 02:35:12 - INFO - Epoch: 7.15, Step: 22660, Train Loss: 1.8377, Learning Rate: 8.64e-05
2025-12-09 02:35:23 - INFO - Epoch: 7.15, Step: 22670, Train Loss: 1.7958, Learning Rate: 8.64e-05
2025-12-09 02:35:34 - INFO - Epoch: 7.16, Step: 22680, Train Loss: 1.7875, Learning Rate: 8.64e-05
2025-12-09 02:35:45 - INFO - Epoch: 7.16, Step: 22690, Train Loss: 1.8519, Learning Rate: 8.64e-05
2025-12-09 02:35:56 - INFO - Epoch: 7.16, Step: 22700, Train Loss: 1.8072, Learning Rate: 8.64e-05
2025-12-09 02:36:07 - INFO - Epoch: 7.17, Step: 22710, Train Loss: 1.8327, Learning Rate: 8.64e-05
2025-12-09 02:36:18 - INFO - Epoch: 7.17, Step: 22720, Train Loss: 1.8294, Learning Rate: 8.64e-05
2025-12-09 02:36:29 - INFO - Epoch: 7.17, Step: 22730, Train Loss: 1.8376, Learning Rate: 8.64e-05
2025-12-09 02:36:41 - INFO - Epoch: 7.18, Step: 22740, Train Loss: 1.7975, Learning Rate: 8.64e-05
2025-12-09 02:36:52 - INFO - Epoch: 7.18, Step: 22750, Train Loss: 1.8045, Learning Rate: 8.64e-05
2025-12-09 02:37:03 - INFO - Epoch: 7.18, Step: 22760, Train Loss: 1.8362, Learning Rate: 8.64e-05
2025-12-09 02:37:14 - INFO - Epoch: 7.19, Step: 22770, Train Loss: 1.7900, Learning Rate: 8.64e-05
2025-12-09 02:37:25 - INFO - Epoch: 7.19, Step: 22780, Train Loss: 1.8303, Learning Rate: 8.63e-05
2025-12-09 02:37:36 - INFO - Epoch: 7.19, Step: 22790, Train Loss: 1.8645, Learning Rate: 8.63e-05
2025-12-09 02:37:47 - INFO - Epoch: 7.19, Step: 22800, Train Loss: 1.8336, Learning Rate: 8.63e-05
2025-12-09 02:37:58 - INFO - Epoch: 7.20, Step: 22810, Train Loss: 1.8048, Learning Rate: 8.63e-05
2025-12-09 02:38:09 - INFO - Epoch: 7.20, Step: 22820, Train Loss: 1.7942, Learning Rate: 8.63e-05
2025-12-09 02:38:20 - INFO - Epoch: 7.20, Step: 22830, Train Loss: 1.8312, Learning Rate: 8.63e-05
2025-12-09 02:38:31 - INFO - Epoch: 7.21, Step: 22840, Train Loss: 1.7685, Learning Rate: 8.63e-05
2025-12-09 02:38:42 - INFO - Epoch: 7.21, Step: 22850, Train Loss: 1.8340, Learning Rate: 8.63e-05
2025-12-09 02:38:54 - INFO - Epoch: 7.21, Step: 22860, Train Loss: 1.7848, Learning Rate: 8.63e-05
2025-12-09 02:39:05 - INFO - Epoch: 7.22, Step: 22870, Train Loss: 1.8066, Learning Rate: 8.63e-05
2025-12-09 02:39:16 - INFO - Epoch: 7.22, Step: 22880, Train Loss: 1.8341, Learning Rate: 8.63e-05
2025-12-09 02:39:27 - INFO - Epoch: 7.22, Step: 22890, Train Loss: 1.8067, Learning Rate: 8.63e-05
2025-12-09 02:39:38 - INFO - Epoch: 7.23, Step: 22900, Train Loss: 1.8321, Learning Rate: 8.62e-05
2025-12-09 02:39:49 - INFO - Epoch: 7.23, Step: 22910, Train Loss: 1.7809, Learning Rate: 8.62e-05
2025-12-09 02:40:00 - INFO - Epoch: 7.23, Step: 22920, Train Loss: 1.8197, Learning Rate: 8.62e-05
2025-12-09 02:40:11 - INFO - Epoch: 7.24, Step: 22930, Train Loss: 1.8175, Learning Rate: 8.62e-05
2025-12-09 02:40:22 - INFO - Epoch: 7.24, Step: 22940, Train Loss: 1.8223, Learning Rate: 8.62e-05
2025-12-09 02:40:33 - INFO - Epoch: 7.24, Step: 22950, Train Loss: 1.8148, Learning Rate: 8.62e-05
2025-12-09 02:40:44 - INFO - Epoch: 7.25, Step: 22960, Train Loss: 1.7916, Learning Rate: 8.62e-05
2025-12-09 02:40:55 - INFO - Epoch: 7.25, Step: 22970, Train Loss: 1.8120, Learning Rate: 8.62e-05
2025-12-09 02:41:07 - INFO - Epoch: 7.25, Step: 22980, Train Loss: 1.7848, Learning Rate: 8.62e-05
2025-12-09 02:41:18 - INFO - Epoch: 7.25, Step: 22990, Train Loss: 1.8230, Learning Rate: 8.62e-05
2025-12-09 02:41:29 - INFO - Epoch: 7.26, Step: 23000, Train Loss: 1.7888, Learning Rate: 8.62e-05
2025-12-09 02:41:40 - INFO - Epoch: 7.26, Step: 23010, Train Loss: 1.8086, Learning Rate: 8.62e-05
2025-12-09 02:41:51 - INFO - Epoch: 7.26, Step: 23020, Train Loss: 1.8080, Learning Rate: 8.61e-05
2025-12-09 02:42:02 - INFO - Epoch: 7.27, Step: 23030, Train Loss: 1.8246, Learning Rate: 8.61e-05
2025-12-09 02:42:13 - INFO - Epoch: 7.27, Step: 23040, Train Loss: 1.8435, Learning Rate: 8.61e-05
2025-12-09 02:42:24 - INFO - Epoch: 7.27, Step: 23050, Train Loss: 1.8176, Learning Rate: 8.61e-05
2025-12-09 02:42:35 - INFO - Epoch: 7.28, Step: 23060, Train Loss: 1.8029, Learning Rate: 8.61e-05
2025-12-09 02:42:46 - INFO - Epoch: 7.28, Step: 23070, Train Loss: 1.7944, Learning Rate: 8.61e-05
2025-12-09 02:42:57 - INFO - Epoch: 7.28, Step: 23080, Train Loss: 1.8162, Learning Rate: 8.61e-05
2025-12-09 02:43:08 - INFO - Epoch: 7.29, Step: 23090, Train Loss: 1.7790, Learning Rate: 8.61e-05
2025-12-09 02:43:20 - INFO - Epoch: 7.29, Step: 23100, Train Loss: 1.8054, Learning Rate: 8.61e-05
2025-12-09 02:43:31 - INFO - Epoch: 7.29, Step: 23110, Train Loss: 1.8199, Learning Rate: 8.61e-05
2025-12-09 02:43:42 - INFO - Epoch: 7.30, Step: 23120, Train Loss: 1.8282, Learning Rate: 8.61e-05
2025-12-09 02:43:53 - INFO - Epoch: 7.30, Step: 23130, Train Loss: 1.7723, Learning Rate: 8.61e-05
2025-12-09 02:44:04 - INFO - Epoch: 7.30, Step: 23140, Train Loss: 1.8036, Learning Rate: 8.60e-05
2025-12-09 02:44:15 - INFO - Epoch: 7.31, Step: 23150, Train Loss: 1.7987, Learning Rate: 8.60e-05
2025-12-09 02:44:26 - INFO - Epoch: 7.31, Step: 23160, Train Loss: 1.7632, Learning Rate: 8.60e-05
2025-12-09 02:44:37 - INFO - Epoch: 7.31, Step: 23170, Train Loss: 1.8202, Learning Rate: 8.60e-05
2025-12-09 02:44:48 - INFO - Epoch: 7.31, Step: 23180, Train Loss: 1.7722, Learning Rate: 8.60e-05
2025-12-09 02:44:59 - INFO - Epoch: 7.32, Step: 23190, Train Loss: 1.7681, Learning Rate: 8.60e-05
2025-12-09 02:45:10 - INFO - Epoch: 7.32, Step: 23200, Train Loss: 1.7774, Learning Rate: 8.60e-05
2025-12-09 02:45:21 - INFO - Epoch: 7.32, Step: 23210, Train Loss: 1.7211, Learning Rate: 8.60e-05
2025-12-09 02:45:33 - INFO - Epoch: 7.33, Step: 23220, Train Loss: 1.7884, Learning Rate: 8.60e-05
2025-12-09 02:45:44 - INFO - Epoch: 7.33, Step: 23230, Train Loss: 1.8061, Learning Rate: 8.60e-05
2025-12-09 02:45:55 - INFO - Epoch: 7.33, Step: 23240, Train Loss: 1.8224, Learning Rate: 8.60e-05
2025-12-09 02:46:06 - INFO - Epoch: 7.34, Step: 23250, Train Loss: 1.8309, Learning Rate: 8.60e-05
2025-12-09 02:46:17 - INFO - Epoch: 7.34, Step: 23260, Train Loss: 1.7993, Learning Rate: 8.59e-05
2025-12-09 02:46:28 - INFO - Epoch: 7.34, Step: 23270, Train Loss: 1.8089, Learning Rate: 8.59e-05
2025-12-09 02:46:39 - INFO - Epoch: 7.35, Step: 23280, Train Loss: 1.8120, Learning Rate: 8.59e-05
2025-12-09 02:46:50 - INFO - Epoch: 7.35, Step: 23290, Train Loss: 1.7806, Learning Rate: 8.59e-05
2025-12-09 02:47:01 - INFO - Epoch: 7.35, Step: 23300, Train Loss: 1.8344, Learning Rate: 8.59e-05
2025-12-09 02:47:12 - INFO - Epoch: 7.36, Step: 23310, Train Loss: 1.7948, Learning Rate: 8.59e-05
2025-12-09 02:47:23 - INFO - Epoch: 7.36, Step: 23320, Train Loss: 1.8071, Learning Rate: 8.59e-05
2025-12-09 02:47:34 - INFO - Epoch: 7.36, Step: 23330, Train Loss: 1.7845, Learning Rate: 8.59e-05
2025-12-09 02:47:46 - INFO - Epoch: 7.37, Step: 23340, Train Loss: 1.7750, Learning Rate: 8.59e-05
2025-12-09 02:47:57 - INFO - Epoch: 7.37, Step: 23350, Train Loss: 1.8066, Learning Rate: 8.59e-05
2025-12-09 02:48:08 - INFO - Epoch: 7.37, Step: 23360, Train Loss: 1.8150, Learning Rate: 8.59e-05
2025-12-09 02:48:19 - INFO - Epoch: 7.37, Step: 23370, Train Loss: 1.8196, Learning Rate: 8.59e-05
2025-12-09 02:48:30 - INFO - Epoch: 7.38, Step: 23380, Train Loss: 1.7980, Learning Rate: 8.58e-05
2025-12-09 02:48:41 - INFO - Epoch: 7.38, Step: 23390, Train Loss: 1.7417, Learning Rate: 8.58e-05
2025-12-09 02:48:52 - INFO - Epoch: 7.38, Step: 23400, Train Loss: 1.7887, Learning Rate: 8.58e-05
2025-12-09 02:49:03 - INFO - Epoch: 7.39, Step: 23410, Train Loss: 1.8487, Learning Rate: 8.58e-05
2025-12-09 02:49:14 - INFO - Epoch: 7.39, Step: 23420, Train Loss: 1.8186, Learning Rate: 8.58e-05
2025-12-09 02:49:25 - INFO - Epoch: 7.39, Step: 23430, Train Loss: 1.8133, Learning Rate: 8.58e-05
2025-12-09 02:49:36 - INFO - Epoch: 7.40, Step: 23440, Train Loss: 1.7711, Learning Rate: 8.58e-05
2025-12-09 02:49:47 - INFO - Epoch: 7.40, Step: 23450, Train Loss: 1.8124, Learning Rate: 8.58e-05
2025-12-09 02:49:59 - INFO - Epoch: 7.40, Step: 23460, Train Loss: 1.8051, Learning Rate: 8.58e-05
2025-12-09 02:50:10 - INFO - Epoch: 7.41, Step: 23470, Train Loss: 1.8206, Learning Rate: 8.58e-05
2025-12-09 02:50:21 - INFO - Epoch: 7.41, Step: 23480, Train Loss: 1.8125, Learning Rate: 8.58e-05
2025-12-09 02:50:32 - INFO - Epoch: 7.41, Step: 23490, Train Loss: 1.8214, Learning Rate: 8.58e-05
2025-12-09 02:50:43 - INFO - Epoch: 7.42, Step: 23500, Train Loss: 1.7999, Learning Rate: 8.57e-05
2025-12-09 02:50:54 - INFO - Epoch: 7.42, Step: 23510, Train Loss: 1.7929, Learning Rate: 8.57e-05
2025-12-09 02:51:05 - INFO - Epoch: 7.42, Step: 23520, Train Loss: 1.7989, Learning Rate: 8.57e-05
2025-12-09 02:51:16 - INFO - Epoch: 7.43, Step: 23530, Train Loss: 1.8007, Learning Rate: 8.57e-05
2025-12-09 02:51:27 - INFO - Epoch: 7.43, Step: 23540, Train Loss: 1.7547, Learning Rate: 8.57e-05
2025-12-09 02:51:38 - INFO - Epoch: 7.43, Step: 23550, Train Loss: 1.7667, Learning Rate: 8.57e-05
2025-12-09 02:51:49 - INFO - Epoch: 7.43, Step: 23560, Train Loss: 1.7856, Learning Rate: 8.57e-05
2025-12-09 02:52:00 - INFO - Epoch: 7.44, Step: 23570, Train Loss: 1.7999, Learning Rate: 8.57e-05
2025-12-09 02:52:12 - INFO - Epoch: 7.44, Step: 23580, Train Loss: 1.7903, Learning Rate: 8.57e-05
2025-12-09 02:52:23 - INFO - Epoch: 7.44, Step: 23590, Train Loss: 1.8037, Learning Rate: 8.57e-05
2025-12-09 02:52:34 - INFO - Epoch: 7.45, Step: 23600, Train Loss: 1.8192, Learning Rate: 8.57e-05
2025-12-09 02:52:45 - INFO - Epoch: 7.45, Step: 23610, Train Loss: 1.7724, Learning Rate: 8.57e-05
2025-12-09 02:52:56 - INFO - Epoch: 7.45, Step: 23620, Train Loss: 1.7998, Learning Rate: 8.56e-05
2025-12-09 02:53:07 - INFO - Epoch: 7.46, Step: 23630, Train Loss: 1.7810, Learning Rate: 8.56e-05
2025-12-09 02:53:18 - INFO - Epoch: 7.46, Step: 23640, Train Loss: 1.7207, Learning Rate: 8.56e-05
2025-12-09 02:53:29 - INFO - Epoch: 7.46, Step: 23650, Train Loss: 1.8189, Learning Rate: 8.56e-05
2025-12-09 02:53:40 - INFO - Epoch: 7.47, Step: 23660, Train Loss: 1.7384, Learning Rate: 8.56e-05
2025-12-09 02:53:51 - INFO - Epoch: 7.47, Step: 23670, Train Loss: 1.7923, Learning Rate: 8.56e-05
2025-12-09 02:54:02 - INFO - Epoch: 7.47, Step: 23680, Train Loss: 1.7555, Learning Rate: 8.56e-05
2025-12-09 02:54:13 - INFO - Epoch: 7.48, Step: 23690, Train Loss: 1.7878, Learning Rate: 8.56e-05
2025-12-09 02:54:25 - INFO - Epoch: 7.48, Step: 23700, Train Loss: 1.7627, Learning Rate: 8.56e-05
2025-12-09 02:54:36 - INFO - Epoch: 7.48, Step: 23710, Train Loss: 1.8058, Learning Rate: 8.56e-05
2025-12-09 02:54:47 - INFO - Epoch: 7.49, Step: 23720, Train Loss: 1.7456, Learning Rate: 8.56e-05
2025-12-09 02:54:58 - INFO - Epoch: 7.49, Step: 23730, Train Loss: 1.7637, Learning Rate: 8.56e-05
2025-12-09 02:55:09 - INFO - Epoch: 7.49, Step: 23740, Train Loss: 1.7823, Learning Rate: 8.55e-05
2025-12-09 02:55:20 - INFO - Epoch: 7.49, Step: 23750, Train Loss: 1.7593, Learning Rate: 8.55e-05
2025-12-09 02:55:31 - INFO - Epoch: 7.50, Step: 23760, Train Loss: 1.7461, Learning Rate: 8.55e-05
2025-12-09 02:55:42 - INFO - Epoch: 7.50, Step: 23770, Train Loss: 1.7725, Learning Rate: 8.55e-05
2025-12-09 02:55:53 - INFO - Epoch: 7.50, Step: 23780, Train Loss: 1.7979, Learning Rate: 8.55e-05
2025-12-09 02:56:04 - INFO - Epoch: 7.51, Step: 23790, Train Loss: 1.7740, Learning Rate: 8.55e-05
2025-12-09 02:56:15 - INFO - Epoch: 7.51, Step: 23800, Train Loss: 1.7767, Learning Rate: 8.55e-05
2025-12-09 02:56:26 - INFO - Epoch: 7.51, Step: 23810, Train Loss: 1.7520, Learning Rate: 8.55e-05
2025-12-09 02:56:38 - INFO - Epoch: 7.52, Step: 23820, Train Loss: 1.7753, Learning Rate: 8.55e-05
2025-12-09 02:56:49 - INFO - Epoch: 7.52, Step: 23830, Train Loss: 1.8143, Learning Rate: 8.55e-05
2025-12-09 02:57:00 - INFO - Epoch: 7.52, Step: 23840, Train Loss: 1.7962, Learning Rate: 8.55e-05
2025-12-09 02:57:11 - INFO - Epoch: 7.53, Step: 23850, Train Loss: 1.7784, Learning Rate: 8.55e-05
2025-12-09 02:57:22 - INFO - Epoch: 7.53, Step: 23860, Train Loss: 1.7797, Learning Rate: 8.55e-05
2025-12-09 02:57:33 - INFO - Epoch: 7.53, Step: 23870, Train Loss: 1.7974, Learning Rate: 8.54e-05
2025-12-09 02:57:44 - INFO - Epoch: 7.54, Step: 23880, Train Loss: 1.7792, Learning Rate: 8.54e-05
2025-12-09 02:57:55 - INFO - Epoch: 7.54, Step: 23890, Train Loss: 1.7982, Learning Rate: 8.54e-05
2025-12-09 02:58:06 - INFO - Epoch: 7.54, Step: 23900, Train Loss: 1.7450, Learning Rate: 8.54e-05
2025-12-09 02:58:17 - INFO - Epoch: 7.54, Step: 23910, Train Loss: 1.8083, Learning Rate: 8.54e-05
2025-12-09 02:58:28 - INFO - Epoch: 7.55, Step: 23920, Train Loss: 1.7687, Learning Rate: 8.54e-05
2025-12-09 02:58:39 - INFO - Epoch: 7.55, Step: 23930, Train Loss: 1.7816, Learning Rate: 8.54e-05
2025-12-09 02:58:51 - INFO - Epoch: 7.55, Step: 23940, Train Loss: 1.7799, Learning Rate: 8.54e-05
2025-12-09 02:59:02 - INFO - Epoch: 7.56, Step: 23950, Train Loss: 1.7985, Learning Rate: 8.54e-05
2025-12-09 02:59:13 - INFO - Epoch: 7.56, Step: 23960, Train Loss: 1.7849, Learning Rate: 8.54e-05
2025-12-09 02:59:24 - INFO - Epoch: 7.56, Step: 23970, Train Loss: 1.7891, Learning Rate: 8.54e-05
2025-12-09 02:59:35 - INFO - Epoch: 7.57, Step: 23980, Train Loss: 1.7623, Learning Rate: 8.54e-05
2025-12-09 02:59:46 - INFO - Epoch: 7.57, Step: 23990, Train Loss: 1.7735, Learning Rate: 8.53e-05
2025-12-09 02:59:57 - INFO - Epoch: 7.57, Step: 24000, Train Loss: 1.7218, Learning Rate: 8.53e-05
2025-12-09 03:00:08 - INFO - Epoch: 7.58, Step: 24010, Train Loss: 1.8059, Learning Rate: 8.53e-05
2025-12-09 03:00:19 - INFO - Epoch: 7.58, Step: 24020, Train Loss: 1.7709, Learning Rate: 8.53e-05
2025-12-09 03:00:30 - INFO - Epoch: 7.58, Step: 24030, Train Loss: 1.7980, Learning Rate: 8.53e-05
2025-12-09 03:00:41 - INFO - Epoch: 7.59, Step: 24040, Train Loss: 1.8056, Learning Rate: 8.53e-05
2025-12-09 03:00:52 - INFO - Epoch: 7.59, Step: 24050, Train Loss: 1.8066, Learning Rate: 8.53e-05
2025-12-09 03:01:04 - INFO - Epoch: 7.59, Step: 24060, Train Loss: 1.7963, Learning Rate: 8.53e-05
2025-12-09 03:01:15 - INFO - Epoch: 7.60, Step: 24070, Train Loss: 1.7507, Learning Rate: 8.53e-05
2025-12-09 03:01:26 - INFO - Epoch: 7.60, Step: 24080, Train Loss: 1.7441, Learning Rate: 8.53e-05
2025-12-09 03:01:37 - INFO - Epoch: 7.60, Step: 24090, Train Loss: 1.7931, Learning Rate: 8.53e-05
2025-12-09 03:01:48 - INFO - Epoch: 7.60, Step: 24100, Train Loss: 1.7655, Learning Rate: 8.53e-05
2025-12-09 03:01:59 - INFO - Epoch: 7.61, Step: 24110, Train Loss: 1.7620, Learning Rate: 8.52e-05
2025-12-09 03:02:10 - INFO - Epoch: 7.61, Step: 24120, Train Loss: 1.7880, Learning Rate: 8.52e-05
2025-12-09 03:02:21 - INFO - Epoch: 7.61, Step: 24130, Train Loss: 1.7728, Learning Rate: 8.52e-05
2025-12-09 03:02:32 - INFO - Epoch: 7.62, Step: 24140, Train Loss: 1.7866, Learning Rate: 8.52e-05
2025-12-09 03:02:43 - INFO - Epoch: 7.62, Step: 24150, Train Loss: 1.7802, Learning Rate: 8.52e-05
2025-12-09 03:02:54 - INFO - Epoch: 7.62, Step: 24160, Train Loss: 1.7901, Learning Rate: 8.52e-05
2025-12-09 03:03:05 - INFO - Epoch: 7.63, Step: 24170, Train Loss: 1.7791, Learning Rate: 8.52e-05
2025-12-09 03:03:16 - INFO - Epoch: 7.63, Step: 24180, Train Loss: 1.7765, Learning Rate: 8.52e-05
2025-12-09 03:03:28 - INFO - Epoch: 7.63, Step: 24190, Train Loss: 1.7459, Learning Rate: 8.52e-05
2025-12-09 03:03:39 - INFO - Epoch: 7.64, Step: 24200, Train Loss: 1.7193, Learning Rate: 8.52e-05
2025-12-09 03:03:50 - INFO - Epoch: 7.64, Step: 24210, Train Loss: 1.7676, Learning Rate: 8.52e-05
2025-12-09 03:04:01 - INFO - Epoch: 7.64, Step: 24220, Train Loss: 1.7795, Learning Rate: 8.52e-05
2025-12-09 03:04:12 - INFO - Epoch: 7.65, Step: 24230, Train Loss: 1.7755, Learning Rate: 8.51e-05
2025-12-09 03:04:23 - INFO - Epoch: 7.65, Step: 24240, Train Loss: 1.7805, Learning Rate: 8.51e-05
2025-12-09 03:04:34 - INFO - Epoch: 7.65, Step: 24250, Train Loss: 1.7623, Learning Rate: 8.51e-05
2025-12-09 03:04:45 - INFO - Epoch: 7.66, Step: 24260, Train Loss: 1.7637, Learning Rate: 8.51e-05
2025-12-09 03:04:56 - INFO - Epoch: 7.66, Step: 24270, Train Loss: 1.7942, Learning Rate: 8.51e-05
2025-12-09 03:05:07 - INFO - Epoch: 7.66, Step: 24280, Train Loss: 1.7576, Learning Rate: 8.51e-05
2025-12-09 03:05:18 - INFO - Epoch: 7.66, Step: 24290, Train Loss: 1.7359, Learning Rate: 8.51e-05
2025-12-09 03:05:29 - INFO - Epoch: 7.67, Step: 24300, Train Loss: 1.7574, Learning Rate: 8.51e-05
2025-12-09 03:05:41 - INFO - Epoch: 7.67, Step: 24310, Train Loss: 1.7942, Learning Rate: 8.51e-05
2025-12-09 03:05:52 - INFO - Epoch: 7.67, Step: 24320, Train Loss: 1.7879, Learning Rate: 8.51e-05
2025-12-09 03:06:03 - INFO - Epoch: 7.68, Step: 24330, Train Loss: 1.7303, Learning Rate: 8.51e-05
2025-12-09 03:06:14 - INFO - Epoch: 7.68, Step: 24340, Train Loss: 1.7804, Learning Rate: 8.51e-05
2025-12-09 03:06:25 - INFO - Epoch: 7.68, Step: 24350, Train Loss: 1.7250, Learning Rate: 8.50e-05
2025-12-09 03:06:36 - INFO - Epoch: 7.69, Step: 24360, Train Loss: 1.7709, Learning Rate: 8.50e-05
2025-12-09 03:06:47 - INFO - Epoch: 7.69, Step: 24370, Train Loss: 1.8140, Learning Rate: 8.50e-05
2025-12-09 03:06:58 - INFO - Epoch: 7.69, Step: 24380, Train Loss: 1.7768, Learning Rate: 8.50e-05
2025-12-09 03:07:09 - INFO - Epoch: 7.70, Step: 24390, Train Loss: 1.7636, Learning Rate: 8.50e-05
2025-12-09 03:07:20 - INFO - Epoch: 7.70, Step: 24400, Train Loss: 1.7710, Learning Rate: 8.50e-05
2025-12-09 03:07:31 - INFO - Epoch: 7.70, Step: 24410, Train Loss: 1.7307, Learning Rate: 8.50e-05
2025-12-09 03:07:42 - INFO - Epoch: 7.71, Step: 24420, Train Loss: 1.7341, Learning Rate: 8.50e-05
2025-12-09 03:07:54 - INFO - Epoch: 7.71, Step: 24430, Train Loss: 1.7640, Learning Rate: 8.50e-05
2025-12-09 03:08:05 - INFO - Epoch: 7.71, Step: 24440, Train Loss: 1.7683, Learning Rate: 8.50e-05
2025-12-09 03:08:16 - INFO - Epoch: 7.72, Step: 24450, Train Loss: 1.7895, Learning Rate: 8.50e-05
2025-12-09 03:08:27 - INFO - Epoch: 7.72, Step: 24460, Train Loss: 1.7796, Learning Rate: 8.50e-05
2025-12-09 03:08:38 - INFO - Epoch: 7.72, Step: 24470, Train Loss: 1.7859, Learning Rate: 8.49e-05
2025-12-09 03:08:49 - INFO - Epoch: 7.72, Step: 24480, Train Loss: 1.7796, Learning Rate: 8.49e-05
2025-12-09 03:09:00 - INFO - Epoch: 7.73, Step: 24490, Train Loss: 1.7871, Learning Rate: 8.49e-05
2025-12-09 03:09:11 - INFO - Epoch: 7.73, Step: 24500, Train Loss: 1.7517, Learning Rate: 8.49e-05
2025-12-09 03:09:22 - INFO - Epoch: 7.73, Step: 24510, Train Loss: 1.7288, Learning Rate: 8.49e-05
2025-12-09 03:09:33 - INFO - Epoch: 7.74, Step: 24520, Train Loss: 1.7298, Learning Rate: 8.49e-05
2025-12-09 03:09:44 - INFO - Epoch: 7.74, Step: 24530, Train Loss: 1.7397, Learning Rate: 8.49e-05
2025-12-09 03:09:55 - INFO - Epoch: 7.74, Step: 24540, Train Loss: 1.7542, Learning Rate: 8.49e-05
2025-12-09 03:10:07 - INFO - Epoch: 7.75, Step: 24550, Train Loss: 1.7723, Learning Rate: 8.49e-05
2025-12-09 03:10:18 - INFO - Epoch: 7.75, Step: 24560, Train Loss: 1.7602, Learning Rate: 8.49e-05
2025-12-09 03:10:29 - INFO - Epoch: 7.75, Step: 24570, Train Loss: 1.7451, Learning Rate: 8.49e-05
2025-12-09 03:10:40 - INFO - Epoch: 7.76, Step: 24580, Train Loss: 1.7352, Learning Rate: 8.49e-05
2025-12-09 03:10:51 - INFO - Epoch: 7.76, Step: 24590, Train Loss: 1.8107, Learning Rate: 8.48e-05
2025-12-09 03:11:02 - INFO - Epoch: 7.76, Step: 24600, Train Loss: 1.7658, Learning Rate: 8.48e-05
2025-12-09 03:11:13 - INFO - Epoch: 7.77, Step: 24610, Train Loss: 1.7693, Learning Rate: 8.48e-05
2025-12-09 03:11:24 - INFO - Epoch: 7.77, Step: 24620, Train Loss: 1.7668, Learning Rate: 8.48e-05
2025-12-09 03:11:35 - INFO - Epoch: 7.77, Step: 24630, Train Loss: 1.7638, Learning Rate: 8.48e-05
2025-12-09 03:11:46 - INFO - Epoch: 7.78, Step: 24640, Train Loss: 1.7547, Learning Rate: 8.48e-05
2025-12-09 03:11:57 - INFO - Epoch: 7.78, Step: 24650, Train Loss: 1.7689, Learning Rate: 8.48e-05
2025-12-09 03:12:08 - INFO - Epoch: 7.78, Step: 24660, Train Loss: 1.7483, Learning Rate: 8.48e-05
2025-12-09 03:12:20 - INFO - Epoch: 7.78, Step: 24670, Train Loss: 1.7569, Learning Rate: 8.48e-05
2025-12-09 03:12:31 - INFO - Epoch: 7.79, Step: 24680, Train Loss: 1.7853, Learning Rate: 8.48e-05
2025-12-09 03:12:42 - INFO - Epoch: 7.79, Step: 24690, Train Loss: 1.7813, Learning Rate: 8.48e-05
2025-12-09 03:12:53 - INFO - Epoch: 7.79, Step: 24700, Train Loss: 1.7456, Learning Rate: 8.48e-05
2025-12-09 03:13:04 - INFO - Epoch: 7.80, Step: 24710, Train Loss: 1.7591, Learning Rate: 8.47e-05
2025-12-09 03:13:15 - INFO - Epoch: 7.80, Step: 24720, Train Loss: 1.7687, Learning Rate: 8.47e-05
2025-12-09 03:13:26 - INFO - Epoch: 7.80, Step: 24730, Train Loss: 1.7631, Learning Rate: 8.47e-05
2025-12-09 03:13:37 - INFO - Epoch: 7.81, Step: 24740, Train Loss: 1.8060, Learning Rate: 8.47e-05
2025-12-09 03:13:48 - INFO - Epoch: 7.81, Step: 24750, Train Loss: 1.7783, Learning Rate: 8.47e-05
2025-12-09 03:13:59 - INFO - Epoch: 7.81, Step: 24760, Train Loss: 1.7893, Learning Rate: 8.47e-05
2025-12-09 03:14:10 - INFO - Epoch: 7.82, Step: 24770, Train Loss: 1.7483, Learning Rate: 8.47e-05
2025-12-09 03:14:21 - INFO - Epoch: 7.82, Step: 24780, Train Loss: 1.7538, Learning Rate: 8.47e-05
2025-12-09 03:14:33 - INFO - Epoch: 7.82, Step: 24790, Train Loss: 1.7707, Learning Rate: 8.47e-05
2025-12-09 03:14:44 - INFO - Epoch: 7.83, Step: 24800, Train Loss: 1.7301, Learning Rate: 8.47e-05
2025-12-09 03:14:55 - INFO - Epoch: 7.83, Step: 24810, Train Loss: 1.7661, Learning Rate: 8.47e-05
2025-12-09 03:15:06 - INFO - Epoch: 7.83, Step: 24820, Train Loss: 1.7722, Learning Rate: 8.47e-05
2025-12-09 03:15:17 - INFO - Epoch: 7.84, Step: 24830, Train Loss: 1.7804, Learning Rate: 8.46e-05
2025-12-09 03:15:28 - INFO - Epoch: 7.84, Step: 24840, Train Loss: 1.7682, Learning Rate: 8.46e-05
2025-12-09 03:15:39 - INFO - Epoch: 7.84, Step: 24850, Train Loss: 1.7282, Learning Rate: 8.46e-05
2025-12-09 03:15:50 - INFO - Epoch: 7.84, Step: 24860, Train Loss: 1.7697, Learning Rate: 8.46e-05
2025-12-09 03:16:01 - INFO - Epoch: 7.85, Step: 24870, Train Loss: 1.7972, Learning Rate: 8.46e-05
2025-12-09 03:16:12 - INFO - Epoch: 7.85, Step: 24880, Train Loss: 1.7062, Learning Rate: 8.46e-05
2025-12-09 03:16:23 - INFO - Epoch: 7.85, Step: 24890, Train Loss: 1.7467, Learning Rate: 8.46e-05
2025-12-09 03:16:34 - INFO - Epoch: 7.86, Step: 24900, Train Loss: 1.7653, Learning Rate: 8.46e-05
2025-12-09 03:16:46 - INFO - Epoch: 7.86, Step: 24910, Train Loss: 1.7521, Learning Rate: 8.46e-05
2025-12-09 03:16:57 - INFO - Epoch: 7.86, Step: 24920, Train Loss: 1.7688, Learning Rate: 8.46e-05
2025-12-09 03:17:08 - INFO - Epoch: 7.87, Step: 24930, Train Loss: 1.7340, Learning Rate: 8.46e-05
2025-12-09 03:17:19 - INFO - Epoch: 7.87, Step: 24940, Train Loss: 1.7482, Learning Rate: 8.46e-05
2025-12-09 03:17:30 - INFO - Epoch: 7.87, Step: 24950, Train Loss: 1.7506, Learning Rate: 8.45e-05
2025-12-09 03:17:41 - INFO - Epoch: 7.88, Step: 24960, Train Loss: 1.7250, Learning Rate: 8.45e-05
2025-12-09 03:17:52 - INFO - Epoch: 7.88, Step: 24970, Train Loss: 1.7575, Learning Rate: 8.45e-05
2025-12-09 03:18:03 - INFO - Epoch: 7.88, Step: 24980, Train Loss: 1.7910, Learning Rate: 8.45e-05
2025-12-09 03:18:14 - INFO - Epoch: 7.89, Step: 24990, Train Loss: 1.7157, Learning Rate: 8.45e-05
2025-12-09 03:18:25 - INFO - Epoch: 7.89, Step: 25000, Train Loss: 1.7918, Learning Rate: 8.45e-05
2025-12-09 03:18:36 - INFO - Epoch: 7.89, Step: 25010, Train Loss: 1.7452, Learning Rate: 8.45e-05
2025-12-09 03:18:47 - INFO - Epoch: 7.90, Step: 25020, Train Loss: 1.7578, Learning Rate: 8.45e-05
2025-12-09 03:18:59 - INFO - Epoch: 7.90, Step: 25030, Train Loss: 1.7513, Learning Rate: 8.45e-05
2025-12-09 03:19:10 - INFO - Epoch: 7.90, Step: 25040, Train Loss: 1.7519, Learning Rate: 8.45e-05
2025-12-09 03:19:21 - INFO - Epoch: 7.90, Step: 25050, Train Loss: 1.7413, Learning Rate: 8.45e-05
2025-12-09 03:19:32 - INFO - Epoch: 7.91, Step: 25060, Train Loss: 1.7452, Learning Rate: 8.45e-05
2025-12-09 03:19:43 - INFO - Epoch: 7.91, Step: 25070, Train Loss: 1.6871, Learning Rate: 8.44e-05
2025-12-09 03:19:54 - INFO - Epoch: 7.91, Step: 25080, Train Loss: 1.7282, Learning Rate: 8.44e-05
2025-12-09 03:20:05 - INFO - Epoch: 7.92, Step: 25090, Train Loss: 1.7176, Learning Rate: 8.44e-05
2025-12-09 03:20:16 - INFO - Epoch: 7.92, Step: 25100, Train Loss: 1.7619, Learning Rate: 8.44e-05
2025-12-09 03:20:27 - INFO - Epoch: 7.92, Step: 25110, Train Loss: 1.7372, Learning Rate: 8.44e-05
2025-12-09 03:20:38 - INFO - Epoch: 7.93, Step: 25120, Train Loss: 1.7577, Learning Rate: 8.44e-05
2025-12-09 03:20:49 - INFO - Epoch: 7.93, Step: 25130, Train Loss: 1.7560, Learning Rate: 8.44e-05
2025-12-09 03:21:00 - INFO - Epoch: 7.93, Step: 25140, Train Loss: 1.7307, Learning Rate: 8.44e-05
2025-12-09 03:21:12 - INFO - Epoch: 7.94, Step: 25150, Train Loss: 1.7212, Learning Rate: 8.44e-05
2025-12-09 03:21:23 - INFO - Epoch: 7.94, Step: 25160, Train Loss: 1.7209, Learning Rate: 8.44e-05
2025-12-09 03:21:34 - INFO - Epoch: 7.94, Step: 25170, Train Loss: 1.6993, Learning Rate: 8.44e-05
2025-12-09 03:21:45 - INFO - Epoch: 7.95, Step: 25180, Train Loss: 1.7855, Learning Rate: 8.44e-05
2025-12-09 03:21:56 - INFO - Epoch: 7.95, Step: 25190, Train Loss: 1.7086, Learning Rate: 8.43e-05
2025-12-09 03:22:07 - INFO - Epoch: 7.95, Step: 25200, Train Loss: 1.7324, Learning Rate: 8.43e-05
2025-12-09 03:22:18 - INFO - Epoch: 7.96, Step: 25210, Train Loss: 1.7287, Learning Rate: 8.43e-05
2025-12-09 03:22:29 - INFO - Epoch: 7.96, Step: 25220, Train Loss: 1.7505, Learning Rate: 8.43e-05
2025-12-09 03:22:40 - INFO - Epoch: 7.96, Step: 25230, Train Loss: 1.7641, Learning Rate: 8.43e-05
2025-12-09 03:22:51 - INFO - Epoch: 7.96, Step: 25240, Train Loss: 1.7629, Learning Rate: 8.43e-05
2025-12-09 03:23:02 - INFO - Epoch: 7.97, Step: 25250, Train Loss: 1.7763, Learning Rate: 8.43e-05
2025-12-09 03:23:13 - INFO - Epoch: 7.97, Step: 25260, Train Loss: 1.7475, Learning Rate: 8.43e-05
2025-12-09 03:23:25 - INFO - Epoch: 7.97, Step: 25270, Train Loss: 1.7475, Learning Rate: 8.43e-05
2025-12-09 03:23:36 - INFO - Epoch: 7.98, Step: 25280, Train Loss: 1.7470, Learning Rate: 8.43e-05
2025-12-09 03:23:47 - INFO - Epoch: 7.98, Step: 25290, Train Loss: 1.7731, Learning Rate: 8.43e-05
2025-12-09 03:23:58 - INFO - Epoch: 7.98, Step: 25300, Train Loss: 1.7802, Learning Rate: 8.43e-05
2025-12-09 03:24:09 - INFO - Epoch: 7.99, Step: 25310, Train Loss: 1.7640, Learning Rate: 8.42e-05
2025-12-09 03:24:20 - INFO - Epoch: 7.99, Step: 25320, Train Loss: 1.7339, Learning Rate: 8.42e-05
2025-12-09 03:24:31 - INFO - Epoch: 7.99, Step: 25330, Train Loss: 1.7365, Learning Rate: 8.42e-05
2025-12-09 03:24:42 - INFO - Epoch: 8.00, Step: 25340, Train Loss: 1.7143, Learning Rate: 8.42e-05
2025-12-09 03:24:53 - INFO - Epoch: 8.00, Step: 25350, Train Loss: 1.7558, Learning Rate: 8.42e-05
2025-12-09 03:25:04 - INFO - Epoch: 8.00, Step: 25360, Train Loss: 1.7571, Learning Rate: 8.42e-05
2025-12-09 03:25:15 - INFO - Epoch: 8.01, Step: 25370, Train Loss: 1.7086, Learning Rate: 8.42e-05
2025-12-09 03:25:26 - INFO - Epoch: 8.01, Step: 25380, Train Loss: 1.7235, Learning Rate: 8.42e-05
2025-12-09 03:25:38 - INFO - Epoch: 8.01, Step: 25390, Train Loss: 1.7210, Learning Rate: 8.42e-05
2025-12-09 03:25:49 - INFO - Epoch: 8.02, Step: 25400, Train Loss: 1.7268, Learning Rate: 8.42e-05
2025-12-09 03:26:00 - INFO - Epoch: 8.02, Step: 25410, Train Loss: 1.7455, Learning Rate: 8.42e-05
2025-12-09 03:26:11 - INFO - Epoch: 8.02, Step: 25420, Train Loss: 1.7218, Learning Rate: 8.42e-05
2025-12-09 03:26:22 - INFO - Epoch: 8.02, Step: 25430, Train Loss: 1.7367, Learning Rate: 8.41e-05
2025-12-09 03:26:33 - INFO - Epoch: 8.03, Step: 25440, Train Loss: 1.7164, Learning Rate: 8.41e-05
2025-12-09 03:26:44 - INFO - Epoch: 8.03, Step: 25450, Train Loss: 1.7538, Learning Rate: 8.41e-05
2025-12-09 03:26:55 - INFO - Epoch: 8.03, Step: 25460, Train Loss: 1.7104, Learning Rate: 8.41e-05
2025-12-09 03:27:06 - INFO - Epoch: 8.04, Step: 25470, Train Loss: 1.7338, Learning Rate: 8.41e-05
2025-12-09 03:27:17 - INFO - Epoch: 8.04, Step: 25480, Train Loss: 1.7915, Learning Rate: 8.41e-05
2025-12-09 03:27:28 - INFO - Epoch: 8.04, Step: 25490, Train Loss: 1.7497, Learning Rate: 8.41e-05
2025-12-09 03:27:39 - INFO - Epoch: 8.05, Step: 25500, Train Loss: 1.7295, Learning Rate: 8.41e-05
2025-12-09 03:27:51 - INFO - Epoch: 8.05, Step: 25510, Train Loss: 1.7114, Learning Rate: 8.41e-05
2025-12-09 03:28:02 - INFO - Epoch: 8.05, Step: 25520, Train Loss: 1.7521, Learning Rate: 8.41e-05
2025-12-09 03:28:13 - INFO - Epoch: 8.06, Step: 25530, Train Loss: 1.7036, Learning Rate: 8.41e-05
2025-12-09 03:28:24 - INFO - Epoch: 8.06, Step: 25540, Train Loss: 1.7124, Learning Rate: 8.41e-05
2025-12-09 03:28:35 - INFO - Epoch: 8.06, Step: 25550, Train Loss: 1.7411, Learning Rate: 8.40e-05
2025-12-09 03:28:46 - INFO - Epoch: 8.07, Step: 25560, Train Loss: 1.7281, Learning Rate: 8.40e-05
2025-12-09 03:28:57 - INFO - Epoch: 8.07, Step: 25570, Train Loss: 1.7508, Learning Rate: 8.40e-05
2025-12-09 03:29:08 - INFO - Epoch: 8.07, Step: 25580, Train Loss: 1.7898, Learning Rate: 8.40e-05
2025-12-09 03:29:19 - INFO - Epoch: 8.08, Step: 25590, Train Loss: 1.7610, Learning Rate: 8.40e-05
2025-12-09 03:29:30 - INFO - Epoch: 8.08, Step: 25600, Train Loss: 1.7093, Learning Rate: 8.40e-05
2025-12-09 03:29:41 - INFO - Epoch: 8.08, Step: 25610, Train Loss: 1.6803, Learning Rate: 8.40e-05
2025-12-09 03:29:52 - INFO - Epoch: 8.08, Step: 25620, Train Loss: 1.7323, Learning Rate: 8.40e-05
2025-12-09 03:30:03 - INFO - Epoch: 8.09, Step: 25630, Train Loss: 1.7172, Learning Rate: 8.40e-05
2025-12-09 03:30:15 - INFO - Epoch: 8.09, Step: 25640, Train Loss: 1.7592, Learning Rate: 8.40e-05
2025-12-09 03:30:26 - INFO - Epoch: 8.09, Step: 25650, Train Loss: 1.7594, Learning Rate: 8.40e-05
2025-12-09 03:30:37 - INFO - Epoch: 8.10, Step: 25660, Train Loss: 1.7324, Learning Rate: 8.40e-05
2025-12-09 03:30:48 - INFO - Epoch: 8.10, Step: 25670, Train Loss: 1.6720, Learning Rate: 8.39e-05
2025-12-09 03:30:59 - INFO - Epoch: 8.10, Step: 25680, Train Loss: 1.7222, Learning Rate: 8.39e-05
2025-12-09 03:31:10 - INFO - Epoch: 8.11, Step: 25690, Train Loss: 1.7513, Learning Rate: 8.39e-05
2025-12-09 03:31:21 - INFO - Epoch: 8.11, Step: 25700, Train Loss: 1.7557, Learning Rate: 8.39e-05
2025-12-09 03:31:32 - INFO - Epoch: 8.11, Step: 25710, Train Loss: 1.7162, Learning Rate: 8.39e-05
2025-12-09 03:31:43 - INFO - Epoch: 8.12, Step: 25720, Train Loss: 1.7553, Learning Rate: 8.39e-05
2025-12-09 03:31:54 - INFO - Epoch: 8.12, Step: 25730, Train Loss: 1.7172, Learning Rate: 8.39e-05
2025-12-09 03:32:05 - INFO - Epoch: 8.12, Step: 25740, Train Loss: 1.7162, Learning Rate: 8.39e-05
2025-12-09 03:32:16 - INFO - Epoch: 8.13, Step: 25750, Train Loss: 1.7027, Learning Rate: 8.39e-05
2025-12-09 03:32:28 - INFO - Epoch: 8.13, Step: 25760, Train Loss: 1.7113, Learning Rate: 8.39e-05
2025-12-09 03:32:39 - INFO - Epoch: 8.13, Step: 25770, Train Loss: 1.7438, Learning Rate: 8.39e-05
2025-12-09 03:32:50 - INFO - Epoch: 8.14, Step: 25780, Train Loss: 1.7097, Learning Rate: 8.39e-05
2025-12-09 03:33:01 - INFO - Epoch: 8.14, Step: 25790, Train Loss: 1.7278, Learning Rate: 8.38e-05
2025-12-09 03:33:12 - INFO - Epoch: 8.14, Step: 25800, Train Loss: 1.7265, Learning Rate: 8.38e-05
2025-12-09 03:33:23 - INFO - Epoch: 8.14, Step: 25810, Train Loss: 1.7062, Learning Rate: 8.38e-05
2025-12-09 03:33:34 - INFO - Epoch: 8.15, Step: 25820, Train Loss: 1.7145, Learning Rate: 8.38e-05
2025-12-09 03:33:45 - INFO - Epoch: 8.15, Step: 25830, Train Loss: 1.6848, Learning Rate: 8.38e-05
2025-12-09 03:33:56 - INFO - Epoch: 8.15, Step: 25840, Train Loss: 1.7378, Learning Rate: 8.38e-05
2025-12-09 03:34:07 - INFO - Epoch: 8.16, Step: 25850, Train Loss: 1.7433, Learning Rate: 8.38e-05
2025-12-09 03:34:18 - INFO - Epoch: 8.16, Step: 25860, Train Loss: 1.7423, Learning Rate: 8.38e-05
2025-12-09 03:34:29 - INFO - Epoch: 8.16, Step: 25870, Train Loss: 1.6947, Learning Rate: 8.38e-05
2025-12-09 03:34:41 - INFO - Epoch: 8.17, Step: 25880, Train Loss: 1.7361, Learning Rate: 8.38e-05
2025-12-09 03:34:52 - INFO - Epoch: 8.17, Step: 25890, Train Loss: 1.7526, Learning Rate: 8.38e-05
2025-12-09 03:35:03 - INFO - Epoch: 8.17, Step: 25900, Train Loss: 1.7353, Learning Rate: 8.38e-05
2025-12-09 03:35:14 - INFO - Epoch: 8.18, Step: 25910, Train Loss: 1.7278, Learning Rate: 8.37e-05
2025-12-09 03:35:25 - INFO - Epoch: 8.18, Step: 25920, Train Loss: 1.7359, Learning Rate: 8.37e-05
2025-12-09 03:35:36 - INFO - Epoch: 8.18, Step: 25930, Train Loss: 1.6877, Learning Rate: 8.37e-05
2025-12-09 03:35:47 - INFO - Epoch: 8.19, Step: 25940, Train Loss: 1.7410, Learning Rate: 8.37e-05
2025-12-09 03:35:58 - INFO - Epoch: 8.19, Step: 25950, Train Loss: 1.7201, Learning Rate: 8.37e-05
2025-12-09 03:36:09 - INFO - Epoch: 8.19, Step: 25960, Train Loss: 1.7091, Learning Rate: 8.37e-05
2025-12-09 03:36:20 - INFO - Epoch: 8.20, Step: 25970, Train Loss: 1.7556, Learning Rate: 8.37e-05
2025-12-09 03:36:31 - INFO - Epoch: 8.20, Step: 25980, Train Loss: 1.7103, Learning Rate: 8.37e-05
2025-12-09 03:36:42 - INFO - Epoch: 8.20, Step: 25990, Train Loss: 1.7163, Learning Rate: 8.37e-05
2025-12-09 03:36:54 - INFO - Epoch: 8.20, Step: 26000, Train Loss: 1.7176, Learning Rate: 8.37e-05
2025-12-09 03:37:05 - INFO - Epoch: 8.21, Step: 26010, Train Loss: 1.7240, Learning Rate: 8.37e-05
2025-12-09 03:37:16 - INFO - Epoch: 8.21, Step: 26020, Train Loss: 1.7351, Learning Rate: 8.37e-05
2025-12-09 03:37:27 - INFO - Epoch: 8.21, Step: 26030, Train Loss: 1.7509, Learning Rate: 8.36e-05
2025-12-09 03:37:38 - INFO - Epoch: 8.22, Step: 26040, Train Loss: 1.7329, Learning Rate: 8.36e-05
2025-12-09 03:37:49 - INFO - Epoch: 8.22, Step: 26050, Train Loss: 1.7265, Learning Rate: 8.36e-05
2025-12-09 03:38:00 - INFO - Epoch: 8.22, Step: 26060, Train Loss: 1.6903, Learning Rate: 8.36e-05
2025-12-09 03:38:11 - INFO - Epoch: 8.23, Step: 26070, Train Loss: 1.7405, Learning Rate: 8.36e-05
2025-12-09 03:38:22 - INFO - Epoch: 8.23, Step: 26080, Train Loss: 1.6982, Learning Rate: 8.36e-05
2025-12-09 03:38:33 - INFO - Epoch: 8.23, Step: 26090, Train Loss: 1.7122, Learning Rate: 8.36e-05
2025-12-09 03:38:44 - INFO - Epoch: 8.24, Step: 26100, Train Loss: 1.7205, Learning Rate: 8.36e-05
2025-12-09 03:38:55 - INFO - Epoch: 8.24, Step: 26110, Train Loss: 1.7400, Learning Rate: 8.36e-05
2025-12-09 03:39:07 - INFO - Epoch: 8.24, Step: 26120, Train Loss: 1.6752, Learning Rate: 8.36e-05
2025-12-09 03:39:18 - INFO - Epoch: 8.25, Step: 26130, Train Loss: 1.6934, Learning Rate: 8.36e-05
2025-12-09 03:39:29 - INFO - Epoch: 8.25, Step: 26140, Train Loss: 1.7270, Learning Rate: 8.36e-05
2025-12-09 03:39:40 - INFO - Epoch: 8.25, Step: 26150, Train Loss: 1.7465, Learning Rate: 8.35e-05
2025-12-09 03:39:51 - INFO - Epoch: 8.25, Step: 26160, Train Loss: 1.6960, Learning Rate: 8.35e-05
2025-12-09 03:40:02 - INFO - Epoch: 8.26, Step: 26170, Train Loss: 1.7725, Learning Rate: 8.35e-05
2025-12-09 03:40:13 - INFO - Epoch: 8.26, Step: 26180, Train Loss: 1.7123, Learning Rate: 8.35e-05
2025-12-09 03:40:24 - INFO - Epoch: 8.26, Step: 26190, Train Loss: 1.7597, Learning Rate: 8.35e-05
2025-12-09 03:40:35 - INFO - Epoch: 8.27, Step: 26200, Train Loss: 1.6671, Learning Rate: 8.35e-05
2025-12-09 03:40:46 - INFO - Epoch: 8.27, Step: 26210, Train Loss: 1.7244, Learning Rate: 8.35e-05
2025-12-09 03:40:57 - INFO - Epoch: 8.27, Step: 26220, Train Loss: 1.6924, Learning Rate: 8.35e-05
2025-12-09 03:41:08 - INFO - Epoch: 8.28, Step: 26230, Train Loss: 1.6887, Learning Rate: 8.35e-05
2025-12-09 03:41:20 - INFO - Epoch: 8.28, Step: 26240, Train Loss: 1.7019, Learning Rate: 8.35e-05
2025-12-09 03:41:31 - INFO - Epoch: 8.28, Step: 26250, Train Loss: 1.6904, Learning Rate: 8.35e-05
2025-12-09 03:41:42 - INFO - Epoch: 8.29, Step: 26260, Train Loss: 1.7189, Learning Rate: 8.35e-05
2025-12-09 03:41:53 - INFO - Epoch: 8.29, Step: 26270, Train Loss: 1.6697, Learning Rate: 8.34e-05
2025-12-09 03:42:04 - INFO - Epoch: 8.29, Step: 26280, Train Loss: 1.6824, Learning Rate: 8.34e-05
2025-12-09 03:42:15 - INFO - Epoch: 8.30, Step: 26290, Train Loss: 1.7001, Learning Rate: 8.34e-05
2025-12-09 03:42:26 - INFO - Epoch: 8.30, Step: 26300, Train Loss: 1.7140, Learning Rate: 8.34e-05
2025-12-09 03:42:37 - INFO - Epoch: 8.30, Step: 26310, Train Loss: 1.7025, Learning Rate: 8.34e-05
2025-12-09 03:42:48 - INFO - Epoch: 8.31, Step: 26320, Train Loss: 1.7584, Learning Rate: 8.34e-05
2025-12-09 03:42:59 - INFO - Epoch: 8.31, Step: 26330, Train Loss: 1.7134, Learning Rate: 8.34e-05
2025-12-09 03:43:10 - INFO - Epoch: 8.31, Step: 26340, Train Loss: 1.7186, Learning Rate: 8.34e-05
2025-12-09 03:43:21 - INFO - Epoch: 8.31, Step: 26350, Train Loss: 1.7214, Learning Rate: 8.34e-05
2025-12-09 03:43:33 - INFO - Epoch: 8.32, Step: 26360, Train Loss: 1.7308, Learning Rate: 8.34e-05
2025-12-09 03:43:44 - INFO - Epoch: 8.32, Step: 26370, Train Loss: 1.7077, Learning Rate: 8.34e-05
2025-12-09 03:43:55 - INFO - Epoch: 8.32, Step: 26380, Train Loss: 1.6808, Learning Rate: 8.34e-05
2025-12-09 03:44:06 - INFO - Epoch: 8.33, Step: 26390, Train Loss: 1.6778, Learning Rate: 8.33e-05
2025-12-09 03:44:17 - INFO - Epoch: 8.33, Step: 26400, Train Loss: 1.6813, Learning Rate: 8.33e-05
2025-12-09 03:44:28 - INFO - Epoch: 8.33, Step: 26410, Train Loss: 1.6969, Learning Rate: 8.33e-05
2025-12-09 03:44:39 - INFO - Epoch: 8.34, Step: 26420, Train Loss: 1.7407, Learning Rate: 8.33e-05
2025-12-09 03:44:50 - INFO - Epoch: 8.34, Step: 26430, Train Loss: 1.7101, Learning Rate: 8.33e-05
2025-12-09 03:45:01 - INFO - Epoch: 8.34, Step: 26440, Train Loss: 1.7161, Learning Rate: 8.33e-05
2025-12-09 03:45:12 - INFO - Epoch: 8.35, Step: 26450, Train Loss: 1.7192, Learning Rate: 8.33e-05
2025-12-09 03:45:23 - INFO - Epoch: 8.35, Step: 26460, Train Loss: 1.6946, Learning Rate: 8.33e-05
2025-12-09 03:45:34 - INFO - Epoch: 8.35, Step: 26470, Train Loss: 1.6972, Learning Rate: 8.33e-05
2025-12-09 03:45:45 - INFO - Epoch: 8.36, Step: 26480, Train Loss: 1.6918, Learning Rate: 8.33e-05
2025-12-09 03:45:57 - INFO - Epoch: 8.36, Step: 26490, Train Loss: 1.7382, Learning Rate: 8.33e-05
2025-12-09 03:46:08 - INFO - Epoch: 8.36, Step: 26500, Train Loss: 1.7020, Learning Rate: 8.33e-05
2025-12-09 03:46:19 - INFO - Epoch: 8.37, Step: 26510, Train Loss: 1.6954, Learning Rate: 8.32e-05
2025-12-09 03:46:30 - INFO - Epoch: 8.37, Step: 26520, Train Loss: 1.7058, Learning Rate: 8.32e-05
2025-12-09 03:46:41 - INFO - Epoch: 8.37, Step: 26530, Train Loss: 1.6989, Learning Rate: 8.32e-05
2025-12-09 03:46:52 - INFO - Epoch: 8.37, Step: 26540, Train Loss: 1.6972, Learning Rate: 8.32e-05
2025-12-09 03:47:03 - INFO - Epoch: 8.38, Step: 26550, Train Loss: 1.6837, Learning Rate: 8.32e-05
2025-12-09 03:47:14 - INFO - Epoch: 8.38, Step: 26560, Train Loss: 1.6988, Learning Rate: 8.32e-05
2025-12-09 03:47:25 - INFO - Epoch: 8.38, Step: 26570, Train Loss: 1.6841, Learning Rate: 8.32e-05
2025-12-09 03:47:36 - INFO - Epoch: 8.39, Step: 26580, Train Loss: 1.6931, Learning Rate: 8.32e-05
2025-12-09 03:47:47 - INFO - Epoch: 8.39, Step: 26590, Train Loss: 1.6988, Learning Rate: 8.32e-05
2025-12-09 03:47:58 - INFO - Epoch: 8.39, Step: 26600, Train Loss: 1.6698, Learning Rate: 8.32e-05
2025-12-09 03:48:10 - INFO - Epoch: 8.40, Step: 26610, Train Loss: 1.6921, Learning Rate: 8.32e-05
2025-12-09 03:48:21 - INFO - Epoch: 8.40, Step: 26620, Train Loss: 1.6744, Learning Rate: 8.32e-05
2025-12-09 03:48:32 - INFO - Epoch: 8.40, Step: 26630, Train Loss: 1.7047, Learning Rate: 8.32e-05
2025-12-09 03:48:43 - INFO - Epoch: 8.41, Step: 26640, Train Loss: 1.6833, Learning Rate: 8.31e-05
2025-12-09 03:48:54 - INFO - Epoch: 8.41, Step: 26650, Train Loss: 1.7241, Learning Rate: 8.31e-05
2025-12-09 03:49:05 - INFO - Epoch: 8.41, Step: 26660, Train Loss: 1.7005, Learning Rate: 8.31e-05
2025-12-09 03:49:16 - INFO - Epoch: 8.42, Step: 26670, Train Loss: 1.7050, Learning Rate: 8.31e-05
2025-12-09 03:49:27 - INFO - Epoch: 8.42, Step: 26680, Train Loss: 1.6936, Learning Rate: 8.31e-05
2025-12-09 03:49:38 - INFO - Epoch: 8.42, Step: 26690, Train Loss: 1.7157, Learning Rate: 8.31e-05
2025-12-09 03:49:49 - INFO - Epoch: 8.43, Step: 26700, Train Loss: 1.6866, Learning Rate: 8.31e-05
2025-12-09 03:50:00 - INFO - Epoch: 8.43, Step: 26710, Train Loss: 1.7053, Learning Rate: 8.31e-05
2025-12-09 03:50:11 - INFO - Epoch: 8.43, Step: 26720, Train Loss: 1.7248, Learning Rate: 8.31e-05
2025-12-09 03:50:23 - INFO - Epoch: 8.43, Step: 26730, Train Loss: 1.7082, Learning Rate: 8.31e-05
2025-12-09 03:50:34 - INFO - Epoch: 8.44, Step: 26740, Train Loss: 1.7013, Learning Rate: 8.31e-05
2025-12-09 03:50:45 - INFO - Epoch: 8.44, Step: 26750, Train Loss: 1.6947, Learning Rate: 8.31e-05
2025-12-09 03:50:56 - INFO - Epoch: 8.44, Step: 26760, Train Loss: 1.7073, Learning Rate: 8.30e-05
2025-12-09 03:51:07 - INFO - Epoch: 8.45, Step: 26770, Train Loss: 1.6920, Learning Rate: 8.30e-05
2025-12-09 03:51:18 - INFO - Epoch: 8.45, Step: 26780, Train Loss: 1.7154, Learning Rate: 8.30e-05
2025-12-09 03:51:29 - INFO - Epoch: 8.45, Step: 26790, Train Loss: 1.7067, Learning Rate: 8.30e-05
2025-12-09 03:51:40 - INFO - Epoch: 8.46, Step: 26800, Train Loss: 1.6570, Learning Rate: 8.30e-05
2025-12-09 03:51:51 - INFO - Epoch: 8.46, Step: 26810, Train Loss: 1.6953, Learning Rate: 8.30e-05
2025-12-09 03:52:02 - INFO - Epoch: 8.46, Step: 26820, Train Loss: 1.7330, Learning Rate: 8.30e-05
2025-12-09 03:52:13 - INFO - Epoch: 8.47, Step: 26830, Train Loss: 1.7026, Learning Rate: 8.30e-05
2025-12-09 03:52:24 - INFO - Epoch: 8.47, Step: 26840, Train Loss: 1.7226, Learning Rate: 8.30e-05
2025-12-09 03:52:36 - INFO - Epoch: 8.47, Step: 26850, Train Loss: 1.7353, Learning Rate: 8.30e-05
2025-12-09 03:52:47 - INFO - Epoch: 8.48, Step: 26860, Train Loss: 1.6898, Learning Rate: 8.30e-05
2025-12-09 03:52:58 - INFO - Epoch: 8.48, Step: 26870, Train Loss: 1.6754, Learning Rate: 8.30e-05
2025-12-09 03:53:09 - INFO - Epoch: 8.48, Step: 26880, Train Loss: 1.6717, Learning Rate: 8.29e-05
2025-12-09 03:53:20 - INFO - Epoch: 8.49, Step: 26890, Train Loss: 1.7257, Learning Rate: 8.29e-05
2025-12-09 03:53:31 - INFO - Epoch: 8.49, Step: 26900, Train Loss: 1.6933, Learning Rate: 8.29e-05
2025-12-09 03:53:42 - INFO - Epoch: 8.49, Step: 26910, Train Loss: 1.7035, Learning Rate: 8.29e-05
2025-12-09 03:53:53 - INFO - Epoch: 8.49, Step: 26920, Train Loss: 1.6944, Learning Rate: 8.29e-05
2025-12-09 03:54:04 - INFO - Epoch: 8.50, Step: 26930, Train Loss: 1.7103, Learning Rate: 8.29e-05
2025-12-09 03:54:15 - INFO - Epoch: 8.50, Step: 26940, Train Loss: 1.6975, Learning Rate: 8.29e-05
2025-12-09 03:54:26 - INFO - Epoch: 8.50, Step: 26950, Train Loss: 1.6999, Learning Rate: 8.29e-05
2025-12-09 03:54:37 - INFO - Epoch: 8.51, Step: 26960, Train Loss: 1.6988, Learning Rate: 8.29e-05
2025-12-09 03:54:49 - INFO - Epoch: 8.51, Step: 26970, Train Loss: 1.7064, Learning Rate: 8.29e-05
2025-12-09 03:55:00 - INFO - Epoch: 8.51, Step: 26980, Train Loss: 1.6899, Learning Rate: 8.29e-05
2025-12-09 03:55:11 - INFO - Epoch: 8.52, Step: 26990, Train Loss: 1.6818, Learning Rate: 8.29e-05
2025-12-09 03:55:22 - INFO - Epoch: 8.52, Step: 27000, Train Loss: 1.6626, Learning Rate: 8.28e-05
2025-12-09 03:55:33 - INFO - Epoch: 8.52, Step: 27010, Train Loss: 1.7191, Learning Rate: 8.28e-05
2025-12-09 03:55:44 - INFO - Epoch: 8.53, Step: 27020, Train Loss: 1.7305, Learning Rate: 8.28e-05
2025-12-09 03:55:55 - INFO - Epoch: 8.53, Step: 27030, Train Loss: 1.7031, Learning Rate: 8.28e-05
2025-12-09 03:56:06 - INFO - Epoch: 8.53, Step: 27040, Train Loss: 1.6996, Learning Rate: 8.28e-05
2025-12-09 03:56:17 - INFO - Epoch: 8.54, Step: 27050, Train Loss: 1.6817, Learning Rate: 8.28e-05
2025-12-09 03:56:28 - INFO - Epoch: 8.54, Step: 27060, Train Loss: 1.6732, Learning Rate: 8.28e-05
2025-12-09 03:56:39 - INFO - Epoch: 8.54, Step: 27070, Train Loss: 1.6920, Learning Rate: 8.28e-05
2025-12-09 03:56:50 - INFO - Epoch: 8.55, Step: 27080, Train Loss: 1.6998, Learning Rate: 8.28e-05
2025-12-09 03:57:02 - INFO - Epoch: 8.55, Step: 27090, Train Loss: 1.6938, Learning Rate: 8.28e-05
2025-12-09 03:57:13 - INFO - Epoch: 8.55, Step: 27100, Train Loss: 1.6995, Learning Rate: 8.28e-05
2025-12-09 03:57:24 - INFO - Epoch: 8.55, Step: 27110, Train Loss: 1.6960, Learning Rate: 8.28e-05
2025-12-09 03:57:35 - INFO - Epoch: 8.56, Step: 27120, Train Loss: 1.6820, Learning Rate: 8.27e-05
2025-12-09 03:57:46 - INFO - Epoch: 8.56, Step: 27130, Train Loss: 1.6621, Learning Rate: 8.27e-05
2025-12-09 03:57:57 - INFO - Epoch: 8.56, Step: 27140, Train Loss: 1.6658, Learning Rate: 8.27e-05
2025-12-09 03:58:08 - INFO - Epoch: 8.57, Step: 27150, Train Loss: 1.6959, Learning Rate: 8.27e-05
2025-12-09 03:58:19 - INFO - Epoch: 8.57, Step: 27160, Train Loss: 1.7087, Learning Rate: 8.27e-05
2025-12-09 03:58:30 - INFO - Epoch: 8.57, Step: 27170, Train Loss: 1.6633, Learning Rate: 8.27e-05
2025-12-09 03:58:41 - INFO - Epoch: 8.58, Step: 27180, Train Loss: 1.6707, Learning Rate: 8.27e-05
2025-12-09 03:58:52 - INFO - Epoch: 8.58, Step: 27190, Train Loss: 1.6808, Learning Rate: 8.27e-05
2025-12-09 03:59:03 - INFO - Epoch: 8.58, Step: 27200, Train Loss: 1.6713, Learning Rate: 8.27e-05
2025-12-09 03:59:14 - INFO - Epoch: 8.59, Step: 27210, Train Loss: 1.7264, Learning Rate: 8.27e-05
2025-12-09 03:59:26 - INFO - Epoch: 8.59, Step: 27220, Train Loss: 1.6569, Learning Rate: 8.27e-05
2025-12-09 03:59:37 - INFO - Epoch: 8.59, Step: 27230, Train Loss: 1.7287, Learning Rate: 8.27e-05
2025-12-09 03:59:48 - INFO - Epoch: 8.60, Step: 27240, Train Loss: 1.6967, Learning Rate: 8.26e-05
2025-12-09 03:59:59 - INFO - Epoch: 8.60, Step: 27250, Train Loss: 1.7047, Learning Rate: 8.26e-05
2025-12-09 04:00:10 - INFO - Epoch: 8.60, Step: 27260, Train Loss: 1.6472, Learning Rate: 8.26e-05
2025-12-09 04:00:21 - INFO - Epoch: 8.61, Step: 27270, Train Loss: 1.6893, Learning Rate: 8.26e-05
2025-12-09 04:00:32 - INFO - Epoch: 8.61, Step: 27280, Train Loss: 1.7081, Learning Rate: 8.26e-05
2025-12-09 04:00:43 - INFO - Epoch: 8.61, Step: 27290, Train Loss: 1.6816, Learning Rate: 8.26e-05
2025-12-09 04:00:54 - INFO - Epoch: 8.61, Step: 27300, Train Loss: 1.6848, Learning Rate: 8.26e-05
2025-12-09 04:01:05 - INFO - Epoch: 8.62, Step: 27310, Train Loss: 1.6713, Learning Rate: 8.26e-05
2025-12-09 04:01:16 - INFO - Epoch: 8.62, Step: 27320, Train Loss: 1.7156, Learning Rate: 8.26e-05
2025-12-09 04:01:27 - INFO - Epoch: 8.62, Step: 27330, Train Loss: 1.6953, Learning Rate: 8.26e-05
2025-12-09 04:01:39 - INFO - Epoch: 8.63, Step: 27340, Train Loss: 1.6785, Learning Rate: 8.26e-05
2025-12-09 04:01:50 - INFO - Epoch: 8.63, Step: 27350, Train Loss: 1.6573, Learning Rate: 8.26e-05
2025-12-09 04:02:01 - INFO - Epoch: 8.63, Step: 27360, Train Loss: 1.6846, Learning Rate: 8.25e-05
2025-12-09 04:02:12 - INFO - Epoch: 8.64, Step: 27370, Train Loss: 1.6517, Learning Rate: 8.25e-05
2025-12-09 04:02:23 - INFO - Epoch: 8.64, Step: 27380, Train Loss: 1.7201, Learning Rate: 8.25e-05
2025-12-09 04:02:34 - INFO - Epoch: 8.64, Step: 27390, Train Loss: 1.6992, Learning Rate: 8.25e-05
2025-12-09 04:02:45 - INFO - Epoch: 8.65, Step: 27400, Train Loss: 1.6500, Learning Rate: 8.25e-05
2025-12-09 04:02:56 - INFO - Epoch: 8.65, Step: 27410, Train Loss: 1.7139, Learning Rate: 8.25e-05
2025-12-09 04:03:07 - INFO - Epoch: 8.65, Step: 27420, Train Loss: 1.6646, Learning Rate: 8.25e-05
2025-12-09 04:03:18 - INFO - Epoch: 8.66, Step: 27430, Train Loss: 1.7065, Learning Rate: 8.25e-05
2025-12-09 04:03:29 - INFO - Epoch: 8.66, Step: 27440, Train Loss: 1.6898, Learning Rate: 8.25e-05
2025-12-09 04:03:40 - INFO - Epoch: 8.66, Step: 27450, Train Loss: 1.6611, Learning Rate: 8.25e-05
2025-12-09 04:03:52 - INFO - Epoch: 8.67, Step: 27460, Train Loss: 1.6823, Learning Rate: 8.25e-05
2025-12-09 04:04:03 - INFO - Epoch: 8.67, Step: 27470, Train Loss: 1.6871, Learning Rate: 8.25e-05
2025-12-09 04:04:14 - INFO - Epoch: 8.67, Step: 27480, Train Loss: 1.6717, Learning Rate: 8.24e-05
2025-12-09 04:04:25 - INFO - Epoch: 8.67, Step: 27490, Train Loss: 1.6686, Learning Rate: 8.24e-05
2025-12-09 04:04:36 - INFO - Epoch: 8.68, Step: 27500, Train Loss: 1.7048, Learning Rate: 8.24e-05
2025-12-09 04:04:47 - INFO - Epoch: 8.68, Step: 27510, Train Loss: 1.6819, Learning Rate: 8.24e-05
2025-12-09 04:04:58 - INFO - Epoch: 8.68, Step: 27520, Train Loss: 1.6786, Learning Rate: 8.24e-05
2025-12-09 04:05:09 - INFO - Epoch: 8.69, Step: 27530, Train Loss: 1.7109, Learning Rate: 8.24e-05
2025-12-09 04:05:20 - INFO - Epoch: 8.69, Step: 27540, Train Loss: 1.6939, Learning Rate: 8.24e-05
2025-12-09 04:05:31 - INFO - Epoch: 8.69, Step: 27550, Train Loss: 1.6855, Learning Rate: 8.24e-05
2025-12-09 04:05:42 - INFO - Epoch: 8.70, Step: 27560, Train Loss: 1.6957, Learning Rate: 8.24e-05
2025-12-09 04:05:53 - INFO - Epoch: 8.70, Step: 27570, Train Loss: 1.6903, Learning Rate: 8.24e-05
2025-12-09 04:06:05 - INFO - Epoch: 8.70, Step: 27580, Train Loss: 1.6770, Learning Rate: 8.24e-05
2025-12-09 04:06:16 - INFO - Epoch: 8.71, Step: 27590, Train Loss: 1.7348, Learning Rate: 8.24e-05
2025-12-09 04:06:27 - INFO - Epoch: 8.71, Step: 27600, Train Loss: 1.6834, Learning Rate: 8.23e-05
2025-12-09 04:06:38 - INFO - Epoch: 8.71, Step: 27610, Train Loss: 1.6785, Learning Rate: 8.23e-05
2025-12-09 04:06:49 - INFO - Epoch: 8.72, Step: 27620, Train Loss: 1.6753, Learning Rate: 8.23e-05
2025-12-09 04:07:00 - INFO - Epoch: 8.72, Step: 27630, Train Loss: 1.7109, Learning Rate: 8.23e-05
2025-12-09 04:07:11 - INFO - Epoch: 8.72, Step: 27640, Train Loss: 1.6994, Learning Rate: 8.23e-05
2025-12-09 04:07:22 - INFO - Epoch: 8.73, Step: 27650, Train Loss: 1.6834, Learning Rate: 8.23e-05
2025-12-09 04:07:33 - INFO - Epoch: 8.73, Step: 27660, Train Loss: 1.6824, Learning Rate: 8.23e-05
2025-12-09 04:07:44 - INFO - Epoch: 8.73, Step: 27670, Train Loss: 1.6789, Learning Rate: 8.23e-05
2025-12-09 04:07:55 - INFO - Epoch: 8.73, Step: 27680, Train Loss: 1.6507, Learning Rate: 8.23e-05
2025-12-09 04:08:06 - INFO - Epoch: 8.74, Step: 27690, Train Loss: 1.6598, Learning Rate: 8.23e-05
2025-12-09 04:08:18 - INFO - Epoch: 8.74, Step: 27700, Train Loss: 1.6490, Learning Rate: 8.23e-05
2025-12-09 04:08:29 - INFO - Epoch: 8.74, Step: 27710, Train Loss: 1.7358, Learning Rate: 8.23e-05
2025-12-09 04:08:40 - INFO - Epoch: 8.75, Step: 27720, Train Loss: 1.6590, Learning Rate: 8.22e-05
2025-12-09 04:08:51 - INFO - Epoch: 8.75, Step: 27730, Train Loss: 1.6847, Learning Rate: 8.22e-05
2025-12-09 04:09:02 - INFO - Epoch: 8.75, Step: 27740, Train Loss: 1.6991, Learning Rate: 8.22e-05
2025-12-09 04:09:13 - INFO - Epoch: 8.76, Step: 27750, Train Loss: 1.7008, Learning Rate: 8.22e-05
2025-12-09 04:09:24 - INFO - Epoch: 8.76, Step: 27760, Train Loss: 1.6606, Learning Rate: 8.22e-05
2025-12-09 04:09:35 - INFO - Epoch: 8.76, Step: 27770, Train Loss: 1.6918, Learning Rate: 8.22e-05
2025-12-09 04:09:46 - INFO - Epoch: 8.77, Step: 27780, Train Loss: 1.6309, Learning Rate: 8.22e-05
2025-12-09 04:09:57 - INFO - Epoch: 8.77, Step: 27790, Train Loss: 1.6261, Learning Rate: 8.22e-05
2025-12-09 04:10:08 - INFO - Epoch: 8.77, Step: 27800, Train Loss: 1.7296, Learning Rate: 8.22e-05
2025-12-09 04:10:19 - INFO - Epoch: 8.78, Step: 27810, Train Loss: 1.6554, Learning Rate: 8.22e-05
2025-12-09 04:10:31 - INFO - Epoch: 8.78, Step: 27820, Train Loss: 1.6659, Learning Rate: 8.22e-05
2025-12-09 04:10:42 - INFO - Epoch: 8.78, Step: 27830, Train Loss: 1.6825, Learning Rate: 8.22e-05
2025-12-09 04:10:53 - INFO - Epoch: 8.79, Step: 27840, Train Loss: 1.6787, Learning Rate: 8.21e-05
2025-12-09 04:11:04 - INFO - Epoch: 8.79, Step: 27850, Train Loss: 1.6955, Learning Rate: 8.21e-05
2025-12-09 04:11:15 - INFO - Epoch: 8.79, Step: 27860, Train Loss: 1.6534, Learning Rate: 8.21e-05
2025-12-09 04:11:26 - INFO - Epoch: 8.79, Step: 27870, Train Loss: 1.6770, Learning Rate: 8.21e-05
2025-12-09 04:11:37 - INFO - Epoch: 8.80, Step: 27880, Train Loss: 1.7053, Learning Rate: 8.21e-05
2025-12-09 04:11:48 - INFO - Epoch: 8.80, Step: 27890, Train Loss: 1.6965, Learning Rate: 8.21e-05
2025-12-09 04:11:59 - INFO - Epoch: 8.80, Step: 27900, Train Loss: 1.6706, Learning Rate: 8.21e-05
2025-12-09 04:12:10 - INFO - Epoch: 8.81, Step: 27910, Train Loss: 1.6614, Learning Rate: 8.21e-05
2025-12-09 04:12:21 - INFO - Epoch: 8.81, Step: 27920, Train Loss: 1.6904, Learning Rate: 8.21e-05
2025-12-09 04:12:32 - INFO - Epoch: 8.81, Step: 27930, Train Loss: 1.6712, Learning Rate: 8.21e-05
2025-12-09 04:12:44 - INFO - Epoch: 8.82, Step: 27940, Train Loss: 1.6831, Learning Rate: 8.21e-05
2025-12-09 04:12:55 - INFO - Epoch: 8.82, Step: 27950, Train Loss: 1.6642, Learning Rate: 8.21e-05
2025-12-09 04:13:06 - INFO - Epoch: 8.82, Step: 27960, Train Loss: 1.6735, Learning Rate: 8.20e-05
2025-12-09 04:13:17 - INFO - Epoch: 8.83, Step: 27970, Train Loss: 1.7029, Learning Rate: 8.20e-05
2025-12-09 04:13:28 - INFO - Epoch: 8.83, Step: 27980, Train Loss: 1.6383, Learning Rate: 8.20e-05
2025-12-09 04:13:39 - INFO - Epoch: 8.83, Step: 27990, Train Loss: 1.6351, Learning Rate: 8.20e-05
2025-12-09 04:13:50 - INFO - Epoch: 8.84, Step: 28000, Train Loss: 1.6889, Learning Rate: 8.20e-05
2025-12-09 04:14:01 - INFO - Epoch: 8.84, Step: 28010, Train Loss: 1.6563, Learning Rate: 8.20e-05
2025-12-09 04:14:12 - INFO - Epoch: 8.84, Step: 28020, Train Loss: 1.6652, Learning Rate: 8.20e-05
2025-12-09 04:14:23 - INFO - Epoch: 8.85, Step: 28030, Train Loss: 1.7093, Learning Rate: 8.20e-05
2025-12-09 04:14:34 - INFO - Epoch: 8.85, Step: 28040, Train Loss: 1.6720, Learning Rate: 8.20e-05
2025-12-09 04:14:45 - INFO - Epoch: 8.85, Step: 28050, Train Loss: 1.6754, Learning Rate: 8.20e-05
2025-12-09 04:14:56 - INFO - Epoch: 8.85, Step: 28060, Train Loss: 1.6573, Learning Rate: 8.20e-05
2025-12-09 04:15:08 - INFO - Epoch: 8.86, Step: 28070, Train Loss: 1.6901, Learning Rate: 8.20e-05
2025-12-09 04:15:19 - INFO - Epoch: 8.86, Step: 28080, Train Loss: 1.6799, Learning Rate: 8.19e-05
2025-12-09 04:15:30 - INFO - Epoch: 8.86, Step: 28090, Train Loss: 1.6757, Learning Rate: 8.19e-05
2025-12-09 04:15:41 - INFO - Epoch: 8.87, Step: 28100, Train Loss: 1.6842, Learning Rate: 8.19e-05
2025-12-09 04:15:52 - INFO - Epoch: 8.87, Step: 28110, Train Loss: 1.6774, Learning Rate: 8.19e-05
2025-12-09 04:16:03 - INFO - Epoch: 8.87, Step: 28120, Train Loss: 1.6838, Learning Rate: 8.19e-05
2025-12-09 04:16:14 - INFO - Epoch: 8.88, Step: 28130, Train Loss: 1.6564, Learning Rate: 8.19e-05
2025-12-09 04:16:25 - INFO - Epoch: 8.88, Step: 28140, Train Loss: 1.6481, Learning Rate: 8.19e-05
2025-12-09 04:16:36 - INFO - Epoch: 8.88, Step: 28150, Train Loss: 1.6872, Learning Rate: 8.19e-05
2025-12-09 04:16:47 - INFO - Epoch: 8.89, Step: 28160, Train Loss: 1.6599, Learning Rate: 8.19e-05
2025-12-09 04:16:58 - INFO - Epoch: 8.89, Step: 28170, Train Loss: 1.6784, Learning Rate: 8.19e-05
2025-12-09 04:17:09 - INFO - Epoch: 8.89, Step: 28180, Train Loss: 1.6262, Learning Rate: 8.19e-05
2025-12-09 04:17:21 - INFO - Epoch: 8.90, Step: 28190, Train Loss: 1.6846, Learning Rate: 8.19e-05
2025-12-09 04:17:32 - INFO - Epoch: 8.90, Step: 28200, Train Loss: 1.6595, Learning Rate: 8.18e-05
2025-12-09 04:17:43 - INFO - Epoch: 8.90, Step: 28210, Train Loss: 1.6536, Learning Rate: 8.18e-05
2025-12-09 04:17:54 - INFO - Epoch: 8.91, Step: 28220, Train Loss: 1.6711, Learning Rate: 8.18e-05
2025-12-09 04:18:05 - INFO - Epoch: 8.91, Step: 28230, Train Loss: 1.6573, Learning Rate: 8.18e-05
2025-12-09 04:18:16 - INFO - Epoch: 8.91, Step: 28240, Train Loss: 1.6774, Learning Rate: 8.18e-05
2025-12-09 04:18:27 - INFO - Epoch: 8.91, Step: 28250, Train Loss: 1.6583, Learning Rate: 8.18e-05
2025-12-09 04:18:38 - INFO - Epoch: 8.92, Step: 28260, Train Loss: 1.7012, Learning Rate: 8.18e-05
2025-12-09 04:18:49 - INFO - Epoch: 8.92, Step: 28270, Train Loss: 1.6828, Learning Rate: 8.18e-05
2025-12-09 04:19:00 - INFO - Epoch: 8.92, Step: 28280, Train Loss: 1.6502, Learning Rate: 8.18e-05
2025-12-09 04:19:11 - INFO - Epoch: 8.93, Step: 28290, Train Loss: 1.6854, Learning Rate: 8.18e-05
2025-12-09 04:19:22 - INFO - Epoch: 8.93, Step: 28300, Train Loss: 1.6570, Learning Rate: 8.18e-05
2025-12-09 04:19:34 - INFO - Epoch: 8.93, Step: 28310, Train Loss: 1.6280, Learning Rate: 8.18e-05
2025-12-09 04:19:45 - INFO - Epoch: 8.94, Step: 28320, Train Loss: 1.6898, Learning Rate: 8.17e-05
2025-12-09 04:19:56 - INFO - Epoch: 8.94, Step: 28330, Train Loss: 1.6405, Learning Rate: 8.17e-05
2025-12-09 04:20:07 - INFO - Epoch: 8.94, Step: 28340, Train Loss: 1.6451, Learning Rate: 8.17e-05
2025-12-09 04:20:18 - INFO - Epoch: 8.95, Step: 28350, Train Loss: 1.6642, Learning Rate: 8.17e-05
2025-12-09 04:20:29 - INFO - Epoch: 8.95, Step: 28360, Train Loss: 1.6757, Learning Rate: 8.17e-05
2025-12-09 04:20:40 - INFO - Epoch: 8.95, Step: 28370, Train Loss: 1.6619, Learning Rate: 8.17e-05
2025-12-09 04:20:51 - INFO - Epoch: 8.96, Step: 28380, Train Loss: 1.6793, Learning Rate: 8.17e-05
2025-12-09 04:21:02 - INFO - Epoch: 8.96, Step: 28390, Train Loss: 1.6580, Learning Rate: 8.17e-05
2025-12-09 04:21:13 - INFO - Epoch: 8.96, Step: 28400, Train Loss: 1.6953, Learning Rate: 8.17e-05
2025-12-09 04:21:24 - INFO - Epoch: 8.96, Step: 28410, Train Loss: 1.6030, Learning Rate: 8.17e-05
2025-12-09 04:21:35 - INFO - Epoch: 8.97, Step: 28420, Train Loss: 1.6552, Learning Rate: 8.17e-05
2025-12-09 04:21:47 - INFO - Epoch: 8.97, Step: 28430, Train Loss: 1.6581, Learning Rate: 8.17e-05
2025-12-09 04:21:58 - INFO - Epoch: 8.97, Step: 28440, Train Loss: 1.6619, Learning Rate: 8.16e-05
2025-12-09 04:22:09 - INFO - Epoch: 8.98, Step: 28450, Train Loss: 1.6598, Learning Rate: 8.16e-05
2025-12-09 04:22:20 - INFO - Epoch: 8.98, Step: 28460, Train Loss: 1.6797, Learning Rate: 8.16e-05
2025-12-09 04:22:31 - INFO - Epoch: 8.98, Step: 28470, Train Loss: 1.6206, Learning Rate: 8.16e-05
2025-12-09 04:22:42 - INFO - Epoch: 8.99, Step: 28480, Train Loss: 1.6942, Learning Rate: 8.16e-05
2025-12-09 04:22:53 - INFO - Epoch: 8.99, Step: 28490, Train Loss: 1.6430, Learning Rate: 8.16e-05
2025-12-09 04:23:04 - INFO - Epoch: 8.99, Step: 28500, Train Loss: 1.6832, Learning Rate: 8.16e-05
2025-12-09 04:23:15 - INFO - Epoch: 9.00, Step: 28510, Train Loss: 1.6728, Learning Rate: 8.16e-05
2025-12-09 04:23:26 - INFO - Epoch: 9.00, Step: 28520, Train Loss: 1.7210, Learning Rate: 8.16e-05
2025-12-09 04:23:37 - INFO - Epoch: 9.00, Step: 28530, Train Loss: 1.6367, Learning Rate: 8.16e-05
2025-12-09 04:23:48 - INFO - Epoch: 9.01, Step: 28540, Train Loss: 1.6024, Learning Rate: 8.16e-05
2025-12-09 04:24:00 - INFO - Epoch: 9.01, Step: 28550, Train Loss: 1.6883, Learning Rate: 8.16e-05
2025-12-09 04:24:11 - INFO - Epoch: 9.01, Step: 28560, Train Loss: 1.6370, Learning Rate: 8.15e-05
2025-12-09 04:24:22 - INFO - Epoch: 9.02, Step: 28570, Train Loss: 1.6845, Learning Rate: 8.15e-05
2025-12-09 04:24:33 - INFO - Epoch: 9.02, Step: 28580, Train Loss: 1.6262, Learning Rate: 8.15e-05
2025-12-09 04:24:44 - INFO - Epoch: 9.02, Step: 28590, Train Loss: 1.6791, Learning Rate: 8.15e-05
2025-12-09 04:24:55 - INFO - Epoch: 9.02, Step: 28600, Train Loss: 1.6757, Learning Rate: 8.15e-05
2025-12-09 04:25:06 - INFO - Epoch: 9.03, Step: 28610, Train Loss: 1.6668, Learning Rate: 8.15e-05
2025-12-09 04:25:17 - INFO - Epoch: 9.03, Step: 28620, Train Loss: 1.6491, Learning Rate: 8.15e-05
2025-12-09 04:25:28 - INFO - Epoch: 9.03, Step: 28630, Train Loss: 1.6738, Learning Rate: 8.15e-05
2025-12-09 04:25:39 - INFO - Epoch: 9.04, Step: 28640, Train Loss: 1.6727, Learning Rate: 8.15e-05
2025-12-09 04:25:50 - INFO - Epoch: 9.04, Step: 28650, Train Loss: 1.6529, Learning Rate: 8.15e-05
2025-12-09 04:26:01 - INFO - Epoch: 9.04, Step: 28660, Train Loss: 1.6325, Learning Rate: 8.15e-05
2025-12-09 04:26:12 - INFO - Epoch: 9.05, Step: 28670, Train Loss: 1.6420, Learning Rate: 8.15e-05
2025-12-09 04:26:24 - INFO - Epoch: 9.05, Step: 28680, Train Loss: 1.7205, Learning Rate: 8.14e-05
2025-12-09 04:26:35 - INFO - Epoch: 9.05, Step: 28690, Train Loss: 1.6375, Learning Rate: 8.14e-05
2025-12-09 04:26:46 - INFO - Epoch: 9.06, Step: 28700, Train Loss: 1.6287, Learning Rate: 8.14e-05
2025-12-09 04:26:57 - INFO - Epoch: 9.06, Step: 28710, Train Loss: 1.6701, Learning Rate: 8.14e-05
2025-12-09 04:27:08 - INFO - Epoch: 9.06, Step: 28720, Train Loss: 1.6645, Learning Rate: 8.14e-05
2025-12-09 04:27:19 - INFO - Epoch: 9.07, Step: 28730, Train Loss: 1.6555, Learning Rate: 8.14e-05
2025-12-09 04:27:30 - INFO - Epoch: 9.07, Step: 28740, Train Loss: 1.6349, Learning Rate: 8.14e-05
2025-12-09 04:27:41 - INFO - Epoch: 9.07, Step: 28750, Train Loss: 1.6632, Learning Rate: 8.14e-05
2025-12-09 04:27:52 - INFO - Epoch: 9.08, Step: 28760, Train Loss: 1.6407, Learning Rate: 8.14e-05
2025-12-09 04:28:03 - INFO - Epoch: 9.08, Step: 28770, Train Loss: 1.6679, Learning Rate: 8.14e-05
2025-12-09 04:28:14 - INFO - Epoch: 9.08, Step: 28780, Train Loss: 1.6768, Learning Rate: 8.14e-05
2025-12-09 04:28:25 - INFO - Epoch: 9.08, Step: 28790, Train Loss: 1.6530, Learning Rate: 8.14e-05
2025-12-09 04:28:37 - INFO - Epoch: 9.09, Step: 28800, Train Loss: 1.6528, Learning Rate: 8.13e-05
2025-12-09 04:28:48 - INFO - Epoch: 9.09, Step: 28810, Train Loss: 1.6584, Learning Rate: 8.13e-05
2025-12-09 04:28:59 - INFO - Epoch: 9.09, Step: 28820, Train Loss: 1.6745, Learning Rate: 8.13e-05
2025-12-09 04:29:10 - INFO - Epoch: 9.10, Step: 28830, Train Loss: 1.6549, Learning Rate: 8.13e-05
2025-12-09 04:29:21 - INFO - Epoch: 9.10, Step: 28840, Train Loss: 1.6550, Learning Rate: 8.13e-05
2025-12-09 04:29:32 - INFO - Epoch: 9.10, Step: 28850, Train Loss: 1.6828, Learning Rate: 8.13e-05
2025-12-09 04:29:43 - INFO - Epoch: 9.11, Step: 28860, Train Loss: 1.6662, Learning Rate: 8.13e-05
2025-12-09 04:29:54 - INFO - Epoch: 9.11, Step: 28870, Train Loss: 1.6774, Learning Rate: 8.13e-05
2025-12-09 04:30:05 - INFO - Epoch: 9.11, Step: 28880, Train Loss: 1.6408, Learning Rate: 8.13e-05
2025-12-09 04:30:16 - INFO - Epoch: 9.12, Step: 28890, Train Loss: 1.6598, Learning Rate: 8.13e-05
2025-12-09 04:30:27 - INFO - Epoch: 9.12, Step: 28900, Train Loss: 1.6538, Learning Rate: 8.13e-05
2025-12-09 04:30:38 - INFO - Epoch: 9.12, Step: 28910, Train Loss: 1.6284, Learning Rate: 8.13e-05
2025-12-09 04:30:50 - INFO - Epoch: 9.13, Step: 28920, Train Loss: 1.6581, Learning Rate: 8.12e-05
2025-12-09 04:31:01 - INFO - Epoch: 9.13, Step: 28930, Train Loss: 1.6772, Learning Rate: 8.12e-05
2025-12-09 04:31:12 - INFO - Epoch: 9.13, Step: 28940, Train Loss: 1.6203, Learning Rate: 8.12e-05
2025-12-09 04:31:23 - INFO - Epoch: 9.14, Step: 28950, Train Loss: 1.6793, Learning Rate: 8.12e-05
2025-12-09 04:31:34 - INFO - Epoch: 9.14, Step: 28960, Train Loss: 1.6696, Learning Rate: 8.12e-05
2025-12-09 04:31:45 - INFO - Epoch: 9.14, Step: 28970, Train Loss: 1.6545, Learning Rate: 8.12e-05
2025-12-09 04:31:56 - INFO - Epoch: 9.14, Step: 28980, Train Loss: 1.6615, Learning Rate: 8.12e-05
2025-12-09 04:32:07 - INFO - Epoch: 9.15, Step: 28990, Train Loss: 1.6204, Learning Rate: 8.12e-05
2025-12-09 04:32:18 - INFO - Epoch: 9.15, Step: 29000, Train Loss: 1.6510, Learning Rate: 8.12e-05
2025-12-09 04:32:29 - INFO - Epoch: 9.15, Step: 29010, Train Loss: 1.6320, Learning Rate: 8.12e-05
2025-12-09 04:32:40 - INFO - Epoch: 9.16, Step: 29020, Train Loss: 1.6022, Learning Rate: 8.12e-05
2025-12-09 04:32:51 - INFO - Epoch: 9.16, Step: 29030, Train Loss: 1.6406, Learning Rate: 8.12e-05
2025-12-09 04:33:03 - INFO - Epoch: 9.16, Step: 29040, Train Loss: 1.6313, Learning Rate: 8.11e-05
2025-12-09 04:33:14 - INFO - Epoch: 9.17, Step: 29050, Train Loss: 1.6320, Learning Rate: 8.11e-05
2025-12-09 04:33:25 - INFO - Epoch: 9.17, Step: 29060, Train Loss: 1.6825, Learning Rate: 8.11e-05
2025-12-09 04:33:36 - INFO - Epoch: 9.17, Step: 29070, Train Loss: 1.6326, Learning Rate: 8.11e-05
2025-12-09 04:33:47 - INFO - Epoch: 9.18, Step: 29080, Train Loss: 1.6529, Learning Rate: 8.11e-05
2025-12-09 04:33:58 - INFO - Epoch: 9.18, Step: 29090, Train Loss: 1.6343, Learning Rate: 8.11e-05
2025-12-09 04:34:09 - INFO - Epoch: 9.18, Step: 29100, Train Loss: 1.6673, Learning Rate: 8.11e-05
2025-12-09 04:34:20 - INFO - Epoch: 9.19, Step: 29110, Train Loss: 1.6200, Learning Rate: 8.11e-05
2025-12-09 04:34:31 - INFO - Epoch: 9.19, Step: 29120, Train Loss: 1.6557, Learning Rate: 8.11e-05
2025-12-09 04:34:42 - INFO - Epoch: 9.19, Step: 29130, Train Loss: 1.6683, Learning Rate: 8.11e-05
2025-12-09 04:34:53 - INFO - Epoch: 9.20, Step: 29140, Train Loss: 1.6369, Learning Rate: 8.11e-05
2025-12-09 04:35:04 - INFO - Epoch: 9.20, Step: 29150, Train Loss: 1.6604, Learning Rate: 8.11e-05
2025-12-09 04:35:16 - INFO - Epoch: 9.20, Step: 29160, Train Loss: 1.6796, Learning Rate: 8.10e-05
2025-12-09 04:35:27 - INFO - Epoch: 9.20, Step: 29170, Train Loss: 1.6469, Learning Rate: 8.10e-05
2025-12-09 04:35:38 - INFO - Epoch: 9.21, Step: 29180, Train Loss: 1.6408, Learning Rate: 8.10e-05
2025-12-09 04:35:49 - INFO - Epoch: 9.21, Step: 29190, Train Loss: 1.6205, Learning Rate: 8.10e-05
2025-12-09 04:36:00 - INFO - Epoch: 9.21, Step: 29200, Train Loss: 1.6802, Learning Rate: 8.10e-05
2025-12-09 04:36:11 - INFO - Epoch: 9.22, Step: 29210, Train Loss: 1.6376, Learning Rate: 8.10e-05
2025-12-09 04:36:22 - INFO - Epoch: 9.22, Step: 29220, Train Loss: 1.6880, Learning Rate: 8.10e-05
2025-12-09 04:36:33 - INFO - Epoch: 9.22, Step: 29230, Train Loss: 1.6494, Learning Rate: 8.10e-05
2025-12-09 04:36:44 - INFO - Epoch: 9.23, Step: 29240, Train Loss: 1.6245, Learning Rate: 8.10e-05
2025-12-09 04:36:55 - INFO - Epoch: 9.23, Step: 29250, Train Loss: 1.6296, Learning Rate: 8.10e-05
2025-12-09 04:37:06 - INFO - Epoch: 9.23, Step: 29260, Train Loss: 1.6668, Learning Rate: 8.10e-05
2025-12-09 04:37:17 - INFO - Epoch: 9.24, Step: 29270, Train Loss: 1.6368, Learning Rate: 8.10e-05
2025-12-09 04:37:28 - INFO - Epoch: 9.24, Step: 29280, Train Loss: 1.6274, Learning Rate: 8.09e-05
2025-12-09 04:37:40 - INFO - Epoch: 9.24, Step: 29290, Train Loss: 1.6484, Learning Rate: 8.09e-05
2025-12-09 04:37:51 - INFO - Epoch: 9.25, Step: 29300, Train Loss: 1.6544, Learning Rate: 8.09e-05
2025-12-09 04:38:02 - INFO - Epoch: 9.25, Step: 29310, Train Loss: 1.6808, Learning Rate: 8.09e-05
2025-12-09 04:38:13 - INFO - Epoch: 9.25, Step: 29320, Train Loss: 1.6742, Learning Rate: 8.09e-05
2025-12-09 04:38:24 - INFO - Epoch: 9.26, Step: 29330, Train Loss: 1.5881, Learning Rate: 8.09e-05
2025-12-09 04:38:35 - INFO - Epoch: 9.26, Step: 29340, Train Loss: 1.6603, Learning Rate: 8.09e-05
2025-12-09 04:38:46 - INFO - Epoch: 9.26, Step: 29350, Train Loss: 1.6379, Learning Rate: 8.09e-05
2025-12-09 04:38:57 - INFO - Epoch: 9.26, Step: 29360, Train Loss: 1.6652, Learning Rate: 8.09e-05
2025-12-09 04:39:08 - INFO - Epoch: 9.27, Step: 29370, Train Loss: 1.6196, Learning Rate: 8.09e-05
2025-12-09 04:39:19 - INFO - Epoch: 9.27, Step: 29380, Train Loss: 1.6414, Learning Rate: 8.09e-05
2025-12-09 04:39:30 - INFO - Epoch: 9.27, Step: 29390, Train Loss: 1.6658, Learning Rate: 8.09e-05
2025-12-09 04:39:41 - INFO - Epoch: 9.28, Step: 29400, Train Loss: 1.6366, Learning Rate: 8.08e-05
2025-12-09 04:39:53 - INFO - Epoch: 9.28, Step: 29410, Train Loss: 1.6114, Learning Rate: 8.08e-05
2025-12-09 04:40:04 - INFO - Epoch: 9.28, Step: 29420, Train Loss: 1.6374, Learning Rate: 8.08e-05
2025-12-09 04:40:15 - INFO - Epoch: 9.29, Step: 29430, Train Loss: 1.6133, Learning Rate: 8.08e-05
2025-12-09 04:40:26 - INFO - Epoch: 9.29, Step: 29440, Train Loss: 1.6483, Learning Rate: 8.08e-05
2025-12-09 04:40:37 - INFO - Epoch: 9.29, Step: 29450, Train Loss: 1.6166, Learning Rate: 8.08e-05
2025-12-09 04:40:48 - INFO - Epoch: 9.30, Step: 29460, Train Loss: 1.6159, Learning Rate: 8.08e-05
2025-12-09 04:40:59 - INFO - Epoch: 9.30, Step: 29470, Train Loss: 1.6348, Learning Rate: 8.08e-05
2025-12-09 04:41:10 - INFO - Epoch: 9.30, Step: 29480, Train Loss: 1.6626, Learning Rate: 8.08e-05
2025-12-09 04:41:21 - INFO - Epoch: 9.31, Step: 29490, Train Loss: 1.6561, Learning Rate: 8.08e-05
2025-12-09 04:41:32 - INFO - Epoch: 9.31, Step: 29500, Train Loss: 1.5904, Learning Rate: 8.08e-05
2025-12-09 04:41:43 - INFO - Epoch: 9.31, Step: 29510, Train Loss: 1.6651, Learning Rate: 8.08e-05
2025-12-09 04:41:54 - INFO - Epoch: 9.32, Step: 29520, Train Loss: 1.6218, Learning Rate: 8.08e-05
2025-12-09 04:42:06 - INFO - Epoch: 9.32, Step: 29530, Train Loss: 1.6310, Learning Rate: 8.07e-05
2025-12-09 04:42:17 - INFO - Epoch: 9.32, Step: 29540, Train Loss: 1.6647, Learning Rate: 8.07e-05
2025-12-09 04:42:28 - INFO - Epoch: 9.32, Step: 29550, Train Loss: 1.6477, Learning Rate: 8.07e-05
2025-12-09 04:42:39 - INFO - Epoch: 9.33, Step: 29560, Train Loss: 1.6184, Learning Rate: 8.07e-05
2025-12-09 04:42:50 - INFO - Epoch: 9.33, Step: 29570, Train Loss: 1.6640, Learning Rate: 8.07e-05
2025-12-09 04:43:01 - INFO - Epoch: 9.33, Step: 29580, Train Loss: 1.6581, Learning Rate: 8.07e-05
2025-12-09 04:43:12 - INFO - Epoch: 9.34, Step: 29590, Train Loss: 1.6339, Learning Rate: 8.07e-05
2025-12-09 04:43:23 - INFO - Epoch: 9.34, Step: 29600, Train Loss: 1.6373, Learning Rate: 8.07e-05
2025-12-09 04:43:34 - INFO - Epoch: 9.34, Step: 29610, Train Loss: 1.6373, Learning Rate: 8.07e-05
2025-12-09 04:43:45 - INFO - Epoch: 9.35, Step: 29620, Train Loss: 1.6218, Learning Rate: 8.07e-05
2025-12-09 04:43:56 - INFO - Epoch: 9.35, Step: 29630, Train Loss: 1.6635, Learning Rate: 8.07e-05
2025-12-09 04:44:07 - INFO - Epoch: 9.35, Step: 29640, Train Loss: 1.6693, Learning Rate: 8.07e-05
2025-12-09 04:44:19 - INFO - Epoch: 9.36, Step: 29650, Train Loss: 1.6406, Learning Rate: 8.06e-05
2025-12-09 04:44:30 - INFO - Epoch: 9.36, Step: 29660, Train Loss: 1.5926, Learning Rate: 8.06e-05
2025-12-09 04:44:41 - INFO - Epoch: 9.36, Step: 29670, Train Loss: 1.6024, Learning Rate: 8.06e-05
2025-12-09 04:44:52 - INFO - Epoch: 9.37, Step: 29680, Train Loss: 1.6360, Learning Rate: 8.06e-05
2025-12-09 04:45:03 - INFO - Epoch: 9.37, Step: 29690, Train Loss: 1.6349, Learning Rate: 8.06e-05
2025-12-09 04:45:14 - INFO - Epoch: 9.37, Step: 29700, Train Loss: 1.6256, Learning Rate: 8.06e-05
2025-12-09 04:45:25 - INFO - Epoch: 9.38, Step: 29710, Train Loss: 1.6328, Learning Rate: 8.06e-05
2025-12-09 04:45:36 - INFO - Epoch: 9.38, Step: 29720, Train Loss: 1.6574, Learning Rate: 8.06e-05
2025-12-09 04:45:47 - INFO - Epoch: 9.38, Step: 29730, Train Loss: 1.6416, Learning Rate: 8.06e-05
2025-12-09 04:45:58 - INFO - Epoch: 9.38, Step: 29740, Train Loss: 1.6240, Learning Rate: 8.06e-05
2025-12-09 04:46:09 - INFO - Epoch: 9.39, Step: 29750, Train Loss: 1.6500, Learning Rate: 8.06e-05
2025-12-09 04:46:20 - INFO - Epoch: 9.39, Step: 29760, Train Loss: 1.6481, Learning Rate: 8.06e-05
2025-12-09 04:46:31 - INFO - Epoch: 9.39, Step: 29770, Train Loss: 1.6258, Learning Rate: 8.05e-05
2025-12-09 04:46:43 - INFO - Epoch: 9.40, Step: 29780, Train Loss: 1.6138, Learning Rate: 8.05e-05
2025-12-09 04:46:54 - INFO - Epoch: 9.40, Step: 29790, Train Loss: 1.6710, Learning Rate: 8.05e-05
2025-12-09 04:47:05 - INFO - Epoch: 9.40, Step: 29800, Train Loss: 1.6183, Learning Rate: 8.05e-05
2025-12-09 04:47:16 - INFO - Epoch: 9.41, Step: 29810, Train Loss: 1.6459, Learning Rate: 8.05e-05
2025-12-09 04:47:27 - INFO - Epoch: 9.41, Step: 29820, Train Loss: 1.6337, Learning Rate: 8.05e-05
2025-12-09 04:47:38 - INFO - Epoch: 9.41, Step: 29830, Train Loss: 1.5902, Learning Rate: 8.05e-05
2025-12-09 04:47:49 - INFO - Epoch: 9.42, Step: 29840, Train Loss: 1.6621, Learning Rate: 8.05e-05
2025-12-09 04:48:00 - INFO - Epoch: 9.42, Step: 29850, Train Loss: 1.6688, Learning Rate: 8.05e-05
2025-12-09 04:48:11 - INFO - Epoch: 9.42, Step: 29860, Train Loss: 1.6418, Learning Rate: 8.05e-05
2025-12-09 04:48:22 - INFO - Epoch: 9.43, Step: 29870, Train Loss: 1.5824, Learning Rate: 8.05e-05
2025-12-09 04:48:33 - INFO - Epoch: 9.43, Step: 29880, Train Loss: 1.5967, Learning Rate: 8.05e-05
2025-12-09 04:48:44 - INFO - Epoch: 9.43, Step: 29890, Train Loss: 1.6164, Learning Rate: 8.04e-05
2025-12-09 04:48:56 - INFO - Epoch: 9.44, Step: 29900, Train Loss: 1.6253, Learning Rate: 8.04e-05
2025-12-09 04:49:07 - INFO - Epoch: 9.44, Step: 29910, Train Loss: 1.6203, Learning Rate: 8.04e-05
2025-12-09 04:49:18 - INFO - Epoch: 9.44, Step: 29920, Train Loss: 1.6568, Learning Rate: 8.04e-05
2025-12-09 04:49:29 - INFO - Epoch: 9.44, Step: 29930, Train Loss: 1.6406, Learning Rate: 8.04e-05
2025-12-09 04:49:40 - INFO - Epoch: 9.45, Step: 29940, Train Loss: 1.6363, Learning Rate: 8.04e-05
2025-12-09 04:49:51 - INFO - Epoch: 9.45, Step: 29950, Train Loss: 1.6135, Learning Rate: 8.04e-05
2025-12-09 04:50:02 - INFO - Epoch: 9.45, Step: 29960, Train Loss: 1.6311, Learning Rate: 8.04e-05
2025-12-09 04:50:13 - INFO - Epoch: 9.46, Step: 29970, Train Loss: 1.6357, Learning Rate: 8.04e-05
2025-12-09 04:50:24 - INFO - Epoch: 9.46, Step: 29980, Train Loss: 1.6613, Learning Rate: 8.04e-05
2025-12-09 04:50:35 - INFO - Epoch: 9.46, Step: 29990, Train Loss: 1.6322, Learning Rate: 8.04e-05
2025-12-09 04:50:46 - INFO - Epoch: 9.47, Step: 30000, Train Loss: 1.6209, Learning Rate: 8.04e-05
2025-12-09 04:50:57 - INFO - Epoch: 9.47, Step: 30010, Train Loss: 1.6861, Learning Rate: 8.03e-05
2025-12-09 04:51:09 - INFO - Epoch: 9.47, Step: 30020, Train Loss: 1.6127, Learning Rate: 8.03e-05
2025-12-09 04:51:20 - INFO - Epoch: 9.48, Step: 30030, Train Loss: 1.6382, Learning Rate: 8.03e-05
2025-12-09 04:51:31 - INFO - Epoch: 9.48, Step: 30040, Train Loss: 1.6151, Learning Rate: 8.03e-05
2025-12-09 04:51:42 - INFO - Epoch: 9.48, Step: 30050, Train Loss: 1.6033, Learning Rate: 8.03e-05
2025-12-09 04:51:53 - INFO - Epoch: 9.49, Step: 30060, Train Loss: 1.6487, Learning Rate: 8.03e-05
2025-12-09 04:52:04 - INFO - Epoch: 9.49, Step: 30070, Train Loss: 1.6327, Learning Rate: 8.03e-05
2025-12-09 04:52:15 - INFO - Epoch: 9.49, Step: 30080, Train Loss: 1.6210, Learning Rate: 8.03e-05
2025-12-09 04:52:26 - INFO - Epoch: 9.50, Step: 30090, Train Loss: 1.6399, Learning Rate: 8.03e-05
2025-12-09 04:52:37 - INFO - Epoch: 9.50, Step: 30100, Train Loss: 1.6118, Learning Rate: 8.03e-05
2025-12-09 04:52:48 - INFO - Epoch: 9.50, Step: 30110, Train Loss: 1.6192, Learning Rate: 8.03e-05
2025-12-09 04:52:59 - INFO - Epoch: 9.50, Step: 30120, Train Loss: 1.6080, Learning Rate: 8.03e-05
2025-12-09 04:53:10 - INFO - Epoch: 9.51, Step: 30130, Train Loss: 1.6317, Learning Rate: 8.02e-05
2025-12-09 04:53:22 - INFO - Epoch: 9.51, Step: 30140, Train Loss: 1.6537, Learning Rate: 8.02e-05
2025-12-09 04:53:33 - INFO - Epoch: 9.51, Step: 30150, Train Loss: 1.6165, Learning Rate: 8.02e-05
2025-12-09 04:53:44 - INFO - Epoch: 9.52, Step: 30160, Train Loss: 1.6250, Learning Rate: 8.02e-05
2025-12-09 04:53:55 - INFO - Epoch: 9.52, Step: 30170, Train Loss: 1.6202, Learning Rate: 8.02e-05
2025-12-09 04:54:06 - INFO - Epoch: 9.52, Step: 30180, Train Loss: 1.6451, Learning Rate: 8.02e-05
2025-12-09 04:54:17 - INFO - Epoch: 9.53, Step: 30190, Train Loss: 1.6283, Learning Rate: 8.02e-05
2025-12-09 04:54:28 - INFO - Epoch: 9.53, Step: 30200, Train Loss: 1.6509, Learning Rate: 8.02e-05
2025-12-09 04:54:39 - INFO - Epoch: 9.53, Step: 30210, Train Loss: 1.6123, Learning Rate: 8.02e-05
2025-12-09 04:54:50 - INFO - Epoch: 9.54, Step: 30220, Train Loss: 1.6476, Learning Rate: 8.02e-05
2025-12-09 04:55:01 - INFO - Epoch: 9.54, Step: 30230, Train Loss: 1.6250, Learning Rate: 8.02e-05
2025-12-09 04:55:12 - INFO - Epoch: 9.54, Step: 30240, Train Loss: 1.6282, Learning Rate: 8.02e-05
2025-12-09 04:55:23 - INFO - Epoch: 9.55, Step: 30250, Train Loss: 1.6036, Learning Rate: 8.01e-05
2025-12-09 04:55:35 - INFO - Epoch: 9.55, Step: 30260, Train Loss: 1.6528, Learning Rate: 8.01e-05
2025-12-09 04:55:46 - INFO - Epoch: 9.55, Step: 30270, Train Loss: 1.6271, Learning Rate: 8.01e-05
2025-12-09 04:55:57 - INFO - Epoch: 9.56, Step: 30280, Train Loss: 1.6331, Learning Rate: 8.01e-05
2025-12-09 04:56:08 - INFO - Epoch: 9.56, Step: 30290, Train Loss: 1.5773, Learning Rate: 8.01e-05
2025-12-09 04:56:19 - INFO - Epoch: 9.56, Step: 30300, Train Loss: 1.6757, Learning Rate: 8.01e-05
2025-12-09 04:56:30 - INFO - Epoch: 9.56, Step: 30310, Train Loss: 1.6238, Learning Rate: 8.01e-05
2025-12-09 04:56:41 - INFO - Epoch: 9.57, Step: 30320, Train Loss: 1.6516, Learning Rate: 8.01e-05
2025-12-09 04:56:52 - INFO - Epoch: 9.57, Step: 30330, Train Loss: 1.6024, Learning Rate: 8.01e-05
2025-12-09 04:57:03 - INFO - Epoch: 9.57, Step: 30340, Train Loss: 1.6222, Learning Rate: 8.01e-05
2025-12-09 04:57:14 - INFO - Epoch: 9.58, Step: 30350, Train Loss: 1.6482, Learning Rate: 8.01e-05
2025-12-09 04:57:25 - INFO - Epoch: 9.58, Step: 30360, Train Loss: 1.5967, Learning Rate: 8.01e-05
2025-12-09 04:57:36 - INFO - Epoch: 9.58, Step: 30370, Train Loss: 1.6261, Learning Rate: 8.00e-05
2025-12-09 04:57:47 - INFO - Epoch: 9.59, Step: 30380, Train Loss: 1.6625, Learning Rate: 8.00e-05
2025-12-09 04:57:59 - INFO - Epoch: 9.59, Step: 30390, Train Loss: 1.6388, Learning Rate: 8.00e-05
2025-12-09 04:58:10 - INFO - Epoch: 9.59, Step: 30400, Train Loss: 1.6433, Learning Rate: 8.00e-05
2025-12-09 04:58:21 - INFO - Epoch: 9.60, Step: 30410, Train Loss: 1.6197, Learning Rate: 8.00e-05
2025-12-09 04:58:32 - INFO - Epoch: 9.60, Step: 30420, Train Loss: 1.6292, Learning Rate: 8.00e-05
2025-12-09 04:58:43 - INFO - Epoch: 9.60, Step: 30430, Train Loss: 1.6080, Learning Rate: 8.00e-05
2025-12-09 04:58:54 - INFO - Epoch: 9.61, Step: 30440, Train Loss: 1.6141, Learning Rate: 8.00e-05
2025-12-09 04:59:05 - INFO - Epoch: 9.61, Step: 30450, Train Loss: 1.6444, Learning Rate: 8.00e-05
2025-12-09 04:59:16 - INFO - Epoch: 9.61, Step: 30460, Train Loss: 1.6349, Learning Rate: 8.00e-05
2025-12-09 04:59:27 - INFO - Epoch: 9.62, Step: 30470, Train Loss: 1.5930, Learning Rate: 8.00e-05
2025-12-09 04:59:38 - INFO - Epoch: 9.62, Step: 30480, Train Loss: 1.6233, Learning Rate: 8.00e-05
2025-12-09 04:59:49 - INFO - Epoch: 9.62, Step: 30490, Train Loss: 1.6001, Learning Rate: 7.99e-05
2025-12-09 05:00:00 - INFO - Epoch: 9.62, Step: 30500, Train Loss: 1.6058, Learning Rate: 7.99e-05
2025-12-09 05:00:12 - INFO - Epoch: 9.63, Step: 30510, Train Loss: 1.6370, Learning Rate: 7.99e-05
2025-12-09 05:00:23 - INFO - Epoch: 9.63, Step: 30520, Train Loss: 1.6093, Learning Rate: 7.99e-05
2025-12-09 05:00:34 - INFO - Epoch: 9.63, Step: 30530, Train Loss: 1.6478, Learning Rate: 7.99e-05
2025-12-09 05:00:45 - INFO - Epoch: 9.64, Step: 30540, Train Loss: 1.6029, Learning Rate: 7.99e-05
2025-12-09 05:00:56 - INFO - Epoch: 9.64, Step: 30550, Train Loss: 1.5852, Learning Rate: 7.99e-05
2025-12-09 05:01:07 - INFO - Epoch: 9.64, Step: 30560, Train Loss: 1.6337, Learning Rate: 7.99e-05
2025-12-09 05:01:18 - INFO - Epoch: 9.65, Step: 30570, Train Loss: 1.6113, Learning Rate: 7.99e-05
2025-12-09 05:01:29 - INFO - Epoch: 9.65, Step: 30580, Train Loss: 1.6423, Learning Rate: 7.99e-05
2025-12-09 05:01:40 - INFO - Epoch: 9.65, Step: 30590, Train Loss: 1.6244, Learning Rate: 7.99e-05
2025-12-09 05:01:51 - INFO - Epoch: 9.66, Step: 30600, Train Loss: 1.6386, Learning Rate: 7.99e-05
2025-12-09 05:02:02 - INFO - Epoch: 9.66, Step: 30610, Train Loss: 1.6103, Learning Rate: 7.98e-05
2025-12-09 05:02:13 - INFO - Epoch: 9.66, Step: 30620, Train Loss: 1.5544, Learning Rate: 7.98e-05
2025-12-09 05:02:25 - INFO - Epoch: 9.67, Step: 30630, Train Loss: 1.6429, Learning Rate: 7.98e-05
2025-12-09 05:02:36 - INFO - Epoch: 9.67, Step: 30640, Train Loss: 1.6352, Learning Rate: 7.98e-05
2025-12-09 05:02:47 - INFO - Epoch: 9.67, Step: 30650, Train Loss: 1.6316, Learning Rate: 7.98e-05
2025-12-09 05:02:58 - INFO - Epoch: 9.67, Step: 30660, Train Loss: 1.6299, Learning Rate: 7.98e-05
2025-12-09 05:03:09 - INFO - Epoch: 9.68, Step: 30670, Train Loss: 1.6521, Learning Rate: 7.98e-05
2025-12-09 05:03:20 - INFO - Epoch: 9.68, Step: 30680, Train Loss: 1.6054, Learning Rate: 7.98e-05
2025-12-09 05:03:31 - INFO - Epoch: 9.68, Step: 30690, Train Loss: 1.6499, Learning Rate: 7.98e-05
2025-12-09 05:03:42 - INFO - Epoch: 9.69, Step: 30700, Train Loss: 1.6234, Learning Rate: 7.98e-05
2025-12-09 05:03:53 - INFO - Epoch: 9.69, Step: 30710, Train Loss: 1.5857, Learning Rate: 7.98e-05
2025-12-09 05:04:04 - INFO - Epoch: 9.69, Step: 30720, Train Loss: 1.6203, Learning Rate: 7.98e-05
2025-12-09 05:04:15 - INFO - Epoch: 9.70, Step: 30730, Train Loss: 1.6254, Learning Rate: 7.97e-05
2025-12-09 05:04:26 - INFO - Epoch: 9.70, Step: 30740, Train Loss: 1.6336, Learning Rate: 7.97e-05
2025-12-09 05:04:38 - INFO - Epoch: 9.70, Step: 30750, Train Loss: 1.6441, Learning Rate: 7.97e-05
2025-12-09 05:04:49 - INFO - Epoch: 9.71, Step: 30760, Train Loss: 1.5960, Learning Rate: 7.97e-05
2025-12-09 05:05:00 - INFO - Epoch: 9.71, Step: 30770, Train Loss: 1.5971, Learning Rate: 7.97e-05
2025-12-09 05:05:11 - INFO - Epoch: 9.71, Step: 30780, Train Loss: 1.5924, Learning Rate: 7.97e-05
2025-12-09 05:05:22 - INFO - Epoch: 9.72, Step: 30790, Train Loss: 1.6115, Learning Rate: 7.97e-05
2025-12-09 05:05:33 - INFO - Epoch: 9.72, Step: 30800, Train Loss: 1.5779, Learning Rate: 7.97e-05
2025-12-09 05:05:44 - INFO - Epoch: 9.72, Step: 30810, Train Loss: 1.6337, Learning Rate: 7.97e-05
2025-12-09 05:05:55 - INFO - Epoch: 9.73, Step: 30820, Train Loss: 1.6311, Learning Rate: 7.97e-05
2025-12-09 05:06:06 - INFO - Epoch: 9.73, Step: 30830, Train Loss: 1.6411, Learning Rate: 7.97e-05
2025-12-09 05:06:17 - INFO - Epoch: 9.73, Step: 30840, Train Loss: 1.6233, Learning Rate: 7.97e-05
2025-12-09 05:06:28 - INFO - Epoch: 9.73, Step: 30850, Train Loss: 1.6594, Learning Rate: 7.96e-05
2025-12-09 05:06:39 - INFO - Epoch: 9.74, Step: 30860, Train Loss: 1.6058, Learning Rate: 7.96e-05
2025-12-09 05:06:50 - INFO - Epoch: 9.74, Step: 30870, Train Loss: 1.6526, Learning Rate: 7.96e-05
2025-12-09 05:07:02 - INFO - Epoch: 9.74, Step: 30880, Train Loss: 1.6247, Learning Rate: 7.96e-05
2025-12-09 05:07:13 - INFO - Epoch: 9.75, Step: 30890, Train Loss: 1.5771, Learning Rate: 7.96e-05
2025-12-09 05:07:24 - INFO - Epoch: 9.75, Step: 30900, Train Loss: 1.5799, Learning Rate: 7.96e-05
2025-12-09 05:07:35 - INFO - Epoch: 9.75, Step: 30910, Train Loss: 1.6227, Learning Rate: 7.96e-05
2025-12-09 05:07:46 - INFO - Epoch: 9.76, Step: 30920, Train Loss: 1.5899, Learning Rate: 7.96e-05
2025-12-09 05:07:57 - INFO - Epoch: 9.76, Step: 30930, Train Loss: 1.6015, Learning Rate: 7.96e-05
2025-12-09 05:08:08 - INFO - Epoch: 9.76, Step: 30940, Train Loss: 1.6044, Learning Rate: 7.96e-05
2025-12-09 05:08:19 - INFO - Epoch: 9.77, Step: 30950, Train Loss: 1.5576, Learning Rate: 7.96e-05
2025-12-09 05:08:30 - INFO - Epoch: 9.77, Step: 30960, Train Loss: 1.6303, Learning Rate: 7.96e-05
2025-12-09 05:08:41 - INFO - Epoch: 9.77, Step: 30970, Train Loss: 1.6044, Learning Rate: 7.95e-05
2025-12-09 05:08:52 - INFO - Epoch: 9.78, Step: 30980, Train Loss: 1.6143, Learning Rate: 7.95e-05
2025-12-09 05:09:03 - INFO - Epoch: 9.78, Step: 30990, Train Loss: 1.6197, Learning Rate: 7.95e-05
2025-12-09 05:09:15 - INFO - Epoch: 9.78, Step: 31000, Train Loss: 1.6053, Learning Rate: 7.95e-05
2025-12-09 05:09:26 - INFO - Epoch: 9.79, Step: 31010, Train Loss: 1.5772, Learning Rate: 7.95e-05
2025-12-09 05:09:37 - INFO - Epoch: 9.79, Step: 31020, Train Loss: 1.5815, Learning Rate: 7.95e-05
2025-12-09 05:09:48 - INFO - Epoch: 9.79, Step: 31030, Train Loss: 1.6226, Learning Rate: 7.95e-05
2025-12-09 05:09:59 - INFO - Epoch: 9.79, Step: 31040, Train Loss: 1.6056, Learning Rate: 7.95e-05
2025-12-09 05:10:10 - INFO - Epoch: 9.80, Step: 31050, Train Loss: 1.6027, Learning Rate: 7.95e-05
2025-12-09 05:10:21 - INFO - Epoch: 9.80, Step: 31060, Train Loss: 1.5833, Learning Rate: 7.95e-05
2025-12-09 05:10:32 - INFO - Epoch: 9.80, Step: 31070, Train Loss: 1.6029, Learning Rate: 7.95e-05
2025-12-09 05:10:43 - INFO - Epoch: 9.81, Step: 31080, Train Loss: 1.6244, Learning Rate: 7.95e-05
2025-12-09 05:10:54 - INFO - Epoch: 9.81, Step: 31090, Train Loss: 1.6114, Learning Rate: 7.94e-05
2025-12-09 05:11:05 - INFO - Epoch: 9.81, Step: 31100, Train Loss: 1.6017, Learning Rate: 7.94e-05
2025-12-09 05:11:16 - INFO - Epoch: 9.82, Step: 31110, Train Loss: 1.6223, Learning Rate: 7.94e-05
2025-12-09 05:11:28 - INFO - Epoch: 9.82, Step: 31120, Train Loss: 1.6117, Learning Rate: 7.94e-05
2025-12-09 05:11:39 - INFO - Epoch: 9.82, Step: 31130, Train Loss: 1.5972, Learning Rate: 7.94e-05
2025-12-09 05:11:50 - INFO - Epoch: 9.83, Step: 31140, Train Loss: 1.6120, Learning Rate: 7.94e-05
2025-12-09 05:12:01 - INFO - Epoch: 9.83, Step: 31150, Train Loss: 1.6174, Learning Rate: 7.94e-05
2025-12-09 05:12:12 - INFO - Epoch: 9.83, Step: 31160, Train Loss: 1.5727, Learning Rate: 7.94e-05
2025-12-09 05:12:23 - INFO - Epoch: 9.84, Step: 31170, Train Loss: 1.6449, Learning Rate: 7.94e-05
2025-12-09 05:12:34 - INFO - Epoch: 9.84, Step: 31180, Train Loss: 1.5762, Learning Rate: 7.94e-05
2025-12-09 05:12:45 - INFO - Epoch: 9.84, Step: 31190, Train Loss: 1.5962, Learning Rate: 7.94e-05
2025-12-09 05:12:56 - INFO - Epoch: 9.85, Step: 31200, Train Loss: 1.6311, Learning Rate: 7.94e-05
2025-12-09 05:13:07 - INFO - Epoch: 9.85, Step: 31210, Train Loss: 1.6294, Learning Rate: 7.93e-05
2025-12-09 05:13:18 - INFO - Epoch: 9.85, Step: 31220, Train Loss: 1.6093, Learning Rate: 7.93e-05
2025-12-09 05:13:29 - INFO - Epoch: 9.85, Step: 31230, Train Loss: 1.6123, Learning Rate: 7.93e-05
2025-12-09 05:13:41 - INFO - Epoch: 9.86, Step: 31240, Train Loss: 1.6382, Learning Rate: 7.93e-05
2025-12-09 05:13:52 - INFO - Epoch: 9.86, Step: 31250, Train Loss: 1.6055, Learning Rate: 7.93e-05
2025-12-09 05:14:03 - INFO - Epoch: 9.86, Step: 31260, Train Loss: 1.6053, Learning Rate: 7.93e-05
2025-12-09 05:14:14 - INFO - Epoch: 9.87, Step: 31270, Train Loss: 1.6182, Learning Rate: 7.93e-05
2025-12-09 05:14:25 - INFO - Epoch: 9.87, Step: 31280, Train Loss: 1.6167, Learning Rate: 7.93e-05
2025-12-09 05:14:36 - INFO - Epoch: 9.87, Step: 31290, Train Loss: 1.5692, Learning Rate: 7.93e-05
2025-12-09 05:14:47 - INFO - Epoch: 9.88, Step: 31300, Train Loss: 1.6096, Learning Rate: 7.93e-05
2025-12-09 05:14:58 - INFO - Epoch: 9.88, Step: 31310, Train Loss: 1.6124, Learning Rate: 7.93e-05
2025-12-09 05:15:09 - INFO - Epoch: 9.88, Step: 31320, Train Loss: 1.5919, Learning Rate: 7.93e-05
2025-12-09 05:15:20 - INFO - Epoch: 9.89, Step: 31330, Train Loss: 1.6214, Learning Rate: 7.92e-05
2025-12-09 05:15:31 - INFO - Epoch: 9.89, Step: 31340, Train Loss: 1.5780, Learning Rate: 7.92e-05
2025-12-09 05:15:42 - INFO - Epoch: 9.89, Step: 31350, Train Loss: 1.6479, Learning Rate: 7.92e-05
2025-12-09 05:15:54 - INFO - Epoch: 9.90, Step: 31360, Train Loss: 1.6010, Learning Rate: 7.92e-05
2025-12-09 05:16:05 - INFO - Epoch: 9.90, Step: 31370, Train Loss: 1.6429, Learning Rate: 7.92e-05
2025-12-09 05:16:16 - INFO - Epoch: 9.90, Step: 31380, Train Loss: 1.6336, Learning Rate: 7.92e-05
2025-12-09 05:16:27 - INFO - Epoch: 9.91, Step: 31390, Train Loss: 1.6103, Learning Rate: 7.92e-05
2025-12-09 05:16:38 - INFO - Epoch: 9.91, Step: 31400, Train Loss: 1.6179, Learning Rate: 7.92e-05
2025-12-09 05:16:49 - INFO - Epoch: 9.91, Step: 31410, Train Loss: 1.6082, Learning Rate: 7.92e-05
2025-12-09 05:17:00 - INFO - Epoch: 9.91, Step: 31420, Train Loss: 1.6043, Learning Rate: 7.92e-05
2025-12-09 05:17:11 - INFO - Epoch: 9.92, Step: 31430, Train Loss: 1.5916, Learning Rate: 7.92e-05
2025-12-09 05:17:22 - INFO - Epoch: 9.92, Step: 31440, Train Loss: 1.5993, Learning Rate: 7.92e-05
2025-12-09 05:17:33 - INFO - Epoch: 9.92, Step: 31450, Train Loss: 1.6384, Learning Rate: 7.91e-05
2025-12-09 05:17:44 - INFO - Epoch: 9.93, Step: 31460, Train Loss: 1.6168, Learning Rate: 7.91e-05
2025-12-09 05:17:55 - INFO - Epoch: 9.93, Step: 31470, Train Loss: 1.5714, Learning Rate: 7.91e-05
2025-12-09 05:18:06 - INFO - Epoch: 9.93, Step: 31480, Train Loss: 1.6039, Learning Rate: 7.91e-05
2025-12-09 05:18:18 - INFO - Epoch: 9.94, Step: 31490, Train Loss: 1.5844, Learning Rate: 7.91e-05
2025-12-09 05:18:29 - INFO - Epoch: 9.94, Step: 31500, Train Loss: 1.5783, Learning Rate: 7.91e-05
2025-12-09 05:18:40 - INFO - Epoch: 9.94, Step: 31510, Train Loss: 1.6050, Learning Rate: 7.91e-05
2025-12-09 05:18:51 - INFO - Epoch: 9.95, Step: 31520, Train Loss: 1.5999, Learning Rate: 7.91e-05
2025-12-09 05:19:02 - INFO - Epoch: 9.95, Step: 31530, Train Loss: 1.6083, Learning Rate: 7.91e-05
2025-12-09 05:19:13 - INFO - Epoch: 9.95, Step: 31540, Train Loss: 1.5972, Learning Rate: 7.91e-05
2025-12-09 05:19:24 - INFO - Epoch: 9.96, Step: 31550, Train Loss: 1.6298, Learning Rate: 7.91e-05
2025-12-09 05:19:35 - INFO - Epoch: 9.96, Step: 31560, Train Loss: 1.6345, Learning Rate: 7.91e-05
2025-12-09 05:19:46 - INFO - Epoch: 9.96, Step: 31570, Train Loss: 1.5714, Learning Rate: 7.90e-05
2025-12-09 05:19:57 - INFO - Epoch: 9.97, Step: 31580, Train Loss: 1.6405, Learning Rate: 7.90e-05
2025-12-09 05:20:08 - INFO - Epoch: 9.97, Step: 31590, Train Loss: 1.5851, Learning Rate: 7.90e-05
2025-12-09 05:20:19 - INFO - Epoch: 9.97, Step: 31600, Train Loss: 1.5846, Learning Rate: 7.90e-05
2025-12-09 05:20:31 - INFO - Epoch: 9.97, Step: 31610, Train Loss: 1.6354, Learning Rate: 7.90e-05
2025-12-09 05:20:42 - INFO - Epoch: 9.98, Step: 31620, Train Loss: 1.5881, Learning Rate: 7.90e-05
2025-12-09 05:20:53 - INFO - Epoch: 9.98, Step: 31630, Train Loss: 1.5888, Learning Rate: 7.90e-05
2025-12-09 05:21:04 - INFO - Epoch: 9.98, Step: 31640, Train Loss: 1.5857, Learning Rate: 7.90e-05
2025-12-09 05:21:15 - INFO - Epoch: 9.99, Step: 31650, Train Loss: 1.6429, Learning Rate: 7.90e-05
2025-12-09 05:21:26 - INFO - Epoch: 9.99, Step: 31660, Train Loss: 1.6093, Learning Rate: 7.90e-05
2025-12-09 05:21:37 - INFO - Epoch: 9.99, Step: 31670, Train Loss: 1.5964, Learning Rate: 7.90e-05
2025-12-09 05:21:48 - INFO - Epoch: 10.00, Step: 31680, Train Loss: 1.5739, Learning Rate: 7.90e-05
2025-12-09 05:21:59 - INFO - Epoch: 10.00, Step: 31690, Train Loss: 1.6176, Learning Rate: 7.89e-05
2025-12-09 05:22:10 - INFO - Epoch: 10.00, Step: 31700, Train Loss: 1.5637, Learning Rate: 7.89e-05
2025-12-09 05:22:21 - INFO - Epoch: 10.01, Step: 31710, Train Loss: 1.6193, Learning Rate: 7.89e-05
2025-12-09 05:22:32 - INFO - Epoch: 10.01, Step: 31720, Train Loss: 1.6304, Learning Rate: 7.89e-05
2025-12-09 05:22:44 - INFO - Epoch: 10.01, Step: 31730, Train Loss: 1.6065, Learning Rate: 7.89e-05
2025-12-09 05:22:55 - INFO - Epoch: 10.02, Step: 31740, Train Loss: 1.6013, Learning Rate: 7.89e-05
2025-12-09 05:23:06 - INFO - Epoch: 10.02, Step: 31750, Train Loss: 1.5997, Learning Rate: 7.89e-05
2025-12-09 05:23:17 - INFO - Epoch: 10.02, Step: 31760, Train Loss: 1.5837, Learning Rate: 7.89e-05
2025-12-09 05:23:28 - INFO - Epoch: 10.03, Step: 31770, Train Loss: 1.5601, Learning Rate: 7.89e-05
2025-12-09 05:23:39 - INFO - Epoch: 10.03, Step: 31780, Train Loss: 1.5769, Learning Rate: 7.89e-05
2025-12-09 05:23:50 - INFO - Epoch: 10.03, Step: 31790, Train Loss: 1.5915, Learning Rate: 7.89e-05
2025-12-09 05:24:01 - INFO - Epoch: 10.03, Step: 31800, Train Loss: 1.5879, Learning Rate: 7.89e-05
2025-12-09 05:24:12 - INFO - Epoch: 10.04, Step: 31810, Train Loss: 1.5318, Learning Rate: 7.88e-05
2025-12-09 05:24:23 - INFO - Epoch: 10.04, Step: 31820, Train Loss: 1.6151, Learning Rate: 7.88e-05
2025-12-09 05:24:34 - INFO - Epoch: 10.04, Step: 31830, Train Loss: 1.5937, Learning Rate: 7.88e-05
2025-12-09 05:24:45 - INFO - Epoch: 10.05, Step: 31840, Train Loss: 1.5596, Learning Rate: 7.88e-05
2025-12-09 05:24:57 - INFO - Epoch: 10.05, Step: 31850, Train Loss: 1.5962, Learning Rate: 7.88e-05
2025-12-09 05:25:08 - INFO - Epoch: 10.05, Step: 31860, Train Loss: 1.5413, Learning Rate: 7.88e-05
2025-12-09 05:25:19 - INFO - Epoch: 10.06, Step: 31870, Train Loss: 1.5895, Learning Rate: 7.88e-05
2025-12-09 05:25:30 - INFO - Epoch: 10.06, Step: 31880, Train Loss: 1.5609, Learning Rate: 7.88e-05
2025-12-09 05:25:41 - INFO - Epoch: 10.06, Step: 31890, Train Loss: 1.5766, Learning Rate: 7.88e-05
2025-12-09 05:25:52 - INFO - Epoch: 10.07, Step: 31900, Train Loss: 1.5713, Learning Rate: 7.88e-05
2025-12-09 05:26:03 - INFO - Epoch: 10.07, Step: 31910, Train Loss: 1.5783, Learning Rate: 7.88e-05
2025-12-09 05:26:14 - INFO - Epoch: 10.07, Step: 31920, Train Loss: 1.5496, Learning Rate: 7.88e-05
2025-12-09 05:26:25 - INFO - Epoch: 10.08, Step: 31930, Train Loss: 1.5748, Learning Rate: 7.87e-05
2025-12-09 05:26:36 - INFO - Epoch: 10.08, Step: 31940, Train Loss: 1.5849, Learning Rate: 7.87e-05
2025-12-09 05:26:47 - INFO - Epoch: 10.08, Step: 31950, Train Loss: 1.6067, Learning Rate: 7.87e-05
2025-12-09 05:26:58 - INFO - Epoch: 10.09, Step: 31960, Train Loss: 1.5657, Learning Rate: 7.87e-05
2025-12-09 05:27:10 - INFO - Epoch: 10.09, Step: 31970, Train Loss: 1.6047, Learning Rate: 7.87e-05
2025-12-09 05:27:21 - INFO - Epoch: 10.09, Step: 31980, Train Loss: 1.5610, Learning Rate: 7.87e-05
2025-12-09 05:27:32 - INFO - Epoch: 10.09, Step: 31990, Train Loss: 1.5810, Learning Rate: 7.87e-05
2025-12-09 05:27:43 - INFO - Epoch: 10.10, Step: 32000, Train Loss: 1.5917, Learning Rate: 7.87e-05
2025-12-09 05:27:54 - INFO - Epoch: 10.10, Step: 32010, Train Loss: 1.6157, Learning Rate: 7.87e-05
2025-12-09 05:28:05 - INFO - Epoch: 10.10, Step: 32020, Train Loss: 1.6045, Learning Rate: 7.87e-05
2025-12-09 05:28:16 - INFO - Epoch: 10.11, Step: 32030, Train Loss: 1.5661, Learning Rate: 7.87e-05
2025-12-09 05:28:27 - INFO - Epoch: 10.11, Step: 32040, Train Loss: 1.5764, Learning Rate: 7.87e-05
2025-12-09 05:28:38 - INFO - Epoch: 10.11, Step: 32050, Train Loss: 1.5581, Learning Rate: 7.86e-05
2025-12-09 05:28:49 - INFO - Epoch: 10.12, Step: 32060, Train Loss: 1.5221, Learning Rate: 7.86e-05
2025-12-09 05:29:00 - INFO - Epoch: 10.12, Step: 32070, Train Loss: 1.5784, Learning Rate: 7.86e-05
2025-12-09 05:29:11 - INFO - Epoch: 10.12, Step: 32080, Train Loss: 1.5978, Learning Rate: 7.86e-05
2025-12-09 05:29:22 - INFO - Epoch: 10.13, Step: 32090, Train Loss: 1.5569, Learning Rate: 7.86e-05
2025-12-09 05:29:34 - INFO - Epoch: 10.13, Step: 32100, Train Loss: 1.5871, Learning Rate: 7.86e-05
2025-12-09 05:29:45 - INFO - Epoch: 10.13, Step: 32110, Train Loss: 1.5833, Learning Rate: 7.86e-05
2025-12-09 05:29:56 - INFO - Epoch: 10.14, Step: 32120, Train Loss: 1.5817, Learning Rate: 7.86e-05
2025-12-09 05:30:07 - INFO - Epoch: 10.14, Step: 32130, Train Loss: 1.5653, Learning Rate: 7.86e-05
2025-12-09 05:30:18 - INFO - Epoch: 10.14, Step: 32140, Train Loss: 1.5858, Learning Rate: 7.86e-05
2025-12-09 05:30:29 - INFO - Epoch: 10.15, Step: 32150, Train Loss: 1.5895, Learning Rate: 7.86e-05
2025-12-09 05:30:40 - INFO - Epoch: 10.15, Step: 32160, Train Loss: 1.5865, Learning Rate: 7.86e-05
2025-12-09 05:30:51 - INFO - Epoch: 10.15, Step: 32170, Train Loss: 1.5778, Learning Rate: 7.85e-05
2025-12-09 05:31:02 - INFO - Epoch: 10.15, Step: 32180, Train Loss: 1.5795, Learning Rate: 7.85e-05
2025-12-09 05:31:13 - INFO - Epoch: 10.16, Step: 32190, Train Loss: 1.6232, Learning Rate: 7.85e-05
2025-12-09 05:31:24 - INFO - Epoch: 10.16, Step: 32200, Train Loss: 1.5772, Learning Rate: 7.85e-05
2025-12-09 05:31:35 - INFO - Epoch: 10.16, Step: 32210, Train Loss: 1.6039, Learning Rate: 7.85e-05
2025-12-09 05:31:47 - INFO - Epoch: 10.17, Step: 32220, Train Loss: 1.5980, Learning Rate: 7.85e-05
2025-12-09 05:31:58 - INFO - Epoch: 10.17, Step: 32230, Train Loss: 1.5840, Learning Rate: 7.85e-05
2025-12-09 05:32:09 - INFO - Epoch: 10.17, Step: 32240, Train Loss: 1.5761, Learning Rate: 7.85e-05
2025-12-09 05:32:20 - INFO - Epoch: 10.18, Step: 32250, Train Loss: 1.5760, Learning Rate: 7.85e-05
2025-12-09 05:32:31 - INFO - Epoch: 10.18, Step: 32260, Train Loss: 1.5665, Learning Rate: 7.85e-05
2025-12-09 05:32:42 - INFO - Epoch: 10.18, Step: 32270, Train Loss: 1.5976, Learning Rate: 7.85e-05
2025-12-09 05:32:53 - INFO - Epoch: 10.19, Step: 32280, Train Loss: 1.5814, Learning Rate: 7.85e-05
2025-12-09 05:33:04 - INFO - Epoch: 10.19, Step: 32290, Train Loss: 1.5887, Learning Rate: 7.84e-05
2025-12-09 05:33:15 - INFO - Epoch: 10.19, Step: 32300, Train Loss: 1.5871, Learning Rate: 7.84e-05
2025-12-09 05:33:26 - INFO - Epoch: 10.20, Step: 32310, Train Loss: 1.6013, Learning Rate: 7.84e-05
2025-12-09 05:33:37 - INFO - Epoch: 10.20, Step: 32320, Train Loss: 1.5901, Learning Rate: 7.84e-05
2025-12-09 05:33:48 - INFO - Epoch: 10.20, Step: 32330, Train Loss: 1.5905, Learning Rate: 7.84e-05
2025-12-09 05:34:00 - INFO - Epoch: 10.21, Step: 32340, Train Loss: 1.5763, Learning Rate: 7.84e-05
2025-12-09 05:34:11 - INFO - Epoch: 10.21, Step: 32350, Train Loss: 1.5757, Learning Rate: 7.84e-05
2025-12-09 05:34:22 - INFO - Epoch: 10.21, Step: 32360, Train Loss: 1.5794, Learning Rate: 7.84e-05
2025-12-09 05:34:33 - INFO - Epoch: 10.21, Step: 32370, Train Loss: 1.5507, Learning Rate: 7.84e-05
2025-12-09 05:34:44 - INFO - Epoch: 10.22, Step: 32380, Train Loss: 1.6431, Learning Rate: 7.84e-05
2025-12-09 05:34:55 - INFO - Epoch: 10.22, Step: 32390, Train Loss: 1.6382, Learning Rate: 7.84e-05
2025-12-09 05:35:06 - INFO - Epoch: 10.22, Step: 32400, Train Loss: 1.5691, Learning Rate: 7.84e-05
2025-12-09 05:35:17 - INFO - Epoch: 10.23, Step: 32410, Train Loss: 1.6187, Learning Rate: 7.84e-05
2025-12-09 05:35:28 - INFO - Epoch: 10.23, Step: 32420, Train Loss: 1.5192, Learning Rate: 7.83e-05
2025-12-09 05:35:39 - INFO - Epoch: 10.23, Step: 32430, Train Loss: 1.5706, Learning Rate: 7.83e-05
2025-12-09 05:35:50 - INFO - Epoch: 10.24, Step: 32440, Train Loss: 1.5742, Learning Rate: 7.83e-05
2025-12-09 05:36:01 - INFO - Epoch: 10.24, Step: 32450, Train Loss: 1.5830, Learning Rate: 7.83e-05
2025-12-09 05:36:13 - INFO - Epoch: 10.24, Step: 32460, Train Loss: 1.5713, Learning Rate: 7.83e-05
2025-12-09 05:36:24 - INFO - Epoch: 10.25, Step: 32470, Train Loss: 1.6038, Learning Rate: 7.83e-05
2025-12-09 05:36:35 - INFO - Epoch: 10.25, Step: 32480, Train Loss: 1.5541, Learning Rate: 7.83e-05
2025-12-09 05:36:46 - INFO - Epoch: 10.25, Step: 32490, Train Loss: 1.5637, Learning Rate: 7.83e-05
2025-12-09 05:36:57 - INFO - Epoch: 10.26, Step: 32500, Train Loss: 1.5718, Learning Rate: 7.83e-05
2025-12-09 05:37:08 - INFO - Epoch: 10.26, Step: 32510, Train Loss: 1.5462, Learning Rate: 7.83e-05
2025-12-09 05:37:19 - INFO - Epoch: 10.26, Step: 32520, Train Loss: 1.5896, Learning Rate: 7.83e-05
2025-12-09 05:37:30 - INFO - Epoch: 10.27, Step: 32530, Train Loss: 1.6061, Learning Rate: 7.83e-05
2025-12-09 05:37:41 - INFO - Epoch: 10.27, Step: 32540, Train Loss: 1.5541, Learning Rate: 7.82e-05
2025-12-09 05:37:52 - INFO - Epoch: 10.27, Step: 32550, Train Loss: 1.5765, Learning Rate: 7.82e-05
2025-12-09 05:38:03 - INFO - Epoch: 10.27, Step: 32560, Train Loss: 1.6165, Learning Rate: 7.82e-05
2025-12-09 05:38:14 - INFO - Epoch: 10.28, Step: 32570, Train Loss: 1.5622, Learning Rate: 7.82e-05
2025-12-09 05:38:26 - INFO - Epoch: 10.28, Step: 32580, Train Loss: 1.5710, Learning Rate: 7.82e-05
2025-12-09 05:38:37 - INFO - Epoch: 10.28, Step: 32590, Train Loss: 1.6002, Learning Rate: 7.82e-05
2025-12-09 05:38:48 - INFO - Epoch: 10.29, Step: 32600, Train Loss: 1.5675, Learning Rate: 7.82e-05
2025-12-09 05:38:59 - INFO - Epoch: 10.29, Step: 32610, Train Loss: 1.5717, Learning Rate: 7.82e-05
2025-12-09 05:39:10 - INFO - Epoch: 10.29, Step: 32620, Train Loss: 1.5473, Learning Rate: 7.82e-05
2025-12-09 05:39:21 - INFO - Epoch: 10.30, Step: 32630, Train Loss: 1.5643, Learning Rate: 7.82e-05
2025-12-09 05:39:32 - INFO - Epoch: 10.30, Step: 32640, Train Loss: 1.6055, Learning Rate: 7.82e-05
2025-12-09 05:39:43 - INFO - Epoch: 10.30, Step: 32650, Train Loss: 1.5561, Learning Rate: 7.82e-05
2025-12-09 05:39:54 - INFO - Epoch: 10.31, Step: 32660, Train Loss: 1.5814, Learning Rate: 7.81e-05
2025-12-09 05:40:05 - INFO - Epoch: 10.31, Step: 32670, Train Loss: 1.5907, Learning Rate: 7.81e-05
2025-12-09 05:40:16 - INFO - Epoch: 10.31, Step: 32680, Train Loss: 1.5954, Learning Rate: 7.81e-05
2025-12-09 05:40:27 - INFO - Epoch: 10.32, Step: 32690, Train Loss: 1.5772, Learning Rate: 7.81e-05
2025-12-09 05:40:39 - INFO - Epoch: 10.32, Step: 32700, Train Loss: 1.5617, Learning Rate: 7.81e-05
2025-12-09 05:40:50 - INFO - Epoch: 10.32, Step: 32710, Train Loss: 1.5721, Learning Rate: 7.81e-05
2025-12-09 05:41:01 - INFO - Epoch: 10.33, Step: 32720, Train Loss: 1.6076, Learning Rate: 7.81e-05
2025-12-09 05:41:12 - INFO - Epoch: 10.33, Step: 32730, Train Loss: 1.5879, Learning Rate: 7.81e-05
2025-12-09 05:41:23 - INFO - Epoch: 10.33, Step: 32740, Train Loss: 1.5782, Learning Rate: 7.81e-05
2025-12-09 05:41:34 - INFO - Epoch: 10.33, Step: 32750, Train Loss: 1.5882, Learning Rate: 7.81e-05
2025-12-09 05:41:45 - INFO - Epoch: 10.34, Step: 32760, Train Loss: 1.5335, Learning Rate: 7.81e-05
2025-12-09 05:41:56 - INFO - Epoch: 10.34, Step: 32770, Train Loss: 1.6028, Learning Rate: 7.81e-05
2025-12-09 05:42:07 - INFO - Epoch: 10.34, Step: 32780, Train Loss: 1.5480, Learning Rate: 7.80e-05
2025-12-09 05:42:18 - INFO - Epoch: 10.35, Step: 32790, Train Loss: 1.5619, Learning Rate: 7.80e-05
2025-12-09 05:42:29 - INFO - Epoch: 10.35, Step: 32800, Train Loss: 1.5298, Learning Rate: 7.80e-05
2025-12-09 05:42:40 - INFO - Epoch: 10.35, Step: 32810, Train Loss: 1.5440, Learning Rate: 7.80e-05
2025-12-09 05:42:51 - INFO - Epoch: 10.36, Step: 32820, Train Loss: 1.5497, Learning Rate: 7.80e-05
2025-12-09 05:43:03 - INFO - Epoch: 10.36, Step: 32830, Train Loss: 1.5629, Learning Rate: 7.80e-05
2025-12-09 05:43:14 - INFO - Epoch: 10.36, Step: 32840, Train Loss: 1.5526, Learning Rate: 7.80e-05
2025-12-09 05:43:25 - INFO - Epoch: 10.37, Step: 32850, Train Loss: 1.5967, Learning Rate: 7.80e-05
2025-12-09 05:43:36 - INFO - Epoch: 10.37, Step: 32860, Train Loss: 1.5686, Learning Rate: 7.80e-05
2025-12-09 05:43:47 - INFO - Epoch: 10.37, Step: 32870, Train Loss: 1.5656, Learning Rate: 7.80e-05
2025-12-09 05:43:58 - INFO - Epoch: 10.38, Step: 32880, Train Loss: 1.5616, Learning Rate: 7.80e-05
2025-12-09 05:44:09 - INFO - Epoch: 10.38, Step: 32890, Train Loss: 1.5532, Learning Rate: 7.80e-05
2025-12-09 05:44:20 - INFO - Epoch: 10.38, Step: 32900, Train Loss: 1.5792, Learning Rate: 7.79e-05
2025-12-09 05:44:31 - INFO - Epoch: 10.38, Step: 32910, Train Loss: 1.5508, Learning Rate: 7.79e-05
2025-12-09 05:44:42 - INFO - Epoch: 10.39, Step: 32920, Train Loss: 1.6163, Learning Rate: 7.79e-05
2025-12-09 05:44:53 - INFO - Epoch: 10.39, Step: 32930, Train Loss: 1.6122, Learning Rate: 7.79e-05
2025-12-09 05:45:04 - INFO - Epoch: 10.39, Step: 32940, Train Loss: 1.5696, Learning Rate: 7.79e-05
2025-12-09 05:45:16 - INFO - Epoch: 10.40, Step: 32950, Train Loss: 1.5893, Learning Rate: 7.79e-05
2025-12-09 05:45:27 - INFO - Epoch: 10.40, Step: 32960, Train Loss: 1.5826, Learning Rate: 7.79e-05
2025-12-09 05:45:38 - INFO - Epoch: 10.40, Step: 32970, Train Loss: 1.5683, Learning Rate: 7.79e-05
2025-12-09 05:45:49 - INFO - Epoch: 10.41, Step: 32980, Train Loss: 1.5971, Learning Rate: 7.79e-05
2025-12-09 05:46:00 - INFO - Epoch: 10.41, Step: 32990, Train Loss: 1.5816, Learning Rate: 7.79e-05
2025-12-09 05:46:11 - INFO - Epoch: 10.41, Step: 33000, Train Loss: 1.6153, Learning Rate: 7.79e-05
2025-12-09 05:46:22 - INFO - Epoch: 10.42, Step: 33010, Train Loss: 1.6293, Learning Rate: 7.79e-05
2025-12-09 05:46:33 - INFO - Epoch: 10.42, Step: 33020, Train Loss: 1.5702, Learning Rate: 7.78e-05
2025-12-09 05:46:44 - INFO - Epoch: 10.42, Step: 33030, Train Loss: 1.5832, Learning Rate: 7.78e-05
2025-12-09 05:46:55 - INFO - Epoch: 10.43, Step: 33040, Train Loss: 1.5966, Learning Rate: 7.78e-05
2025-12-09 05:47:06 - INFO - Epoch: 10.43, Step: 33050, Train Loss: 1.5766, Learning Rate: 7.78e-05
2025-12-09 05:47:17 - INFO - Epoch: 10.43, Step: 33060, Train Loss: 1.5944, Learning Rate: 7.78e-05
2025-12-09 05:47:29 - INFO - Epoch: 10.44, Step: 33070, Train Loss: 1.5784, Learning Rate: 7.78e-05
2025-12-09 05:47:40 - INFO - Epoch: 10.44, Step: 33080, Train Loss: 1.5444, Learning Rate: 7.78e-05
2025-12-09 05:47:51 - INFO - Epoch: 10.44, Step: 33090, Train Loss: 1.5958, Learning Rate: 7.78e-05
2025-12-09 05:48:02 - INFO - Epoch: 10.44, Step: 33100, Train Loss: 1.5988, Learning Rate: 7.78e-05
2025-12-09 05:48:13 - INFO - Epoch: 10.45, Step: 33110, Train Loss: 1.6094, Learning Rate: 7.78e-05
2025-12-09 05:48:24 - INFO - Epoch: 10.45, Step: 33120, Train Loss: 1.5458, Learning Rate: 7.78e-05
2025-12-09 05:48:35 - INFO - Epoch: 10.45, Step: 33130, Train Loss: 1.6122, Learning Rate: 7.78e-05
2025-12-09 05:48:46 - INFO - Epoch: 10.46, Step: 33140, Train Loss: 1.5948, Learning Rate: 7.77e-05
2025-12-09 05:48:57 - INFO - Epoch: 10.46, Step: 33150, Train Loss: 1.5870, Learning Rate: 7.77e-05
2025-12-09 05:49:08 - INFO - Epoch: 10.46, Step: 33160, Train Loss: 1.5901, Learning Rate: 7.77e-05
2025-12-09 05:49:19 - INFO - Epoch: 10.47, Step: 33170, Train Loss: 1.5635, Learning Rate: 7.77e-05
2025-12-09 05:49:30 - INFO - Epoch: 10.47, Step: 33180, Train Loss: 1.5820, Learning Rate: 7.77e-05
2025-12-09 05:49:42 - INFO - Epoch: 10.47, Step: 33190, Train Loss: 1.5836, Learning Rate: 7.77e-05
2025-12-09 05:49:53 - INFO - Epoch: 10.48, Step: 33200, Train Loss: 1.5638, Learning Rate: 7.77e-05
2025-12-09 05:50:04 - INFO - Epoch: 10.48, Step: 33210, Train Loss: 1.5581, Learning Rate: 7.77e-05
2025-12-09 05:50:15 - INFO - Epoch: 10.48, Step: 33220, Train Loss: 1.5880, Learning Rate: 7.77e-05
2025-12-09 05:50:26 - INFO - Epoch: 10.49, Step: 33230, Train Loss: 1.5107, Learning Rate: 7.77e-05
2025-12-09 05:50:37 - INFO - Epoch: 10.49, Step: 33240, Train Loss: 1.5704, Learning Rate: 7.77e-05
2025-12-09 05:50:48 - INFO - Epoch: 10.49, Step: 33250, Train Loss: 1.5827, Learning Rate: 7.77e-05
2025-12-09 05:50:59 - INFO - Epoch: 10.50, Step: 33260, Train Loss: 1.5751, Learning Rate: 7.76e-05
2025-12-09 05:51:10 - INFO - Epoch: 10.50, Step: 33270, Train Loss: 1.5949, Learning Rate: 7.76e-05
2025-12-09 05:51:21 - INFO - Epoch: 10.50, Step: 33280, Train Loss: 1.5727, Learning Rate: 7.76e-05
2025-12-09 05:51:32 - INFO - Epoch: 10.50, Step: 33290, Train Loss: 1.5734, Learning Rate: 7.76e-05
2025-12-09 05:51:43 - INFO - Epoch: 10.51, Step: 33300, Train Loss: 1.5494, Learning Rate: 7.76e-05
2025-12-09 05:51:55 - INFO - Epoch: 10.51, Step: 33310, Train Loss: 1.5804, Learning Rate: 7.76e-05
2025-12-09 05:52:06 - INFO - Epoch: 10.51, Step: 33320, Train Loss: 1.5727, Learning Rate: 7.76e-05
2025-12-09 05:52:17 - INFO - Epoch: 10.52, Step: 33330, Train Loss: 1.5563, Learning Rate: 7.76e-05
2025-12-09 05:52:28 - INFO - Epoch: 10.52, Step: 33340, Train Loss: 1.5799, Learning Rate: 7.76e-05
2025-12-09 05:52:39 - INFO - Epoch: 10.52, Step: 33350, Train Loss: 1.5433, Learning Rate: 7.76e-05
2025-12-09 05:52:50 - INFO - Epoch: 10.53, Step: 33360, Train Loss: 1.5300, Learning Rate: 7.76e-05
2025-12-09 05:53:01 - INFO - Epoch: 10.53, Step: 33370, Train Loss: 1.6067, Learning Rate: 7.76e-05
2025-12-09 05:53:12 - INFO - Epoch: 10.53, Step: 33380, Train Loss: 1.5522, Learning Rate: 7.75e-05
2025-12-09 05:53:23 - INFO - Epoch: 10.54, Step: 33390, Train Loss: 1.5942, Learning Rate: 7.75e-05
2025-12-09 05:53:34 - INFO - Epoch: 10.54, Step: 33400, Train Loss: 1.5754, Learning Rate: 7.75e-05
2025-12-09 05:53:45 - INFO - Epoch: 10.54, Step: 33410, Train Loss: 1.5554, Learning Rate: 7.75e-05
2025-12-09 05:53:56 - INFO - Epoch: 10.55, Step: 33420, Train Loss: 1.6105, Learning Rate: 7.75e-05
2025-12-09 05:54:08 - INFO - Epoch: 10.55, Step: 33430, Train Loss: 1.5878, Learning Rate: 7.75e-05
2025-12-09 05:54:19 - INFO - Epoch: 10.55, Step: 33440, Train Loss: 1.5251, Learning Rate: 7.75e-05
2025-12-09 05:54:30 - INFO - Epoch: 10.56, Step: 33450, Train Loss: 1.5429, Learning Rate: 7.75e-05
2025-12-09 05:54:41 - INFO - Epoch: 10.56, Step: 33460, Train Loss: 1.5975, Learning Rate: 7.75e-05
2025-12-09 05:54:52 - INFO - Epoch: 10.56, Step: 33470, Train Loss: 1.5668, Learning Rate: 7.75e-05
2025-12-09 05:55:03 - INFO - Epoch: 10.56, Step: 33480, Train Loss: 1.5923, Learning Rate: 7.75e-05
2025-12-09 05:55:14 - INFO - Epoch: 10.57, Step: 33490, Train Loss: 1.5957, Learning Rate: 7.75e-05
2025-12-09 05:55:25 - INFO - Epoch: 10.57, Step: 33500, Train Loss: 1.6019, Learning Rate: 7.74e-05
2025-12-09 05:55:36 - INFO - Epoch: 10.57, Step: 33510, Train Loss: 1.5760, Learning Rate: 7.74e-05
2025-12-09 05:55:47 - INFO - Epoch: 10.58, Step: 33520, Train Loss: 1.5683, Learning Rate: 7.74e-05
2025-12-09 05:55:58 - INFO - Epoch: 10.58, Step: 33530, Train Loss: 1.5595, Learning Rate: 7.74e-05
2025-12-09 05:56:09 - INFO - Epoch: 10.58, Step: 33540, Train Loss: 1.5957, Learning Rate: 7.74e-05
2025-12-09 05:56:21 - INFO - Epoch: 10.59, Step: 33550, Train Loss: 1.5457, Learning Rate: 7.74e-05
2025-12-09 05:56:32 - INFO - Epoch: 10.59, Step: 33560, Train Loss: 1.5531, Learning Rate: 7.74e-05
2025-12-09 05:56:43 - INFO - Epoch: 10.59, Step: 33570, Train Loss: 1.6103, Learning Rate: 7.74e-05
2025-12-09 05:56:54 - INFO - Epoch: 10.60, Step: 33580, Train Loss: 1.5352, Learning Rate: 7.74e-05
2025-12-09 05:57:05 - INFO - Epoch: 10.60, Step: 33590, Train Loss: 1.5818, Learning Rate: 7.74e-05
2025-12-09 05:57:16 - INFO - Epoch: 10.60, Step: 33600, Train Loss: 1.5387, Learning Rate: 7.74e-05
2025-12-09 05:57:27 - INFO - Epoch: 10.61, Step: 33610, Train Loss: 1.5495, Learning Rate: 7.74e-05
2025-12-09 05:57:38 - INFO - Epoch: 10.61, Step: 33620, Train Loss: 1.5466, Learning Rate: 7.73e-05
2025-12-09 05:57:49 - INFO - Epoch: 10.61, Step: 33630, Train Loss: 1.5632, Learning Rate: 7.73e-05
2025-12-09 05:58:00 - INFO - Epoch: 10.62, Step: 33640, Train Loss: 1.5608, Learning Rate: 7.73e-05
2025-12-09 05:58:11 - INFO - Epoch: 10.62, Step: 33650, Train Loss: 1.5666, Learning Rate: 7.73e-05
2025-12-09 05:58:22 - INFO - Epoch: 10.62, Step: 33660, Train Loss: 1.5134, Learning Rate: 7.73e-05
2025-12-09 05:58:33 - INFO - Epoch: 10.62, Step: 33670, Train Loss: 1.5797, Learning Rate: 7.73e-05
2025-12-09 05:58:45 - INFO - Epoch: 10.63, Step: 33680, Train Loss: 1.5647, Learning Rate: 7.73e-05
2025-12-09 05:58:56 - INFO - Epoch: 10.63, Step: 33690, Train Loss: 1.5690, Learning Rate: 7.73e-05
2025-12-09 05:59:07 - INFO - Epoch: 10.63, Step: 33700, Train Loss: 1.5962, Learning Rate: 7.73e-05
2025-12-09 05:59:18 - INFO - Epoch: 10.64, Step: 33710, Train Loss: 1.5855, Learning Rate: 7.73e-05
2025-12-09 05:59:29 - INFO - Epoch: 10.64, Step: 33720, Train Loss: 1.5485, Learning Rate: 7.73e-05
2025-12-09 05:59:40 - INFO - Epoch: 10.64, Step: 33730, Train Loss: 1.5673, Learning Rate: 7.73e-05
2025-12-09 05:59:51 - INFO - Epoch: 10.65, Step: 33740, Train Loss: 1.5394, Learning Rate: 7.72e-05
2025-12-09 06:00:02 - INFO - Epoch: 10.65, Step: 33750, Train Loss: 1.5583, Learning Rate: 7.72e-05
2025-12-09 06:00:13 - INFO - Epoch: 10.65, Step: 33760, Train Loss: 1.5401, Learning Rate: 7.72e-05
2025-12-09 06:00:24 - INFO - Epoch: 10.66, Step: 33770, Train Loss: 1.5877, Learning Rate: 7.72e-05
2025-12-09 06:00:35 - INFO - Epoch: 10.66, Step: 33780, Train Loss: 1.5713, Learning Rate: 7.72e-05
2025-12-09 06:00:46 - INFO - Epoch: 10.66, Step: 33790, Train Loss: 1.5508, Learning Rate: 7.72e-05
2025-12-09 06:00:58 - INFO - Epoch: 10.67, Step: 33800, Train Loss: 1.5643, Learning Rate: 7.72e-05
2025-12-09 06:01:09 - INFO - Epoch: 10.67, Step: 33810, Train Loss: 1.5446, Learning Rate: 7.72e-05
2025-12-09 06:01:20 - INFO - Epoch: 10.67, Step: 33820, Train Loss: 1.5588, Learning Rate: 7.72e-05
2025-12-09 06:01:31 - INFO - Epoch: 10.68, Step: 33830, Train Loss: 1.5665, Learning Rate: 7.72e-05
2025-12-09 06:01:42 - INFO - Epoch: 10.68, Step: 33840, Train Loss: 1.5248, Learning Rate: 7.72e-05
2025-12-09 06:01:53 - INFO - Epoch: 10.68, Step: 33850, Train Loss: 1.5799, Learning Rate: 7.72e-05
2025-12-09 06:02:04 - INFO - Epoch: 10.68, Step: 33860, Train Loss: 1.5952, Learning Rate: 7.71e-05
2025-12-09 06:02:15 - INFO - Epoch: 10.69, Step: 33870, Train Loss: 1.5096, Learning Rate: 7.71e-05
2025-12-09 06:02:26 - INFO - Epoch: 10.69, Step: 33880, Train Loss: 1.5672, Learning Rate: 7.71e-05
2025-12-09 06:02:37 - INFO - Epoch: 10.69, Step: 33890, Train Loss: 1.5483, Learning Rate: 7.71e-05
2025-12-09 06:02:48 - INFO - Epoch: 10.70, Step: 33900, Train Loss: 1.5586, Learning Rate: 7.71e-05
2025-12-09 06:02:59 - INFO - Epoch: 10.70, Step: 33910, Train Loss: 1.5756, Learning Rate: 7.71e-05
2025-12-09 06:03:11 - INFO - Epoch: 10.70, Step: 33920, Train Loss: 1.5538, Learning Rate: 7.71e-05
2025-12-09 06:03:22 - INFO - Epoch: 10.71, Step: 33930, Train Loss: 1.5543, Learning Rate: 7.71e-05
2025-12-09 06:03:33 - INFO - Epoch: 10.71, Step: 33940, Train Loss: 1.5547, Learning Rate: 7.71e-05
2025-12-09 06:03:44 - INFO - Epoch: 10.71, Step: 33950, Train Loss: 1.5576, Learning Rate: 7.71e-05
2025-12-09 06:03:55 - INFO - Epoch: 10.72, Step: 33960, Train Loss: 1.5611, Learning Rate: 7.71e-05
2025-12-09 06:04:06 - INFO - Epoch: 10.72, Step: 33970, Train Loss: 1.5302, Learning Rate: 7.71e-05
2025-12-09 06:04:17 - INFO - Epoch: 10.72, Step: 33980, Train Loss: 1.5644, Learning Rate: 7.70e-05
2025-12-09 06:04:28 - INFO - Epoch: 10.73, Step: 33990, Train Loss: 1.5421, Learning Rate: 7.70e-05
2025-12-09 06:04:39 - INFO - Epoch: 10.73, Step: 34000, Train Loss: 1.5369, Learning Rate: 7.70e-05
2025-12-09 06:04:50 - INFO - Epoch: 10.73, Step: 34010, Train Loss: 1.5477, Learning Rate: 7.70e-05
2025-12-09 06:05:01 - INFO - Epoch: 10.74, Step: 34020, Train Loss: 1.5565, Learning Rate: 7.70e-05
2025-12-09 06:05:12 - INFO - Epoch: 10.74, Step: 34030, Train Loss: 1.5264, Learning Rate: 7.70e-05
2025-12-09 06:05:24 - INFO - Epoch: 10.74, Step: 34040, Train Loss: 1.5724, Learning Rate: 7.70e-05
2025-12-09 06:05:35 - INFO - Epoch: 10.74, Step: 34050, Train Loss: 1.5677, Learning Rate: 7.70e-05
2025-12-09 06:05:46 - INFO - Epoch: 10.75, Step: 34060, Train Loss: 1.5635, Learning Rate: 7.70e-05
2025-12-09 06:05:57 - INFO - Epoch: 10.75, Step: 34070, Train Loss: 1.5785, Learning Rate: 7.70e-05
2025-12-09 06:06:08 - INFO - Epoch: 10.75, Step: 34080, Train Loss: 1.5822, Learning Rate: 7.70e-05
2025-12-09 06:06:19 - INFO - Epoch: 10.76, Step: 34090, Train Loss: 1.5312, Learning Rate: 7.70e-05
2025-12-09 06:06:30 - INFO - Epoch: 10.76, Step: 34100, Train Loss: 1.5245, Learning Rate: 7.69e-05
2025-12-09 06:06:41 - INFO - Epoch: 10.76, Step: 34110, Train Loss: 1.6024, Learning Rate: 7.69e-05
2025-12-09 06:06:52 - INFO - Epoch: 10.77, Step: 34120, Train Loss: 1.5761, Learning Rate: 7.69e-05
2025-12-09 06:07:03 - INFO - Epoch: 10.77, Step: 34130, Train Loss: 1.5585, Learning Rate: 7.69e-05
2025-12-09 06:07:14 - INFO - Epoch: 10.77, Step: 34140, Train Loss: 1.5842, Learning Rate: 7.69e-05
2025-12-09 06:07:25 - INFO - Epoch: 10.78, Step: 34150, Train Loss: 1.5320, Learning Rate: 7.69e-05
2025-12-09 06:07:37 - INFO - Epoch: 10.78, Step: 34160, Train Loss: 1.5513, Learning Rate: 7.69e-05
2025-12-09 06:07:48 - INFO - Epoch: 10.78, Step: 34170, Train Loss: 1.5657, Learning Rate: 7.69e-05
2025-12-09 06:07:59 - INFO - Epoch: 10.79, Step: 34180, Train Loss: 1.5536, Learning Rate: 7.69e-05
2025-12-09 06:08:10 - INFO - Epoch: 10.79, Step: 34190, Train Loss: 1.5651, Learning Rate: 7.69e-05
2025-12-09 06:08:21 - INFO - Epoch: 10.79, Step: 34200, Train Loss: 1.5863, Learning Rate: 7.69e-05
2025-12-09 06:08:32 - INFO - Epoch: 10.80, Step: 34210, Train Loss: 1.5487, Learning Rate: 7.69e-05
2025-12-09 06:08:43 - INFO - Epoch: 10.80, Step: 34220, Train Loss: 1.5398, Learning Rate: 7.68e-05
2025-12-09 06:08:54 - INFO - Epoch: 10.80, Step: 34230, Train Loss: 1.5575, Learning Rate: 7.68e-05
2025-12-09 06:09:05 - INFO - Epoch: 10.80, Step: 34240, Train Loss: 1.5362, Learning Rate: 7.68e-05
2025-12-09 06:09:16 - INFO - Epoch: 10.81, Step: 34250, Train Loss: 1.5735, Learning Rate: 7.68e-05
2025-12-09 06:09:27 - INFO - Epoch: 10.81, Step: 34260, Train Loss: 1.6012, Learning Rate: 7.68e-05
2025-12-09 06:09:38 - INFO - Epoch: 10.81, Step: 34270, Train Loss: 1.5729, Learning Rate: 7.68e-05
2025-12-09 06:09:50 - INFO - Epoch: 10.82, Step: 34280, Train Loss: 1.5784, Learning Rate: 7.68e-05
2025-12-09 06:10:01 - INFO - Epoch: 10.82, Step: 34290, Train Loss: 1.5335, Learning Rate: 7.68e-05
2025-12-09 06:10:12 - INFO - Epoch: 10.82, Step: 34300, Train Loss: 1.5443, Learning Rate: 7.68e-05
2025-12-09 06:10:23 - INFO - Epoch: 10.83, Step: 34310, Train Loss: 1.5997, Learning Rate: 7.68e-05
2025-12-09 06:10:34 - INFO - Epoch: 10.83, Step: 34320, Train Loss: 1.5803, Learning Rate: 7.68e-05
2025-12-09 06:10:45 - INFO - Epoch: 10.83, Step: 34330, Train Loss: 1.5588, Learning Rate: 7.68e-05
2025-12-09 06:10:56 - INFO - Epoch: 10.84, Step: 34340, Train Loss: 1.5898, Learning Rate: 7.67e-05
2025-12-09 06:11:07 - INFO - Epoch: 10.84, Step: 34350, Train Loss: 1.4947, Learning Rate: 7.67e-05
2025-12-09 06:11:18 - INFO - Epoch: 10.84, Step: 34360, Train Loss: 1.5062, Learning Rate: 7.67e-05
2025-12-09 06:11:29 - INFO - Epoch: 10.85, Step: 34370, Train Loss: 1.5647, Learning Rate: 7.67e-05
2025-12-09 06:11:40 - INFO - Epoch: 10.85, Step: 34380, Train Loss: 1.5724, Learning Rate: 7.67e-05
2025-12-09 06:11:51 - INFO - Epoch: 10.85, Step: 34390, Train Loss: 1.5537, Learning Rate: 7.67e-05
2025-12-09 06:12:02 - INFO - Epoch: 10.86, Step: 34400, Train Loss: 1.5851, Learning Rate: 7.67e-05
2025-12-09 06:12:14 - INFO - Epoch: 10.86, Step: 34410, Train Loss: 1.5414, Learning Rate: 7.67e-05
2025-12-09 06:12:25 - INFO - Epoch: 10.86, Step: 34420, Train Loss: 1.5731, Learning Rate: 7.67e-05
2025-12-09 06:12:36 - INFO - Epoch: 10.86, Step: 34430, Train Loss: 1.5818, Learning Rate: 7.67e-05
2025-12-09 06:12:47 - INFO - Epoch: 10.87, Step: 34440, Train Loss: 1.5491, Learning Rate: 7.67e-05
2025-12-09 06:12:58 - INFO - Epoch: 10.87, Step: 34450, Train Loss: 1.5812, Learning Rate: 7.67e-05
2025-12-09 06:13:09 - INFO - Epoch: 10.87, Step: 34460, Train Loss: 1.5850, Learning Rate: 7.66e-05
2025-12-09 06:13:20 - INFO - Epoch: 10.88, Step: 34470, Train Loss: 1.5405, Learning Rate: 7.66e-05
2025-12-09 06:13:31 - INFO - Epoch: 10.88, Step: 34480, Train Loss: 1.5252, Learning Rate: 7.66e-05
2025-12-09 06:13:42 - INFO - Epoch: 10.88, Step: 34490, Train Loss: 1.6034, Learning Rate: 7.66e-05
2025-12-09 06:13:53 - INFO - Epoch: 10.89, Step: 34500, Train Loss: 1.5291, Learning Rate: 7.66e-05
2025-12-09 06:14:04 - INFO - Epoch: 10.89, Step: 34510, Train Loss: 1.5549, Learning Rate: 7.66e-05
2025-12-09 06:14:15 - INFO - Epoch: 10.89, Step: 34520, Train Loss: 1.5176, Learning Rate: 7.66e-05
2025-12-09 06:14:27 - INFO - Epoch: 10.90, Step: 34530, Train Loss: 1.6046, Learning Rate: 7.66e-05
2025-12-09 06:14:38 - INFO - Epoch: 10.90, Step: 34540, Train Loss: 1.5481, Learning Rate: 7.66e-05
2025-12-09 06:14:49 - INFO - Epoch: 10.90, Step: 34550, Train Loss: 1.5122, Learning Rate: 7.66e-05
2025-12-09 06:15:00 - INFO - Epoch: 10.91, Step: 34560, Train Loss: 1.5660, Learning Rate: 7.66e-05
2025-12-09 06:15:11 - INFO - Epoch: 10.91, Step: 34570, Train Loss: 1.5833, Learning Rate: 7.66e-05
2025-12-09 06:15:22 - INFO - Epoch: 10.91, Step: 34580, Train Loss: 1.5718, Learning Rate: 7.65e-05
2025-12-09 06:15:33 - INFO - Epoch: 10.92, Step: 34590, Train Loss: 1.5288, Learning Rate: 7.65e-05
2025-12-09 06:15:44 - INFO - Epoch: 10.92, Step: 34600, Train Loss: 1.5589, Learning Rate: 7.65e-05
2025-12-09 06:15:55 - INFO - Epoch: 10.92, Step: 34610, Train Loss: 1.5017, Learning Rate: 7.65e-05
2025-12-09 06:16:06 - INFO - Epoch: 10.92, Step: 34620, Train Loss: 1.5692, Learning Rate: 7.65e-05
2025-12-09 06:16:17 - INFO - Epoch: 10.93, Step: 34630, Train Loss: 1.5774, Learning Rate: 7.65e-05
2025-12-09 06:16:28 - INFO - Epoch: 10.93, Step: 34640, Train Loss: 1.5376, Learning Rate: 7.65e-05
2025-12-09 06:16:40 - INFO - Epoch: 10.93, Step: 34650, Train Loss: 1.5387, Learning Rate: 7.65e-05
2025-12-09 06:16:51 - INFO - Epoch: 10.94, Step: 34660, Train Loss: 1.5724, Learning Rate: 7.65e-05
2025-12-09 06:17:02 - INFO - Epoch: 10.94, Step: 34670, Train Loss: 1.5171, Learning Rate: 7.65e-05
2025-12-09 06:17:13 - INFO - Epoch: 10.94, Step: 34680, Train Loss: 1.5789, Learning Rate: 7.65e-05
2025-12-09 06:17:24 - INFO - Epoch: 10.95, Step: 34690, Train Loss: 1.5972, Learning Rate: 7.65e-05
2025-12-09 06:17:35 - INFO - Epoch: 10.95, Step: 34700, Train Loss: 1.5449, Learning Rate: 7.64e-05
2025-12-09 06:17:46 - INFO - Epoch: 10.95, Step: 34710, Train Loss: 1.5673, Learning Rate: 7.64e-05
2025-12-09 06:17:57 - INFO - Epoch: 10.96, Step: 34720, Train Loss: 1.5654, Learning Rate: 7.64e-05
2025-12-09 06:18:08 - INFO - Epoch: 10.96, Step: 34730, Train Loss: 1.5457, Learning Rate: 7.64e-05
2025-12-09 06:18:19 - INFO - Epoch: 10.96, Step: 34740, Train Loss: 1.5516, Learning Rate: 7.64e-05
2025-12-09 06:18:30 - INFO - Epoch: 10.97, Step: 34750, Train Loss: 1.5448, Learning Rate: 7.64e-05
2025-12-09 06:18:41 - INFO - Epoch: 10.97, Step: 34760, Train Loss: 1.5820, Learning Rate: 7.64e-05
2025-12-09 06:18:53 - INFO - Epoch: 10.97, Step: 34770, Train Loss: 1.5520, Learning Rate: 7.64e-05
2025-12-09 06:19:04 - INFO - Epoch: 10.98, Step: 34780, Train Loss: 1.5316, Learning Rate: 7.64e-05
2025-12-09 06:19:15 - INFO - Epoch: 10.98, Step: 34790, Train Loss: 1.5450, Learning Rate: 7.64e-05
2025-12-09 06:19:26 - INFO - Epoch: 10.98, Step: 34800, Train Loss: 1.5514, Learning Rate: 7.64e-05
2025-12-09 06:19:37 - INFO - Epoch: 10.98, Step: 34810, Train Loss: 1.5498, Learning Rate: 7.64e-05
2025-12-09 06:19:48 - INFO - Epoch: 10.99, Step: 34820, Train Loss: 1.5137, Learning Rate: 7.63e-05
2025-12-09 06:19:59 - INFO - Epoch: 10.99, Step: 34830, Train Loss: 1.5930, Learning Rate: 7.63e-05
2025-12-09 06:20:10 - INFO - Epoch: 10.99, Step: 34840, Train Loss: 1.5655, Learning Rate: 7.63e-05
2025-12-09 06:20:21 - INFO - Epoch: 11.00, Step: 34850, Train Loss: 1.5244, Learning Rate: 7.63e-05
2025-12-09 06:20:32 - INFO - Epoch: 11.00, Step: 34860, Train Loss: 1.5658, Learning Rate: 7.63e-05
2025-12-09 06:20:43 - INFO - Epoch: 11.00, Step: 34870, Train Loss: 1.5238, Learning Rate: 7.63e-05
2025-12-09 06:20:54 - INFO - Epoch: 11.01, Step: 34880, Train Loss: 1.5145, Learning Rate: 7.63e-05
2025-12-09 06:21:06 - INFO - Epoch: 11.01, Step: 34890, Train Loss: 1.5402, Learning Rate: 7.63e-05
2025-12-09 06:21:17 - INFO - Epoch: 11.01, Step: 34900, Train Loss: 1.5734, Learning Rate: 7.63e-05
2025-12-09 06:21:28 - INFO - Epoch: 11.02, Step: 34910, Train Loss: 1.5791, Learning Rate: 7.63e-05
2025-12-09 06:21:39 - INFO - Epoch: 11.02, Step: 34920, Train Loss: 1.5854, Learning Rate: 7.63e-05
2025-12-09 06:21:50 - INFO - Epoch: 11.02, Step: 34930, Train Loss: 1.5347, Learning Rate: 7.63e-05
2025-12-09 06:22:01 - INFO - Epoch: 11.03, Step: 34940, Train Loss: 1.5615, Learning Rate: 7.62e-05
2025-12-09 06:22:12 - INFO - Epoch: 11.03, Step: 34950, Train Loss: 1.5408, Learning Rate: 7.62e-05
2025-12-09 06:22:23 - INFO - Epoch: 11.03, Step: 34960, Train Loss: 1.5200, Learning Rate: 7.62e-05
2025-12-09 06:22:34 - INFO - Epoch: 11.04, Step: 34970, Train Loss: 1.5711, Learning Rate: 7.62e-05
2025-12-09 06:22:45 - INFO - Epoch: 11.04, Step: 34980, Train Loss: 1.5658, Learning Rate: 7.62e-05
2025-12-09 06:22:56 - INFO - Epoch: 11.04, Step: 34990, Train Loss: 1.5499, Learning Rate: 7.62e-05
2025-12-09 06:23:07 - INFO - Epoch: 11.04, Step: 35000, Train Loss: 1.5573, Learning Rate: 7.62e-05
2025-12-09 06:23:18 - INFO - Epoch: 11.05, Step: 35010, Train Loss: 1.5207, Learning Rate: 7.62e-05
2025-12-09 06:23:30 - INFO - Epoch: 11.05, Step: 35020, Train Loss: 1.5307, Learning Rate: 7.62e-05
2025-12-09 06:23:41 - INFO - Epoch: 11.05, Step: 35030, Train Loss: 1.5791, Learning Rate: 7.62e-05
2025-12-09 06:23:52 - INFO - Epoch: 11.06, Step: 35040, Train Loss: 1.5055, Learning Rate: 7.62e-05
2025-12-09 06:24:03 - INFO - Epoch: 11.06, Step: 35050, Train Loss: 1.5564, Learning Rate: 7.62e-05
2025-12-09 06:24:14 - INFO - Epoch: 11.06, Step: 35060, Train Loss: 1.5640, Learning Rate: 7.61e-05
2025-12-09 06:24:25 - INFO - Epoch: 11.07, Step: 35070, Train Loss: 1.5474, Learning Rate: 7.61e-05
2025-12-09 06:24:36 - INFO - Epoch: 11.07, Step: 35080, Train Loss: 1.5547, Learning Rate: 7.61e-05
2025-12-09 06:24:47 - INFO - Epoch: 11.07, Step: 35090, Train Loss: 1.5546, Learning Rate: 7.61e-05
2025-12-09 06:24:58 - INFO - Epoch: 11.08, Step: 35100, Train Loss: 1.5532, Learning Rate: 7.61e-05
2025-12-09 06:25:09 - INFO - Epoch: 11.08, Step: 35110, Train Loss: 1.5330, Learning Rate: 7.61e-05
2025-12-09 06:25:20 - INFO - Epoch: 11.08, Step: 35120, Train Loss: 1.5590, Learning Rate: 7.61e-05
2025-12-09 06:25:31 - INFO - Epoch: 11.09, Step: 35130, Train Loss: 1.5066, Learning Rate: 7.61e-05
2025-12-09 06:25:43 - INFO - Epoch: 11.09, Step: 35140, Train Loss: 1.5585, Learning Rate: 7.61e-05
2025-12-09 06:25:54 - INFO - Epoch: 11.09, Step: 35150, Train Loss: 1.5325, Learning Rate: 7.61e-05
2025-12-09 06:26:05 - INFO - Epoch: 11.09, Step: 35160, Train Loss: 1.5423, Learning Rate: 7.61e-05
2025-12-09 06:26:16 - INFO - Epoch: 11.10, Step: 35170, Train Loss: 1.5626, Learning Rate: 7.61e-05
2025-12-09 06:26:27 - INFO - Epoch: 11.10, Step: 35180, Train Loss: 1.5728, Learning Rate: 7.61e-05
2025-12-09 06:26:38 - INFO - Epoch: 11.10, Step: 35190, Train Loss: 1.5414, Learning Rate: 7.60e-05
2025-12-09 06:26:49 - INFO - Epoch: 11.11, Step: 35200, Train Loss: 1.5299, Learning Rate: 7.60e-05
2025-12-09 06:27:00 - INFO - Epoch: 11.11, Step: 35210, Train Loss: 1.5637, Learning Rate: 7.60e-05
2025-12-09 06:27:11 - INFO - Epoch: 11.11, Step: 35220, Train Loss: 1.5557, Learning Rate: 7.60e-05
2025-12-09 06:27:22 - INFO - Epoch: 11.12, Step: 35230, Train Loss: 1.5120, Learning Rate: 7.60e-05
2025-12-09 06:27:33 - INFO - Epoch: 11.12, Step: 35240, Train Loss: 1.5298, Learning Rate: 7.60e-05
2025-12-09 06:27:44 - INFO - Epoch: 11.12, Step: 35250, Train Loss: 1.5450, Learning Rate: 7.60e-05
2025-12-09 06:27:56 - INFO - Epoch: 11.13, Step: 35260, Train Loss: 1.5450, Learning Rate: 7.60e-05
2025-12-09 06:28:07 - INFO - Epoch: 11.13, Step: 35270, Train Loss: 1.5395, Learning Rate: 7.60e-05
2025-12-09 06:28:18 - INFO - Epoch: 11.13, Step: 35280, Train Loss: 1.5274, Learning Rate: 7.60e-05
2025-12-09 06:28:29 - INFO - Epoch: 11.14, Step: 35290, Train Loss: 1.5500, Learning Rate: 7.60e-05
2025-12-09 06:28:40 - INFO - Epoch: 11.14, Step: 35300, Train Loss: 1.5256, Learning Rate: 7.60e-05
2025-12-09 06:28:51 - INFO - Epoch: 11.14, Step: 35310, Train Loss: 1.5498, Learning Rate: 7.59e-05
2025-12-09 06:29:02 - INFO - Epoch: 11.15, Step: 35320, Train Loss: 1.5325, Learning Rate: 7.59e-05
2025-12-09 06:29:13 - INFO - Epoch: 11.15, Step: 35330, Train Loss: 1.5296, Learning Rate: 7.59e-05
2025-12-09 06:29:24 - INFO - Epoch: 11.15, Step: 35340, Train Loss: 1.6159, Learning Rate: 7.59e-05
2025-12-09 06:29:35 - INFO - Epoch: 11.15, Step: 35350, Train Loss: 1.5176, Learning Rate: 7.59e-05
2025-12-09 06:29:46 - INFO - Epoch: 11.16, Step: 35360, Train Loss: 1.5274, Learning Rate: 7.59e-05
2025-12-09 06:29:57 - INFO - Epoch: 11.16, Step: 35370, Train Loss: 1.5373, Learning Rate: 7.59e-05
2025-12-09 06:30:09 - INFO - Epoch: 11.16, Step: 35380, Train Loss: 1.5562, Learning Rate: 7.59e-05
2025-12-09 06:30:20 - INFO - Epoch: 11.17, Step: 35390, Train Loss: 1.4950, Learning Rate: 7.59e-05
2025-12-09 06:30:31 - INFO - Epoch: 11.17, Step: 35400, Train Loss: 1.5431, Learning Rate: 7.59e-05
2025-12-09 06:30:42 - INFO - Epoch: 11.17, Step: 35410, Train Loss: 1.5138, Learning Rate: 7.59e-05
2025-12-09 06:30:53 - INFO - Epoch: 11.18, Step: 35420, Train Loss: 1.5254, Learning Rate: 7.59e-05
2025-12-09 06:31:04 - INFO - Epoch: 11.18, Step: 35430, Train Loss: 1.5097, Learning Rate: 7.58e-05
2025-12-09 06:31:15 - INFO - Epoch: 11.18, Step: 35440, Train Loss: 1.5549, Learning Rate: 7.58e-05
2025-12-09 06:31:26 - INFO - Epoch: 11.19, Step: 35450, Train Loss: 1.4825, Learning Rate: 7.58e-05
2025-12-09 06:31:37 - INFO - Epoch: 11.19, Step: 35460, Train Loss: 1.5207, Learning Rate: 7.58e-05
2025-12-09 06:31:48 - INFO - Epoch: 11.19, Step: 35470, Train Loss: 1.5126, Learning Rate: 7.58e-05
2025-12-09 06:31:59 - INFO - Epoch: 11.20, Step: 35480, Train Loss: 1.5525, Learning Rate: 7.58e-05
2025-12-09 06:32:10 - INFO - Epoch: 11.20, Step: 35490, Train Loss: 1.5648, Learning Rate: 7.58e-05
2025-12-09 06:32:22 - INFO - Epoch: 11.20, Step: 35500, Train Loss: 1.5237, Learning Rate: 7.58e-05
2025-12-09 06:32:33 - INFO - Epoch: 11.21, Step: 35510, Train Loss: 1.5134, Learning Rate: 7.58e-05
2025-12-09 06:32:44 - INFO - Epoch: 11.21, Step: 35520, Train Loss: 1.5307, Learning Rate: 7.58e-05
2025-12-09 06:32:55 - INFO - Epoch: 11.21, Step: 35530, Train Loss: 1.5469, Learning Rate: 7.58e-05
2025-12-09 06:33:06 - INFO - Epoch: 11.21, Step: 35540, Train Loss: 1.5543, Learning Rate: 7.58e-05
2025-12-09 06:33:17 - INFO - Epoch: 11.22, Step: 35550, Train Loss: 1.5610, Learning Rate: 7.57e-05
2025-12-09 06:33:28 - INFO - Epoch: 11.22, Step: 35560, Train Loss: 1.5776, Learning Rate: 7.57e-05
2025-12-09 06:33:39 - INFO - Epoch: 11.22, Step: 35570, Train Loss: 1.5311, Learning Rate: 7.57e-05
2025-12-09 06:33:50 - INFO - Epoch: 11.23, Step: 35580, Train Loss: 1.5048, Learning Rate: 7.57e-05
2025-12-09 06:34:01 - INFO - Epoch: 11.23, Step: 35590, Train Loss: 1.5116, Learning Rate: 7.57e-05
2025-12-09 06:34:12 - INFO - Epoch: 11.23, Step: 35600, Train Loss: 1.5207, Learning Rate: 7.57e-05
2025-12-09 06:34:23 - INFO - Epoch: 11.24, Step: 35610, Train Loss: 1.5752, Learning Rate: 7.57e-05
2025-12-09 06:34:34 - INFO - Epoch: 11.24, Step: 35620, Train Loss: 1.5139, Learning Rate: 7.57e-05
2025-12-09 06:34:46 - INFO - Epoch: 11.24, Step: 35630, Train Loss: 1.5401, Learning Rate: 7.57e-05
2025-12-09 06:34:57 - INFO - Epoch: 11.25, Step: 35640, Train Loss: 1.5278, Learning Rate: 7.57e-05
2025-12-09 06:35:08 - INFO - Epoch: 11.25, Step: 35650, Train Loss: 1.5870, Learning Rate: 7.57e-05
2025-12-09 06:35:19 - INFO - Epoch: 11.25, Step: 35660, Train Loss: 1.5122, Learning Rate: 7.57e-05
2025-12-09 06:35:30 - INFO - Epoch: 11.26, Step: 35670, Train Loss: 1.5443, Learning Rate: 7.56e-05
2025-12-09 06:35:41 - INFO - Epoch: 11.26, Step: 35680, Train Loss: 1.5376, Learning Rate: 7.56e-05
2025-12-09 06:35:52 - INFO - Epoch: 11.26, Step: 35690, Train Loss: 1.5452, Learning Rate: 7.56e-05
2025-12-09 06:36:03 - INFO - Epoch: 11.27, Step: 35700, Train Loss: 1.5099, Learning Rate: 7.56e-05
2025-12-09 06:36:14 - INFO - Epoch: 11.27, Step: 35710, Train Loss: 1.4953, Learning Rate: 7.56e-05
2025-12-09 06:36:25 - INFO - Epoch: 11.27, Step: 35720, Train Loss: 1.5266, Learning Rate: 7.56e-05
2025-12-09 06:36:36 - INFO - Epoch: 11.27, Step: 35730, Train Loss: 1.5705, Learning Rate: 7.56e-05
2025-12-09 06:36:47 - INFO - Epoch: 11.28, Step: 35740, Train Loss: 1.5901, Learning Rate: 7.56e-05
2025-12-09 06:36:59 - INFO - Epoch: 11.28, Step: 35750, Train Loss: 1.5504, Learning Rate: 7.56e-05
2025-12-09 06:37:10 - INFO - Epoch: 11.28, Step: 35760, Train Loss: 1.5477, Learning Rate: 7.56e-05
2025-12-09 06:37:21 - INFO - Epoch: 11.29, Step: 35770, Train Loss: 1.5670, Learning Rate: 7.56e-05
2025-12-09 06:37:32 - INFO - Epoch: 11.29, Step: 35780, Train Loss: 1.4872, Learning Rate: 7.56e-05
2025-12-09 06:37:43 - INFO - Epoch: 11.29, Step: 35790, Train Loss: 1.5261, Learning Rate: 7.55e-05
2025-12-09 06:37:54 - INFO - Epoch: 11.30, Step: 35800, Train Loss: 1.5407, Learning Rate: 7.55e-05
2025-12-09 06:38:05 - INFO - Epoch: 11.30, Step: 35810, Train Loss: 1.5753, Learning Rate: 7.55e-05
2025-12-09 06:38:16 - INFO - Epoch: 11.30, Step: 35820, Train Loss: 1.5217, Learning Rate: 7.55e-05
2025-12-09 06:38:27 - INFO - Epoch: 11.31, Step: 35830, Train Loss: 1.5122, Learning Rate: 7.55e-05
2025-12-09 06:38:38 - INFO - Epoch: 11.31, Step: 35840, Train Loss: 1.5418, Learning Rate: 7.55e-05
2025-12-09 06:38:49 - INFO - Epoch: 11.31, Step: 35850, Train Loss: 1.5257, Learning Rate: 7.55e-05
2025-12-09 06:39:00 - INFO - Epoch: 11.32, Step: 35860, Train Loss: 1.5286, Learning Rate: 7.55e-05
2025-12-09 06:39:12 - INFO - Epoch: 11.32, Step: 35870, Train Loss: 1.5223, Learning Rate: 7.55e-05
2025-12-09 06:39:23 - INFO - Epoch: 11.32, Step: 35880, Train Loss: 1.5441, Learning Rate: 7.55e-05
2025-12-09 06:39:34 - INFO - Epoch: 11.33, Step: 35890, Train Loss: 1.5242, Learning Rate: 7.55e-05
2025-12-09 06:39:45 - INFO - Epoch: 11.33, Step: 35900, Train Loss: 1.4935, Learning Rate: 7.55e-05
2025-12-09 06:39:56 - INFO - Epoch: 11.33, Step: 35910, Train Loss: 1.5207, Learning Rate: 7.54e-05
2025-12-09 06:40:07 - INFO - Epoch: 11.33, Step: 35920, Train Loss: 1.4942, Learning Rate: 7.54e-05
2025-12-09 06:40:18 - INFO - Epoch: 11.34, Step: 35930, Train Loss: 1.5186, Learning Rate: 7.54e-05
2025-12-09 06:40:29 - INFO - Epoch: 11.34, Step: 35940, Train Loss: 1.5308, Learning Rate: 7.54e-05
2025-12-09 06:40:40 - INFO - Epoch: 11.34, Step: 35950, Train Loss: 1.5549, Learning Rate: 7.54e-05
2025-12-09 06:40:51 - INFO - Epoch: 11.35, Step: 35960, Train Loss: 1.4872, Learning Rate: 7.54e-05
2025-12-09 06:41:02 - INFO - Epoch: 11.35, Step: 35970, Train Loss: 1.5032, Learning Rate: 7.54e-05
2025-12-09 06:41:13 - INFO - Epoch: 11.35, Step: 35980, Train Loss: 1.5197, Learning Rate: 7.54e-05
2025-12-09 06:41:25 - INFO - Epoch: 11.36, Step: 35990, Train Loss: 1.5363, Learning Rate: 7.54e-05
2025-12-09 06:41:36 - INFO - Epoch: 11.36, Step: 36000, Train Loss: 1.5351, Learning Rate: 7.54e-05
2025-12-09 06:41:47 - INFO - Epoch: 11.36, Step: 36010, Train Loss: 1.5415, Learning Rate: 7.54e-05
2025-12-09 06:41:58 - INFO - Epoch: 11.37, Step: 36020, Train Loss: 1.5148, Learning Rate: 7.54e-05
2025-12-09 06:42:09 - INFO - Epoch: 11.37, Step: 36030, Train Loss: 1.5407, Learning Rate: 7.53e-05
2025-12-09 06:42:20 - INFO - Epoch: 11.37, Step: 36040, Train Loss: 1.5415, Learning Rate: 7.53e-05
2025-12-09 06:42:31 - INFO - Epoch: 11.38, Step: 36050, Train Loss: 1.5344, Learning Rate: 7.53e-05
2025-12-09 06:42:42 - INFO - Epoch: 11.38, Step: 36060, Train Loss: 1.5037, Learning Rate: 7.53e-05
2025-12-09 06:42:53 - INFO - Epoch: 11.38, Step: 36070, Train Loss: 1.5292, Learning Rate: 7.53e-05
2025-12-09 06:43:04 - INFO - Epoch: 11.39, Step: 36080, Train Loss: 1.5512, Learning Rate: 7.53e-05
2025-12-09 06:43:15 - INFO - Epoch: 11.39, Step: 36090, Train Loss: 1.5229, Learning Rate: 7.53e-05
2025-12-09 06:43:26 - INFO - Epoch: 11.39, Step: 36100, Train Loss: 1.5463, Learning Rate: 7.53e-05
2025-12-09 06:43:37 - INFO - Epoch: 11.39, Step: 36110, Train Loss: 1.5360, Learning Rate: 7.53e-05
2025-12-09 06:43:49 - INFO - Epoch: 11.40, Step: 36120, Train Loss: 1.5379, Learning Rate: 7.53e-05
2025-12-09 06:44:00 - INFO - Epoch: 11.40, Step: 36130, Train Loss: 1.5421, Learning Rate: 7.53e-05
2025-12-09 06:44:11 - INFO - Epoch: 11.40, Step: 36140, Train Loss: 1.5299, Learning Rate: 7.53e-05
2025-12-09 06:44:22 - INFO - Epoch: 11.41, Step: 36150, Train Loss: 1.5529, Learning Rate: 7.52e-05
2025-12-09 06:44:33 - INFO - Epoch: 11.41, Step: 36160, Train Loss: 1.5632, Learning Rate: 7.52e-05
2025-12-09 06:44:44 - INFO - Epoch: 11.41, Step: 36170, Train Loss: 1.5454, Learning Rate: 7.52e-05
2025-12-09 06:44:55 - INFO - Epoch: 11.42, Step: 36180, Train Loss: 1.5095, Learning Rate: 7.52e-05
2025-12-09 06:45:06 - INFO - Epoch: 11.42, Step: 36190, Train Loss: 1.5230, Learning Rate: 7.52e-05
2025-12-09 06:45:17 - INFO - Epoch: 11.42, Step: 36200, Train Loss: 1.4892, Learning Rate: 7.52e-05
2025-12-09 06:45:28 - INFO - Epoch: 11.43, Step: 36210, Train Loss: 1.5044, Learning Rate: 7.52e-05
2025-12-09 06:45:39 - INFO - Epoch: 11.43, Step: 36220, Train Loss: 1.5074, Learning Rate: 7.52e-05
2025-12-09 06:45:50 - INFO - Epoch: 11.43, Step: 36230, Train Loss: 1.5341, Learning Rate: 7.52e-05
2025-12-09 06:46:02 - INFO - Epoch: 11.44, Step: 36240, Train Loss: 1.5791, Learning Rate: 7.52e-05
2025-12-09 06:46:13 - INFO - Epoch: 11.44, Step: 36250, Train Loss: 1.5038, Learning Rate: 7.52e-05
2025-12-09 06:46:24 - INFO - Epoch: 11.44, Step: 36260, Train Loss: 1.5143, Learning Rate: 7.52e-05
2025-12-09 06:46:35 - INFO - Epoch: 11.45, Step: 36270, Train Loss: 1.5397, Learning Rate: 7.51e-05
2025-12-09 06:46:46 - INFO - Epoch: 11.45, Step: 36280, Train Loss: 1.5476, Learning Rate: 7.51e-05
2025-12-09 06:46:57 - INFO - Epoch: 11.45, Step: 36290, Train Loss: 1.4996, Learning Rate: 7.51e-05
2025-12-09 06:47:08 - INFO - Epoch: 11.45, Step: 36300, Train Loss: 1.5438, Learning Rate: 7.51e-05
2025-12-09 06:47:19 - INFO - Epoch: 11.46, Step: 36310, Train Loss: 1.5284, Learning Rate: 7.51e-05
2025-12-09 06:47:30 - INFO - Epoch: 11.46, Step: 36320, Train Loss: 1.5306, Learning Rate: 7.51e-05
2025-12-09 06:47:41 - INFO - Epoch: 11.46, Step: 36330, Train Loss: 1.5305, Learning Rate: 7.51e-05
2025-12-09 06:47:52 - INFO - Epoch: 11.47, Step: 36340, Train Loss: 1.4995, Learning Rate: 7.51e-05
2025-12-09 06:48:03 - INFO - Epoch: 11.47, Step: 36350, Train Loss: 1.5141, Learning Rate: 7.51e-05
2025-12-09 06:48:15 - INFO - Epoch: 11.47, Step: 36360, Train Loss: 1.5224, Learning Rate: 7.51e-05
2025-12-09 06:48:26 - INFO - Epoch: 11.48, Step: 36370, Train Loss: 1.5172, Learning Rate: 7.51e-05
2025-12-09 06:48:37 - INFO - Epoch: 11.48, Step: 36380, Train Loss: 1.5573, Learning Rate: 7.51e-05
2025-12-09 06:48:48 - INFO - Epoch: 11.48, Step: 36390, Train Loss: 1.4885, Learning Rate: 7.50e-05
2025-12-09 06:48:59 - INFO - Epoch: 11.49, Step: 36400, Train Loss: 1.5285, Learning Rate: 7.50e-05
2025-12-09 06:49:10 - INFO - Epoch: 11.49, Step: 36410, Train Loss: 1.5386, Learning Rate: 7.50e-05
2025-12-09 06:49:21 - INFO - Epoch: 11.49, Step: 36420, Train Loss: 1.5009, Learning Rate: 7.50e-05
2025-12-09 06:49:32 - INFO - Epoch: 11.50, Step: 36430, Train Loss: 1.5115, Learning Rate: 7.50e-05
2025-12-09 06:49:43 - INFO - Epoch: 11.50, Step: 36440, Train Loss: 1.5182, Learning Rate: 7.50e-05
2025-12-09 06:49:54 - INFO - Epoch: 11.50, Step: 36450, Train Loss: 1.5309, Learning Rate: 7.50e-05
2025-12-09 06:50:05 - INFO - Epoch: 11.51, Step: 36460, Train Loss: 1.5012, Learning Rate: 7.50e-05
2025-12-09 06:50:16 - INFO - Epoch: 11.51, Step: 36470, Train Loss: 1.5259, Learning Rate: 7.50e-05
2025-12-09 06:50:28 - INFO - Epoch: 11.51, Step: 36480, Train Loss: 1.5124, Learning Rate: 7.50e-05
2025-12-09 06:50:39 - INFO - Epoch: 11.51, Step: 36490, Train Loss: 1.5903, Learning Rate: 7.50e-05
2025-12-09 06:50:50 - INFO - Epoch: 11.52, Step: 36500, Train Loss: 1.5268, Learning Rate: 7.50e-05
2025-12-09 06:51:01 - INFO - Epoch: 11.52, Step: 36510, Train Loss: 1.5366, Learning Rate: 7.49e-05
2025-12-09 06:51:12 - INFO - Epoch: 11.52, Step: 36520, Train Loss: 1.5312, Learning Rate: 7.49e-05
2025-12-09 06:51:23 - INFO - Epoch: 11.53, Step: 36530, Train Loss: 1.5292, Learning Rate: 7.49e-05
2025-12-09 06:51:34 - INFO - Epoch: 11.53, Step: 36540, Train Loss: 1.4996, Learning Rate: 7.49e-05
2025-12-09 06:51:45 - INFO - Epoch: 11.53, Step: 36550, Train Loss: 1.5573, Learning Rate: 7.49e-05
2025-12-09 06:51:56 - INFO - Epoch: 11.54, Step: 36560, Train Loss: 1.5384, Learning Rate: 7.49e-05
2025-12-09 06:52:07 - INFO - Epoch: 11.54, Step: 36570, Train Loss: 1.5052, Learning Rate: 7.49e-05
2025-12-09 06:52:18 - INFO - Epoch: 11.54, Step: 36580, Train Loss: 1.5185, Learning Rate: 7.49e-05
2025-12-09 06:52:29 - INFO - Epoch: 11.55, Step: 36590, Train Loss: 1.5155, Learning Rate: 7.49e-05
2025-12-09 06:52:40 - INFO - Epoch: 11.55, Step: 36600, Train Loss: 1.5232, Learning Rate: 7.49e-05
2025-12-09 06:52:52 - INFO - Epoch: 11.55, Step: 36610, Train Loss: 1.5027, Learning Rate: 7.49e-05
2025-12-09 06:53:03 - INFO - Epoch: 11.56, Step: 36620, Train Loss: 1.5106, Learning Rate: 7.49e-05
2025-12-09 06:53:14 - INFO - Epoch: 11.56, Step: 36630, Train Loss: 1.5129, Learning Rate: 7.48e-05
2025-12-09 06:53:25 - INFO - Epoch: 11.56, Step: 36640, Train Loss: 1.5039, Learning Rate: 7.48e-05
2025-12-09 06:53:36 - INFO - Epoch: 11.57, Step: 36650, Train Loss: 1.5174, Learning Rate: 7.48e-05
2025-12-09 06:53:47 - INFO - Epoch: 11.57, Step: 36660, Train Loss: 1.5187, Learning Rate: 7.48e-05
2025-12-09 06:53:58 - INFO - Epoch: 11.57, Step: 36670, Train Loss: 1.5162, Learning Rate: 7.48e-05
2025-12-09 06:54:09 - INFO - Epoch: 11.57, Step: 36680, Train Loss: 1.4965, Learning Rate: 7.48e-05
2025-12-09 06:54:20 - INFO - Epoch: 11.58, Step: 36690, Train Loss: 1.5029, Learning Rate: 7.48e-05
2025-12-09 06:54:31 - INFO - Epoch: 11.58, Step: 36700, Train Loss: 1.5434, Learning Rate: 7.48e-05
2025-12-09 06:54:42 - INFO - Epoch: 11.58, Step: 36710, Train Loss: 1.4941, Learning Rate: 7.48e-05
2025-12-09 06:54:53 - INFO - Epoch: 11.59, Step: 36720, Train Loss: 1.5402, Learning Rate: 7.48e-05
2025-12-09 06:55:05 - INFO - Epoch: 11.59, Step: 36730, Train Loss: 1.5548, Learning Rate: 7.48e-05
2025-12-09 06:55:16 - INFO - Epoch: 11.59, Step: 36740, Train Loss: 1.5114, Learning Rate: 7.48e-05
2025-12-09 06:55:27 - INFO - Epoch: 11.60, Step: 36750, Train Loss: 1.5653, Learning Rate: 7.47e-05
2025-12-09 06:55:38 - INFO - Epoch: 11.60, Step: 36760, Train Loss: 1.4967, Learning Rate: 7.47e-05
2025-12-09 06:55:49 - INFO - Epoch: 11.60, Step: 36770, Train Loss: 1.5039, Learning Rate: 7.47e-05
2025-12-09 06:56:00 - INFO - Epoch: 11.61, Step: 36780, Train Loss: 1.5380, Learning Rate: 7.47e-05
2025-12-09 06:56:11 - INFO - Epoch: 11.61, Step: 36790, Train Loss: 1.5281, Learning Rate: 7.47e-05
2025-12-09 06:56:22 - INFO - Epoch: 11.61, Step: 36800, Train Loss: 1.5175, Learning Rate: 7.47e-05
2025-12-09 06:56:33 - INFO - Epoch: 11.62, Step: 36810, Train Loss: 1.5399, Learning Rate: 7.47e-05
2025-12-09 06:56:44 - INFO - Epoch: 11.62, Step: 36820, Train Loss: 1.5276, Learning Rate: 7.47e-05
2025-12-09 06:56:55 - INFO - Epoch: 11.62, Step: 36830, Train Loss: 1.4941, Learning Rate: 7.47e-05
2025-12-09 06:57:06 - INFO - Epoch: 11.63, Step: 36840, Train Loss: 1.5041, Learning Rate: 7.47e-05
2025-12-09 06:57:18 - INFO - Epoch: 11.63, Step: 36850, Train Loss: 1.5060, Learning Rate: 7.47e-05
2025-12-09 06:57:29 - INFO - Epoch: 11.63, Step: 36860, Train Loss: 1.5020, Learning Rate: 7.47e-05
2025-12-09 06:57:40 - INFO - Epoch: 11.63, Step: 36870, Train Loss: 1.5379, Learning Rate: 7.46e-05
2025-12-09 06:57:51 - INFO - Epoch: 11.64, Step: 36880, Train Loss: 1.5178, Learning Rate: 7.46e-05
2025-12-09 06:58:02 - INFO - Epoch: 11.64, Step: 36890, Train Loss: 1.5236, Learning Rate: 7.46e-05
2025-12-09 06:58:13 - INFO - Epoch: 11.64, Step: 36900, Train Loss: 1.5522, Learning Rate: 7.46e-05
2025-12-09 06:58:24 - INFO - Epoch: 11.65, Step: 36910, Train Loss: 1.5381, Learning Rate: 7.46e-05
2025-12-09 06:58:35 - INFO - Epoch: 11.65, Step: 36920, Train Loss: 1.5318, Learning Rate: 7.46e-05
2025-12-09 06:58:46 - INFO - Epoch: 11.65, Step: 36930, Train Loss: 1.5224, Learning Rate: 7.46e-05
2025-12-09 06:58:57 - INFO - Epoch: 11.66, Step: 36940, Train Loss: 1.4861, Learning Rate: 7.46e-05
2025-12-09 06:59:08 - INFO - Epoch: 11.66, Step: 36950, Train Loss: 1.5172, Learning Rate: 7.46e-05
2025-12-09 06:59:19 - INFO - Epoch: 11.66, Step: 36960, Train Loss: 1.5298, Learning Rate: 7.46e-05
2025-12-09 06:59:31 - INFO - Epoch: 11.67, Step: 36970, Train Loss: 1.5190, Learning Rate: 7.46e-05
2025-12-09 06:59:42 - INFO - Epoch: 11.67, Step: 36980, Train Loss: 1.5004, Learning Rate: 7.46e-05
2025-12-09 06:59:53 - INFO - Epoch: 11.67, Step: 36990, Train Loss: 1.5448, Learning Rate: 7.45e-05
2025-12-09 07:00:04 - INFO - Epoch: 11.68, Step: 37000, Train Loss: 1.5365, Learning Rate: 7.45e-05
2025-12-09 07:00:15 - INFO - Epoch: 11.68, Step: 37010, Train Loss: 1.5268, Learning Rate: 7.45e-05
2025-12-09 07:00:26 - INFO - Epoch: 11.68, Step: 37020, Train Loss: 1.4908, Learning Rate: 7.45e-05
2025-12-09 07:00:37 - INFO - Epoch: 11.69, Step: 37030, Train Loss: 1.4698, Learning Rate: 7.45e-05
2025-12-09 07:00:48 - INFO - Epoch: 11.69, Step: 37040, Train Loss: 1.5301, Learning Rate: 7.45e-05
2025-12-09 07:00:59 - INFO - Epoch: 11.69, Step: 37050, Train Loss: 1.5266, Learning Rate: 7.45e-05
2025-12-09 07:01:10 - INFO - Epoch: 11.69, Step: 37060, Train Loss: 1.4940, Learning Rate: 7.45e-05
2025-12-09 07:01:21 - INFO - Epoch: 11.70, Step: 37070, Train Loss: 1.5414, Learning Rate: 7.45e-05
2025-12-09 07:01:32 - INFO - Epoch: 11.70, Step: 37080, Train Loss: 1.5214, Learning Rate: 7.45e-05
2025-12-09 07:01:44 - INFO - Epoch: 11.70, Step: 37090, Train Loss: 1.5403, Learning Rate: 7.45e-05
2025-12-09 07:01:55 - INFO - Epoch: 11.71, Step: 37100, Train Loss: 1.5184, Learning Rate: 7.45e-05
2025-12-09 07:02:06 - INFO - Epoch: 11.71, Step: 37110, Train Loss: 1.5133, Learning Rate: 7.44e-05
2025-12-09 07:02:17 - INFO - Epoch: 11.71, Step: 37120, Train Loss: 1.5284, Learning Rate: 7.44e-05
2025-12-09 07:02:28 - INFO - Epoch: 11.72, Step: 37130, Train Loss: 1.5260, Learning Rate: 7.44e-05
2025-12-09 07:02:39 - INFO - Epoch: 11.72, Step: 37140, Train Loss: 1.5088, Learning Rate: 7.44e-05
2025-12-09 07:02:50 - INFO - Epoch: 11.72, Step: 37150, Train Loss: 1.5128, Learning Rate: 7.44e-05
2025-12-09 07:03:01 - INFO - Epoch: 11.73, Step: 37160, Train Loss: 1.4640, Learning Rate: 7.44e-05
2025-12-09 07:03:12 - INFO - Epoch: 11.73, Step: 37170, Train Loss: 1.5699, Learning Rate: 7.44e-05
2025-12-09 07:03:23 - INFO - Epoch: 11.73, Step: 37180, Train Loss: 1.5286, Learning Rate: 7.44e-05
2025-12-09 07:03:34 - INFO - Epoch: 11.74, Step: 37190, Train Loss: 1.5132, Learning Rate: 7.44e-05
2025-12-09 07:03:45 - INFO - Epoch: 11.74, Step: 37200, Train Loss: 1.5148, Learning Rate: 7.44e-05
2025-12-09 07:03:56 - INFO - Epoch: 11.74, Step: 37210, Train Loss: 1.5277, Learning Rate: 7.44e-05
2025-12-09 07:04:08 - INFO - Epoch: 11.75, Step: 37220, Train Loss: 1.5091, Learning Rate: 7.44e-05
2025-12-09 07:04:19 - INFO - Epoch: 11.75, Step: 37230, Train Loss: 1.5150, Learning Rate: 7.43e-05
2025-12-09 07:04:30 - INFO - Epoch: 11.75, Step: 37240, Train Loss: 1.5146, Learning Rate: 7.43e-05
2025-12-09 07:04:41 - INFO - Epoch: 11.75, Step: 37250, Train Loss: 1.5257, Learning Rate: 7.43e-05
2025-12-09 07:04:52 - INFO - Epoch: 11.76, Step: 37260, Train Loss: 1.5346, Learning Rate: 7.43e-05
2025-12-09 07:05:03 - INFO - Epoch: 11.76, Step: 37270, Train Loss: 1.4881, Learning Rate: 7.43e-05
2025-12-09 07:05:14 - INFO - Epoch: 11.76, Step: 37280, Train Loss: 1.5453, Learning Rate: 7.43e-05
2025-12-09 07:05:25 - INFO - Epoch: 11.77, Step: 37290, Train Loss: 1.4816, Learning Rate: 7.43e-05
2025-12-09 07:05:36 - INFO - Epoch: 11.77, Step: 37300, Train Loss: 1.4767, Learning Rate: 7.43e-05
2025-12-09 07:05:47 - INFO - Epoch: 11.77, Step: 37310, Train Loss: 1.5080, Learning Rate: 7.43e-05
2025-12-09 07:05:58 - INFO - Epoch: 11.78, Step: 37320, Train Loss: 1.5315, Learning Rate: 7.43e-05
2025-12-09 07:06:09 - INFO - Epoch: 11.78, Step: 37330, Train Loss: 1.5280, Learning Rate: 7.43e-05
2025-12-09 07:06:21 - INFO - Epoch: 11.78, Step: 37340, Train Loss: 1.5038, Learning Rate: 7.43e-05
2025-12-09 07:06:32 - INFO - Epoch: 11.79, Step: 37350, Train Loss: 1.5524, Learning Rate: 7.42e-05
2025-12-09 07:06:43 - INFO - Epoch: 11.79, Step: 37360, Train Loss: 1.4934, Learning Rate: 7.42e-05
2025-12-09 07:06:54 - INFO - Epoch: 11.79, Step: 37370, Train Loss: 1.5028, Learning Rate: 7.42e-05
2025-12-09 07:07:05 - INFO - Epoch: 11.80, Step: 37380, Train Loss: 1.5171, Learning Rate: 7.42e-05
2025-12-09 07:07:16 - INFO - Epoch: 11.80, Step: 37390, Train Loss: 1.4935, Learning Rate: 7.42e-05
2025-12-09 07:07:27 - INFO - Epoch: 11.80, Step: 37400, Train Loss: 1.4810, Learning Rate: 7.42e-05
2025-12-09 07:07:38 - INFO - Epoch: 11.80, Step: 37410, Train Loss: 1.5137, Learning Rate: 7.42e-05
2025-12-09 07:07:49 - INFO - Epoch: 11.81, Step: 37420, Train Loss: 1.5582, Learning Rate: 7.42e-05
2025-12-09 07:08:00 - INFO - Epoch: 11.81, Step: 37430, Train Loss: 1.4828, Learning Rate: 7.42e-05
2025-12-09 07:08:11 - INFO - Epoch: 11.81, Step: 37440, Train Loss: 1.4793, Learning Rate: 7.42e-05
2025-12-09 07:08:22 - INFO - Epoch: 11.82, Step: 37450, Train Loss: 1.5230, Learning Rate: 7.42e-05
2025-12-09 07:08:34 - INFO - Epoch: 11.82, Step: 37460, Train Loss: 1.5326, Learning Rate: 7.42e-05
2025-12-09 07:08:45 - INFO - Epoch: 11.82, Step: 37470, Train Loss: 1.5300, Learning Rate: 7.41e-05
2025-12-09 07:08:56 - INFO - Epoch: 11.83, Step: 37480, Train Loss: 1.4808, Learning Rate: 7.41e-05
2025-12-09 07:09:07 - INFO - Epoch: 11.83, Step: 37490, Train Loss: 1.5128, Learning Rate: 7.41e-05
2025-12-09 07:09:18 - INFO - Epoch: 11.83, Step: 37500, Train Loss: 1.5037, Learning Rate: 7.41e-05
2025-12-09 07:09:29 - INFO - Epoch: 11.84, Step: 37510, Train Loss: 1.4942, Learning Rate: 7.41e-05
2025-12-09 07:09:40 - INFO - Epoch: 11.84, Step: 37520, Train Loss: 1.5237, Learning Rate: 7.41e-05
2025-12-09 07:09:51 - INFO - Epoch: 11.84, Step: 37530, Train Loss: 1.5122, Learning Rate: 7.41e-05
2025-12-09 07:10:02 - INFO - Epoch: 11.85, Step: 37540, Train Loss: 1.5061, Learning Rate: 7.41e-05
2025-12-09 07:10:13 - INFO - Epoch: 11.85, Step: 37550, Train Loss: 1.5133, Learning Rate: 7.41e-05
2025-12-09 07:10:24 - INFO - Epoch: 11.85, Step: 37560, Train Loss: 1.5139, Learning Rate: 7.41e-05
2025-12-09 07:10:35 - INFO - Epoch: 11.86, Step: 37570, Train Loss: 1.5018, Learning Rate: 7.41e-05
2025-12-09 07:10:47 - INFO - Epoch: 11.86, Step: 37580, Train Loss: 1.5243, Learning Rate: 7.41e-05
2025-12-09 07:10:58 - INFO - Epoch: 11.86, Step: 37590, Train Loss: 1.4711, Learning Rate: 7.40e-05
2025-12-09 07:11:09 - INFO - Epoch: 11.86, Step: 37600, Train Loss: 1.5345, Learning Rate: 7.40e-05
2025-12-09 07:11:20 - INFO - Epoch: 11.87, Step: 37610, Train Loss: 1.4844, Learning Rate: 7.40e-05
2025-12-09 07:11:31 - INFO - Epoch: 11.87, Step: 37620, Train Loss: 1.5240, Learning Rate: 7.40e-05
2025-12-09 07:11:42 - INFO - Epoch: 11.87, Step: 37630, Train Loss: 1.5339, Learning Rate: 7.40e-05
2025-12-09 07:11:53 - INFO - Epoch: 11.88, Step: 37640, Train Loss: 1.4873, Learning Rate: 7.40e-05
2025-12-09 07:12:04 - INFO - Epoch: 11.88, Step: 37650, Train Loss: 1.5218, Learning Rate: 7.40e-05
2025-12-09 07:12:15 - INFO - Epoch: 11.88, Step: 37660, Train Loss: 1.4876, Learning Rate: 7.40e-05
2025-12-09 07:12:26 - INFO - Epoch: 11.89, Step: 37670, Train Loss: 1.5305, Learning Rate: 7.40e-05
2025-12-09 07:12:37 - INFO - Epoch: 11.89, Step: 37680, Train Loss: 1.4890, Learning Rate: 7.40e-05
2025-12-09 07:12:48 - INFO - Epoch: 11.89, Step: 37690, Train Loss: 1.5177, Learning Rate: 7.40e-05
2025-12-09 07:12:59 - INFO - Epoch: 11.90, Step: 37700, Train Loss: 1.5062, Learning Rate: 7.40e-05
2025-12-09 07:13:11 - INFO - Epoch: 11.90, Step: 37710, Train Loss: 1.4725, Learning Rate: 7.39e-05
2025-12-09 07:13:22 - INFO - Epoch: 11.90, Step: 37720, Train Loss: 1.5063, Learning Rate: 7.39e-05
2025-12-09 07:13:33 - INFO - Epoch: 11.91, Step: 37730, Train Loss: 1.5033, Learning Rate: 7.39e-05
2025-12-09 07:13:44 - INFO - Epoch: 11.91, Step: 37740, Train Loss: 1.4609, Learning Rate: 7.39e-05
2025-12-09 07:13:55 - INFO - Epoch: 11.91, Step: 37750, Train Loss: 1.5209, Learning Rate: 7.39e-05
2025-12-09 07:14:06 - INFO - Epoch: 11.92, Step: 37760, Train Loss: 1.5572, Learning Rate: 7.39e-05
2025-12-09 07:14:17 - INFO - Epoch: 11.92, Step: 37770, Train Loss: 1.4606, Learning Rate: 7.39e-05
2025-12-09 07:14:28 - INFO - Epoch: 11.92, Step: 37780, Train Loss: 1.5126, Learning Rate: 7.39e-05
2025-12-09 07:14:39 - INFO - Epoch: 11.92, Step: 37790, Train Loss: 1.5121, Learning Rate: 7.39e-05
2025-12-09 07:14:50 - INFO - Epoch: 11.93, Step: 37800, Train Loss: 1.5499, Learning Rate: 7.39e-05
2025-12-09 07:15:01 - INFO - Epoch: 11.93, Step: 37810, Train Loss: 1.5031, Learning Rate: 7.39e-05
2025-12-09 07:15:12 - INFO - Epoch: 11.93, Step: 37820, Train Loss: 1.5055, Learning Rate: 7.39e-05
2025-12-09 07:15:24 - INFO - Epoch: 11.94, Step: 37830, Train Loss: 1.5159, Learning Rate: 7.38e-05
2025-12-09 07:15:35 - INFO - Epoch: 11.94, Step: 37840, Train Loss: 1.4857, Learning Rate: 7.38e-05
2025-12-09 07:15:46 - INFO - Epoch: 11.94, Step: 37850, Train Loss: 1.5266, Learning Rate: 7.38e-05
2025-12-09 07:15:57 - INFO - Epoch: 11.95, Step: 37860, Train Loss: 1.5034, Learning Rate: 7.38e-05
2025-12-09 07:16:08 - INFO - Epoch: 11.95, Step: 37870, Train Loss: 1.5068, Learning Rate: 7.38e-05
2025-12-09 07:16:19 - INFO - Epoch: 11.95, Step: 37880, Train Loss: 1.5070, Learning Rate: 7.38e-05
2025-12-09 07:16:30 - INFO - Epoch: 11.96, Step: 37890, Train Loss: 1.5391, Learning Rate: 7.38e-05
2025-12-09 07:16:41 - INFO - Epoch: 11.96, Step: 37900, Train Loss: 1.4899, Learning Rate: 7.38e-05
2025-12-09 07:16:52 - INFO - Epoch: 11.96, Step: 37910, Train Loss: 1.5253, Learning Rate: 7.38e-05
2025-12-09 07:17:03 - INFO - Epoch: 11.97, Step: 37920, Train Loss: 1.5234, Learning Rate: 7.38e-05
2025-12-09 07:17:14 - INFO - Epoch: 11.97, Step: 37930, Train Loss: 1.5224, Learning Rate: 7.38e-05
2025-12-09 07:17:25 - INFO - Epoch: 11.97, Step: 37940, Train Loss: 1.5007, Learning Rate: 7.38e-05
2025-12-09 07:17:37 - INFO - Epoch: 11.98, Step: 37950, Train Loss: 1.5183, Learning Rate: 7.37e-05
2025-12-09 07:17:48 - INFO - Epoch: 11.98, Step: 37960, Train Loss: 1.4900, Learning Rate: 7.37e-05
2025-12-09 07:17:59 - INFO - Epoch: 11.98, Step: 37970, Train Loss: 1.4826, Learning Rate: 7.37e-05
2025-12-09 07:18:10 - INFO - Epoch: 11.98, Step: 37980, Train Loss: 1.4672, Learning Rate: 7.37e-05
2025-12-09 07:18:21 - INFO - Epoch: 11.99, Step: 37990, Train Loss: 1.5178, Learning Rate: 7.37e-05
2025-12-09 07:18:32 - INFO - Epoch: 11.99, Step: 38000, Train Loss: 1.5280, Learning Rate: 7.37e-05
2025-12-09 07:18:43 - INFO - Epoch: 11.99, Step: 38010, Train Loss: 1.5108, Learning Rate: 7.37e-05
2025-12-09 07:18:54 - INFO - Epoch: 12.00, Step: 38020, Train Loss: 1.5104, Learning Rate: 7.37e-05
2025-12-09 07:19:05 - INFO - Epoch: 12.00, Step: 38030, Train Loss: 1.4919, Learning Rate: 7.37e-05
2025-12-09 07:19:16 - INFO - Epoch: 12.00, Step: 38040, Train Loss: 1.5235, Learning Rate: 7.37e-05
2025-12-09 07:19:27 - INFO - Epoch: 12.01, Step: 38050, Train Loss: 1.5174, Learning Rate: 7.37e-05
2025-12-09 07:19:38 - INFO - Epoch: 12.01, Step: 38060, Train Loss: 1.5043, Learning Rate: 7.37e-05
2025-12-09 07:19:50 - INFO - Epoch: 12.01, Step: 38070, Train Loss: 1.5049, Learning Rate: 7.37e-05
2025-12-09 07:20:01 - INFO - Epoch: 12.02, Step: 38080, Train Loss: 1.4803, Learning Rate: 7.36e-05
2025-12-09 07:20:12 - INFO - Epoch: 12.02, Step: 38090, Train Loss: 1.4731, Learning Rate: 7.36e-05
2025-12-09 07:20:23 - INFO - Epoch: 12.02, Step: 38100, Train Loss: 1.5289, Learning Rate: 7.36e-05
2025-12-09 07:20:34 - INFO - Epoch: 12.03, Step: 38110, Train Loss: 1.5147, Learning Rate: 7.36e-05
2025-12-09 07:20:45 - INFO - Epoch: 12.03, Step: 38120, Train Loss: 1.5063, Learning Rate: 7.36e-05
2025-12-09 07:20:56 - INFO - Epoch: 12.03, Step: 38130, Train Loss: 1.5095, Learning Rate: 7.36e-05
2025-12-09 07:21:07 - INFO - Epoch: 12.04, Step: 38140, Train Loss: 1.4999, Learning Rate: 7.36e-05
2025-12-09 07:21:18 - INFO - Epoch: 12.04, Step: 38150, Train Loss: 1.5010, Learning Rate: 7.36e-05
2025-12-09 07:21:29 - INFO - Epoch: 12.04, Step: 38160, Train Loss: 1.4913, Learning Rate: 7.36e-05
2025-12-09 07:21:40 - INFO - Epoch: 12.04, Step: 38170, Train Loss: 1.4895, Learning Rate: 7.36e-05
2025-12-09 07:21:51 - INFO - Epoch: 12.05, Step: 38180, Train Loss: 1.5534, Learning Rate: 7.36e-05
2025-12-09 07:22:02 - INFO - Epoch: 12.05, Step: 38190, Train Loss: 1.4860, Learning Rate: 7.36e-05
2025-12-09 07:22:14 - INFO - Epoch: 12.05, Step: 38200, Train Loss: 1.5047, Learning Rate: 7.35e-05
2025-12-09 07:22:25 - INFO - Epoch: 12.06, Step: 38210, Train Loss: 1.4978, Learning Rate: 7.35e-05
2025-12-09 07:22:36 - INFO - Epoch: 12.06, Step: 38220, Train Loss: 1.5207, Learning Rate: 7.35e-05
2025-12-09 07:22:47 - INFO - Epoch: 12.06, Step: 38230, Train Loss: 1.5016, Learning Rate: 7.35e-05
2025-12-09 07:22:58 - INFO - Epoch: 12.07, Step: 38240, Train Loss: 1.5223, Learning Rate: 7.35e-05
2025-12-09 07:23:09 - INFO - Epoch: 12.07, Step: 38250, Train Loss: 1.4820, Learning Rate: 7.35e-05
2025-12-09 07:23:20 - INFO - Epoch: 12.07, Step: 38260, Train Loss: 1.4866, Learning Rate: 7.35e-05
2025-12-09 07:23:31 - INFO - Epoch: 12.08, Step: 38270, Train Loss: 1.5426, Learning Rate: 7.35e-05
2025-12-09 07:23:42 - INFO - Epoch: 12.08, Step: 38280, Train Loss: 1.5032, Learning Rate: 7.35e-05
2025-12-09 07:23:53 - INFO - Epoch: 12.08, Step: 38290, Train Loss: 1.5209, Learning Rate: 7.35e-05
2025-12-09 07:24:04 - INFO - Epoch: 12.09, Step: 38300, Train Loss: 1.5041, Learning Rate: 7.35e-05
2025-12-09 07:24:15 - INFO - Epoch: 12.09, Step: 38310, Train Loss: 1.4986, Learning Rate: 7.35e-05
2025-12-09 07:24:27 - INFO - Epoch: 12.09, Step: 38320, Train Loss: 1.5129, Learning Rate: 7.34e-05
2025-12-09 07:24:38 - INFO - Epoch: 12.10, Step: 38330, Train Loss: 1.4796, Learning Rate: 7.34e-05
2025-12-09 07:24:49 - INFO - Epoch: 12.10, Step: 38340, Train Loss: 1.4987, Learning Rate: 7.34e-05
2025-12-09 07:25:00 - INFO - Epoch: 12.10, Step: 38350, Train Loss: 1.4942, Learning Rate: 7.34e-05
2025-12-09 07:25:11 - INFO - Epoch: 12.10, Step: 38360, Train Loss: 1.5266, Learning Rate: 7.34e-05
2025-12-09 07:25:22 - INFO - Epoch: 12.11, Step: 38370, Train Loss: 1.4929, Learning Rate: 7.34e-05
2025-12-09 07:25:33 - INFO - Epoch: 12.11, Step: 38380, Train Loss: 1.5097, Learning Rate: 7.34e-05
2025-12-09 07:25:44 - INFO - Epoch: 12.11, Step: 38390, Train Loss: 1.4896, Learning Rate: 7.34e-05
2025-12-09 07:25:55 - INFO - Epoch: 12.12, Step: 38400, Train Loss: 1.4929, Learning Rate: 7.34e-05
2025-12-09 07:26:06 - INFO - Epoch: 12.12, Step: 38410, Train Loss: 1.4997, Learning Rate: 7.34e-05
2025-12-09 07:26:17 - INFO - Epoch: 12.12, Step: 38420, Train Loss: 1.4961, Learning Rate: 7.34e-05
2025-12-09 07:26:28 - INFO - Epoch: 12.13, Step: 38430, Train Loss: 1.5367, Learning Rate: 7.34e-05
2025-12-09 07:26:40 - INFO - Epoch: 12.13, Step: 38440, Train Loss: 1.5023, Learning Rate: 7.33e-05
2025-12-09 07:26:51 - INFO - Epoch: 12.13, Step: 38450, Train Loss: 1.5363, Learning Rate: 7.33e-05
2025-12-09 07:27:02 - INFO - Epoch: 12.14, Step: 38460, Train Loss: 1.4766, Learning Rate: 7.33e-05
2025-12-09 07:27:13 - INFO - Epoch: 12.14, Step: 38470, Train Loss: 1.4951, Learning Rate: 7.33e-05
2025-12-09 07:27:24 - INFO - Epoch: 12.14, Step: 38480, Train Loss: 1.5369, Learning Rate: 7.33e-05
2025-12-09 07:27:35 - INFO - Epoch: 12.15, Step: 38490, Train Loss: 1.5256, Learning Rate: 7.33e-05
2025-12-09 07:27:46 - INFO - Epoch: 12.15, Step: 38500, Train Loss: 1.4752, Learning Rate: 7.33e-05
2025-12-09 07:27:57 - INFO - Epoch: 12.15, Step: 38510, Train Loss: 1.4852, Learning Rate: 7.33e-05
2025-12-09 07:28:08 - INFO - Epoch: 12.16, Step: 38520, Train Loss: 1.5074, Learning Rate: 7.33e-05
2025-12-09 07:28:19 - INFO - Epoch: 12.16, Step: 38530, Train Loss: 1.4995, Learning Rate: 7.33e-05
2025-12-09 07:28:30 - INFO - Epoch: 12.16, Step: 38540, Train Loss: 1.5106, Learning Rate: 7.33e-05
2025-12-09 07:28:41 - INFO - Epoch: 12.16, Step: 38550, Train Loss: 1.4706, Learning Rate: 7.33e-05
2025-12-09 07:28:52 - INFO - Epoch: 12.17, Step: 38560, Train Loss: 1.4991, Learning Rate: 7.32e-05
2025-12-09 07:29:04 - INFO - Epoch: 12.17, Step: 38570, Train Loss: 1.5140, Learning Rate: 7.32e-05
2025-12-09 07:29:15 - INFO - Epoch: 12.17, Step: 38580, Train Loss: 1.4814, Learning Rate: 7.32e-05
2025-12-09 07:29:26 - INFO - Epoch: 12.18, Step: 38590, Train Loss: 1.4559, Learning Rate: 7.32e-05
2025-12-09 07:29:37 - INFO - Epoch: 12.18, Step: 38600, Train Loss: 1.5157, Learning Rate: 7.32e-05
2025-12-09 07:29:48 - INFO - Epoch: 12.18, Step: 38610, Train Loss: 1.5157, Learning Rate: 7.32e-05
2025-12-09 07:29:59 - INFO - Epoch: 12.19, Step: 38620, Train Loss: 1.5140, Learning Rate: 7.32e-05
2025-12-09 07:30:10 - INFO - Epoch: 12.19, Step: 38630, Train Loss: 1.4774, Learning Rate: 7.32e-05
2025-12-09 07:30:21 - INFO - Epoch: 12.19, Step: 38640, Train Loss: 1.5610, Learning Rate: 7.32e-05
2025-12-09 07:30:32 - INFO - Epoch: 12.20, Step: 38650, Train Loss: 1.5277, Learning Rate: 7.32e-05
2025-12-09 07:30:43 - INFO - Epoch: 12.20, Step: 38660, Train Loss: 1.4937, Learning Rate: 7.32e-05
2025-12-09 07:30:54 - INFO - Epoch: 12.20, Step: 38670, Train Loss: 1.4673, Learning Rate: 7.32e-05
2025-12-09 07:31:05 - INFO - Epoch: 12.21, Step: 38680, Train Loss: 1.4695, Learning Rate: 7.31e-05
2025-12-09 07:31:17 - INFO - Epoch: 12.21, Step: 38690, Train Loss: 1.4996, Learning Rate: 7.31e-05
2025-12-09 07:31:28 - INFO - Epoch: 12.21, Step: 38700, Train Loss: 1.4896, Learning Rate: 7.31e-05
2025-12-09 07:31:39 - INFO - Epoch: 12.22, Step: 38710, Train Loss: 1.5234, Learning Rate: 7.31e-05
2025-12-09 07:31:50 - INFO - Epoch: 12.22, Step: 38720, Train Loss: 1.4399, Learning Rate: 7.31e-05
2025-12-09 07:32:01 - INFO - Epoch: 12.22, Step: 38730, Train Loss: 1.4677, Learning Rate: 7.31e-05
2025-12-09 07:32:12 - INFO - Epoch: 12.22, Step: 38740, Train Loss: 1.4884, Learning Rate: 7.31e-05
2025-12-09 07:32:23 - INFO - Epoch: 12.23, Step: 38750, Train Loss: 1.4992, Learning Rate: 7.31e-05
2025-12-09 07:32:34 - INFO - Epoch: 12.23, Step: 38760, Train Loss: 1.5184, Learning Rate: 7.31e-05
2025-12-09 07:32:45 - INFO - Epoch: 12.23, Step: 38770, Train Loss: 1.4136, Learning Rate: 7.31e-05
2025-12-09 07:32:56 - INFO - Epoch: 12.24, Step: 38780, Train Loss: 1.5026, Learning Rate: 7.31e-05
2025-12-09 07:33:07 - INFO - Epoch: 12.24, Step: 38790, Train Loss: 1.4879, Learning Rate: 7.31e-05
2025-12-09 07:33:18 - INFO - Epoch: 12.24, Step: 38800, Train Loss: 1.4940, Learning Rate: 7.30e-05
2025-12-09 07:33:30 - INFO - Epoch: 12.25, Step: 38810, Train Loss: 1.4680, Learning Rate: 7.30e-05
2025-12-09 07:33:41 - INFO - Epoch: 12.25, Step: 38820, Train Loss: 1.5051, Learning Rate: 7.30e-05
2025-12-09 07:33:52 - INFO - Epoch: 12.25, Step: 38830, Train Loss: 1.4553, Learning Rate: 7.30e-05
2025-12-09 07:34:03 - INFO - Epoch: 12.26, Step: 38840, Train Loss: 1.5113, Learning Rate: 7.30e-05
2025-12-09 07:34:14 - INFO - Epoch: 12.26, Step: 38850, Train Loss: 1.4906, Learning Rate: 7.30e-05
2025-12-09 07:34:25 - INFO - Epoch: 12.26, Step: 38860, Train Loss: 1.4914, Learning Rate: 7.30e-05
2025-12-09 07:34:36 - INFO - Epoch: 12.27, Step: 38870, Train Loss: 1.4663, Learning Rate: 7.30e-05
2025-12-09 07:34:47 - INFO - Epoch: 12.27, Step: 38880, Train Loss: 1.5118, Learning Rate: 7.30e-05
2025-12-09 07:34:58 - INFO - Epoch: 12.27, Step: 38890, Train Loss: 1.4565, Learning Rate: 7.30e-05
2025-12-09 07:35:09 - INFO - Epoch: 12.28, Step: 38900, Train Loss: 1.4924, Learning Rate: 7.30e-05
2025-12-09 07:35:20 - INFO - Epoch: 12.28, Step: 38910, Train Loss: 1.5032, Learning Rate: 7.30e-05
2025-12-09 07:35:31 - INFO - Epoch: 12.28, Step: 38920, Train Loss: 1.5307, Learning Rate: 7.29e-05
2025-12-09 07:35:42 - INFO - Epoch: 12.28, Step: 38930, Train Loss: 1.4694, Learning Rate: 7.29e-05
2025-12-09 07:35:54 - INFO - Epoch: 12.29, Step: 38940, Train Loss: 1.4587, Learning Rate: 7.29e-05
2025-12-09 07:36:05 - INFO - Epoch: 12.29, Step: 38950, Train Loss: 1.4800, Learning Rate: 7.29e-05
2025-12-09 07:36:16 - INFO - Epoch: 12.29, Step: 38960, Train Loss: 1.5154, Learning Rate: 7.29e-05
2025-12-09 07:36:27 - INFO - Epoch: 12.30, Step: 38970, Train Loss: 1.5144, Learning Rate: 7.29e-05
2025-12-09 07:36:38 - INFO - Epoch: 12.30, Step: 38980, Train Loss: 1.4780, Learning Rate: 7.29e-05
2025-12-09 07:36:49 - INFO - Epoch: 12.30, Step: 38990, Train Loss: 1.5201, Learning Rate: 7.29e-05
2025-12-09 07:37:00 - INFO - Epoch: 12.31, Step: 39000, Train Loss: 1.4945, Learning Rate: 7.29e-05
2025-12-09 07:37:11 - INFO - Epoch: 12.31, Step: 39010, Train Loss: 1.4678, Learning Rate: 7.29e-05
2025-12-09 07:37:22 - INFO - Epoch: 12.31, Step: 39020, Train Loss: 1.4991, Learning Rate: 7.29e-05
2025-12-09 07:37:33 - INFO - Epoch: 12.32, Step: 39030, Train Loss: 1.4798, Learning Rate: 7.29e-05
2025-12-09 07:37:44 - INFO - Epoch: 12.32, Step: 39040, Train Loss: 1.4543, Learning Rate: 7.28e-05
2025-12-09 07:37:55 - INFO - Epoch: 12.32, Step: 39050, Train Loss: 1.4821, Learning Rate: 7.28e-05
2025-12-09 07:38:07 - INFO - Epoch: 12.33, Step: 39060, Train Loss: 1.5001, Learning Rate: 7.28e-05
2025-12-09 07:38:18 - INFO - Epoch: 12.33, Step: 39070, Train Loss: 1.5253, Learning Rate: 7.28e-05
2025-12-09 07:38:29 - INFO - Epoch: 12.33, Step: 39080, Train Loss: 1.5079, Learning Rate: 7.28e-05
2025-12-09 07:38:40 - INFO - Epoch: 12.34, Step: 39090, Train Loss: 1.5051, Learning Rate: 7.28e-05
2025-12-09 07:38:51 - INFO - Epoch: 12.34, Step: 39100, Train Loss: 1.5208, Learning Rate: 7.28e-05
2025-12-09 07:39:02 - INFO - Epoch: 12.34, Step: 39110, Train Loss: 1.4517, Learning Rate: 7.28e-05
2025-12-09 07:39:13 - INFO - Epoch: 12.34, Step: 39120, Train Loss: 1.5120, Learning Rate: 7.28e-05
2025-12-09 07:39:24 - INFO - Epoch: 12.35, Step: 39130, Train Loss: 1.5079, Learning Rate: 7.28e-05
2025-12-09 07:39:35 - INFO - Epoch: 12.35, Step: 39140, Train Loss: 1.4793, Learning Rate: 7.28e-05
2025-12-09 07:39:46 - INFO - Epoch: 12.35, Step: 39150, Train Loss: 1.4742, Learning Rate: 7.28e-05
2025-12-09 07:39:57 - INFO - Epoch: 12.36, Step: 39160, Train Loss: 1.4799, Learning Rate: 7.27e-05
2025-12-09 07:40:08 - INFO - Epoch: 12.36, Step: 39170, Train Loss: 1.4886, Learning Rate: 7.27e-05
2025-12-09 07:40:20 - INFO - Epoch: 12.36, Step: 39180, Train Loss: 1.4890, Learning Rate: 7.27e-05
2025-12-09 07:40:31 - INFO - Epoch: 12.37, Step: 39190, Train Loss: 1.5041, Learning Rate: 7.27e-05
2025-12-09 07:40:42 - INFO - Epoch: 12.37, Step: 39200, Train Loss: 1.5056, Learning Rate: 7.27e-05
2025-12-09 07:40:53 - INFO - Epoch: 12.37, Step: 39210, Train Loss: 1.5273, Learning Rate: 7.27e-05
2025-12-09 07:41:04 - INFO - Epoch: 12.38, Step: 39220, Train Loss: 1.5191, Learning Rate: 7.27e-05
2025-12-09 07:41:15 - INFO - Epoch: 12.38, Step: 39230, Train Loss: 1.4767, Learning Rate: 7.27e-05
2025-12-09 07:41:26 - INFO - Epoch: 12.38, Step: 39240, Train Loss: 1.5015, Learning Rate: 7.27e-05
2025-12-09 07:41:37 - INFO - Epoch: 12.39, Step: 39250, Train Loss: 1.4958, Learning Rate: 7.27e-05
2025-12-09 07:41:48 - INFO - Epoch: 12.39, Step: 39260, Train Loss: 1.4995, Learning Rate: 7.27e-05
2025-12-09 07:41:59 - INFO - Epoch: 12.39, Step: 39270, Train Loss: 1.5020, Learning Rate: 7.27e-05
2025-12-09 07:42:10 - INFO - Epoch: 12.40, Step: 39280, Train Loss: 1.4888, Learning Rate: 7.26e-05
2025-12-09 07:42:21 - INFO - Epoch: 12.40, Step: 39290, Train Loss: 1.4790, Learning Rate: 7.26e-05
2025-12-09 07:42:32 - INFO - Epoch: 12.40, Step: 39300, Train Loss: 1.4866, Learning Rate: 7.26e-05
2025-12-09 07:42:44 - INFO - Epoch: 12.40, Step: 39310, Train Loss: 1.4977, Learning Rate: 7.26e-05
2025-12-09 07:42:55 - INFO - Epoch: 12.41, Step: 39320, Train Loss: 1.4632, Learning Rate: 7.26e-05
2025-12-09 07:43:06 - INFO - Epoch: 12.41, Step: 39330, Train Loss: 1.4993, Learning Rate: 7.26e-05
2025-12-09 07:43:17 - INFO - Epoch: 12.41, Step: 39340, Train Loss: 1.4901, Learning Rate: 7.26e-05
2025-12-09 07:43:28 - INFO - Epoch: 12.42, Step: 39350, Train Loss: 1.5123, Learning Rate: 7.26e-05
2025-12-09 07:43:39 - INFO - Epoch: 12.42, Step: 39360, Train Loss: 1.4834, Learning Rate: 7.26e-05
2025-12-09 07:43:50 - INFO - Epoch: 12.42, Step: 39370, Train Loss: 1.4973, Learning Rate: 7.26e-05
2025-12-09 07:44:01 - INFO - Epoch: 12.43, Step: 39380, Train Loss: 1.4706, Learning Rate: 7.26e-05
2025-12-09 07:44:12 - INFO - Epoch: 12.43, Step: 39390, Train Loss: 1.5211, Learning Rate: 7.26e-05
2025-12-09 07:44:23 - INFO - Epoch: 12.43, Step: 39400, Train Loss: 1.4833, Learning Rate: 7.25e-05
2025-12-09 07:44:34 - INFO - Epoch: 12.44, Step: 39410, Train Loss: 1.5204, Learning Rate: 7.25e-05
2025-12-09 07:44:45 - INFO - Epoch: 12.44, Step: 39420, Train Loss: 1.4651, Learning Rate: 7.25e-05
2025-12-09 07:44:57 - INFO - Epoch: 12.44, Step: 39430, Train Loss: 1.4592, Learning Rate: 7.25e-05
2025-12-09 07:45:08 - INFO - Epoch: 12.45, Step: 39440, Train Loss: 1.4627, Learning Rate: 7.25e-05
2025-12-09 07:45:19 - INFO - Epoch: 12.45, Step: 39450, Train Loss: 1.4966, Learning Rate: 7.25e-05
2025-12-09 07:45:30 - INFO - Epoch: 12.45, Step: 39460, Train Loss: 1.5056, Learning Rate: 7.25e-05
2025-12-09 07:45:41 - INFO - Epoch: 12.46, Step: 39470, Train Loss: 1.4626, Learning Rate: 7.25e-05
2025-12-09 07:45:52 - INFO - Epoch: 12.46, Step: 39480, Train Loss: 1.4794, Learning Rate: 7.25e-05
2025-12-09 07:46:03 - INFO - Epoch: 12.46, Step: 39490, Train Loss: 1.5153, Learning Rate: 7.25e-05
2025-12-09 07:46:14 - INFO - Epoch: 12.46, Step: 39500, Train Loss: 1.4891, Learning Rate: 7.25e-05
2025-12-09 07:46:25 - INFO - Epoch: 12.47, Step: 39510, Train Loss: 1.5110, Learning Rate: 7.25e-05
2025-12-09 07:46:36 - INFO - Epoch: 12.47, Step: 39520, Train Loss: 1.5073, Learning Rate: 7.24e-05
2025-12-09 07:46:47 - INFO - Epoch: 12.47, Step: 39530, Train Loss: 1.4938, Learning Rate: 7.24e-05
2025-12-09 07:46:58 - INFO - Epoch: 12.48, Step: 39540, Train Loss: 1.4701, Learning Rate: 7.24e-05
2025-12-09 07:47:10 - INFO - Epoch: 12.48, Step: 39550, Train Loss: 1.5035, Learning Rate: 7.24e-05
2025-12-09 07:47:21 - INFO - Epoch: 12.48, Step: 39560, Train Loss: 1.4985, Learning Rate: 7.24e-05
2025-12-09 07:47:32 - INFO - Epoch: 12.49, Step: 39570, Train Loss: 1.5063, Learning Rate: 7.24e-05
2025-12-09 07:47:43 - INFO - Epoch: 12.49, Step: 39580, Train Loss: 1.4782, Learning Rate: 7.24e-05
2025-12-09 07:47:54 - INFO - Epoch: 12.49, Step: 39590, Train Loss: 1.4973, Learning Rate: 7.24e-05
2025-12-09 07:48:05 - INFO - Epoch: 12.50, Step: 39600, Train Loss: 1.4965, Learning Rate: 7.24e-05
2025-12-09 07:48:16 - INFO - Epoch: 12.50, Step: 39610, Train Loss: 1.4958, Learning Rate: 7.24e-05
2025-12-09 07:48:27 - INFO - Epoch: 12.50, Step: 39620, Train Loss: 1.4623, Learning Rate: 7.24e-05
2025-12-09 07:48:38 - INFO - Epoch: 12.51, Step: 39630, Train Loss: 1.4454, Learning Rate: 7.24e-05
2025-12-09 07:48:49 - INFO - Epoch: 12.51, Step: 39640, Train Loss: 1.4580, Learning Rate: 7.23e-05
2025-12-09 07:49:00 - INFO - Epoch: 12.51, Step: 39650, Train Loss: 1.4895, Learning Rate: 7.23e-05
2025-12-09 07:49:11 - INFO - Epoch: 12.51, Step: 39660, Train Loss: 1.4697, Learning Rate: 7.23e-05
2025-12-09 07:49:22 - INFO - Epoch: 12.52, Step: 39670, Train Loss: 1.4648, Learning Rate: 7.23e-05
2025-12-09 07:49:34 - INFO - Epoch: 12.52, Step: 39680, Train Loss: 1.4598, Learning Rate: 7.23e-05
2025-12-09 07:49:45 - INFO - Epoch: 12.52, Step: 39690, Train Loss: 1.5040, Learning Rate: 7.23e-05
2025-12-09 07:49:56 - INFO - Epoch: 12.53, Step: 39700, Train Loss: 1.4811, Learning Rate: 7.23e-05
2025-12-09 07:50:07 - INFO - Epoch: 12.53, Step: 39710, Train Loss: 1.4768, Learning Rate: 7.23e-05
2025-12-09 07:50:18 - INFO - Epoch: 12.53, Step: 39720, Train Loss: 1.4895, Learning Rate: 7.23e-05
2025-12-09 07:50:29 - INFO - Epoch: 12.54, Step: 39730, Train Loss: 1.4422, Learning Rate: 7.23e-05
2025-12-09 07:50:40 - INFO - Epoch: 12.54, Step: 39740, Train Loss: 1.4976, Learning Rate: 7.23e-05
2025-12-09 07:50:51 - INFO - Epoch: 12.54, Step: 39750, Train Loss: 1.4819, Learning Rate: 7.23e-05
2025-12-09 07:51:02 - INFO - Epoch: 12.55, Step: 39760, Train Loss: 1.4856, Learning Rate: 7.22e-05
2025-12-09 07:51:13 - INFO - Epoch: 12.55, Step: 39770, Train Loss: 1.5022, Learning Rate: 7.22e-05
2025-12-09 07:51:24 - INFO - Epoch: 12.55, Step: 39780, Train Loss: 1.4943, Learning Rate: 7.22e-05
2025-12-09 07:51:35 - INFO - Epoch: 12.56, Step: 39790, Train Loss: 1.4833, Learning Rate: 7.22e-05
2025-12-09 07:51:47 - INFO - Epoch: 12.56, Step: 39800, Train Loss: 1.4596, Learning Rate: 7.22e-05
2025-12-09 07:51:58 - INFO - Epoch: 12.56, Step: 39810, Train Loss: 1.4679, Learning Rate: 7.22e-05
2025-12-09 07:52:09 - INFO - Epoch: 12.57, Step: 39820, Train Loss: 1.4602, Learning Rate: 7.22e-05
2025-12-09 07:52:20 - INFO - Epoch: 12.57, Step: 39830, Train Loss: 1.4856, Learning Rate: 7.22e-05
2025-12-09 07:52:31 - INFO - Epoch: 12.57, Step: 39840, Train Loss: 1.4914, Learning Rate: 7.22e-05
2025-12-09 07:52:42 - INFO - Epoch: 12.57, Step: 39850, Train Loss: 1.5165, Learning Rate: 7.22e-05
2025-12-09 07:52:53 - INFO - Epoch: 12.58, Step: 39860, Train Loss: 1.4973, Learning Rate: 7.22e-05
2025-12-09 07:53:04 - INFO - Epoch: 12.58, Step: 39870, Train Loss: 1.4869, Learning Rate: 7.22e-05
2025-12-09 07:53:15 - INFO - Epoch: 12.58, Step: 39880, Train Loss: 1.4959, Learning Rate: 7.21e-05
2025-12-09 07:53:26 - INFO - Epoch: 12.59, Step: 39890, Train Loss: 1.5022, Learning Rate: 7.21e-05
2025-12-09 07:53:37 - INFO - Epoch: 12.59, Step: 39900, Train Loss: 1.4865, Learning Rate: 7.21e-05
2025-12-09 07:53:48 - INFO - Epoch: 12.59, Step: 39910, Train Loss: 1.4590, Learning Rate: 7.21e-05
2025-12-09 07:54:00 - INFO - Epoch: 12.60, Step: 39920, Train Loss: 1.4992, Learning Rate: 7.21e-05
2025-12-09 07:54:11 - INFO - Epoch: 12.60, Step: 39930, Train Loss: 1.4788, Learning Rate: 7.21e-05
2025-12-09 07:54:22 - INFO - Epoch: 12.60, Step: 39940, Train Loss: 1.5046, Learning Rate: 7.21e-05
2025-12-09 07:54:33 - INFO - Epoch: 12.61, Step: 39950, Train Loss: 1.4918, Learning Rate: 7.21e-05
2025-12-09 07:54:44 - INFO - Epoch: 12.61, Step: 39960, Train Loss: 1.4610, Learning Rate: 7.21e-05
2025-12-09 07:54:55 - INFO - Epoch: 12.61, Step: 39970, Train Loss: 1.4694, Learning Rate: 7.21e-05
2025-12-09 07:55:06 - INFO - Epoch: 12.62, Step: 39980, Train Loss: 1.4954, Learning Rate: 7.21e-05
2025-12-09 07:55:17 - INFO - Epoch: 12.62, Step: 39990, Train Loss: 1.4984, Learning Rate: 7.21e-05
2025-12-09 07:55:28 - INFO - Epoch: 12.62, Step: 40000, Train Loss: 1.4316, Learning Rate: 7.20e-05
2025-12-09 07:55:39 - INFO - Epoch: 12.63, Step: 40010, Train Loss: 1.4814, Learning Rate: 7.20e-05
2025-12-09 07:55:50 - INFO - Epoch: 12.63, Step: 40020, Train Loss: 1.4624, Learning Rate: 7.20e-05
2025-12-09 07:56:01 - INFO - Epoch: 12.63, Step: 40030, Train Loss: 1.4787, Learning Rate: 7.20e-05
2025-12-09 07:56:12 - INFO - Epoch: 12.63, Step: 40040, Train Loss: 1.4646, Learning Rate: 7.20e-05
2025-12-09 07:56:24 - INFO - Epoch: 12.64, Step: 40050, Train Loss: 1.4810, Learning Rate: 7.20e-05
2025-12-09 07:56:35 - INFO - Epoch: 12.64, Step: 40060, Train Loss: 1.4537, Learning Rate: 7.20e-05
2025-12-09 07:56:46 - INFO - Epoch: 12.64, Step: 40070, Train Loss: 1.4566, Learning Rate: 7.20e-05
2025-12-09 07:56:57 - INFO - Epoch: 12.65, Step: 40080, Train Loss: 1.5067, Learning Rate: 7.20e-05
2025-12-09 07:57:08 - INFO - Epoch: 12.65, Step: 40090, Train Loss: 1.5271, Learning Rate: 7.20e-05
2025-12-09 07:57:19 - INFO - Epoch: 12.65, Step: 40100, Train Loss: 1.4749, Learning Rate: 7.20e-05
2025-12-09 07:57:30 - INFO - Epoch: 12.66, Step: 40110, Train Loss: 1.4872, Learning Rate: 7.20e-05
2025-12-09 07:57:41 - INFO - Epoch: 12.66, Step: 40120, Train Loss: 1.4795, Learning Rate: 7.19e-05
2025-12-09 07:57:52 - INFO - Epoch: 12.66, Step: 40130, Train Loss: 1.4774, Learning Rate: 7.19e-05
2025-12-09 07:58:03 - INFO - Epoch: 12.67, Step: 40140, Train Loss: 1.4864, Learning Rate: 7.19e-05
2025-12-09 07:58:14 - INFO - Epoch: 12.67, Step: 40150, Train Loss: 1.4440, Learning Rate: 7.19e-05
2025-12-09 07:58:25 - INFO - Epoch: 12.67, Step: 40160, Train Loss: 1.4996, Learning Rate: 7.19e-05
2025-12-09 07:58:37 - INFO - Epoch: 12.68, Step: 40170, Train Loss: 1.5037, Learning Rate: 7.19e-05
2025-12-09 07:58:48 - INFO - Epoch: 12.68, Step: 40180, Train Loss: 1.4351, Learning Rate: 7.19e-05
2025-12-09 07:58:59 - INFO - Epoch: 12.68, Step: 40190, Train Loss: 1.4790, Learning Rate: 7.19e-05
2025-12-09 07:59:10 - INFO - Epoch: 12.69, Step: 40200, Train Loss: 1.4301, Learning Rate: 7.19e-05
2025-12-09 07:59:21 - INFO - Epoch: 12.69, Step: 40210, Train Loss: 1.4712, Learning Rate: 7.19e-05
2025-12-09 07:59:32 - INFO - Epoch: 12.69, Step: 40220, Train Loss: 1.4765, Learning Rate: 7.19e-05
2025-12-09 07:59:43 - INFO - Epoch: 12.69, Step: 40230, Train Loss: 1.4916, Learning Rate: 7.19e-05
2025-12-09 07:59:54 - INFO - Epoch: 12.70, Step: 40240, Train Loss: 1.4647, Learning Rate: 7.18e-05
2025-12-09 08:00:05 - INFO - Epoch: 12.70, Step: 40250, Train Loss: 1.4977, Learning Rate: 7.18e-05
2025-12-09 08:00:16 - INFO - Epoch: 12.70, Step: 40260, Train Loss: 1.5191, Learning Rate: 7.18e-05
2025-12-09 08:00:27 - INFO - Epoch: 12.71, Step: 40270, Train Loss: 1.5004, Learning Rate: 7.18e-05
2025-12-09 08:00:38 - INFO - Epoch: 12.71, Step: 40280, Train Loss: 1.4504, Learning Rate: 7.18e-05
2025-12-09 08:00:50 - INFO - Epoch: 12.71, Step: 40290, Train Loss: 1.5218, Learning Rate: 7.18e-05
2025-12-09 08:01:01 - INFO - Epoch: 12.72, Step: 40300, Train Loss: 1.4992, Learning Rate: 7.18e-05
2025-12-09 08:01:12 - INFO - Epoch: 12.72, Step: 40310, Train Loss: 1.4829, Learning Rate: 7.18e-05
2025-12-09 08:01:23 - INFO - Epoch: 12.72, Step: 40320, Train Loss: 1.4855, Learning Rate: 7.18e-05
2025-12-09 08:01:34 - INFO - Epoch: 12.73, Step: 40330, Train Loss: 1.4809, Learning Rate: 7.18e-05
2025-12-09 08:01:45 - INFO - Epoch: 12.73, Step: 40340, Train Loss: 1.4741, Learning Rate: 7.18e-05
2025-12-09 08:01:56 - INFO - Epoch: 12.73, Step: 40350, Train Loss: 1.4621, Learning Rate: 7.18e-05
2025-12-09 08:02:07 - INFO - Epoch: 12.74, Step: 40360, Train Loss: 1.4701, Learning Rate: 7.17e-05
2025-12-09 08:02:18 - INFO - Epoch: 12.74, Step: 40370, Train Loss: 1.4544, Learning Rate: 7.17e-05
2025-12-09 08:02:29 - INFO - Epoch: 12.74, Step: 40380, Train Loss: 1.4602, Learning Rate: 7.17e-05
2025-12-09 08:02:40 - INFO - Epoch: 12.75, Step: 40390, Train Loss: 1.4913, Learning Rate: 7.17e-05
2025-12-09 08:02:51 - INFO - Epoch: 12.75, Step: 40400, Train Loss: 1.4523, Learning Rate: 7.17e-05
2025-12-09 08:03:02 - INFO - Epoch: 12.75, Step: 40410, Train Loss: 1.4935, Learning Rate: 7.17e-05
2025-12-09 08:03:14 - INFO - Epoch: 12.75, Step: 40420, Train Loss: 1.4793, Learning Rate: 7.17e-05
2025-12-09 08:03:25 - INFO - Epoch: 12.76, Step: 40430, Train Loss: 1.4870, Learning Rate: 7.17e-05
2025-12-09 08:03:36 - INFO - Epoch: 12.76, Step: 40440, Train Loss: 1.4765, Learning Rate: 7.17e-05
2025-12-09 08:03:47 - INFO - Epoch: 12.76, Step: 40450, Train Loss: 1.4557, Learning Rate: 7.17e-05
2025-12-09 08:03:58 - INFO - Epoch: 12.77, Step: 40460, Train Loss: 1.4656, Learning Rate: 7.17e-05
2025-12-09 08:04:09 - INFO - Epoch: 12.77, Step: 40470, Train Loss: 1.4793, Learning Rate: 7.17e-05
2025-12-09 08:04:20 - INFO - Epoch: 12.77, Step: 40480, Train Loss: 1.4780, Learning Rate: 7.16e-05
2025-12-09 08:04:31 - INFO - Epoch: 12.78, Step: 40490, Train Loss: 1.4714, Learning Rate: 7.16e-05
2025-12-09 08:04:42 - INFO - Epoch: 12.78, Step: 40500, Train Loss: 1.4585, Learning Rate: 7.16e-05
2025-12-09 08:04:53 - INFO - Epoch: 12.78, Step: 40510, Train Loss: 1.4785, Learning Rate: 7.16e-05
2025-12-09 08:05:04 - INFO - Epoch: 12.79, Step: 40520, Train Loss: 1.4367, Learning Rate: 7.16e-05
2025-12-09 08:05:15 - INFO - Epoch: 12.79, Step: 40530, Train Loss: 1.4663, Learning Rate: 7.16e-05
2025-12-09 08:05:27 - INFO - Epoch: 12.79, Step: 40540, Train Loss: 1.4539, Learning Rate: 7.16e-05
2025-12-09 08:05:38 - INFO - Epoch: 12.80, Step: 40550, Train Loss: 1.4501, Learning Rate: 7.16e-05
2025-12-09 08:05:49 - INFO - Epoch: 12.80, Step: 40560, Train Loss: 1.4669, Learning Rate: 7.16e-05
2025-12-09 08:06:00 - INFO - Epoch: 12.80, Step: 40570, Train Loss: 1.4928, Learning Rate: 7.16e-05
2025-12-09 08:06:11 - INFO - Epoch: 12.81, Step: 40580, Train Loss: 1.4860, Learning Rate: 7.16e-05
2025-12-09 08:06:22 - INFO - Epoch: 12.81, Step: 40590, Train Loss: 1.4786, Learning Rate: 7.16e-05
2025-12-09 08:06:33 - INFO - Epoch: 12.81, Step: 40600, Train Loss: 1.4800, Learning Rate: 7.15e-05
2025-12-09 08:06:44 - INFO - Epoch: 12.81, Step: 40610, Train Loss: 1.4616, Learning Rate: 7.15e-05
2025-12-09 08:06:55 - INFO - Epoch: 12.82, Step: 40620, Train Loss: 1.4789, Learning Rate: 7.15e-05
2025-12-09 08:07:06 - INFO - Epoch: 12.82, Step: 40630, Train Loss: 1.4642, Learning Rate: 7.15e-05
2025-12-09 08:07:17 - INFO - Epoch: 12.82, Step: 40640, Train Loss: 1.4935, Learning Rate: 7.15e-05
2025-12-09 08:07:28 - INFO - Epoch: 12.83, Step: 40650, Train Loss: 1.4456, Learning Rate: 7.15e-05
2025-12-09 08:07:40 - INFO - Epoch: 12.83, Step: 40660, Train Loss: 1.4705, Learning Rate: 7.15e-05
2025-12-09 08:07:51 - INFO - Epoch: 12.83, Step: 40670, Train Loss: 1.5091, Learning Rate: 7.15e-05
2025-12-09 08:08:02 - INFO - Epoch: 12.84, Step: 40680, Train Loss: 1.4497, Learning Rate: 7.15e-05
2025-12-09 08:08:13 - INFO - Epoch: 12.84, Step: 40690, Train Loss: 1.4707, Learning Rate: 7.15e-05
2025-12-09 08:08:24 - INFO - Epoch: 12.84, Step: 40700, Train Loss: 1.4543, Learning Rate: 7.15e-05
2025-12-09 08:08:35 - INFO - Epoch: 12.85, Step: 40710, Train Loss: 1.5083, Learning Rate: 7.15e-05
2025-12-09 08:08:46 - INFO - Epoch: 12.85, Step: 40720, Train Loss: 1.4697, Learning Rate: 7.14e-05
2025-12-09 08:08:57 - INFO - Epoch: 12.85, Step: 40730, Train Loss: 1.4699, Learning Rate: 7.14e-05
2025-12-09 08:09:08 - INFO - Epoch: 12.86, Step: 40740, Train Loss: 1.4969, Learning Rate: 7.14e-05
2025-12-09 08:09:19 - INFO - Epoch: 12.86, Step: 40750, Train Loss: 1.5034, Learning Rate: 7.14e-05
2025-12-09 08:09:30 - INFO - Epoch: 12.86, Step: 40760, Train Loss: 1.4852, Learning Rate: 7.14e-05
2025-12-09 08:09:41 - INFO - Epoch: 12.87, Step: 40770, Train Loss: 1.4414, Learning Rate: 7.14e-05
2025-12-09 08:09:52 - INFO - Epoch: 12.87, Step: 40780, Train Loss: 1.4468, Learning Rate: 7.14e-05
2025-12-09 08:10:04 - INFO - Epoch: 12.87, Step: 40790, Train Loss: 1.4922, Learning Rate: 7.14e-05
2025-12-09 08:10:15 - INFO - Epoch: 12.87, Step: 40800, Train Loss: 1.4812, Learning Rate: 7.14e-05
2025-12-09 08:10:26 - INFO - Epoch: 12.88, Step: 40810, Train Loss: 1.4928, Learning Rate: 7.14e-05
2025-12-09 08:10:37 - INFO - Epoch: 12.88, Step: 40820, Train Loss: 1.4809, Learning Rate: 7.14e-05
2025-12-09 08:10:48 - INFO - Epoch: 12.88, Step: 40830, Train Loss: 1.4367, Learning Rate: 7.14e-05
2025-12-09 08:10:59 - INFO - Epoch: 12.89, Step: 40840, Train Loss: 1.4673, Learning Rate: 7.13e-05
2025-12-09 08:11:10 - INFO - Epoch: 12.89, Step: 40850, Train Loss: 1.4616, Learning Rate: 7.13e-05
2025-12-09 08:11:21 - INFO - Epoch: 12.89, Step: 40860, Train Loss: 1.4643, Learning Rate: 7.13e-05
2025-12-09 08:11:32 - INFO - Epoch: 12.90, Step: 40870, Train Loss: 1.5118, Learning Rate: 7.13e-05
2025-12-09 08:11:43 - INFO - Epoch: 12.90, Step: 40880, Train Loss: 1.4785, Learning Rate: 7.13e-05
2025-12-09 08:11:54 - INFO - Epoch: 12.90, Step: 40890, Train Loss: 1.4231, Learning Rate: 7.13e-05
2025-12-09 08:12:05 - INFO - Epoch: 12.91, Step: 40900, Train Loss: 1.5155, Learning Rate: 7.13e-05
2025-12-09 08:12:17 - INFO - Epoch: 12.91, Step: 40910, Train Loss: 1.4671, Learning Rate: 7.13e-05
2025-12-09 08:12:28 - INFO - Epoch: 12.91, Step: 40920, Train Loss: 1.4873, Learning Rate: 7.13e-05
2025-12-09 08:12:39 - INFO - Epoch: 12.92, Step: 40930, Train Loss: 1.4837, Learning Rate: 7.13e-05
2025-12-09 08:12:50 - INFO - Epoch: 12.92, Step: 40940, Train Loss: 1.4499, Learning Rate: 7.13e-05
2025-12-09 08:13:01 - INFO - Epoch: 12.92, Step: 40950, Train Loss: 1.4544, Learning Rate: 7.13e-05
2025-12-09 08:13:12 - INFO - Epoch: 12.93, Step: 40960, Train Loss: 1.4469, Learning Rate: 7.13e-05
2025-12-09 08:13:23 - INFO - Epoch: 12.93, Step: 40970, Train Loss: 1.5153, Learning Rate: 7.12e-05
2025-12-09 08:13:34 - INFO - Epoch: 12.93, Step: 40980, Train Loss: 1.4810, Learning Rate: 7.12e-05
2025-12-09 08:13:45 - INFO - Epoch: 12.93, Step: 40990, Train Loss: 1.4674, Learning Rate: 7.12e-05
2025-12-09 08:13:56 - INFO - Epoch: 12.94, Step: 41000, Train Loss: 1.4406, Learning Rate: 7.12e-05
2025-12-09 08:14:07 - INFO - Epoch: 12.94, Step: 41010, Train Loss: 1.4477, Learning Rate: 7.12e-05
2025-12-09 08:14:18 - INFO - Epoch: 12.94, Step: 41020, Train Loss: 1.4682, Learning Rate: 7.12e-05
2025-12-09 08:14:30 - INFO - Epoch: 12.95, Step: 41030, Train Loss: 1.4444, Learning Rate: 7.12e-05
2025-12-09 08:14:41 - INFO - Epoch: 12.95, Step: 41040, Train Loss: 1.4911, Learning Rate: 7.12e-05
2025-12-09 08:14:52 - INFO - Epoch: 12.95, Step: 41050, Train Loss: 1.4533, Learning Rate: 7.12e-05
2025-12-09 08:15:03 - INFO - Epoch: 12.96, Step: 41060, Train Loss: 1.4718, Learning Rate: 7.12e-05
2025-12-09 08:15:14 - INFO - Epoch: 12.96, Step: 41070, Train Loss: 1.5055, Learning Rate: 7.12e-05
2025-12-09 08:15:25 - INFO - Epoch: 12.96, Step: 41080, Train Loss: 1.4585, Learning Rate: 7.12e-05
2025-12-09 08:15:36 - INFO - Epoch: 12.97, Step: 41090, Train Loss: 1.4355, Learning Rate: 7.11e-05
2025-12-09 08:15:47 - INFO - Epoch: 12.97, Step: 41100, Train Loss: 1.4555, Learning Rate: 7.11e-05
2025-12-09 08:15:58 - INFO - Epoch: 12.97, Step: 41110, Train Loss: 1.5050, Learning Rate: 7.11e-05
2025-12-09 08:16:09 - INFO - Epoch: 12.98, Step: 41120, Train Loss: 1.4683, Learning Rate: 7.11e-05
2025-12-09 08:16:20 - INFO - Epoch: 12.98, Step: 41130, Train Loss: 1.4684, Learning Rate: 7.11e-05
2025-12-09 08:16:31 - INFO - Epoch: 12.98, Step: 41140, Train Loss: 1.4769, Learning Rate: 7.11e-05
2025-12-09 08:16:42 - INFO - Epoch: 12.99, Step: 41150, Train Loss: 1.4802, Learning Rate: 7.11e-05
2025-12-09 08:16:54 - INFO - Epoch: 12.99, Step: 41160, Train Loss: 1.4688, Learning Rate: 7.11e-05
2025-12-09 08:17:05 - INFO - Epoch: 12.99, Step: 41170, Train Loss: 1.4497, Learning Rate: 7.11e-05
2025-12-09 08:17:16 - INFO - Epoch: 12.99, Step: 41180, Train Loss: 1.5128, Learning Rate: 7.11e-05
2025-12-09 08:17:27 - INFO - Epoch: 13.00, Step: 41190, Train Loss: 1.4615, Learning Rate: 7.11e-05
2025-12-09 08:17:38 - INFO - Epoch: 13.00, Step: 41200, Train Loss: 1.5294, Learning Rate: 7.11e-05
2025-12-09 08:17:49 - INFO - Epoch: 13.00, Step: 41210, Train Loss: 1.4454, Learning Rate: 7.10e-05
2025-12-09 08:18:00 - INFO - Epoch: 13.01, Step: 41220, Train Loss: 1.4424, Learning Rate: 7.10e-05
2025-12-09 08:18:11 - INFO - Epoch: 13.01, Step: 41230, Train Loss: 1.4693, Learning Rate: 7.10e-05
2025-12-09 08:18:22 - INFO - Epoch: 13.01, Step: 41240, Train Loss: 1.4721, Learning Rate: 7.10e-05
2025-12-09 08:18:33 - INFO - Epoch: 13.02, Step: 41250, Train Loss: 1.4473, Learning Rate: 7.10e-05
2025-12-09 08:18:44 - INFO - Epoch: 13.02, Step: 41260, Train Loss: 1.4999, Learning Rate: 7.10e-05
2025-12-09 08:18:55 - INFO - Epoch: 13.02, Step: 41270, Train Loss: 1.4789, Learning Rate: 7.10e-05
2025-12-09 08:19:07 - INFO - Epoch: 13.03, Step: 41280, Train Loss: 1.4710, Learning Rate: 7.10e-05
2025-12-09 08:19:18 - INFO - Epoch: 13.03, Step: 41290, Train Loss: 1.4441, Learning Rate: 7.10e-05
2025-12-09 08:19:29 - INFO - Epoch: 13.03, Step: 41300, Train Loss: 1.4878, Learning Rate: 7.10e-05
2025-12-09 08:19:40 - INFO - Epoch: 13.04, Step: 41310, Train Loss: 1.4687, Learning Rate: 7.10e-05
2025-12-09 08:19:51 - INFO - Epoch: 13.04, Step: 41320, Train Loss: 1.4327, Learning Rate: 7.10e-05
2025-12-09 08:20:02 - INFO - Epoch: 13.04, Step: 41330, Train Loss: 1.4608, Learning Rate: 7.09e-05
2025-12-09 08:20:13 - INFO - Epoch: 13.05, Step: 41340, Train Loss: 1.4415, Learning Rate: 7.09e-05
2025-12-09 08:20:24 - INFO - Epoch: 13.05, Step: 41350, Train Loss: 1.4502, Learning Rate: 7.09e-05
2025-12-09 08:20:35 - INFO - Epoch: 13.05, Step: 41360, Train Loss: 1.4733, Learning Rate: 7.09e-05
2025-12-09 08:20:46 - INFO - Epoch: 13.05, Step: 41370, Train Loss: 1.4671, Learning Rate: 7.09e-05
2025-12-09 08:20:57 - INFO - Epoch: 13.06, Step: 41380, Train Loss: 1.4575, Learning Rate: 7.09e-05
2025-12-09 08:21:08 - INFO - Epoch: 13.06, Step: 41390, Train Loss: 1.4638, Learning Rate: 7.09e-05
2025-12-09 08:21:19 - INFO - Epoch: 13.06, Step: 41400, Train Loss: 1.4316, Learning Rate: 7.09e-05
2025-12-09 08:21:31 - INFO - Epoch: 13.07, Step: 41410, Train Loss: 1.4967, Learning Rate: 7.09e-05
2025-12-09 08:21:42 - INFO - Epoch: 13.07, Step: 41420, Train Loss: 1.4819, Learning Rate: 7.09e-05
2025-12-09 08:21:53 - INFO - Epoch: 13.07, Step: 41430, Train Loss: 1.4196, Learning Rate: 7.09e-05
2025-12-09 08:22:04 - INFO - Epoch: 13.08, Step: 41440, Train Loss: 1.5078, Learning Rate: 7.09e-05
2025-12-09 08:22:15 - INFO - Epoch: 13.08, Step: 41450, Train Loss: 1.4819, Learning Rate: 7.08e-05
2025-12-09 08:22:26 - INFO - Epoch: 13.08, Step: 41460, Train Loss: 1.4594, Learning Rate: 7.08e-05
2025-12-09 08:22:37 - INFO - Epoch: 13.09, Step: 41470, Train Loss: 1.4556, Learning Rate: 7.08e-05
2025-12-09 08:22:48 - INFO - Epoch: 13.09, Step: 41480, Train Loss: 1.4585, Learning Rate: 7.08e-05
2025-12-09 08:22:59 - INFO - Epoch: 13.09, Step: 41490, Train Loss: 1.5016, Learning Rate: 7.08e-05
2025-12-09 08:23:10 - INFO - Epoch: 13.10, Step: 41500, Train Loss: 1.4515, Learning Rate: 7.08e-05
2025-12-09 08:23:21 - INFO - Epoch: 13.10, Step: 41510, Train Loss: 1.4644, Learning Rate: 7.08e-05
2025-12-09 08:23:32 - INFO - Epoch: 13.10, Step: 41520, Train Loss: 1.4744, Learning Rate: 7.08e-05
2025-12-09 08:23:44 - INFO - Epoch: 13.11, Step: 41530, Train Loss: 1.4202, Learning Rate: 7.08e-05
2025-12-09 08:23:55 - INFO - Epoch: 13.11, Step: 41540, Train Loss: 1.4690, Learning Rate: 7.08e-05
2025-12-09 08:24:06 - INFO - Epoch: 13.11, Step: 41550, Train Loss: 1.5112, Learning Rate: 7.08e-05
2025-12-09 08:24:17 - INFO - Epoch: 13.11, Step: 41560, Train Loss: 1.4396, Learning Rate: 7.08e-05
2025-12-09 08:24:28 - INFO - Epoch: 13.12, Step: 41570, Train Loss: 1.4373, Learning Rate: 7.07e-05
2025-12-09 08:24:39 - INFO - Epoch: 13.12, Step: 41580, Train Loss: 1.4696, Learning Rate: 7.07e-05
2025-12-09 08:24:50 - INFO - Epoch: 13.12, Step: 41590, Train Loss: 1.4907, Learning Rate: 7.07e-05
2025-12-09 08:25:01 - INFO - Epoch: 13.13, Step: 41600, Train Loss: 1.4758, Learning Rate: 7.07e-05
2025-12-09 08:25:12 - INFO - Epoch: 13.13, Step: 41610, Train Loss: 1.4576, Learning Rate: 7.07e-05
2025-12-09 08:25:23 - INFO - Epoch: 13.13, Step: 41620, Train Loss: 1.4571, Learning Rate: 7.07e-05
2025-12-09 08:25:34 - INFO - Epoch: 13.14, Step: 41630, Train Loss: 1.4554, Learning Rate: 7.07e-05
2025-12-09 08:25:45 - INFO - Epoch: 13.14, Step: 41640, Train Loss: 1.4745, Learning Rate: 7.07e-05
2025-12-09 08:25:56 - INFO - Epoch: 13.14, Step: 41650, Train Loss: 1.4593, Learning Rate: 7.07e-05
2025-12-09 08:26:08 - INFO - Epoch: 13.15, Step: 41660, Train Loss: 1.4743, Learning Rate: 7.07e-05
2025-12-09 08:26:19 - INFO - Epoch: 13.15, Step: 41670, Train Loss: 1.4037, Learning Rate: 7.07e-05
2025-12-09 08:26:30 - INFO - Epoch: 13.15, Step: 41680, Train Loss: 1.4678, Learning Rate: 7.07e-05
2025-12-09 08:26:41 - INFO - Epoch: 13.16, Step: 41690, Train Loss: 1.4528, Learning Rate: 7.06e-05
2025-12-09 08:26:52 - INFO - Epoch: 13.16, Step: 41700, Train Loss: 1.4704, Learning Rate: 7.06e-05
2025-12-09 08:27:03 - INFO - Epoch: 13.16, Step: 41710, Train Loss: 1.4541, Learning Rate: 7.06e-05
2025-12-09 08:27:14 - INFO - Epoch: 13.17, Step: 41720, Train Loss: 1.4591, Learning Rate: 7.06e-05
2025-12-09 08:27:25 - INFO - Epoch: 13.17, Step: 41730, Train Loss: 1.4514, Learning Rate: 7.06e-05
2025-12-09 08:27:36 - INFO - Epoch: 13.17, Step: 41740, Train Loss: 1.4718, Learning Rate: 7.06e-05
2025-12-09 08:27:47 - INFO - Epoch: 13.17, Step: 41750, Train Loss: 1.4389, Learning Rate: 7.06e-05
2025-12-09 08:27:58 - INFO - Epoch: 13.18, Step: 41760, Train Loss: 1.4837, Learning Rate: 7.06e-05
2025-12-09 08:28:09 - INFO - Epoch: 13.18, Step: 41770, Train Loss: 1.4766, Learning Rate: 7.06e-05
2025-12-09 08:28:21 - INFO - Epoch: 13.18, Step: 41780, Train Loss: 1.4493, Learning Rate: 7.06e-05
2025-12-09 08:28:32 - INFO - Epoch: 13.19, Step: 41790, Train Loss: 1.4786, Learning Rate: 7.06e-05
2025-12-09 08:28:43 - INFO - Epoch: 13.19, Step: 41800, Train Loss: 1.4759, Learning Rate: 7.06e-05
2025-12-09 08:28:54 - INFO - Epoch: 13.19, Step: 41810, Train Loss: 1.4538, Learning Rate: 7.05e-05
2025-12-09 08:29:05 - INFO - Epoch: 13.20, Step: 41820, Train Loss: 1.4792, Learning Rate: 7.05e-05
2025-12-09 08:29:16 - INFO - Epoch: 13.20, Step: 41830, Train Loss: 1.4669, Learning Rate: 7.05e-05
2025-12-09 08:29:27 - INFO - Epoch: 13.20, Step: 41840, Train Loss: 1.4478, Learning Rate: 7.05e-05
2025-12-09 08:29:38 - INFO - Epoch: 13.21, Step: 41850, Train Loss: 1.4622, Learning Rate: 7.05e-05
2025-12-09 08:29:49 - INFO - Epoch: 13.21, Step: 41860, Train Loss: 1.4685, Learning Rate: 7.05e-05
2025-12-09 08:30:00 - INFO - Epoch: 13.21, Step: 41870, Train Loss: 1.4216, Learning Rate: 7.05e-05
2025-12-09 08:30:11 - INFO - Epoch: 13.22, Step: 41880, Train Loss: 1.4653, Learning Rate: 7.05e-05
2025-12-09 08:30:22 - INFO - Epoch: 13.22, Step: 41890, Train Loss: 1.4547, Learning Rate: 7.05e-05
2025-12-09 08:30:33 - INFO - Epoch: 13.22, Step: 41900, Train Loss: 1.4521, Learning Rate: 7.05e-05
2025-12-09 08:30:45 - INFO - Epoch: 13.22, Step: 41910, Train Loss: 1.4728, Learning Rate: 7.05e-05
2025-12-09 08:30:56 - INFO - Epoch: 13.23, Step: 41920, Train Loss: 1.4345, Learning Rate: 7.05e-05
2025-12-09 08:31:07 - INFO - Epoch: 13.23, Step: 41930, Train Loss: 1.4567, Learning Rate: 7.04e-05
2025-12-09 08:31:18 - INFO - Epoch: 13.23, Step: 41940, Train Loss: 1.4828, Learning Rate: 7.04e-05
2025-12-09 08:31:29 - INFO - Epoch: 13.24, Step: 41950, Train Loss: 1.4633, Learning Rate: 7.04e-05
2025-12-09 08:31:40 - INFO - Epoch: 13.24, Step: 41960, Train Loss: 1.4722, Learning Rate: 7.04e-05
2025-12-09 08:31:51 - INFO - Epoch: 13.24, Step: 41970, Train Loss: 1.4570, Learning Rate: 7.04e-05
2025-12-09 08:32:02 - INFO - Epoch: 13.25, Step: 41980, Train Loss: 1.4574, Learning Rate: 7.04e-05
2025-12-09 08:32:13 - INFO - Epoch: 13.25, Step: 41990, Train Loss: 1.4538, Learning Rate: 7.04e-05
2025-12-09 08:32:24 - INFO - Epoch: 13.25, Step: 42000, Train Loss: 1.4744, Learning Rate: 7.04e-05
2025-12-09 08:32:35 - INFO - Epoch: 13.26, Step: 42010, Train Loss: 1.4598, Learning Rate: 7.04e-05
2025-12-09 08:32:46 - INFO - Epoch: 13.26, Step: 42020, Train Loss: 1.4519, Learning Rate: 7.04e-05
2025-12-09 08:32:58 - INFO - Epoch: 13.26, Step: 42030, Train Loss: 1.4268, Learning Rate: 7.04e-05
2025-12-09 08:33:09 - INFO - Epoch: 13.27, Step: 42040, Train Loss: 1.4627, Learning Rate: 7.04e-05
2025-12-09 08:33:20 - INFO - Epoch: 13.27, Step: 42050, Train Loss: 1.4835, Learning Rate: 7.03e-05
2025-12-09 08:33:31 - INFO - Epoch: 13.27, Step: 42060, Train Loss: 1.4664, Learning Rate: 7.03e-05
2025-12-09 08:33:42 - INFO - Epoch: 13.28, Step: 42070, Train Loss: 1.4723, Learning Rate: 7.03e-05
2025-12-09 08:33:53 - INFO - Epoch: 13.28, Step: 42080, Train Loss: 1.4665, Learning Rate: 7.03e-05
2025-12-09 08:34:04 - INFO - Epoch: 13.28, Step: 42090, Train Loss: 1.4794, Learning Rate: 7.03e-05
2025-12-09 08:34:15 - INFO - Epoch: 13.28, Step: 42100, Train Loss: 1.4786, Learning Rate: 7.03e-05
2025-12-09 08:34:26 - INFO - Epoch: 13.29, Step: 42110, Train Loss: 1.4208, Learning Rate: 7.03e-05
2025-12-09 08:34:37 - INFO - Epoch: 13.29, Step: 42120, Train Loss: 1.4745, Learning Rate: 7.03e-05
2025-12-09 08:34:48 - INFO - Epoch: 13.29, Step: 42130, Train Loss: 1.4449, Learning Rate: 7.03e-05
2025-12-09 08:34:59 - INFO - Epoch: 13.30, Step: 42140, Train Loss: 1.4837, Learning Rate: 7.03e-05
2025-12-09 08:35:10 - INFO - Epoch: 13.30, Step: 42150, Train Loss: 1.4833, Learning Rate: 7.03e-05
2025-12-09 08:35:22 - INFO - Epoch: 13.30, Step: 42160, Train Loss: 1.4721, Learning Rate: 7.03e-05
2025-12-09 08:35:33 - INFO - Epoch: 13.31, Step: 42170, Train Loss: 1.4751, Learning Rate: 7.02e-05
2025-12-09 08:35:44 - INFO - Epoch: 13.31, Step: 42180, Train Loss: 1.4673, Learning Rate: 7.02e-05
2025-12-09 08:35:55 - INFO - Epoch: 13.31, Step: 42190, Train Loss: 1.4614, Learning Rate: 7.02e-05
2025-12-09 08:36:06 - INFO - Epoch: 13.32, Step: 42200, Train Loss: 1.4525, Learning Rate: 7.02e-05
2025-12-09 08:36:17 - INFO - Epoch: 13.32, Step: 42210, Train Loss: 1.4735, Learning Rate: 7.02e-05
2025-12-09 08:36:28 - INFO - Epoch: 13.32, Step: 42220, Train Loss: 1.4943, Learning Rate: 7.02e-05
2025-12-09 08:36:39 - INFO - Epoch: 13.33, Step: 42230, Train Loss: 1.4349, Learning Rate: 7.02e-05
2025-12-09 08:36:50 - INFO - Epoch: 13.33, Step: 42240, Train Loss: 1.4467, Learning Rate: 7.02e-05
2025-12-09 08:37:01 - INFO - Epoch: 13.33, Step: 42250, Train Loss: 1.4350, Learning Rate: 7.02e-05
2025-12-09 08:37:12 - INFO - Epoch: 13.34, Step: 42260, Train Loss: 1.4657, Learning Rate: 7.02e-05
2025-12-09 08:37:23 - INFO - Epoch: 13.34, Step: 42270, Train Loss: 1.4654, Learning Rate: 7.02e-05
2025-12-09 08:37:35 - INFO - Epoch: 13.34, Step: 42280, Train Loss: 1.4689, Learning Rate: 7.02e-05
2025-12-09 08:37:46 - INFO - Epoch: 13.34, Step: 42290, Train Loss: 1.4880, Learning Rate: 7.01e-05
2025-12-09 08:37:57 - INFO - Epoch: 13.35, Step: 42300, Train Loss: 1.4261, Learning Rate: 7.01e-05
2025-12-09 08:38:08 - INFO - Epoch: 13.35, Step: 42310, Train Loss: 1.4370, Learning Rate: 7.01e-05
2025-12-09 08:38:19 - INFO - Epoch: 13.35, Step: 42320, Train Loss: 1.4549, Learning Rate: 7.01e-05
2025-12-09 08:38:30 - INFO - Epoch: 13.36, Step: 42330, Train Loss: 1.4666, Learning Rate: 7.01e-05
2025-12-09 08:38:41 - INFO - Epoch: 13.36, Step: 42340, Train Loss: 1.4619, Learning Rate: 7.01e-05
2025-12-09 08:38:52 - INFO - Epoch: 13.36, Step: 42350, Train Loss: 1.4482, Learning Rate: 7.01e-05
2025-12-09 08:39:03 - INFO - Epoch: 13.37, Step: 42360, Train Loss: 1.4808, Learning Rate: 7.01e-05
2025-12-09 08:39:14 - INFO - Epoch: 13.37, Step: 42370, Train Loss: 1.4573, Learning Rate: 7.01e-05
2025-12-09 08:39:25 - INFO - Epoch: 13.37, Step: 42380, Train Loss: 1.4544, Learning Rate: 7.01e-05
2025-12-09 08:39:36 - INFO - Epoch: 13.38, Step: 42390, Train Loss: 1.4519, Learning Rate: 7.01e-05
2025-12-09 08:39:47 - INFO - Epoch: 13.38, Step: 42400, Train Loss: 1.4468, Learning Rate: 7.01e-05
2025-12-09 08:39:59 - INFO - Epoch: 13.38, Step: 42410, Train Loss: 1.4332, Learning Rate: 7.00e-05
2025-12-09 08:40:10 - INFO - Epoch: 13.39, Step: 42420, Train Loss: 1.4389, Learning Rate: 7.00e-05
2025-12-09 08:40:21 - INFO - Epoch: 13.39, Step: 42430, Train Loss: 1.4354, Learning Rate: 7.00e-05
2025-12-09 08:40:32 - INFO - Epoch: 13.39, Step: 42440, Train Loss: 1.4620, Learning Rate: 7.00e-05
2025-12-09 08:40:43 - INFO - Epoch: 13.40, Step: 42450, Train Loss: 1.4763, Learning Rate: 7.00e-05
2025-12-09 08:40:54 - INFO - Epoch: 13.40, Step: 42460, Train Loss: 1.4525, Learning Rate: 7.00e-05
2025-12-09 08:41:05 - INFO - Epoch: 13.40, Step: 42470, Train Loss: 1.4835, Learning Rate: 7.00e-05
2025-12-09 08:41:16 - INFO - Epoch: 13.40, Step: 42480, Train Loss: 1.4639, Learning Rate: 7.00e-05
2025-12-09 08:41:27 - INFO - Epoch: 13.41, Step: 42490, Train Loss: 1.4548, Learning Rate: 7.00e-05
2025-12-09 08:41:38 - INFO - Epoch: 13.41, Step: 42500, Train Loss: 1.4465, Learning Rate: 7.00e-05
2025-12-09 08:41:49 - INFO - Epoch: 13.41, Step: 42510, Train Loss: 1.4308, Learning Rate: 7.00e-05
2025-12-09 08:42:00 - INFO - Epoch: 13.42, Step: 42520, Train Loss: 1.4468, Learning Rate: 7.00e-05
2025-12-09 08:42:12 - INFO - Epoch: 13.42, Step: 42530, Train Loss: 1.4414, Learning Rate: 6.99e-05
2025-12-09 08:42:23 - INFO - Epoch: 13.42, Step: 42540, Train Loss: 1.4605, Learning Rate: 6.99e-05
2025-12-09 08:42:34 - INFO - Epoch: 13.43, Step: 42550, Train Loss: 1.4661, Learning Rate: 6.99e-05
2025-12-09 08:42:45 - INFO - Epoch: 13.43, Step: 42560, Train Loss: 1.4635, Learning Rate: 6.99e-05
2025-12-09 08:42:56 - INFO - Epoch: 13.43, Step: 42570, Train Loss: 1.4862, Learning Rate: 6.99e-05
2025-12-09 08:43:07 - INFO - Epoch: 13.44, Step: 42580, Train Loss: 1.4827, Learning Rate: 6.99e-05
2025-12-09 08:43:18 - INFO - Epoch: 13.44, Step: 42590, Train Loss: 1.4187, Learning Rate: 6.99e-05
2025-12-09 08:43:29 - INFO - Epoch: 13.44, Step: 42600, Train Loss: 1.4566, Learning Rate: 6.99e-05
2025-12-09 08:43:40 - INFO - Epoch: 13.45, Step: 42610, Train Loss: 1.4627, Learning Rate: 6.99e-05
2025-12-09 08:43:51 - INFO - Epoch: 13.45, Step: 42620, Train Loss: 1.4462, Learning Rate: 6.99e-05
2025-12-09 08:44:02 - INFO - Epoch: 13.45, Step: 42630, Train Loss: 1.4094, Learning Rate: 6.99e-05
2025-12-09 08:44:13 - INFO - Epoch: 13.46, Step: 42640, Train Loss: 1.4761, Learning Rate: 6.99e-05
2025-12-09 08:44:24 - INFO - Epoch: 13.46, Step: 42650, Train Loss: 1.4989, Learning Rate: 6.98e-05
2025-12-09 08:44:36 - INFO - Epoch: 13.46, Step: 42660, Train Loss: 1.4524, Learning Rate: 6.98e-05
2025-12-09 08:44:47 - INFO - Epoch: 13.46, Step: 42670, Train Loss: 1.4277, Learning Rate: 6.98e-05
2025-12-09 08:44:58 - INFO - Epoch: 13.47, Step: 42680, Train Loss: 1.4509, Learning Rate: 6.98e-05
2025-12-09 08:45:09 - INFO - Epoch: 13.47, Step: 42690, Train Loss: 1.4187, Learning Rate: 6.98e-05
2025-12-09 08:45:20 - INFO - Epoch: 13.47, Step: 42700, Train Loss: 1.4549, Learning Rate: 6.98e-05
2025-12-09 08:45:31 - INFO - Epoch: 13.48, Step: 42710, Train Loss: 1.4790, Learning Rate: 6.98e-05
2025-12-09 08:45:42 - INFO - Epoch: 13.48, Step: 42720, Train Loss: 1.4451, Learning Rate: 6.98e-05
2025-12-09 08:45:53 - INFO - Epoch: 13.48, Step: 42730, Train Loss: 1.4628, Learning Rate: 6.98e-05
2025-12-09 08:46:04 - INFO - Epoch: 13.49, Step: 42740, Train Loss: 1.4596, Learning Rate: 6.98e-05
2025-12-09 08:46:15 - INFO - Epoch: 13.49, Step: 42750, Train Loss: 1.4273, Learning Rate: 6.98e-05
2025-12-09 08:46:26 - INFO - Epoch: 13.49, Step: 42760, Train Loss: 1.5144, Learning Rate: 6.98e-05
2025-12-09 08:46:37 - INFO - Epoch: 13.50, Step: 42770, Train Loss: 1.4507, Learning Rate: 6.97e-05
2025-12-09 08:46:49 - INFO - Epoch: 13.50, Step: 42780, Train Loss: 1.4604, Learning Rate: 6.97e-05
2025-12-09 08:47:00 - INFO - Epoch: 13.50, Step: 42790, Train Loss: 1.4347, Learning Rate: 6.97e-05
2025-12-09 08:47:11 - INFO - Epoch: 13.51, Step: 42800, Train Loss: 1.4404, Learning Rate: 6.97e-05
2025-12-09 08:47:22 - INFO - Epoch: 13.51, Step: 42810, Train Loss: 1.4284, Learning Rate: 6.97e-05
2025-12-09 08:47:33 - INFO - Epoch: 13.51, Step: 42820, Train Loss: 1.4551, Learning Rate: 6.97e-05
2025-12-09 08:47:44 - INFO - Epoch: 13.52, Step: 42830, Train Loss: 1.4454, Learning Rate: 6.97e-05
2025-12-09 08:47:55 - INFO - Epoch: 13.52, Step: 42840, Train Loss: 1.4762, Learning Rate: 6.97e-05
2025-12-09 08:48:06 - INFO - Epoch: 13.52, Step: 42850, Train Loss: 1.4599, Learning Rate: 6.97e-05
2025-12-09 08:48:17 - INFO - Epoch: 13.52, Step: 42860, Train Loss: 1.4490, Learning Rate: 6.97e-05
2025-12-09 08:48:28 - INFO - Epoch: 13.53, Step: 42870, Train Loss: 1.4886, Learning Rate: 6.97e-05
2025-12-09 08:48:39 - INFO - Epoch: 13.53, Step: 42880, Train Loss: 1.4723, Learning Rate: 6.97e-05
2025-12-09 08:48:50 - INFO - Epoch: 13.53, Step: 42890, Train Loss: 1.4461, Learning Rate: 6.96e-05
2025-12-09 08:49:01 - INFO - Epoch: 13.54, Step: 42900, Train Loss: 1.4509, Learning Rate: 6.96e-05
2025-12-09 08:49:13 - INFO - Epoch: 13.54, Step: 42910, Train Loss: 1.4628, Learning Rate: 6.96e-05
2025-12-09 08:49:24 - INFO - Epoch: 13.54, Step: 42920, Train Loss: 1.4107, Learning Rate: 6.96e-05
2025-12-09 08:49:35 - INFO - Epoch: 13.55, Step: 42930, Train Loss: 1.4749, Learning Rate: 6.96e-05
2025-12-09 08:49:46 - INFO - Epoch: 13.55, Step: 42940, Train Loss: 1.4539, Learning Rate: 6.96e-05
2025-12-09 08:49:57 - INFO - Epoch: 13.55, Step: 42950, Train Loss: 1.4493, Learning Rate: 6.96e-05
2025-12-09 08:50:08 - INFO - Epoch: 13.56, Step: 42960, Train Loss: 1.4851, Learning Rate: 6.96e-05
2025-12-09 08:50:19 - INFO - Epoch: 13.56, Step: 42970, Train Loss: 1.4923, Learning Rate: 6.96e-05
2025-12-09 08:50:30 - INFO - Epoch: 13.56, Step: 42980, Train Loss: 1.4607, Learning Rate: 6.96e-05
2025-12-09 08:50:41 - INFO - Epoch: 13.57, Step: 42990, Train Loss: 1.4289, Learning Rate: 6.96e-05
2025-12-09 08:50:52 - INFO - Epoch: 13.57, Step: 43000, Train Loss: 1.5045, Learning Rate: 6.96e-05
2025-12-09 08:51:03 - INFO - Epoch: 13.57, Step: 43010, Train Loss: 1.4006, Learning Rate: 6.95e-05
2025-12-09 08:51:14 - INFO - Epoch: 13.58, Step: 43020, Train Loss: 1.4143, Learning Rate: 6.95e-05
2025-12-09 08:51:26 - INFO - Epoch: 13.58, Step: 43030, Train Loss: 1.4380, Learning Rate: 6.95e-05
2025-12-09 08:51:37 - INFO - Epoch: 13.58, Step: 43040, Train Loss: 1.4697, Learning Rate: 6.95e-05
2025-12-09 08:51:48 - INFO - Epoch: 13.58, Step: 43050, Train Loss: 1.4345, Learning Rate: 6.95e-05
2025-12-09 08:51:59 - INFO - Epoch: 13.59, Step: 43060, Train Loss: 1.4774, Learning Rate: 6.95e-05
2025-12-09 08:52:10 - INFO - Epoch: 13.59, Step: 43070, Train Loss: 1.4574, Learning Rate: 6.95e-05
2025-12-09 08:52:21 - INFO - Epoch: 13.59, Step: 43080, Train Loss: 1.4471, Learning Rate: 6.95e-05
2025-12-09 08:52:32 - INFO - Epoch: 13.60, Step: 43090, Train Loss: 1.4649, Learning Rate: 6.95e-05
2025-12-09 08:52:43 - INFO - Epoch: 13.60, Step: 43100, Train Loss: 1.4589, Learning Rate: 6.95e-05
2025-12-09 08:52:54 - INFO - Epoch: 13.60, Step: 43110, Train Loss: 1.4671, Learning Rate: 6.95e-05
2025-12-09 08:53:05 - INFO - Epoch: 13.61, Step: 43120, Train Loss: 1.4501, Learning Rate: 6.95e-05
2025-12-09 08:53:16 - INFO - Epoch: 13.61, Step: 43130, Train Loss: 1.4648, Learning Rate: 6.94e-05
2025-12-09 08:53:27 - INFO - Epoch: 13.61, Step: 43140, Train Loss: 1.4260, Learning Rate: 6.94e-05
2025-12-09 08:53:38 - INFO - Epoch: 13.62, Step: 43150, Train Loss: 1.4606, Learning Rate: 6.94e-05
2025-12-09 08:53:50 - INFO - Epoch: 13.62, Step: 43160, Train Loss: 1.4036, Learning Rate: 6.94e-05
2025-12-09 08:54:01 - INFO - Epoch: 13.62, Step: 43170, Train Loss: 1.4412, Learning Rate: 6.94e-05
2025-12-09 08:54:12 - INFO - Epoch: 13.63, Step: 43180, Train Loss: 1.4769, Learning Rate: 6.94e-05
2025-12-09 08:54:23 - INFO - Epoch: 13.63, Step: 43190, Train Loss: 1.4369, Learning Rate: 6.94e-05
2025-12-09 08:54:34 - INFO - Epoch: 13.63, Step: 43200, Train Loss: 1.4391, Learning Rate: 6.94e-05
2025-12-09 08:54:45 - INFO - Epoch: 13.64, Step: 43210, Train Loss: 1.4403, Learning Rate: 6.94e-05
2025-12-09 08:54:56 - INFO - Epoch: 13.64, Step: 43220, Train Loss: 1.4046, Learning Rate: 6.94e-05
2025-12-09 08:55:07 - INFO - Epoch: 13.64, Step: 43230, Train Loss: 1.4381, Learning Rate: 6.94e-05
2025-12-09 08:55:18 - INFO - Epoch: 13.64, Step: 43240, Train Loss: 1.4538, Learning Rate: 6.94e-05
2025-12-09 08:55:29 - INFO - Epoch: 13.65, Step: 43250, Train Loss: 1.4611, Learning Rate: 6.93e-05
2025-12-09 08:55:40 - INFO - Epoch: 13.65, Step: 43260, Train Loss: 1.4084, Learning Rate: 6.93e-05
2025-12-09 08:55:51 - INFO - Epoch: 13.65, Step: 43270, Train Loss: 1.4954, Learning Rate: 6.93e-05
2025-12-09 08:56:03 - INFO - Epoch: 13.66, Step: 43280, Train Loss: 1.4810, Learning Rate: 6.93e-05
2025-12-09 08:56:14 - INFO - Epoch: 13.66, Step: 43290, Train Loss: 1.4556, Learning Rate: 6.93e-05
2025-12-09 08:56:25 - INFO - Epoch: 13.66, Step: 43300, Train Loss: 1.4395, Learning Rate: 6.93e-05
2025-12-09 08:56:36 - INFO - Epoch: 13.67, Step: 43310, Train Loss: 1.4550, Learning Rate: 6.93e-05
2025-12-09 08:56:47 - INFO - Epoch: 13.67, Step: 43320, Train Loss: 1.4307, Learning Rate: 6.93e-05
2025-12-09 08:56:58 - INFO - Epoch: 13.67, Step: 43330, Train Loss: 1.4476, Learning Rate: 6.93e-05
2025-12-09 08:57:09 - INFO - Epoch: 13.68, Step: 43340, Train Loss: 1.4336, Learning Rate: 6.93e-05
2025-12-09 08:57:20 - INFO - Epoch: 13.68, Step: 43350, Train Loss: 1.4517, Learning Rate: 6.93e-05
2025-12-09 08:57:31 - INFO - Epoch: 13.68, Step: 43360, Train Loss: 1.4554, Learning Rate: 6.93e-05
2025-12-09 08:57:42 - INFO - Epoch: 13.69, Step: 43370, Train Loss: 1.4210, Learning Rate: 6.92e-05
2025-12-09 08:57:53 - INFO - Epoch: 13.69, Step: 43380, Train Loss: 1.4587, Learning Rate: 6.92e-05
2025-12-09 08:58:04 - INFO - Epoch: 13.69, Step: 43390, Train Loss: 1.4667, Learning Rate: 6.92e-05
2025-12-09 08:58:15 - INFO - Epoch: 13.70, Step: 43400, Train Loss: 1.4325, Learning Rate: 6.92e-05
2025-12-09 08:58:27 - INFO - Epoch: 13.70, Step: 43410, Train Loss: 1.4276, Learning Rate: 6.92e-05
2025-12-09 08:58:38 - INFO - Epoch: 13.70, Step: 43420, Train Loss: 1.4555, Learning Rate: 6.92e-05
2025-12-09 08:58:49 - INFO - Epoch: 13.70, Step: 43430, Train Loss: 1.4074, Learning Rate: 6.92e-05
2025-12-09 08:59:00 - INFO - Epoch: 13.71, Step: 43440, Train Loss: 1.4387, Learning Rate: 6.92e-05
2025-12-09 08:59:11 - INFO - Epoch: 13.71, Step: 43450, Train Loss: 1.4584, Learning Rate: 6.92e-05
2025-12-09 08:59:22 - INFO - Epoch: 13.71, Step: 43460, Train Loss: 1.4567, Learning Rate: 6.92e-05
2025-12-09 08:59:33 - INFO - Epoch: 13.72, Step: 43470, Train Loss: 1.4461, Learning Rate: 6.92e-05
2025-12-09 08:59:44 - INFO - Epoch: 13.72, Step: 43480, Train Loss: 1.4291, Learning Rate: 6.92e-05
2025-12-09 08:59:55 - INFO - Epoch: 13.72, Step: 43490, Train Loss: 1.4412, Learning Rate: 6.91e-05
2025-12-09 09:00:06 - INFO - Epoch: 13.73, Step: 43500, Train Loss: 1.4374, Learning Rate: 6.91e-05
2025-12-09 09:00:17 - INFO - Epoch: 13.73, Step: 43510, Train Loss: 1.4308, Learning Rate: 6.91e-05
2025-12-09 09:00:28 - INFO - Epoch: 13.73, Step: 43520, Train Loss: 1.3974, Learning Rate: 6.91e-05
2025-12-09 09:00:40 - INFO - Epoch: 13.74, Step: 43530, Train Loss: 1.4530, Learning Rate: 6.91e-05
2025-12-09 09:00:51 - INFO - Epoch: 13.74, Step: 43540, Train Loss: 1.4263, Learning Rate: 6.91e-05
2025-12-09 09:01:02 - INFO - Epoch: 13.74, Step: 43550, Train Loss: 1.4583, Learning Rate: 6.91e-05
2025-12-09 09:01:13 - INFO - Epoch: 13.75, Step: 43560, Train Loss: 1.3912, Learning Rate: 6.91e-05
2025-12-09 09:01:24 - INFO - Epoch: 13.75, Step: 43570, Train Loss: 1.4614, Learning Rate: 6.91e-05
2025-12-09 09:01:35 - INFO - Epoch: 13.75, Step: 43580, Train Loss: 1.4390, Learning Rate: 6.91e-05
2025-12-09 09:01:46 - INFO - Epoch: 13.76, Step: 43590, Train Loss: 1.4265, Learning Rate: 6.91e-05
2025-12-09 09:01:57 - INFO - Epoch: 13.76, Step: 43600, Train Loss: 1.4554, Learning Rate: 6.91e-05
2025-12-09 09:02:08 - INFO - Epoch: 13.76, Step: 43610, Train Loss: 1.4208, Learning Rate: 6.90e-05
2025-12-09 09:02:19 - INFO - Epoch: 13.76, Step: 43620, Train Loss: 1.4564, Learning Rate: 6.90e-05
2025-12-09 09:02:30 - INFO - Epoch: 13.77, Step: 43630, Train Loss: 1.4444, Learning Rate: 6.90e-05
2025-12-09 09:02:41 - INFO - Epoch: 13.77, Step: 43640, Train Loss: 1.4383, Learning Rate: 6.90e-05
2025-12-09 09:02:53 - INFO - Epoch: 13.77, Step: 43650, Train Loss: 1.4641, Learning Rate: 6.90e-05
2025-12-09 09:03:04 - INFO - Epoch: 13.78, Step: 43660, Train Loss: 1.4324, Learning Rate: 6.90e-05
2025-12-09 09:03:15 - INFO - Epoch: 13.78, Step: 43670, Train Loss: 1.4239, Learning Rate: 6.90e-05
2025-12-09 09:03:26 - INFO - Epoch: 13.78, Step: 43680, Train Loss: 1.4242, Learning Rate: 6.90e-05
2025-12-09 09:03:37 - INFO - Epoch: 13.79, Step: 43690, Train Loss: 1.4552, Learning Rate: 6.90e-05
2025-12-09 09:03:48 - INFO - Epoch: 13.79, Step: 43700, Train Loss: 1.4217, Learning Rate: 6.90e-05
2025-12-09 09:03:59 - INFO - Epoch: 13.79, Step: 43710, Train Loss: 1.4621, Learning Rate: 6.90e-05
2025-12-09 09:04:10 - INFO - Epoch: 13.80, Step: 43720, Train Loss: 1.4372, Learning Rate: 6.90e-05
2025-12-09 09:04:21 - INFO - Epoch: 13.80, Step: 43730, Train Loss: 1.4700, Learning Rate: 6.90e-05
2025-12-09 09:04:32 - INFO - Epoch: 13.80, Step: 43740, Train Loss: 1.4409, Learning Rate: 6.89e-05
2025-12-09 09:04:43 - INFO - Epoch: 13.81, Step: 43750, Train Loss: 1.4392, Learning Rate: 6.89e-05
2025-12-09 09:04:54 - INFO - Epoch: 13.81, Step: 43760, Train Loss: 1.4386, Learning Rate: 6.89e-05
2025-12-09 09:05:05 - INFO - Epoch: 13.81, Step: 43770, Train Loss: 1.4431, Learning Rate: 6.89e-05
2025-12-09 09:05:17 - INFO - Epoch: 13.82, Step: 43780, Train Loss: 1.4519, Learning Rate: 6.89e-05
2025-12-09 09:05:28 - INFO - Epoch: 13.82, Step: 43790, Train Loss: 1.4413, Learning Rate: 6.89e-05
2025-12-09 09:05:39 - INFO - Epoch: 13.82, Step: 43800, Train Loss: 1.4581, Learning Rate: 6.89e-05
2025-12-09 09:05:50 - INFO - Epoch: 13.82, Step: 43810, Train Loss: 1.4265, Learning Rate: 6.89e-05
2025-12-09 09:06:01 - INFO - Epoch: 13.83, Step: 43820, Train Loss: 1.4371, Learning Rate: 6.89e-05
2025-12-09 09:06:12 - INFO - Epoch: 13.83, Step: 43830, Train Loss: 1.4355, Learning Rate: 6.89e-05
2025-12-09 09:06:23 - INFO - Epoch: 13.83, Step: 43840, Train Loss: 1.4277, Learning Rate: 6.89e-05
2025-12-09 09:06:34 - INFO - Epoch: 13.84, Step: 43850, Train Loss: 1.4399, Learning Rate: 6.89e-05
2025-12-09 09:06:45 - INFO - Epoch: 13.84, Step: 43860, Train Loss: 1.4192, Learning Rate: 6.88e-05
2025-12-09 09:06:56 - INFO - Epoch: 13.84, Step: 43870, Train Loss: 1.4532, Learning Rate: 6.88e-05
2025-12-09 09:07:07 - INFO - Epoch: 13.85, Step: 43880, Train Loss: 1.4237, Learning Rate: 6.88e-05
2025-12-09 09:07:18 - INFO - Epoch: 13.85, Step: 43890, Train Loss: 1.4464, Learning Rate: 6.88e-05
2025-12-09 09:07:30 - INFO - Epoch: 13.85, Step: 43900, Train Loss: 1.4565, Learning Rate: 6.88e-05
2025-12-09 09:07:41 - INFO - Epoch: 13.86, Step: 43910, Train Loss: 1.4416, Learning Rate: 6.88e-05
2025-12-09 09:07:52 - INFO - Epoch: 13.86, Step: 43920, Train Loss: 1.4140, Learning Rate: 6.88e-05
2025-12-09 09:08:03 - INFO - Epoch: 13.86, Step: 43930, Train Loss: 1.4177, Learning Rate: 6.88e-05
2025-12-09 09:08:14 - INFO - Epoch: 13.87, Step: 43940, Train Loss: 1.4352, Learning Rate: 6.88e-05
2025-12-09 09:08:25 - INFO - Epoch: 13.87, Step: 43950, Train Loss: 1.4534, Learning Rate: 6.88e-05
2025-12-09 09:08:36 - INFO - Epoch: 13.87, Step: 43960, Train Loss: 1.4594, Learning Rate: 6.88e-05
2025-12-09 09:08:47 - INFO - Epoch: 13.88, Step: 43970, Train Loss: 1.4400, Learning Rate: 6.88e-05
2025-12-09 09:08:58 - INFO - Epoch: 13.88, Step: 43980, Train Loss: 1.4422, Learning Rate: 6.87e-05
2025-12-09 09:09:09 - INFO - Epoch: 13.88, Step: 43990, Train Loss: 1.4678, Learning Rate: 6.87e-05
2025-12-09 09:09:20 - INFO - Epoch: 13.88, Step: 44000, Train Loss: 1.4331, Learning Rate: 6.87e-05
2025-12-09 09:09:31 - INFO - Epoch: 13.89, Step: 44010, Train Loss: 1.4438, Learning Rate: 6.87e-05
2025-12-09 09:09:42 - INFO - Epoch: 13.89, Step: 44020, Train Loss: 1.4428, Learning Rate: 6.87e-05
2025-12-09 09:09:54 - INFO - Epoch: 13.89, Step: 44030, Train Loss: 1.4541, Learning Rate: 6.87e-05
2025-12-09 09:10:05 - INFO - Epoch: 13.90, Step: 44040, Train Loss: 1.4786, Learning Rate: 6.87e-05
2025-12-09 09:10:16 - INFO - Epoch: 13.90, Step: 44050, Train Loss: 1.4791, Learning Rate: 6.87e-05
2025-12-09 09:10:27 - INFO - Epoch: 13.90, Step: 44060, Train Loss: 1.4465, Learning Rate: 6.87e-05
2025-12-09 09:10:38 - INFO - Epoch: 13.91, Step: 44070, Train Loss: 1.4468, Learning Rate: 6.87e-05
2025-12-09 09:10:49 - INFO - Epoch: 13.91, Step: 44080, Train Loss: 1.4352, Learning Rate: 6.87e-05
2025-12-09 09:11:00 - INFO - Epoch: 13.91, Step: 44090, Train Loss: 1.4556, Learning Rate: 6.87e-05
2025-12-09 09:11:11 - INFO - Epoch: 13.92, Step: 44100, Train Loss: 1.4564, Learning Rate: 6.86e-05
2025-12-09 09:11:22 - INFO - Epoch: 13.92, Step: 44110, Train Loss: 1.4157, Learning Rate: 6.86e-05
2025-12-09 09:11:33 - INFO - Epoch: 13.92, Step: 44120, Train Loss: 1.4065, Learning Rate: 6.86e-05
2025-12-09 09:11:44 - INFO - Epoch: 13.93, Step: 44130, Train Loss: 1.4655, Learning Rate: 6.86e-05
2025-12-09 09:11:55 - INFO - Epoch: 13.93, Step: 44140, Train Loss: 1.4316, Learning Rate: 6.86e-05
2025-12-09 09:12:07 - INFO - Epoch: 13.93, Step: 44150, Train Loss: 1.4603, Learning Rate: 6.86e-05
2025-12-09 09:12:18 - INFO - Epoch: 13.93, Step: 44160, Train Loss: 1.4040, Learning Rate: 6.86e-05
2025-12-09 09:12:29 - INFO - Epoch: 13.94, Step: 44170, Train Loss: 1.4561, Learning Rate: 6.86e-05
2025-12-09 09:12:40 - INFO - Epoch: 13.94, Step: 44180, Train Loss: 1.4887, Learning Rate: 6.86e-05
2025-12-09 09:12:51 - INFO - Epoch: 13.94, Step: 44190, Train Loss: 1.4595, Learning Rate: 6.86e-05
2025-12-09 09:13:02 - INFO - Epoch: 13.95, Step: 44200, Train Loss: 1.4118, Learning Rate: 6.86e-05
2025-12-09 09:13:13 - INFO - Epoch: 13.95, Step: 44210, Train Loss: 1.4824, Learning Rate: 6.86e-05
2025-12-09 09:13:24 - INFO - Epoch: 13.95, Step: 44220, Train Loss: 1.4144, Learning Rate: 6.85e-05
2025-12-09 09:13:35 - INFO - Epoch: 13.96, Step: 44230, Train Loss: 1.4499, Learning Rate: 6.85e-05
2025-12-09 09:13:46 - INFO - Epoch: 13.96, Step: 44240, Train Loss: 1.4256, Learning Rate: 6.85e-05
2025-12-09 09:13:57 - INFO - Epoch: 13.96, Step: 44250, Train Loss: 1.3980, Learning Rate: 6.85e-05
2025-12-09 09:14:08 - INFO - Epoch: 13.97, Step: 44260, Train Loss: 1.4771, Learning Rate: 6.85e-05
2025-12-09 09:14:19 - INFO - Epoch: 13.97, Step: 44270, Train Loss: 1.4254, Learning Rate: 6.85e-05
2025-12-09 09:14:31 - INFO - Epoch: 13.97, Step: 44280, Train Loss: 1.4887, Learning Rate: 6.85e-05
2025-12-09 09:14:42 - INFO - Epoch: 13.98, Step: 44290, Train Loss: 1.4288, Learning Rate: 6.85e-05
2025-12-09 09:14:53 - INFO - Epoch: 13.98, Step: 44300, Train Loss: 1.4526, Learning Rate: 6.85e-05
2025-12-09 09:15:04 - INFO - Epoch: 13.98, Step: 44310, Train Loss: 1.4616, Learning Rate: 6.85e-05
2025-12-09 09:15:15 - INFO - Epoch: 13.99, Step: 44320, Train Loss: 1.4217, Learning Rate: 6.85e-05
2025-12-09 09:15:26 - INFO - Epoch: 13.99, Step: 44330, Train Loss: 1.4250, Learning Rate: 6.85e-05
2025-12-09 09:15:37 - INFO - Epoch: 13.99, Step: 44340, Train Loss: 1.4249, Learning Rate: 6.84e-05
2025-12-09 09:15:48 - INFO - Epoch: 13.99, Step: 44350, Train Loss: 1.4669, Learning Rate: 6.84e-05
2025-12-09 09:15:59 - INFO - Epoch: 14.00, Step: 44360, Train Loss: 1.4216, Learning Rate: 6.84e-05
2025-12-09 09:16:10 - INFO - Epoch: 14.00, Step: 44370, Train Loss: 1.4578, Learning Rate: 6.84e-05
2025-12-09 09:16:21 - INFO - Epoch: 14.00, Step: 44380, Train Loss: 1.4193, Learning Rate: 6.84e-05
2025-12-09 09:16:32 - INFO - Epoch: 14.01, Step: 44390, Train Loss: 1.4513, Learning Rate: 6.84e-05
2025-12-09 09:16:44 - INFO - Epoch: 14.01, Step: 44400, Train Loss: 1.4099, Learning Rate: 6.84e-05
2025-12-09 09:16:55 - INFO - Epoch: 14.01, Step: 44410, Train Loss: 1.4356, Learning Rate: 6.84e-05
2025-12-09 09:17:06 - INFO - Epoch: 14.02, Step: 44420, Train Loss: 1.4261, Learning Rate: 6.84e-05
2025-12-09 09:17:17 - INFO - Epoch: 14.02, Step: 44430, Train Loss: 1.4648, Learning Rate: 6.84e-05
2025-12-09 09:17:28 - INFO - Epoch: 14.02, Step: 44440, Train Loss: 1.4103, Learning Rate: 6.84e-05
2025-12-09 09:17:39 - INFO - Epoch: 14.03, Step: 44450, Train Loss: 1.4472, Learning Rate: 6.84e-05
2025-12-09 09:17:50 - INFO - Epoch: 14.03, Step: 44460, Train Loss: 1.4063, Learning Rate: 6.83e-05
2025-12-09 09:18:01 - INFO - Epoch: 14.03, Step: 44470, Train Loss: 1.4544, Learning Rate: 6.83e-05
2025-12-09 09:18:12 - INFO - Epoch: 14.04, Step: 44480, Train Loss: 1.4347, Learning Rate: 6.83e-05
2025-12-09 09:18:23 - INFO - Epoch: 14.04, Step: 44490, Train Loss: 1.4494, Learning Rate: 6.83e-05
2025-12-09 09:18:34 - INFO - Epoch: 14.04, Step: 44500, Train Loss: 1.4419, Learning Rate: 6.83e-05
2025-12-09 09:18:45 - INFO - Epoch: 14.05, Step: 44510, Train Loss: 1.4280, Learning Rate: 6.83e-05
2025-12-09 09:18:56 - INFO - Epoch: 14.05, Step: 44520, Train Loss: 1.4412, Learning Rate: 6.83e-05
2025-12-09 09:19:08 - INFO - Epoch: 14.05, Step: 44530, Train Loss: 1.4622, Learning Rate: 6.83e-05
2025-12-09 09:19:19 - INFO - Epoch: 14.05, Step: 44540, Train Loss: 1.4603, Learning Rate: 6.83e-05
2025-12-09 09:19:30 - INFO - Epoch: 14.06, Step: 44550, Train Loss: 1.4267, Learning Rate: 6.83e-05
2025-12-09 09:19:41 - INFO - Epoch: 14.06, Step: 44560, Train Loss: 1.4424, Learning Rate: 6.83e-05
2025-12-09 09:19:52 - INFO - Epoch: 14.06, Step: 44570, Train Loss: 1.4130, Learning Rate: 6.83e-05
2025-12-09 09:20:03 - INFO - Epoch: 14.07, Step: 44580, Train Loss: 1.4280, Learning Rate: 6.82e-05
2025-12-09 09:20:14 - INFO - Epoch: 14.07, Step: 44590, Train Loss: 1.4233, Learning Rate: 6.82e-05
2025-12-09 09:20:25 - INFO - Epoch: 14.07, Step: 44600, Train Loss: 1.3938, Learning Rate: 6.82e-05
2025-12-09 09:20:36 - INFO - Epoch: 14.08, Step: 44610, Train Loss: 1.4198, Learning Rate: 6.82e-05
2025-12-09 09:20:47 - INFO - Epoch: 14.08, Step: 44620, Train Loss: 1.4503, Learning Rate: 6.82e-05
2025-12-09 09:20:58 - INFO - Epoch: 14.08, Step: 44630, Train Loss: 1.4798, Learning Rate: 6.82e-05
2025-12-09 09:21:09 - INFO - Epoch: 14.09, Step: 44640, Train Loss: 1.4678, Learning Rate: 6.82e-05
2025-12-09 09:21:21 - INFO - Epoch: 14.09, Step: 44650, Train Loss: 1.4487, Learning Rate: 6.82e-05
2025-12-09 09:21:32 - INFO - Epoch: 14.09, Step: 44660, Train Loss: 1.4351, Learning Rate: 6.82e-05
2025-12-09 09:21:43 - INFO - Epoch: 14.10, Step: 44670, Train Loss: 1.4424, Learning Rate: 6.82e-05
2025-12-09 09:21:54 - INFO - Epoch: 14.10, Step: 44680, Train Loss: 1.4319, Learning Rate: 6.82e-05
2025-12-09 09:22:05 - INFO - Epoch: 14.10, Step: 44690, Train Loss: 1.4443, Learning Rate: 6.82e-05
2025-12-09 09:22:16 - INFO - Epoch: 14.11, Step: 44700, Train Loss: 1.4419, Learning Rate: 6.81e-05
2025-12-09 09:22:27 - INFO - Epoch: 14.11, Step: 44710, Train Loss: 1.4367, Learning Rate: 6.81e-05
2025-12-09 09:22:38 - INFO - Epoch: 14.11, Step: 44720, Train Loss: 1.4426, Learning Rate: 6.81e-05
2025-12-09 09:22:49 - INFO - Epoch: 14.11, Step: 44730, Train Loss: 1.3802, Learning Rate: 6.81e-05
2025-12-09 09:23:00 - INFO - Epoch: 14.12, Step: 44740, Train Loss: 1.4306, Learning Rate: 6.81e-05
2025-12-09 09:23:11 - INFO - Epoch: 14.12, Step: 44750, Train Loss: 1.4506, Learning Rate: 6.81e-05
2025-12-09 09:23:22 - INFO - Epoch: 14.12, Step: 44760, Train Loss: 1.4213, Learning Rate: 6.81e-05
2025-12-09 09:23:34 - INFO - Epoch: 14.13, Step: 44770, Train Loss: 1.4122, Learning Rate: 6.81e-05
2025-12-09 09:23:45 - INFO - Epoch: 14.13, Step: 44780, Train Loss: 1.4203, Learning Rate: 6.81e-05
2025-12-09 09:23:56 - INFO - Epoch: 14.13, Step: 44790, Train Loss: 1.4480, Learning Rate: 6.81e-05
2025-12-09 09:24:07 - INFO - Epoch: 14.14, Step: 44800, Train Loss: 1.4255, Learning Rate: 6.81e-05
2025-12-09 09:24:18 - INFO - Epoch: 14.14, Step: 44810, Train Loss: 1.4350, Learning Rate: 6.81e-05
2025-12-09 09:24:29 - INFO - Epoch: 14.14, Step: 44820, Train Loss: 1.4372, Learning Rate: 6.80e-05
2025-12-09 09:24:40 - INFO - Epoch: 14.15, Step: 44830, Train Loss: 1.4553, Learning Rate: 6.80e-05
2025-12-09 09:24:51 - INFO - Epoch: 14.15, Step: 44840, Train Loss: 1.4207, Learning Rate: 6.80e-05
2025-12-09 09:25:02 - INFO - Epoch: 14.15, Step: 44850, Train Loss: 1.4043, Learning Rate: 6.80e-05
2025-12-09 09:25:13 - INFO - Epoch: 14.16, Step: 44860, Train Loss: 1.4243, Learning Rate: 6.80e-05
2025-12-09 09:25:24 - INFO - Epoch: 14.16, Step: 44870, Train Loss: 1.4120, Learning Rate: 6.80e-05
2025-12-09 09:25:35 - INFO - Epoch: 14.16, Step: 44880, Train Loss: 1.4049, Learning Rate: 6.80e-05
2025-12-09 09:25:46 - INFO - Epoch: 14.17, Step: 44890, Train Loss: 1.4319, Learning Rate: 6.80e-05
2025-12-09 09:25:58 - INFO - Epoch: 14.17, Step: 44900, Train Loss: 1.4381, Learning Rate: 6.80e-05
2025-12-09 09:26:09 - INFO - Epoch: 14.17, Step: 44910, Train Loss: 1.3807, Learning Rate: 6.80e-05
2025-12-09 09:26:20 - INFO - Epoch: 14.17, Step: 44920, Train Loss: 1.4401, Learning Rate: 6.80e-05
2025-12-09 09:26:31 - INFO - Epoch: 14.18, Step: 44930, Train Loss: 1.4142, Learning Rate: 6.80e-05
2025-12-09 09:26:42 - INFO - Epoch: 14.18, Step: 44940, Train Loss: 1.4356, Learning Rate: 6.79e-05
2025-12-09 09:26:53 - INFO - Epoch: 14.18, Step: 44950, Train Loss: 1.4526, Learning Rate: 6.79e-05
2025-12-09 09:27:04 - INFO - Epoch: 14.19, Step: 44960, Train Loss: 1.4114, Learning Rate: 6.79e-05
2025-12-09 09:27:15 - INFO - Epoch: 14.19, Step: 44970, Train Loss: 1.4261, Learning Rate: 6.79e-05
2025-12-09 09:27:26 - INFO - Epoch: 14.19, Step: 44980, Train Loss: 1.4763, Learning Rate: 6.79e-05
2025-12-09 09:27:37 - INFO - Epoch: 14.20, Step: 44990, Train Loss: 1.4279, Learning Rate: 6.79e-05
2025-12-09 09:27:48 - INFO - Epoch: 14.20, Step: 45000, Train Loss: 1.4300, Learning Rate: 6.79e-05
2025-12-09 09:27:59 - INFO - Epoch: 14.20, Step: 45010, Train Loss: 1.3934, Learning Rate: 6.79e-05
2025-12-09 09:28:11 - INFO - Epoch: 14.21, Step: 45020, Train Loss: 1.4203, Learning Rate: 6.79e-05
2025-12-09 09:28:22 - INFO - Epoch: 14.21, Step: 45030, Train Loss: 1.4557, Learning Rate: 6.79e-05
2025-12-09 09:28:33 - INFO - Epoch: 14.21, Step: 45040, Train Loss: 1.4729, Learning Rate: 6.79e-05
2025-12-09 09:28:44 - INFO - Epoch: 14.22, Step: 45050, Train Loss: 1.4249, Learning Rate: 6.79e-05
2025-12-09 09:28:55 - INFO - Epoch: 14.22, Step: 45060, Train Loss: 1.4103, Learning Rate: 6.78e-05
2025-12-09 09:29:06 - INFO - Epoch: 14.22, Step: 45070, Train Loss: 1.4495, Learning Rate: 6.78e-05
2025-12-09 09:29:17 - INFO - Epoch: 14.23, Step: 45080, Train Loss: 1.4708, Learning Rate: 6.78e-05
2025-12-09 09:29:28 - INFO - Epoch: 14.23, Step: 45090, Train Loss: 1.4724, Learning Rate: 6.78e-05
2025-12-09 09:29:39 - INFO - Epoch: 14.23, Step: 45100, Train Loss: 1.4422, Learning Rate: 6.78e-05
2025-12-09 09:29:50 - INFO - Epoch: 14.23, Step: 45110, Train Loss: 1.4413, Learning Rate: 6.78e-05
2025-12-09 09:30:01 - INFO - Epoch: 14.24, Step: 45120, Train Loss: 1.4250, Learning Rate: 6.78e-05
2025-12-09 09:30:12 - INFO - Epoch: 14.24, Step: 45130, Train Loss: 1.4059, Learning Rate: 6.78e-05
2025-12-09 09:30:24 - INFO - Epoch: 14.24, Step: 45140, Train Loss: 1.4183, Learning Rate: 6.78e-05
2025-12-09 09:30:35 - INFO - Epoch: 14.25, Step: 45150, Train Loss: 1.4357, Learning Rate: 6.78e-05
2025-12-09 09:30:46 - INFO - Epoch: 14.25, Step: 45160, Train Loss: 1.3934, Learning Rate: 6.78e-05
2025-12-09 09:30:57 - INFO - Epoch: 14.25, Step: 45170, Train Loss: 1.4459, Learning Rate: 6.78e-05
2025-12-09 09:31:08 - INFO - Epoch: 14.26, Step: 45180, Train Loss: 1.4517, Learning Rate: 6.77e-05
2025-12-09 09:31:19 - INFO - Epoch: 14.26, Step: 45190, Train Loss: 1.4117, Learning Rate: 6.77e-05
2025-12-09 09:31:30 - INFO - Epoch: 14.26, Step: 45200, Train Loss: 1.4221, Learning Rate: 6.77e-05
2025-12-09 09:31:41 - INFO - Epoch: 14.27, Step: 45210, Train Loss: 1.4465, Learning Rate: 6.77e-05
2025-12-09 09:31:52 - INFO - Epoch: 14.27, Step: 45220, Train Loss: 1.4504, Learning Rate: 6.77e-05
2025-12-09 09:32:03 - INFO - Epoch: 14.27, Step: 45230, Train Loss: 1.4071, Learning Rate: 6.77e-05
2025-12-09 09:32:14 - INFO - Epoch: 14.28, Step: 45240, Train Loss: 1.4692, Learning Rate: 6.77e-05
2025-12-09 09:32:25 - INFO - Epoch: 14.28, Step: 45250, Train Loss: 1.4635, Learning Rate: 6.77e-05
2025-12-09 09:32:36 - INFO - Epoch: 14.28, Step: 45260, Train Loss: 1.3941, Learning Rate: 6.77e-05
2025-12-09 09:32:48 - INFO - Epoch: 14.29, Step: 45270, Train Loss: 1.4119, Learning Rate: 6.77e-05
2025-12-09 09:32:59 - INFO - Epoch: 14.29, Step: 45280, Train Loss: 1.4375, Learning Rate: 6.77e-05
2025-12-09 09:33:10 - INFO - Epoch: 14.29, Step: 45290, Train Loss: 1.3928, Learning Rate: 6.77e-05
2025-12-09 09:33:21 - INFO - Epoch: 14.29, Step: 45300, Train Loss: 1.4713, Learning Rate: 6.76e-05
2025-12-09 09:33:32 - INFO - Epoch: 14.30, Step: 45310, Train Loss: 1.4552, Learning Rate: 6.76e-05
2025-12-09 09:33:43 - INFO - Epoch: 14.30, Step: 45320, Train Loss: 1.4688, Learning Rate: 6.76e-05
2025-12-09 09:33:54 - INFO - Epoch: 14.30, Step: 45330, Train Loss: 1.4442, Learning Rate: 6.76e-05
2025-12-09 09:34:05 - INFO - Epoch: 14.31, Step: 45340, Train Loss: 1.4134, Learning Rate: 6.76e-05
2025-12-09 09:34:16 - INFO - Epoch: 14.31, Step: 45350, Train Loss: 1.4475, Learning Rate: 6.76e-05
2025-12-09 09:34:27 - INFO - Epoch: 14.31, Step: 45360, Train Loss: 1.4244, Learning Rate: 6.76e-05
2025-12-09 09:34:38 - INFO - Epoch: 14.32, Step: 45370, Train Loss: 1.4266, Learning Rate: 6.76e-05
2025-12-09 09:34:49 - INFO - Epoch: 14.32, Step: 45380, Train Loss: 1.4544, Learning Rate: 6.76e-05
2025-12-09 09:35:01 - INFO - Epoch: 14.32, Step: 45390, Train Loss: 1.4355, Learning Rate: 6.76e-05
2025-12-09 09:35:12 - INFO - Epoch: 14.33, Step: 45400, Train Loss: 1.4341, Learning Rate: 6.76e-05
2025-12-09 09:35:23 - INFO - Epoch: 14.33, Step: 45410, Train Loss: 1.3921, Learning Rate: 6.76e-05
2025-12-09 09:35:34 - INFO - Epoch: 14.33, Step: 45420, Train Loss: 1.4352, Learning Rate: 6.75e-05
2025-12-09 09:35:45 - INFO - Epoch: 14.34, Step: 45430, Train Loss: 1.4359, Learning Rate: 6.75e-05
2025-12-09 09:35:56 - INFO - Epoch: 14.34, Step: 45440, Train Loss: 1.4020, Learning Rate: 6.75e-05
2025-12-09 09:36:07 - INFO - Epoch: 14.34, Step: 45450, Train Loss: 1.4162, Learning Rate: 6.75e-05
2025-12-09 09:36:18 - INFO - Epoch: 14.35, Step: 45460, Train Loss: 1.4350, Learning Rate: 6.75e-05
2025-12-09 09:36:29 - INFO - Epoch: 14.35, Step: 45470, Train Loss: 1.4049, Learning Rate: 6.75e-05
2025-12-09 09:36:40 - INFO - Epoch: 14.35, Step: 45480, Train Loss: 1.4271, Learning Rate: 6.75e-05
2025-12-09 09:36:51 - INFO - Epoch: 14.35, Step: 45490, Train Loss: 1.4043, Learning Rate: 6.75e-05
2025-12-09 09:37:02 - INFO - Epoch: 14.36, Step: 45500, Train Loss: 1.4544, Learning Rate: 6.75e-05
2025-12-09 09:37:14 - INFO - Epoch: 14.36, Step: 45510, Train Loss: 1.4242, Learning Rate: 6.75e-05
2025-12-09 09:37:25 - INFO - Epoch: 14.36, Step: 45520, Train Loss: 1.3960, Learning Rate: 6.75e-05
2025-12-09 09:37:36 - INFO - Epoch: 14.37, Step: 45530, Train Loss: 1.4178, Learning Rate: 6.75e-05
2025-12-09 09:37:47 - INFO - Epoch: 14.37, Step: 45540, Train Loss: 1.4416, Learning Rate: 6.74e-05
2025-12-09 09:37:58 - INFO - Epoch: 14.37, Step: 45550, Train Loss: 1.4505, Learning Rate: 6.74e-05
2025-12-09 09:38:09 - INFO - Epoch: 14.38, Step: 45560, Train Loss: 1.4021, Learning Rate: 6.74e-05
2025-12-09 09:38:20 - INFO - Epoch: 14.38, Step: 45570, Train Loss: 1.4124, Learning Rate: 6.74e-05
2025-12-09 09:38:31 - INFO - Epoch: 14.38, Step: 45580, Train Loss: 1.3849, Learning Rate: 6.74e-05
2025-12-09 09:38:42 - INFO - Epoch: 14.39, Step: 45590, Train Loss: 1.4308, Learning Rate: 6.74e-05
2025-12-09 09:38:53 - INFO - Epoch: 14.39, Step: 45600, Train Loss: 1.4313, Learning Rate: 6.74e-05
2025-12-09 09:39:04 - INFO - Epoch: 14.39, Step: 45610, Train Loss: 1.4105, Learning Rate: 6.74e-05
2025-12-09 09:39:15 - INFO - Epoch: 14.40, Step: 45620, Train Loss: 1.4070, Learning Rate: 6.74e-05
2025-12-09 09:39:26 - INFO - Epoch: 14.40, Step: 45630, Train Loss: 1.4618, Learning Rate: 6.74e-05
2025-12-09 09:39:38 - INFO - Epoch: 14.40, Step: 45640, Train Loss: 1.4005, Learning Rate: 6.74e-05
2025-12-09 09:39:49 - INFO - Epoch: 14.41, Step: 45650, Train Loss: 1.4066, Learning Rate: 6.74e-05
2025-12-09 09:40:00 - INFO - Epoch: 14.41, Step: 45660, Train Loss: 1.4170, Learning Rate: 6.73e-05
2025-12-09 09:40:11 - INFO - Epoch: 14.41, Step: 45670, Train Loss: 1.4247, Learning Rate: 6.73e-05
2025-12-09 09:40:22 - INFO - Epoch: 14.41, Step: 45680, Train Loss: 1.4067, Learning Rate: 6.73e-05
2025-12-09 09:40:33 - INFO - Epoch: 14.42, Step: 45690, Train Loss: 1.3849, Learning Rate: 6.73e-05
2025-12-09 09:40:44 - INFO - Epoch: 14.42, Step: 45700, Train Loss: 1.4482, Learning Rate: 6.73e-05
2025-12-09 09:40:55 - INFO - Epoch: 14.42, Step: 45710, Train Loss: 1.4486, Learning Rate: 6.73e-05
2025-12-09 09:41:06 - INFO - Epoch: 14.43, Step: 45720, Train Loss: 1.4074, Learning Rate: 6.73e-05
2025-12-09 09:41:17 - INFO - Epoch: 14.43, Step: 45730, Train Loss: 1.4531, Learning Rate: 6.73e-05
2025-12-09 09:41:28 - INFO - Epoch: 14.43, Step: 45740, Train Loss: 1.4305, Learning Rate: 6.73e-05
2025-12-09 09:41:39 - INFO - Epoch: 14.44, Step: 45750, Train Loss: 1.4450, Learning Rate: 6.73e-05
2025-12-09 09:41:51 - INFO - Epoch: 14.44, Step: 45760, Train Loss: 1.4240, Learning Rate: 6.73e-05
2025-12-09 09:42:02 - INFO - Epoch: 14.44, Step: 45770, Train Loss: 1.4058, Learning Rate: 6.73e-05
2025-12-09 09:42:13 - INFO - Epoch: 14.45, Step: 45780, Train Loss: 1.4204, Learning Rate: 6.72e-05
2025-12-09 09:42:24 - INFO - Epoch: 14.45, Step: 45790, Train Loss: 1.4500, Learning Rate: 6.72e-05
2025-12-09 09:42:35 - INFO - Epoch: 14.45, Step: 45800, Train Loss: 1.4424, Learning Rate: 6.72e-05
2025-12-09 09:42:46 - INFO - Epoch: 14.46, Step: 45810, Train Loss: 1.4201, Learning Rate: 6.72e-05
2025-12-09 09:42:57 - INFO - Epoch: 14.46, Step: 45820, Train Loss: 1.4432, Learning Rate: 6.72e-05
2025-12-09 09:43:08 - INFO - Epoch: 14.46, Step: 45830, Train Loss: 1.4493, Learning Rate: 6.72e-05
2025-12-09 09:43:19 - INFO - Epoch: 14.47, Step: 45840, Train Loss: 1.4440, Learning Rate: 6.72e-05
2025-12-09 09:43:30 - INFO - Epoch: 14.47, Step: 45850, Train Loss: 1.4639, Learning Rate: 6.72e-05
2025-12-09 09:43:41 - INFO - Epoch: 14.47, Step: 45860, Train Loss: 1.4384, Learning Rate: 6.72e-05
2025-12-09 09:43:52 - INFO - Epoch: 14.47, Step: 45870, Train Loss: 1.4322, Learning Rate: 6.72e-05
2025-12-09 09:44:04 - INFO - Epoch: 14.48, Step: 45880, Train Loss: 1.4494, Learning Rate: 6.72e-05
2025-12-09 09:44:15 - INFO - Epoch: 14.48, Step: 45890, Train Loss: 1.4206, Learning Rate: 6.72e-05
2025-12-09 09:44:26 - INFO - Epoch: 14.48, Step: 45900, Train Loss: 1.4249, Learning Rate: 6.71e-05
2025-12-09 09:44:37 - INFO - Epoch: 14.49, Step: 45910, Train Loss: 1.4038, Learning Rate: 6.71e-05
2025-12-09 09:44:48 - INFO - Epoch: 14.49, Step: 45920, Train Loss: 1.4241, Learning Rate: 6.71e-05
2025-12-09 09:44:59 - INFO - Epoch: 14.49, Step: 45930, Train Loss: 1.4273, Learning Rate: 6.71e-05
2025-12-09 09:45:10 - INFO - Epoch: 14.50, Step: 45940, Train Loss: 1.4565, Learning Rate: 6.71e-05
2025-12-09 09:45:21 - INFO - Epoch: 14.50, Step: 45950, Train Loss: 1.4420, Learning Rate: 6.71e-05
2025-12-09 09:45:32 - INFO - Epoch: 14.50, Step: 45960, Train Loss: 1.4216, Learning Rate: 6.71e-05
2025-12-09 09:45:43 - INFO - Epoch: 14.51, Step: 45970, Train Loss: 1.4069, Learning Rate: 6.71e-05
2025-12-09 09:45:54 - INFO - Epoch: 14.51, Step: 45980, Train Loss: 1.4150, Learning Rate: 6.71e-05
2025-12-09 09:46:05 - INFO - Epoch: 14.51, Step: 45990, Train Loss: 1.4078, Learning Rate: 6.71e-05
2025-12-09 09:46:16 - INFO - Epoch: 14.52, Step: 46000, Train Loss: 1.4402, Learning Rate: 6.71e-05
2025-12-09 09:46:28 - INFO - Epoch: 14.52, Step: 46010, Train Loss: 1.4642, Learning Rate: 6.71e-05
2025-12-09 09:46:39 - INFO - Epoch: 14.52, Step: 46020, Train Loss: 1.4304, Learning Rate: 6.70e-05
2025-12-09 09:46:50 - INFO - Epoch: 14.53, Step: 46030, Train Loss: 1.4369, Learning Rate: 6.70e-05
2025-12-09 09:47:01 - INFO - Epoch: 14.53, Step: 46040, Train Loss: 1.4231, Learning Rate: 6.70e-05
2025-12-09 09:47:12 - INFO - Epoch: 14.53, Step: 46050, Train Loss: 1.4570, Learning Rate: 6.70e-05
2025-12-09 09:47:23 - INFO - Epoch: 14.53, Step: 46060, Train Loss: 1.4347, Learning Rate: 6.70e-05
2025-12-09 09:47:34 - INFO - Epoch: 14.54, Step: 46070, Train Loss: 1.4117, Learning Rate: 6.70e-05
2025-12-09 09:47:45 - INFO - Epoch: 14.54, Step: 46080, Train Loss: 1.4039, Learning Rate: 6.70e-05
2025-12-09 09:47:56 - INFO - Epoch: 14.54, Step: 46090, Train Loss: 1.4362, Learning Rate: 6.70e-05
2025-12-09 09:48:07 - INFO - Epoch: 14.55, Step: 46100, Train Loss: 1.4257, Learning Rate: 6.70e-05
2025-12-09 09:48:18 - INFO - Epoch: 14.55, Step: 46110, Train Loss: 1.3736, Learning Rate: 6.70e-05
2025-12-09 09:48:29 - INFO - Epoch: 14.55, Step: 46120, Train Loss: 1.4204, Learning Rate: 6.70e-05
2025-12-09 09:48:41 - INFO - Epoch: 14.56, Step: 46130, Train Loss: 1.4158, Learning Rate: 6.70e-05
2025-12-09 09:48:52 - INFO - Epoch: 14.56, Step: 46140, Train Loss: 1.4693, Learning Rate: 6.69e-05
2025-12-09 09:49:03 - INFO - Epoch: 14.56, Step: 46150, Train Loss: 1.4275, Learning Rate: 6.69e-05
2025-12-09 09:49:14 - INFO - Epoch: 14.57, Step: 46160, Train Loss: 1.3931, Learning Rate: 6.69e-05
2025-12-09 09:49:25 - INFO - Epoch: 14.57, Step: 46170, Train Loss: 1.4349, Learning Rate: 6.69e-05
2025-12-09 09:49:36 - INFO - Epoch: 14.57, Step: 46180, Train Loss: 1.4297, Learning Rate: 6.69e-05
2025-12-09 09:49:47 - INFO - Epoch: 14.58, Step: 46190, Train Loss: 1.4431, Learning Rate: 6.69e-05
2025-12-09 09:49:58 - INFO - Epoch: 14.58, Step: 46200, Train Loss: 1.3758, Learning Rate: 6.69e-05
2025-12-09 09:50:09 - INFO - Epoch: 14.58, Step: 46210, Train Loss: 1.4808, Learning Rate: 6.69e-05
2025-12-09 09:50:20 - INFO - Epoch: 14.59, Step: 46220, Train Loss: 1.4264, Learning Rate: 6.69e-05
2025-12-09 09:50:31 - INFO - Epoch: 14.59, Step: 46230, Train Loss: 1.4045, Learning Rate: 6.69e-05
2025-12-09 09:50:42 - INFO - Epoch: 14.59, Step: 46240, Train Loss: 1.3992, Learning Rate: 6.69e-05
2025-12-09 09:50:54 - INFO - Epoch: 14.59, Step: 46250, Train Loss: 1.4510, Learning Rate: 6.69e-05
2025-12-09 09:51:05 - INFO - Epoch: 14.60, Step: 46260, Train Loss: 1.4347, Learning Rate: 6.68e-05
2025-12-09 09:51:16 - INFO - Epoch: 14.60, Step: 46270, Train Loss: 1.4246, Learning Rate: 6.68e-05
2025-12-09 09:51:27 - INFO - Epoch: 14.60, Step: 46280, Train Loss: 1.4072, Learning Rate: 6.68e-05
2025-12-09 09:51:38 - INFO - Epoch: 14.61, Step: 46290, Train Loss: 1.4343, Learning Rate: 6.68e-05
2025-12-09 09:51:49 - INFO - Epoch: 14.61, Step: 46300, Train Loss: 1.4169, Learning Rate: 6.68e-05
2025-12-09 09:52:00 - INFO - Epoch: 14.61, Step: 46310, Train Loss: 1.4238, Learning Rate: 6.68e-05
2025-12-09 09:52:11 - INFO - Epoch: 14.62, Step: 46320, Train Loss: 1.4277, Learning Rate: 6.68e-05
2025-12-09 09:52:22 - INFO - Epoch: 14.62, Step: 46330, Train Loss: 1.4267, Learning Rate: 6.68e-05
2025-12-09 09:52:33 - INFO - Epoch: 14.62, Step: 46340, Train Loss: 1.4311, Learning Rate: 6.68e-05
2025-12-09 09:52:44 - INFO - Epoch: 14.63, Step: 46350, Train Loss: 1.4310, Learning Rate: 6.68e-05
2025-12-09 09:52:55 - INFO - Epoch: 14.63, Step: 46360, Train Loss: 1.4370, Learning Rate: 6.68e-05
2025-12-09 09:53:06 - INFO - Epoch: 14.63, Step: 46370, Train Loss: 1.3894, Learning Rate: 6.68e-05
2025-12-09 09:53:18 - INFO - Epoch: 14.64, Step: 46380, Train Loss: 1.4101, Learning Rate: 6.67e-05
2025-12-09 09:53:29 - INFO - Epoch: 14.64, Step: 46390, Train Loss: 1.3922, Learning Rate: 6.67e-05
2025-12-09 09:53:40 - INFO - Epoch: 14.64, Step: 46400, Train Loss: 1.3766, Learning Rate: 6.67e-05
2025-12-09 09:53:51 - INFO - Epoch: 14.64, Step: 46410, Train Loss: 1.4369, Learning Rate: 6.67e-05
2025-12-09 09:54:02 - INFO - Epoch: 14.65, Step: 46420, Train Loss: 1.4451, Learning Rate: 6.67e-05
2025-12-09 09:54:13 - INFO - Epoch: 14.65, Step: 46430, Train Loss: 1.3803, Learning Rate: 6.67e-05
2025-12-09 09:54:24 - INFO - Epoch: 14.65, Step: 46440, Train Loss: 1.4216, Learning Rate: 6.67e-05
2025-12-09 09:54:35 - INFO - Epoch: 14.66, Step: 46450, Train Loss: 1.4125, Learning Rate: 6.67e-05
2025-12-09 09:54:46 - INFO - Epoch: 14.66, Step: 46460, Train Loss: 1.4210, Learning Rate: 6.67e-05
2025-12-09 09:54:57 - INFO - Epoch: 14.66, Step: 46470, Train Loss: 1.3733, Learning Rate: 6.67e-05
2025-12-09 09:55:08 - INFO - Epoch: 14.67, Step: 46480, Train Loss: 1.4388, Learning Rate: 6.67e-05
2025-12-09 09:55:19 - INFO - Epoch: 14.67, Step: 46490, Train Loss: 1.4113, Learning Rate: 6.67e-05
2025-12-09 09:55:31 - INFO - Epoch: 14.67, Step: 46500, Train Loss: 1.4137, Learning Rate: 6.66e-05
2025-12-09 09:55:42 - INFO - Epoch: 14.68, Step: 46510, Train Loss: 1.3988, Learning Rate: 6.66e-05
2025-12-09 09:55:53 - INFO - Epoch: 14.68, Step: 46520, Train Loss: 1.4064, Learning Rate: 6.66e-05
2025-12-09 09:56:04 - INFO - Epoch: 14.68, Step: 46530, Train Loss: 1.4231, Learning Rate: 6.66e-05
2025-12-09 09:56:15 - INFO - Epoch: 14.69, Step: 46540, Train Loss: 1.3881, Learning Rate: 6.66e-05
2025-12-09 09:56:26 - INFO - Epoch: 14.69, Step: 46550, Train Loss: 1.4116, Learning Rate: 6.66e-05
2025-12-09 09:56:37 - INFO - Epoch: 14.69, Step: 46560, Train Loss: 1.4313, Learning Rate: 6.66e-05
2025-12-09 09:56:48 - INFO - Epoch: 14.70, Step: 46570, Train Loss: 1.3845, Learning Rate: 6.66e-05
2025-12-09 09:56:59 - INFO - Epoch: 14.70, Step: 46580, Train Loss: 1.4574, Learning Rate: 6.66e-05
2025-12-09 09:57:10 - INFO - Epoch: 14.70, Step: 46590, Train Loss: 1.4059, Learning Rate: 6.66e-05
2025-12-09 09:57:21 - INFO - Epoch: 14.70, Step: 46600, Train Loss: 1.4151, Learning Rate: 6.66e-05
2025-12-09 09:57:32 - INFO - Epoch: 14.71, Step: 46610, Train Loss: 1.4153, Learning Rate: 6.66e-05
2025-12-09 09:57:44 - INFO - Epoch: 14.71, Step: 46620, Train Loss: 1.4190, Learning Rate: 6.66e-05
2025-12-09 09:57:55 - INFO - Epoch: 14.71, Step: 46630, Train Loss: 1.4524, Learning Rate: 6.65e-05
2025-12-09 09:58:06 - INFO - Epoch: 14.72, Step: 46640, Train Loss: 1.4396, Learning Rate: 6.65e-05
2025-12-09 09:58:17 - INFO - Epoch: 14.72, Step: 46650, Train Loss: 1.4304, Learning Rate: 6.65e-05
2025-12-09 09:58:28 - INFO - Epoch: 14.72, Step: 46660, Train Loss: 1.3875, Learning Rate: 6.65e-05
2025-12-09 09:58:39 - INFO - Epoch: 14.73, Step: 46670, Train Loss: 1.4102, Learning Rate: 6.65e-05
2025-12-09 09:58:50 - INFO - Epoch: 14.73, Step: 46680, Train Loss: 1.4142, Learning Rate: 6.65e-05
2025-12-09 09:59:01 - INFO - Epoch: 14.73, Step: 46690, Train Loss: 1.3807, Learning Rate: 6.65e-05
2025-12-09 09:59:12 - INFO - Epoch: 14.74, Step: 46700, Train Loss: 1.4264, Learning Rate: 6.65e-05
2025-12-09 09:59:23 - INFO - Epoch: 14.74, Step: 46710, Train Loss: 1.4128, Learning Rate: 6.65e-05
2025-12-09 09:59:34 - INFO - Epoch: 14.74, Step: 46720, Train Loss: 1.4391, Learning Rate: 6.65e-05
2025-12-09 09:59:45 - INFO - Epoch: 14.75, Step: 46730, Train Loss: 1.4260, Learning Rate: 6.65e-05
2025-12-09 09:59:56 - INFO - Epoch: 14.75, Step: 46740, Train Loss: 1.3812, Learning Rate: 6.65e-05
2025-12-09 10:00:08 - INFO - Epoch: 14.75, Step: 46750, Train Loss: 1.3998, Learning Rate: 6.64e-05
2025-12-09 10:00:19 - INFO - Epoch: 14.76, Step: 46760, Train Loss: 1.4083, Learning Rate: 6.64e-05
2025-12-09 10:00:30 - INFO - Epoch: 14.76, Step: 46770, Train Loss: 1.4373, Learning Rate: 6.64e-05
2025-12-09 10:00:41 - INFO - Epoch: 14.76, Step: 46780, Train Loss: 1.4294, Learning Rate: 6.64e-05
2025-12-09 10:00:52 - INFO - Epoch: 14.76, Step: 46790, Train Loss: 1.3841, Learning Rate: 6.64e-05
2025-12-09 10:01:03 - INFO - Epoch: 14.77, Step: 46800, Train Loss: 1.3978, Learning Rate: 6.64e-05
2025-12-09 10:01:14 - INFO - Epoch: 14.77, Step: 46810, Train Loss: 1.4031, Learning Rate: 6.64e-05
2025-12-09 10:01:25 - INFO - Epoch: 14.77, Step: 46820, Train Loss: 1.3856, Learning Rate: 6.64e-05
2025-12-09 10:01:36 - INFO - Epoch: 14.78, Step: 46830, Train Loss: 1.4270, Learning Rate: 6.64e-05
2025-12-09 10:01:47 - INFO - Epoch: 14.78, Step: 46840, Train Loss: 1.4138, Learning Rate: 6.64e-05
2025-12-09 10:01:58 - INFO - Epoch: 14.78, Step: 46850, Train Loss: 1.4403, Learning Rate: 6.64e-05
2025-12-09 10:02:09 - INFO - Epoch: 14.79, Step: 46860, Train Loss: 1.4310, Learning Rate: 6.64e-05
2025-12-09 10:02:21 - INFO - Epoch: 14.79, Step: 46870, Train Loss: 1.4213, Learning Rate: 6.63e-05
2025-12-09 10:02:32 - INFO - Epoch: 14.79, Step: 46880, Train Loss: 1.4230, Learning Rate: 6.63e-05
2025-12-09 10:02:43 - INFO - Epoch: 14.80, Step: 46890, Train Loss: 1.4259, Learning Rate: 6.63e-05
2025-12-09 10:02:54 - INFO - Epoch: 14.80, Step: 46900, Train Loss: 1.4480, Learning Rate: 6.63e-05
2025-12-09 10:03:05 - INFO - Epoch: 14.80, Step: 46910, Train Loss: 1.3873, Learning Rate: 6.63e-05
2025-12-09 10:03:16 - INFO - Epoch: 14.81, Step: 46920, Train Loss: 1.4333, Learning Rate: 6.63e-05
2025-12-09 10:03:27 - INFO - Epoch: 14.81, Step: 46930, Train Loss: 1.4060, Learning Rate: 6.63e-05
2025-12-09 10:03:38 - INFO - Epoch: 14.81, Step: 46940, Train Loss: 1.3994, Learning Rate: 6.63e-05
2025-12-09 10:03:49 - INFO - Epoch: 14.82, Step: 46950, Train Loss: 1.4254, Learning Rate: 6.63e-05
2025-12-09 10:04:00 - INFO - Epoch: 14.82, Step: 46960, Train Loss: 1.3859, Learning Rate: 6.63e-05
2025-12-09 10:04:11 - INFO - Epoch: 14.82, Step: 46970, Train Loss: 1.4222, Learning Rate: 6.63e-05
2025-12-09 10:04:22 - INFO - Epoch: 14.82, Step: 46980, Train Loss: 1.3836, Learning Rate: 6.63e-05
2025-12-09 10:04:34 - INFO - Epoch: 14.83, Step: 46990, Train Loss: 1.4297, Learning Rate: 6.62e-05
2025-12-09 10:04:45 - INFO - Epoch: 14.83, Step: 47000, Train Loss: 1.4163, Learning Rate: 6.62e-05
2025-12-09 10:04:56 - INFO - Epoch: 14.83, Step: 47010, Train Loss: 1.4004, Learning Rate: 6.62e-05
2025-12-09 10:05:07 - INFO - Epoch: 14.84, Step: 47020, Train Loss: 1.4406, Learning Rate: 6.62e-05
2025-12-09 10:05:18 - INFO - Epoch: 14.84, Step: 47030, Train Loss: 1.4371, Learning Rate: 6.62e-05
2025-12-09 10:05:29 - INFO - Epoch: 14.84, Step: 47040, Train Loss: 1.4149, Learning Rate: 6.62e-05
2025-12-09 10:05:40 - INFO - Epoch: 14.85, Step: 47050, Train Loss: 1.4132, Learning Rate: 6.62e-05
2025-12-09 10:05:51 - INFO - Epoch: 14.85, Step: 47060, Train Loss: 1.4077, Learning Rate: 6.62e-05
2025-12-09 10:06:02 - INFO - Epoch: 14.85, Step: 47070, Train Loss: 1.4212, Learning Rate: 6.62e-05
2025-12-09 10:06:13 - INFO - Epoch: 14.86, Step: 47080, Train Loss: 1.4391, Learning Rate: 6.62e-05
2025-12-09 10:06:24 - INFO - Epoch: 14.86, Step: 47090, Train Loss: 1.3783, Learning Rate: 6.62e-05
2025-12-09 10:06:35 - INFO - Epoch: 14.86, Step: 47100, Train Loss: 1.3886, Learning Rate: 6.62e-05
2025-12-09 10:06:46 - INFO - Epoch: 14.87, Step: 47110, Train Loss: 1.4283, Learning Rate: 6.61e-05
2025-12-09 10:06:58 - INFO - Epoch: 14.87, Step: 47120, Train Loss: 1.4194, Learning Rate: 6.61e-05
2025-12-09 10:07:09 - INFO - Epoch: 14.87, Step: 47130, Train Loss: 1.3719, Learning Rate: 6.61e-05
2025-12-09 10:07:20 - INFO - Epoch: 14.88, Step: 47140, Train Loss: 1.4324, Learning Rate: 6.61e-05
2025-12-09 10:07:31 - INFO - Epoch: 14.88, Step: 47150, Train Loss: 1.4248, Learning Rate: 6.61e-05
2025-12-09 10:07:42 - INFO - Epoch: 14.88, Step: 47160, Train Loss: 1.4405, Learning Rate: 6.61e-05
2025-12-09 10:07:53 - INFO - Epoch: 14.88, Step: 47170, Train Loss: 1.4030, Learning Rate: 6.61e-05
2025-12-09 10:08:04 - INFO - Epoch: 14.89, Step: 47180, Train Loss: 1.4094, Learning Rate: 6.61e-05
2025-12-09 10:08:15 - INFO - Epoch: 14.89, Step: 47190, Train Loss: 1.4131, Learning Rate: 6.61e-05
2025-12-09 10:08:26 - INFO - Epoch: 14.89, Step: 47200, Train Loss: 1.4043, Learning Rate: 6.61e-05
2025-12-09 10:08:37 - INFO - Epoch: 14.90, Step: 47210, Train Loss: 1.4368, Learning Rate: 6.61e-05
2025-12-09 10:08:48 - INFO - Epoch: 14.90, Step: 47220, Train Loss: 1.3929, Learning Rate: 6.61e-05
2025-12-09 10:08:59 - INFO - Epoch: 14.90, Step: 47230, Train Loss: 1.3897, Learning Rate: 6.60e-05
2025-12-09 10:09:11 - INFO - Epoch: 14.91, Step: 47240, Train Loss: 1.4123, Learning Rate: 6.60e-05
2025-12-09 10:09:22 - INFO - Epoch: 14.91, Step: 47250, Train Loss: 1.4015, Learning Rate: 6.60e-05
2025-12-09 10:09:33 - INFO - Epoch: 14.91, Step: 47260, Train Loss: 1.4341, Learning Rate: 6.60e-05
2025-12-09 10:09:44 - INFO - Epoch: 14.92, Step: 47270, Train Loss: 1.3687, Learning Rate: 6.60e-05
2025-12-09 10:09:55 - INFO - Epoch: 14.92, Step: 47280, Train Loss: 1.4243, Learning Rate: 6.60e-05
2025-12-09 10:10:06 - INFO - Epoch: 14.92, Step: 47290, Train Loss: 1.4367, Learning Rate: 6.60e-05
2025-12-09 10:10:17 - INFO - Epoch: 14.93, Step: 47300, Train Loss: 1.4324, Learning Rate: 6.60e-05
2025-12-09 10:10:28 - INFO - Epoch: 14.93, Step: 47310, Train Loss: 1.4082, Learning Rate: 6.60e-05
2025-12-09 10:10:39 - INFO - Epoch: 14.93, Step: 47320, Train Loss: 1.4116, Learning Rate: 6.60e-05
2025-12-09 10:10:50 - INFO - Epoch: 14.94, Step: 47330, Train Loss: 1.3908, Learning Rate: 6.60e-05
2025-12-09 10:11:01 - INFO - Epoch: 14.94, Step: 47340, Train Loss: 1.4220, Learning Rate: 6.60e-05
2025-12-09 10:11:12 - INFO - Epoch: 14.94, Step: 47350, Train Loss: 1.3885, Learning Rate: 6.59e-05
2025-12-09 10:11:23 - INFO - Epoch: 14.94, Step: 47360, Train Loss: 1.4296, Learning Rate: 6.59e-05
2025-12-09 10:11:35 - INFO - Epoch: 14.95, Step: 47370, Train Loss: 1.4143, Learning Rate: 6.59e-05
2025-12-09 10:11:46 - INFO - Epoch: 14.95, Step: 47380, Train Loss: 1.4009, Learning Rate: 6.59e-05
2025-12-09 10:11:57 - INFO - Epoch: 14.95, Step: 47390, Train Loss: 1.4278, Learning Rate: 6.59e-05
2025-12-09 10:12:08 - INFO - Epoch: 14.96, Step: 47400, Train Loss: 1.3785, Learning Rate: 6.59e-05
2025-12-09 10:12:19 - INFO - Epoch: 14.96, Step: 47410, Train Loss: 1.3998, Learning Rate: 6.59e-05
2025-12-09 10:12:30 - INFO - Epoch: 14.96, Step: 47420, Train Loss: 1.4428, Learning Rate: 6.59e-05
2025-12-09 10:12:41 - INFO - Epoch: 14.97, Step: 47430, Train Loss: 1.4097, Learning Rate: 6.59e-05
2025-12-09 10:12:52 - INFO - Epoch: 14.97, Step: 47440, Train Loss: 1.3687, Learning Rate: 6.59e-05
2025-12-09 10:13:03 - INFO - Epoch: 14.97, Step: 47450, Train Loss: 1.3679, Learning Rate: 6.59e-05
2025-12-09 10:13:14 - INFO - Epoch: 14.98, Step: 47460, Train Loss: 1.4239, Learning Rate: 6.59e-05
2025-12-09 10:13:25 - INFO - Epoch: 14.98, Step: 47470, Train Loss: 1.4165, Learning Rate: 6.58e-05
2025-12-09 10:13:36 - INFO - Epoch: 14.98, Step: 47480, Train Loss: 1.4361, Learning Rate: 6.58e-05
2025-12-09 10:13:48 - INFO - Epoch: 14.99, Step: 47490, Train Loss: 1.4264, Learning Rate: 6.58e-05
2025-12-09 10:13:59 - INFO - Epoch: 14.99, Step: 47500, Train Loss: 1.3513, Learning Rate: 6.58e-05
2025-12-09 10:14:10 - INFO - Epoch: 14.99, Step: 47510, Train Loss: 1.4061, Learning Rate: 6.58e-05
2025-12-09 10:14:21 - INFO - Epoch: 15.00, Step: 47520, Train Loss: 1.4146, Learning Rate: 6.58e-05
2025-12-09 10:14:32 - INFO - Epoch: 15.00, Step: 47530, Train Loss: 1.4225, Learning Rate: 6.58e-05
2025-12-09 10:14:43 - INFO - Epoch: 15.00, Step: 47540, Train Loss: 1.4183, Learning Rate: 6.58e-05
2025-12-09 10:14:54 - INFO - Epoch: 15.00, Step: 47550, Train Loss: 1.4295, Learning Rate: 6.58e-05
2025-12-09 10:15:05 - INFO - Epoch: 15.01, Step: 47560, Train Loss: 1.4282, Learning Rate: 6.58e-05
2025-12-09 10:15:16 - INFO - Epoch: 15.01, Step: 47570, Train Loss: 1.3927, Learning Rate: 6.58e-05
2025-12-09 10:15:27 - INFO - Epoch: 15.01, Step: 47580, Train Loss: 1.3881, Learning Rate: 6.58e-05
2025-12-09 10:15:38 - INFO - Epoch: 15.02, Step: 47590, Train Loss: 1.4281, Learning Rate: 6.57e-05
2025-12-09 10:15:49 - INFO - Epoch: 15.02, Step: 47600, Train Loss: 1.4390, Learning Rate: 6.57e-05
2025-12-09 10:16:01 - INFO - Epoch: 15.02, Step: 47610, Train Loss: 1.4149, Learning Rate: 6.57e-05
2025-12-09 10:16:12 - INFO - Epoch: 15.03, Step: 47620, Train Loss: 1.4329, Learning Rate: 6.57e-05
2025-12-09 10:16:23 - INFO - Epoch: 15.03, Step: 47630, Train Loss: 1.3844, Learning Rate: 6.57e-05
2025-12-09 10:16:34 - INFO - Epoch: 15.03, Step: 47640, Train Loss: 1.4891, Learning Rate: 6.57e-05
2025-12-09 10:16:45 - INFO - Epoch: 15.04, Step: 47650, Train Loss: 1.3911, Learning Rate: 6.57e-05
2025-12-09 10:16:56 - INFO - Epoch: 15.04, Step: 47660, Train Loss: 1.3713, Learning Rate: 6.57e-05
2025-12-09 10:17:07 - INFO - Epoch: 15.04, Step: 47670, Train Loss: 1.4151, Learning Rate: 6.57e-05
2025-12-09 10:17:18 - INFO - Epoch: 15.05, Step: 47680, Train Loss: 1.3932, Learning Rate: 6.57e-05
2025-12-09 10:17:29 - INFO - Epoch: 15.05, Step: 47690, Train Loss: 1.4101, Learning Rate: 6.57e-05
2025-12-09 10:17:40 - INFO - Epoch: 15.05, Step: 47700, Train Loss: 1.4466, Learning Rate: 6.57e-05
2025-12-09 10:17:51 - INFO - Epoch: 15.06, Step: 47710, Train Loss: 1.4211, Learning Rate: 6.56e-05
2025-12-09 10:18:02 - INFO - Epoch: 15.06, Step: 47720, Train Loss: 1.4012, Learning Rate: 6.56e-05
2025-12-09 10:18:13 - INFO - Epoch: 15.06, Step: 47730, Train Loss: 1.4043, Learning Rate: 6.56e-05
2025-12-09 10:18:25 - INFO - Epoch: 15.06, Step: 47740, Train Loss: 1.4121, Learning Rate: 6.56e-05
2025-12-09 10:18:36 - INFO - Epoch: 15.07, Step: 47750, Train Loss: 1.4510, Learning Rate: 6.56e-05
2025-12-09 10:18:47 - INFO - Epoch: 15.07, Step: 47760, Train Loss: 1.4072, Learning Rate: 6.56e-05
2025-12-09 10:18:58 - INFO - Epoch: 15.07, Step: 47770, Train Loss: 1.4211, Learning Rate: 6.56e-05
2025-12-09 10:19:09 - INFO - Epoch: 15.08, Step: 47780, Train Loss: 1.4045, Learning Rate: 6.56e-05
2025-12-09 10:19:20 - INFO - Epoch: 15.08, Step: 47790, Train Loss: 1.3947, Learning Rate: 6.56e-05
2025-12-09 10:19:31 - INFO - Epoch: 15.08, Step: 47800, Train Loss: 1.3590, Learning Rate: 6.56e-05
2025-12-09 10:19:42 - INFO - Epoch: 15.09, Step: 47810, Train Loss: 1.4057, Learning Rate: 6.56e-05
2025-12-09 10:19:53 - INFO - Epoch: 15.09, Step: 47820, Train Loss: 1.3968, Learning Rate: 6.56e-05
2025-12-09 10:20:04 - INFO - Epoch: 15.09, Step: 47830, Train Loss: 1.4299, Learning Rate: 6.55e-05
2025-12-09 10:20:15 - INFO - Epoch: 15.10, Step: 47840, Train Loss: 1.4127, Learning Rate: 6.55e-05
2025-12-09 10:20:26 - INFO - Epoch: 15.10, Step: 47850, Train Loss: 1.4155, Learning Rate: 6.55e-05
2025-12-09 10:20:38 - INFO - Epoch: 15.10, Step: 47860, Train Loss: 1.3927, Learning Rate: 6.55e-05
2025-12-09 10:20:49 - INFO - Epoch: 15.11, Step: 47870, Train Loss: 1.3783, Learning Rate: 6.55e-05
2025-12-09 10:21:00 - INFO - Epoch: 15.11, Step: 47880, Train Loss: 1.3613, Learning Rate: 6.55e-05
2025-12-09 10:21:11 - INFO - Epoch: 15.11, Step: 47890, Train Loss: 1.3690, Learning Rate: 6.55e-05
2025-12-09 10:21:22 - INFO - Epoch: 15.12, Step: 47900, Train Loss: 1.3797, Learning Rate: 6.55e-05
2025-12-09 10:21:33 - INFO - Epoch: 15.12, Step: 47910, Train Loss: 1.4292, Learning Rate: 6.55e-05
2025-12-09 10:21:44 - INFO - Epoch: 15.12, Step: 47920, Train Loss: 1.3839, Learning Rate: 6.55e-05
2025-12-09 10:21:55 - INFO - Epoch: 15.12, Step: 47930, Train Loss: 1.3580, Learning Rate: 6.55e-05
2025-12-09 10:22:06 - INFO - Epoch: 15.13, Step: 47940, Train Loss: 1.3998, Learning Rate: 6.55e-05
2025-12-09 10:22:17 - INFO - Epoch: 15.13, Step: 47950, Train Loss: 1.4117, Learning Rate: 6.54e-05
2025-12-09 10:22:28 - INFO - Epoch: 15.13, Step: 47960, Train Loss: 1.3940, Learning Rate: 6.54e-05
2025-12-09 10:22:39 - INFO - Epoch: 15.14, Step: 47970, Train Loss: 1.4098, Learning Rate: 6.54e-05
2025-12-09 10:22:50 - INFO - Epoch: 15.14, Step: 47980, Train Loss: 1.3934, Learning Rate: 6.54e-05
2025-12-09 10:23:02 - INFO - Epoch: 15.14, Step: 47990, Train Loss: 1.4184, Learning Rate: 6.54e-05
2025-12-09 10:23:13 - INFO - Epoch: 15.15, Step: 48000, Train Loss: 1.4044, Learning Rate: 6.54e-05
2025-12-09 10:23:24 - INFO - Epoch: 15.15, Step: 48010, Train Loss: 1.4129, Learning Rate: 6.54e-05
2025-12-09 10:23:35 - INFO - Epoch: 15.15, Step: 48020, Train Loss: 1.3900, Learning Rate: 6.54e-05
2025-12-09 10:23:46 - INFO - Epoch: 15.16, Step: 48030, Train Loss: 1.4125, Learning Rate: 6.54e-05
2025-12-09 10:23:57 - INFO - Epoch: 15.16, Step: 48040, Train Loss: 1.3893, Learning Rate: 6.54e-05
2025-12-09 10:24:08 - INFO - Epoch: 15.16, Step: 48050, Train Loss: 1.4209, Learning Rate: 6.54e-05
2025-12-09 10:24:19 - INFO - Epoch: 15.17, Step: 48060, Train Loss: 1.4293, Learning Rate: 6.54e-05
2025-12-09 10:24:30 - INFO - Epoch: 15.17, Step: 48070, Train Loss: 1.4192, Learning Rate: 6.53e-05
2025-12-09 10:24:41 - INFO - Epoch: 15.17, Step: 48080, Train Loss: 1.4252, Learning Rate: 6.53e-05
2025-12-09 10:24:52 - INFO - Epoch: 15.18, Step: 48090, Train Loss: 1.4070, Learning Rate: 6.53e-05
2025-12-09 10:25:03 - INFO - Epoch: 15.18, Step: 48100, Train Loss: 1.4082, Learning Rate: 6.53e-05
2025-12-09 10:25:14 - INFO - Epoch: 15.18, Step: 48110, Train Loss: 1.3954, Learning Rate: 6.53e-05
2025-12-09 10:25:26 - INFO - Epoch: 15.18, Step: 48120, Train Loss: 1.4110, Learning Rate: 6.53e-05
2025-12-09 10:25:37 - INFO - Epoch: 15.19, Step: 48130, Train Loss: 1.3934, Learning Rate: 6.53e-05
2025-12-09 10:25:48 - INFO - Epoch: 15.19, Step: 48140, Train Loss: 1.3927, Learning Rate: 6.53e-05
2025-12-09 10:25:59 - INFO - Epoch: 15.19, Step: 48150, Train Loss: 1.3960, Learning Rate: 6.53e-05
2025-12-09 10:26:10 - INFO - Epoch: 15.20, Step: 48160, Train Loss: 1.4499, Learning Rate: 6.53e-05
2025-12-09 10:26:21 - INFO - Epoch: 15.20, Step: 48170, Train Loss: 1.4110, Learning Rate: 6.53e-05
2025-12-09 10:26:32 - INFO - Epoch: 15.20, Step: 48180, Train Loss: 1.4041, Learning Rate: 6.53e-05
2025-12-09 10:26:43 - INFO - Epoch: 15.21, Step: 48190, Train Loss: 1.4125, Learning Rate: 6.52e-05
2025-12-09 10:26:54 - INFO - Epoch: 15.21, Step: 48200, Train Loss: 1.3932, Learning Rate: 6.52e-05
2025-12-09 10:27:05 - INFO - Epoch: 15.21, Step: 48210, Train Loss: 1.4157, Learning Rate: 6.52e-05
2025-12-09 10:27:16 - INFO - Epoch: 15.22, Step: 48220, Train Loss: 1.3879, Learning Rate: 6.52e-05
2025-12-09 10:27:27 - INFO - Epoch: 15.22, Step: 48230, Train Loss: 1.3980, Learning Rate: 6.52e-05
2025-12-09 10:27:39 - INFO - Epoch: 15.22, Step: 48240, Train Loss: 1.4093, Learning Rate: 6.52e-05
2025-12-09 10:27:50 - INFO - Epoch: 15.23, Step: 48250, Train Loss: 1.3491, Learning Rate: 6.52e-05
2025-12-09 10:28:01 - INFO - Epoch: 15.23, Step: 48260, Train Loss: 1.3926, Learning Rate: 6.52e-05
2025-12-09 10:28:12 - INFO - Epoch: 15.23, Step: 48270, Train Loss: 1.4497, Learning Rate: 6.52e-05
2025-12-09 10:28:23 - INFO - Epoch: 15.24, Step: 48280, Train Loss: 1.4237, Learning Rate: 6.52e-05
2025-12-09 10:28:34 - INFO - Epoch: 15.24, Step: 48290, Train Loss: 1.3752, Learning Rate: 6.52e-05
2025-12-09 10:28:45 - INFO - Epoch: 15.24, Step: 48300, Train Loss: 1.4093, Learning Rate: 6.52e-05
2025-12-09 10:28:56 - INFO - Epoch: 15.24, Step: 48310, Train Loss: 1.4472, Learning Rate: 6.51e-05
2025-12-09 10:29:07 - INFO - Epoch: 15.25, Step: 48320, Train Loss: 1.3920, Learning Rate: 6.51e-05
2025-12-09 10:29:18 - INFO - Epoch: 15.25, Step: 48330, Train Loss: 1.3948, Learning Rate: 6.51e-05
2025-12-09 10:29:29 - INFO - Epoch: 15.25, Step: 48340, Train Loss: 1.3743, Learning Rate: 6.51e-05
2025-12-09 10:29:40 - INFO - Epoch: 15.26, Step: 48350, Train Loss: 1.4017, Learning Rate: 6.51e-05
2025-12-09 10:29:51 - INFO - Epoch: 15.26, Step: 48360, Train Loss: 1.4247, Learning Rate: 6.51e-05
2025-12-09 10:30:03 - INFO - Epoch: 15.26, Step: 48370, Train Loss: 1.4078, Learning Rate: 6.51e-05
2025-12-09 10:30:14 - INFO - Epoch: 15.27, Step: 48380, Train Loss: 1.4134, Learning Rate: 6.51e-05
2025-12-09 10:30:25 - INFO - Epoch: 15.27, Step: 48390, Train Loss: 1.3996, Learning Rate: 6.51e-05
2025-12-09 10:30:36 - INFO - Epoch: 15.27, Step: 48400, Train Loss: 1.4098, Learning Rate: 6.51e-05
2025-12-09 10:30:47 - INFO - Epoch: 15.28, Step: 48410, Train Loss: 1.4126, Learning Rate: 6.51e-05
2025-12-09 10:30:58 - INFO - Epoch: 15.28, Step: 48420, Train Loss: 1.4025, Learning Rate: 6.51e-05
2025-12-09 10:31:09 - INFO - Epoch: 15.28, Step: 48430, Train Loss: 1.4178, Learning Rate: 6.50e-05
2025-12-09 10:31:20 - INFO - Epoch: 15.29, Step: 48440, Train Loss: 1.3886, Learning Rate: 6.50e-05
2025-12-09 10:31:31 - INFO - Epoch: 15.29, Step: 48450, Train Loss: 1.4239, Learning Rate: 6.50e-05
2025-12-09 10:31:42 - INFO - Epoch: 15.29, Step: 48460, Train Loss: 1.4230, Learning Rate: 6.50e-05
2025-12-09 10:31:53 - INFO - Epoch: 15.30, Step: 48470, Train Loss: 1.4449, Learning Rate: 6.50e-05
2025-12-09 10:32:04 - INFO - Epoch: 15.30, Step: 48480, Train Loss: 1.4372, Learning Rate: 6.50e-05
2025-12-09 10:32:16 - INFO - Epoch: 15.30, Step: 48490, Train Loss: 1.4190, Learning Rate: 6.50e-05
2025-12-09 10:32:27 - INFO - Epoch: 15.30, Step: 48500, Train Loss: 1.4204, Learning Rate: 6.50e-05
2025-12-09 10:32:38 - INFO - Epoch: 15.31, Step: 48510, Train Loss: 1.3844, Learning Rate: 6.50e-05
2025-12-09 10:32:49 - INFO - Epoch: 15.31, Step: 48520, Train Loss: 1.3531, Learning Rate: 6.50e-05
2025-12-09 10:33:00 - INFO - Epoch: 15.31, Step: 48530, Train Loss: 1.3831, Learning Rate: 6.50e-05
2025-12-09 10:33:11 - INFO - Epoch: 15.32, Step: 48540, Train Loss: 1.3802, Learning Rate: 6.50e-05
2025-12-09 10:33:22 - INFO - Epoch: 15.32, Step: 48550, Train Loss: 1.4222, Learning Rate: 6.49e-05
2025-12-09 10:33:33 - INFO - Epoch: 15.32, Step: 48560, Train Loss: 1.4295, Learning Rate: 6.49e-05
2025-12-09 10:33:44 - INFO - Epoch: 15.33, Step: 48570, Train Loss: 1.4410, Learning Rate: 6.49e-05
2025-12-09 10:33:55 - INFO - Epoch: 15.33, Step: 48580, Train Loss: 1.4118, Learning Rate: 6.49e-05
2025-12-09 10:34:06 - INFO - Epoch: 15.33, Step: 48590, Train Loss: 1.4034, Learning Rate: 6.49e-05
2025-12-09 10:34:17 - INFO - Epoch: 15.34, Step: 48600, Train Loss: 1.4292, Learning Rate: 6.49e-05
2025-12-09 10:34:28 - INFO - Epoch: 15.34, Step: 48610, Train Loss: 1.4110, Learning Rate: 6.49e-05
2025-12-09 10:34:40 - INFO - Epoch: 15.34, Step: 48620, Train Loss: 1.3981, Learning Rate: 6.49e-05
2025-12-09 10:34:51 - INFO - Epoch: 15.35, Step: 48630, Train Loss: 1.3606, Learning Rate: 6.49e-05
2025-12-09 10:35:02 - INFO - Epoch: 15.35, Step: 48640, Train Loss: 1.4214, Learning Rate: 6.49e-05
2025-12-09 10:35:13 - INFO - Epoch: 15.35, Step: 48650, Train Loss: 1.3642, Learning Rate: 6.49e-05
2025-12-09 10:35:24 - INFO - Epoch: 15.36, Step: 48660, Train Loss: 1.3806, Learning Rate: 6.49e-05
2025-12-09 10:35:35 - INFO - Epoch: 15.36, Step: 48670, Train Loss: 1.4161, Learning Rate: 6.48e-05
2025-12-09 10:35:46 - INFO - Epoch: 15.36, Step: 48680, Train Loss: 1.3790, Learning Rate: 6.48e-05
2025-12-09 10:35:57 - INFO - Epoch: 15.36, Step: 48690, Train Loss: 1.3990, Learning Rate: 6.48e-05
2025-12-09 10:36:08 - INFO - Epoch: 15.37, Step: 48700, Train Loss: 1.3607, Learning Rate: 6.48e-05
2025-12-09 10:36:19 - INFO - Epoch: 15.37, Step: 48710, Train Loss: 1.4649, Learning Rate: 6.48e-05
2025-12-09 10:36:30 - INFO - Epoch: 15.37, Step: 48720, Train Loss: 1.4296, Learning Rate: 6.48e-05
2025-12-09 10:36:41 - INFO - Epoch: 15.38, Step: 48730, Train Loss: 1.3878, Learning Rate: 6.48e-05
2025-12-09 10:36:53 - INFO - Epoch: 15.38, Step: 48740, Train Loss: 1.4347, Learning Rate: 6.48e-05
2025-12-09 10:37:04 - INFO - Epoch: 15.38, Step: 48750, Train Loss: 1.4247, Learning Rate: 6.48e-05
2025-12-09 10:37:15 - INFO - Epoch: 15.39, Step: 48760, Train Loss: 1.4159, Learning Rate: 6.48e-05
2025-12-09 10:37:26 - INFO - Epoch: 15.39, Step: 48770, Train Loss: 1.4342, Learning Rate: 6.48e-05
2025-12-09 10:37:37 - INFO - Epoch: 15.39, Step: 48780, Train Loss: 1.3906, Learning Rate: 6.48e-05
2025-12-09 10:37:48 - INFO - Epoch: 15.40, Step: 48790, Train Loss: 1.3836, Learning Rate: 6.47e-05
2025-12-09 10:37:59 - INFO - Epoch: 15.40, Step: 48800, Train Loss: 1.4145, Learning Rate: 6.47e-05
2025-12-09 10:38:10 - INFO - Epoch: 15.40, Step: 48810, Train Loss: 1.3942, Learning Rate: 6.47e-05
2025-12-09 10:38:21 - INFO - Epoch: 15.41, Step: 48820, Train Loss: 1.3712, Learning Rate: 6.47e-05
2025-12-09 10:38:32 - INFO - Epoch: 15.41, Step: 48830, Train Loss: 1.3939, Learning Rate: 6.47e-05
2025-12-09 10:38:43 - INFO - Epoch: 15.41, Step: 48840, Train Loss: 1.3661, Learning Rate: 6.47e-05
2025-12-09 10:38:54 - INFO - Epoch: 15.41, Step: 48850, Train Loss: 1.4011, Learning Rate: 6.47e-05
2025-12-09 10:39:05 - INFO - Epoch: 15.42, Step: 48860, Train Loss: 1.4258, Learning Rate: 6.47e-05
2025-12-09 10:39:17 - INFO - Epoch: 15.42, Step: 48870, Train Loss: 1.3803, Learning Rate: 6.47e-05
2025-12-09 10:39:28 - INFO - Epoch: 15.42, Step: 48880, Train Loss: 1.3879, Learning Rate: 6.47e-05
2025-12-09 10:39:39 - INFO - Epoch: 15.43, Step: 48890, Train Loss: 1.4013, Learning Rate: 6.47e-05
2025-12-09 10:39:50 - INFO - Epoch: 15.43, Step: 48900, Train Loss: 1.3901, Learning Rate: 6.47e-05
2025-12-09 10:40:01 - INFO - Epoch: 15.43, Step: 48910, Train Loss: 1.3752, Learning Rate: 6.46e-05
2025-12-09 10:40:12 - INFO - Epoch: 15.44, Step: 48920, Train Loss: 1.4064, Learning Rate: 6.46e-05
2025-12-09 10:40:23 - INFO - Epoch: 15.44, Step: 48930, Train Loss: 1.3621, Learning Rate: 6.46e-05
2025-12-09 10:40:34 - INFO - Epoch: 15.44, Step: 48940, Train Loss: 1.3921, Learning Rate: 6.46e-05
2025-12-09 10:40:45 - INFO - Epoch: 15.45, Step: 48950, Train Loss: 1.4049, Learning Rate: 6.46e-05
2025-12-09 10:40:56 - INFO - Epoch: 15.45, Step: 48960, Train Loss: 1.3625, Learning Rate: 6.46e-05
2025-12-09 10:41:07 - INFO - Epoch: 15.45, Step: 48970, Train Loss: 1.4104, Learning Rate: 6.46e-05
2025-12-09 10:41:18 - INFO - Epoch: 15.46, Step: 48980, Train Loss: 1.3783, Learning Rate: 6.46e-05
2025-12-09 10:41:30 - INFO - Epoch: 15.46, Step: 48990, Train Loss: 1.4178, Learning Rate: 6.46e-05
2025-12-09 10:41:41 - INFO - Epoch: 15.46, Step: 49000, Train Loss: 1.4012, Learning Rate: 6.46e-05
2025-12-09 10:41:52 - INFO - Epoch: 15.47, Step: 49010, Train Loss: 1.3914, Learning Rate: 6.46e-05
2025-12-09 10:42:03 - INFO - Epoch: 15.47, Step: 49020, Train Loss: 1.4054, Learning Rate: 6.46e-05
2025-12-09 10:42:14 - INFO - Epoch: 15.47, Step: 49030, Train Loss: 1.4278, Learning Rate: 6.45e-05
2025-12-09 10:42:25 - INFO - Epoch: 15.47, Step: 49040, Train Loss: 1.3490, Learning Rate: 6.45e-05
2025-12-09 10:42:36 - INFO - Epoch: 15.48, Step: 49050, Train Loss: 1.3837, Learning Rate: 6.45e-05
2025-12-09 10:42:47 - INFO - Epoch: 15.48, Step: 49060, Train Loss: 1.4191, Learning Rate: 6.45e-05
2025-12-09 10:42:58 - INFO - Epoch: 15.48, Step: 49070, Train Loss: 1.4051, Learning Rate: 6.45e-05
2025-12-09 10:43:09 - INFO - Epoch: 15.49, Step: 49080, Train Loss: 1.4477, Learning Rate: 6.45e-05
2025-12-09 10:43:20 - INFO - Epoch: 15.49, Step: 49090, Train Loss: 1.4077, Learning Rate: 6.45e-05
2025-12-09 10:43:31 - INFO - Epoch: 15.49, Step: 49100, Train Loss: 1.4147, Learning Rate: 6.45e-05
2025-12-09 10:43:42 - INFO - Epoch: 15.50, Step: 49110, Train Loss: 1.3918, Learning Rate: 6.45e-05
2025-12-09 10:43:54 - INFO - Epoch: 15.50, Step: 49120, Train Loss: 1.4076, Learning Rate: 6.45e-05
2025-12-09 10:44:05 - INFO - Epoch: 15.50, Step: 49130, Train Loss: 1.3814, Learning Rate: 6.45e-05
2025-12-09 10:44:16 - INFO - Epoch: 15.51, Step: 49140, Train Loss: 1.3952, Learning Rate: 6.45e-05
2025-12-09 10:44:27 - INFO - Epoch: 15.51, Step: 49150, Train Loss: 1.3949, Learning Rate: 6.44e-05
2025-12-09 10:44:38 - INFO - Epoch: 15.51, Step: 49160, Train Loss: 1.4110, Learning Rate: 6.44e-05
2025-12-09 10:44:49 - INFO - Epoch: 15.52, Step: 49170, Train Loss: 1.4015, Learning Rate: 6.44e-05
2025-12-09 10:45:00 - INFO - Epoch: 15.52, Step: 49180, Train Loss: 1.3758, Learning Rate: 6.44e-05
2025-12-09 10:45:11 - INFO - Epoch: 15.52, Step: 49190, Train Loss: 1.3865, Learning Rate: 6.44e-05
2025-12-09 10:45:22 - INFO - Epoch: 15.53, Step: 49200, Train Loss: 1.3776, Learning Rate: 6.44e-05
2025-12-09 10:45:33 - INFO - Epoch: 15.53, Step: 49210, Train Loss: 1.4327, Learning Rate: 6.44e-05
2025-12-09 10:45:44 - INFO - Epoch: 15.53, Step: 49220, Train Loss: 1.4311, Learning Rate: 6.44e-05
2025-12-09 10:45:55 - INFO - Epoch: 15.53, Step: 49230, Train Loss: 1.3755, Learning Rate: 6.44e-05
2025-12-09 10:46:06 - INFO - Epoch: 15.54, Step: 49240, Train Loss: 1.3513, Learning Rate: 6.44e-05
2025-12-09 10:46:18 - INFO - Epoch: 15.54, Step: 49250, Train Loss: 1.4106, Learning Rate: 6.44e-05
2025-12-09 10:46:29 - INFO - Epoch: 15.54, Step: 49260, Train Loss: 1.3563, Learning Rate: 6.44e-05
2025-12-09 10:46:40 - INFO - Epoch: 15.55, Step: 49270, Train Loss: 1.3826, Learning Rate: 6.43e-05
2025-12-09 10:46:51 - INFO - Epoch: 15.55, Step: 49280, Train Loss: 1.4442, Learning Rate: 6.43e-05
2025-12-09 10:47:02 - INFO - Epoch: 15.55, Step: 49290, Train Loss: 1.4274, Learning Rate: 6.43e-05
2025-12-09 10:47:13 - INFO - Epoch: 15.56, Step: 49300, Train Loss: 1.3875, Learning Rate: 6.43e-05
2025-12-09 10:47:24 - INFO - Epoch: 15.56, Step: 49310, Train Loss: 1.3842, Learning Rate: 6.43e-05
2025-12-09 10:47:35 - INFO - Epoch: 15.56, Step: 49320, Train Loss: 1.4183, Learning Rate: 6.43e-05
2025-12-09 10:47:46 - INFO - Epoch: 15.57, Step: 49330, Train Loss: 1.3682, Learning Rate: 6.43e-05
2025-12-09 10:47:57 - INFO - Epoch: 15.57, Step: 49340, Train Loss: 1.4082, Learning Rate: 6.43e-05
2025-12-09 10:48:08 - INFO - Epoch: 15.57, Step: 49350, Train Loss: 1.4008, Learning Rate: 6.43e-05
2025-12-09 10:48:19 - INFO - Epoch: 15.58, Step: 49360, Train Loss: 1.3892, Learning Rate: 6.43e-05
2025-12-09 10:48:31 - INFO - Epoch: 15.58, Step: 49370, Train Loss: 1.4319, Learning Rate: 6.43e-05
2025-12-09 10:48:42 - INFO - Epoch: 15.58, Step: 49380, Train Loss: 1.3821, Learning Rate: 6.43e-05
2025-12-09 10:48:53 - INFO - Epoch: 15.59, Step: 49390, Train Loss: 1.4077, Learning Rate: 6.42e-05
2025-12-09 10:49:04 - INFO - Epoch: 15.59, Step: 49400, Train Loss: 1.3966, Learning Rate: 6.42e-05
2025-12-09 10:49:15 - INFO - Epoch: 15.59, Step: 49410, Train Loss: 1.3977, Learning Rate: 6.42e-05
2025-12-09 10:49:26 - INFO - Epoch: 15.59, Step: 49420, Train Loss: 1.3755, Learning Rate: 6.42e-05
2025-12-09 10:49:37 - INFO - Epoch: 15.60, Step: 49430, Train Loss: 1.4222, Learning Rate: 6.42e-05
2025-12-09 10:49:48 - INFO - Epoch: 15.60, Step: 49440, Train Loss: 1.3735, Learning Rate: 6.42e-05
2025-12-09 10:49:59 - INFO - Epoch: 15.60, Step: 49450, Train Loss: 1.4090, Learning Rate: 6.42e-05
2025-12-09 10:50:10 - INFO - Epoch: 15.61, Step: 49460, Train Loss: 1.4121, Learning Rate: 6.42e-05
2025-12-09 10:50:21 - INFO - Epoch: 15.61, Step: 49470, Train Loss: 1.3714, Learning Rate: 6.42e-05
2025-12-09 10:50:32 - INFO - Epoch: 15.61, Step: 49480, Train Loss: 1.3977, Learning Rate: 6.42e-05
2025-12-09 10:50:43 - INFO - Epoch: 15.62, Step: 49490, Train Loss: 1.3919, Learning Rate: 6.42e-05
2025-12-09 10:50:55 - INFO - Epoch: 15.62, Step: 49500, Train Loss: 1.3910, Learning Rate: 6.42e-05
2025-12-09 10:51:06 - INFO - Epoch: 15.62, Step: 49510, Train Loss: 1.4142, Learning Rate: 6.42e-05
2025-12-09 10:51:17 - INFO - Epoch: 15.63, Step: 49520, Train Loss: 1.3712, Learning Rate: 6.41e-05
2025-12-09 10:51:28 - INFO - Epoch: 15.63, Step: 49530, Train Loss: 1.3756, Learning Rate: 6.41e-05
2025-12-09 10:51:39 - INFO - Epoch: 15.63, Step: 49540, Train Loss: 1.4003, Learning Rate: 6.41e-05
2025-12-09 10:51:50 - INFO - Epoch: 15.64, Step: 49550, Train Loss: 1.4011, Learning Rate: 6.41e-05
2025-12-09 10:52:01 - INFO - Epoch: 15.64, Step: 49560, Train Loss: 1.3809, Learning Rate: 6.41e-05
2025-12-09 10:52:12 - INFO - Epoch: 15.64, Step: 49570, Train Loss: 1.4148, Learning Rate: 6.41e-05
2025-12-09 10:52:23 - INFO - Epoch: 15.65, Step: 49580, Train Loss: 1.3964, Learning Rate: 6.41e-05
2025-12-09 10:52:34 - INFO - Epoch: 15.65, Step: 49590, Train Loss: 1.4092, Learning Rate: 6.41e-05
2025-12-09 10:52:45 - INFO - Epoch: 15.65, Step: 49600, Train Loss: 1.4139, Learning Rate: 6.41e-05
2025-12-09 10:52:56 - INFO - Epoch: 15.65, Step: 49610, Train Loss: 1.4026, Learning Rate: 6.41e-05
2025-12-09 10:53:08 - INFO - Epoch: 15.66, Step: 49620, Train Loss: 1.3841, Learning Rate: 6.41e-05
2025-12-09 10:53:19 - INFO - Epoch: 15.66, Step: 49630, Train Loss: 1.4079, Learning Rate: 6.41e-05
2025-12-09 10:53:30 - INFO - Epoch: 15.66, Step: 49640, Train Loss: 1.3955, Learning Rate: 6.40e-05
2025-12-09 10:53:41 - INFO - Epoch: 15.67, Step: 49650, Train Loss: 1.3769, Learning Rate: 6.40e-05
2025-12-09 10:53:52 - INFO - Epoch: 15.67, Step: 49660, Train Loss: 1.3755, Learning Rate: 6.40e-05
2025-12-09 10:54:03 - INFO - Epoch: 15.67, Step: 49670, Train Loss: 1.3862, Learning Rate: 6.40e-05
2025-12-09 10:54:14 - INFO - Epoch: 15.68, Step: 49680, Train Loss: 1.3765, Learning Rate: 6.40e-05
2025-12-09 10:54:25 - INFO - Epoch: 15.68, Step: 49690, Train Loss: 1.3694, Learning Rate: 6.40e-05
2025-12-09 10:54:36 - INFO - Epoch: 15.68, Step: 49700, Train Loss: 1.4067, Learning Rate: 6.40e-05
2025-12-09 10:54:47 - INFO - Epoch: 15.69, Step: 49710, Train Loss: 1.3395, Learning Rate: 6.40e-05
2025-12-09 10:54:58 - INFO - Epoch: 15.69, Step: 49720, Train Loss: 1.4042, Learning Rate: 6.40e-05
2025-12-09 10:55:09 - INFO - Epoch: 15.69, Step: 49730, Train Loss: 1.3958, Learning Rate: 6.40e-05
2025-12-09 10:55:20 - INFO - Epoch: 15.70, Step: 49740, Train Loss: 1.3771, Learning Rate: 6.40e-05
2025-12-09 10:55:32 - INFO - Epoch: 15.70, Step: 49750, Train Loss: 1.4205, Learning Rate: 6.40e-05
2025-12-09 10:55:43 - INFO - Epoch: 15.70, Step: 49760, Train Loss: 1.3893, Learning Rate: 6.39e-05
2025-12-09 10:55:54 - INFO - Epoch: 15.71, Step: 49770, Train Loss: 1.3879, Learning Rate: 6.39e-05
2025-12-09 10:56:05 - INFO - Epoch: 15.71, Step: 49780, Train Loss: 1.4160, Learning Rate: 6.39e-05
2025-12-09 10:56:16 - INFO - Epoch: 15.71, Step: 49790, Train Loss: 1.3700, Learning Rate: 6.39e-05
2025-12-09 10:56:27 - INFO - Epoch: 15.71, Step: 49800, Train Loss: 1.3982, Learning Rate: 6.39e-05
2025-12-09 10:56:38 - INFO - Epoch: 15.72, Step: 49810, Train Loss: 1.4106, Learning Rate: 6.39e-05
2025-12-09 10:56:49 - INFO - Epoch: 15.72, Step: 49820, Train Loss: 1.3777, Learning Rate: 6.39e-05
2025-12-09 10:57:00 - INFO - Epoch: 15.72, Step: 49830, Train Loss: 1.3957, Learning Rate: 6.39e-05
2025-12-09 10:57:11 - INFO - Epoch: 15.73, Step: 49840, Train Loss: 1.3766, Learning Rate: 6.39e-05
2025-12-09 10:57:22 - INFO - Epoch: 15.73, Step: 49850, Train Loss: 1.4145, Learning Rate: 6.39e-05
2025-12-09 10:57:33 - INFO - Epoch: 15.73, Step: 49860, Train Loss: 1.3798, Learning Rate: 6.39e-05
2025-12-09 10:57:45 - INFO - Epoch: 15.74, Step: 49870, Train Loss: 1.4016, Learning Rate: 6.39e-05
2025-12-09 10:57:56 - INFO - Epoch: 15.74, Step: 49880, Train Loss: 1.4115, Learning Rate: 6.38e-05
2025-12-09 10:58:07 - INFO - Epoch: 15.74, Step: 49890, Train Loss: 1.4321, Learning Rate: 6.38e-05
2025-12-09 10:58:18 - INFO - Epoch: 15.75, Step: 49900, Train Loss: 1.3786, Learning Rate: 6.38e-05
2025-12-09 10:58:29 - INFO - Epoch: 15.75, Step: 49910, Train Loss: 1.3833, Learning Rate: 6.38e-05
2025-12-09 10:58:40 - INFO - Epoch: 15.75, Step: 49920, Train Loss: 1.3801, Learning Rate: 6.38e-05
2025-12-09 10:58:51 - INFO - Epoch: 15.76, Step: 49930, Train Loss: 1.3752, Learning Rate: 6.38e-05
2025-12-09 10:59:02 - INFO - Epoch: 15.76, Step: 49940, Train Loss: 1.3670, Learning Rate: 6.38e-05
2025-12-09 10:59:13 - INFO - Epoch: 15.76, Step: 49950, Train Loss: 1.3803, Learning Rate: 6.38e-05
2025-12-09 10:59:24 - INFO - Epoch: 15.77, Step: 49960, Train Loss: 1.3735, Learning Rate: 6.38e-05
2025-12-09 10:59:35 - INFO - Epoch: 15.77, Step: 49970, Train Loss: 1.3722, Learning Rate: 6.38e-05
2025-12-09 10:59:46 - INFO - Epoch: 15.77, Step: 49980, Train Loss: 1.4125, Learning Rate: 6.38e-05
2025-12-09 10:59:57 - INFO - Epoch: 15.77, Step: 49990, Train Loss: 1.3986, Learning Rate: 6.38e-05
2025-12-09 11:00:09 - INFO - Epoch: 15.78, Step: 50000, Train Loss: 1.3646, Learning Rate: 6.37e-05
2025-12-09 11:00:20 - INFO - Epoch: 15.78, Step: 50010, Train Loss: 1.4048, Learning Rate: 6.37e-05
2025-12-09 11:00:31 - INFO - Epoch: 15.78, Step: 50020, Train Loss: 1.4118, Learning Rate: 6.37e-05
2025-12-09 11:00:42 - INFO - Epoch: 15.79, Step: 50030, Train Loss: 1.4175, Learning Rate: 6.37e-05
2025-12-09 11:00:53 - INFO - Epoch: 15.79, Step: 50040, Train Loss: 1.4151, Learning Rate: 6.37e-05
2025-12-09 11:01:04 - INFO - Epoch: 15.79, Step: 50050, Train Loss: 1.3985, Learning Rate: 6.37e-05
2025-12-09 11:01:15 - INFO - Epoch: 15.80, Step: 50060, Train Loss: 1.4167, Learning Rate: 6.37e-05
2025-12-09 11:01:26 - INFO - Epoch: 15.80, Step: 50070, Train Loss: 1.3772, Learning Rate: 6.37e-05
2025-12-09 11:01:37 - INFO - Epoch: 15.80, Step: 50080, Train Loss: 1.3899, Learning Rate: 6.37e-05
2025-12-09 11:01:48 - INFO - Epoch: 15.81, Step: 50090, Train Loss: 1.3937, Learning Rate: 6.37e-05
2025-12-09 11:01:59 - INFO - Epoch: 15.81, Step: 50100, Train Loss: 1.3973, Learning Rate: 6.37e-05
2025-12-09 11:02:10 - INFO - Epoch: 15.81, Step: 50110, Train Loss: 1.3970, Learning Rate: 6.37e-05
2025-12-09 11:02:22 - INFO - Epoch: 15.82, Step: 50120, Train Loss: 1.3894, Learning Rate: 6.36e-05
2025-12-09 11:02:33 - INFO - Epoch: 15.82, Step: 50130, Train Loss: 1.3725, Learning Rate: 6.36e-05
2025-12-09 11:02:44 - INFO - Epoch: 15.82, Step: 50140, Train Loss: 1.4053, Learning Rate: 6.36e-05
2025-12-09 11:02:55 - INFO - Epoch: 15.83, Step: 50150, Train Loss: 1.4032, Learning Rate: 6.36e-05
2025-12-09 11:03:06 - INFO - Epoch: 15.83, Step: 50160, Train Loss: 1.4054, Learning Rate: 6.36e-05
2025-12-09 11:03:17 - INFO - Epoch: 15.83, Step: 50170, Train Loss: 1.4219, Learning Rate: 6.36e-05
2025-12-09 11:03:28 - INFO - Epoch: 15.83, Step: 50180, Train Loss: 1.3747, Learning Rate: 6.36e-05
2025-12-09 11:03:39 - INFO - Epoch: 15.84, Step: 50190, Train Loss: 1.4155, Learning Rate: 6.36e-05
2025-12-09 11:03:50 - INFO - Epoch: 15.84, Step: 50200, Train Loss: 1.3579, Learning Rate: 6.36e-05
2025-12-09 11:04:01 - INFO - Epoch: 15.84, Step: 50210, Train Loss: 1.3894, Learning Rate: 6.36e-05
2025-12-09 11:04:12 - INFO - Epoch: 15.85, Step: 50220, Train Loss: 1.4026, Learning Rate: 6.36e-05
2025-12-09 11:04:23 - INFO - Epoch: 15.85, Step: 50230, Train Loss: 1.3688, Learning Rate: 6.36e-05
2025-12-09 11:04:34 - INFO - Epoch: 15.85, Step: 50240, Train Loss: 1.4105, Learning Rate: 6.35e-05
2025-12-09 11:04:46 - INFO - Epoch: 15.86, Step: 50250, Train Loss: 1.3982, Learning Rate: 6.35e-05
2025-12-09 11:04:57 - INFO - Epoch: 15.86, Step: 50260, Train Loss: 1.3800, Learning Rate: 6.35e-05
2025-12-09 11:05:08 - INFO - Epoch: 15.86, Step: 50270, Train Loss: 1.3564, Learning Rate: 6.35e-05
2025-12-09 11:05:19 - INFO - Epoch: 15.87, Step: 50280, Train Loss: 1.4133, Learning Rate: 6.35e-05
2025-12-09 11:05:30 - INFO - Epoch: 15.87, Step: 50290, Train Loss: 1.3605, Learning Rate: 6.35e-05
2025-12-09 11:05:41 - INFO - Epoch: 15.87, Step: 50300, Train Loss: 1.3554, Learning Rate: 6.35e-05
2025-12-09 11:05:52 - INFO - Epoch: 15.88, Step: 50310, Train Loss: 1.3933, Learning Rate: 6.35e-05
2025-12-09 11:06:03 - INFO - Epoch: 15.88, Step: 50320, Train Loss: 1.3809, Learning Rate: 6.35e-05
2025-12-09 11:06:14 - INFO - Epoch: 15.88, Step: 50330, Train Loss: 1.3898, Learning Rate: 6.35e-05
2025-12-09 11:06:25 - INFO - Epoch: 15.89, Step: 50340, Train Loss: 1.3912, Learning Rate: 6.35e-05
2025-12-09 11:06:36 - INFO - Epoch: 15.89, Step: 50350, Train Loss: 1.3971, Learning Rate: 6.35e-05
2025-12-09 11:06:47 - INFO - Epoch: 15.89, Step: 50360, Train Loss: 1.3717, Learning Rate: 6.34e-05
2025-12-09 11:06:58 - INFO - Epoch: 15.89, Step: 50370, Train Loss: 1.3731, Learning Rate: 6.34e-05
2025-12-09 11:07:10 - INFO - Epoch: 15.90, Step: 50380, Train Loss: 1.3777, Learning Rate: 6.34e-05
2025-12-09 11:07:21 - INFO - Epoch: 15.90, Step: 50390, Train Loss: 1.3952, Learning Rate: 6.34e-05
2025-12-09 11:07:32 - INFO - Epoch: 15.90, Step: 50400, Train Loss: 1.3968, Learning Rate: 6.34e-05
2025-12-09 11:07:43 - INFO - Epoch: 15.91, Step: 50410, Train Loss: 1.3742, Learning Rate: 6.34e-05
2025-12-09 11:07:54 - INFO - Epoch: 15.91, Step: 50420, Train Loss: 1.3648, Learning Rate: 6.34e-05
2025-12-09 11:08:05 - INFO - Epoch: 15.91, Step: 50430, Train Loss: 1.4066, Learning Rate: 6.34e-05
2025-12-09 11:08:16 - INFO - Epoch: 15.92, Step: 50440, Train Loss: 1.3851, Learning Rate: 6.34e-05
2025-12-09 11:08:27 - INFO - Epoch: 15.92, Step: 50450, Train Loss: 1.3482, Learning Rate: 6.34e-05
2025-12-09 11:08:38 - INFO - Epoch: 15.92, Step: 50460, Train Loss: 1.3872, Learning Rate: 6.34e-05
2025-12-09 11:08:49 - INFO - Epoch: 15.93, Step: 50470, Train Loss: 1.3934, Learning Rate: 6.34e-05
2025-12-09 11:09:00 - INFO - Epoch: 15.93, Step: 50480, Train Loss: 1.3806, Learning Rate: 6.33e-05
2025-12-09 11:09:11 - INFO - Epoch: 15.93, Step: 50490, Train Loss: 1.3725, Learning Rate: 6.33e-05
2025-12-09 11:09:23 - INFO - Epoch: 15.94, Step: 50500, Train Loss: 1.4129, Learning Rate: 6.33e-05
2025-12-09 11:09:34 - INFO - Epoch: 15.94, Step: 50510, Train Loss: 1.3712, Learning Rate: 6.33e-05
2025-12-09 11:09:45 - INFO - Epoch: 15.94, Step: 50520, Train Loss: 1.3795, Learning Rate: 6.33e-05
2025-12-09 11:09:56 - INFO - Epoch: 15.95, Step: 50530, Train Loss: 1.3691, Learning Rate: 6.33e-05
2025-12-09 11:10:07 - INFO - Epoch: 15.95, Step: 50540, Train Loss: 1.4223, Learning Rate: 6.33e-05
2025-12-09 11:10:18 - INFO - Epoch: 15.95, Step: 50550, Train Loss: 1.3577, Learning Rate: 6.33e-05
2025-12-09 11:10:29 - INFO - Epoch: 15.95, Step: 50560, Train Loss: 1.3916, Learning Rate: 6.33e-05
2025-12-09 11:10:40 - INFO - Epoch: 15.96, Step: 50570, Train Loss: 1.3874, Learning Rate: 6.33e-05
2025-12-09 11:10:51 - INFO - Epoch: 15.96, Step: 50580, Train Loss: 1.3936, Learning Rate: 6.33e-05
2025-12-09 11:11:02 - INFO - Epoch: 15.96, Step: 50590, Train Loss: 1.3851, Learning Rate: 6.33e-05
2025-12-09 11:11:13 - INFO - Epoch: 15.97, Step: 50600, Train Loss: 1.3789, Learning Rate: 6.32e-05
2025-12-09 11:11:24 - INFO - Epoch: 15.97, Step: 50610, Train Loss: 1.3811, Learning Rate: 6.32e-05
2025-12-09 11:11:35 - INFO - Epoch: 15.97, Step: 50620, Train Loss: 1.3395, Learning Rate: 6.32e-05
2025-12-09 11:11:47 - INFO - Epoch: 15.98, Step: 50630, Train Loss: 1.3834, Learning Rate: 6.32e-05
2025-12-09 11:11:58 - INFO - Epoch: 15.98, Step: 50640, Train Loss: 1.3851, Learning Rate: 6.32e-05
2025-12-09 11:12:09 - INFO - Epoch: 15.98, Step: 50650, Train Loss: 1.3900, Learning Rate: 6.32e-05
2025-12-09 11:12:20 - INFO - Epoch: 15.99, Step: 50660, Train Loss: 1.4121, Learning Rate: 6.32e-05
2025-12-09 11:12:31 - INFO - Epoch: 15.99, Step: 50670, Train Loss: 1.3755, Learning Rate: 6.32e-05
2025-12-09 11:12:42 - INFO - Epoch: 15.99, Step: 50680, Train Loss: 1.4286, Learning Rate: 6.32e-05
2025-12-09 11:12:53 - INFO - Epoch: 16.00, Step: 50690, Train Loss: 1.3731, Learning Rate: 6.32e-05
2025-12-09 11:13:04 - INFO - Epoch: 16.00, Step: 50700, Train Loss: 1.4065, Learning Rate: 6.32e-05
2025-12-09 11:15:53 - INFO - Epoch: 12.80, Step: 50710, Train Loss: 1.3637, Learning Rate: 7.16e-05
2025-12-09 11:20:27 - INFO - Epoch: 12.80, Step: 50720, Train Loss: 1.4062, Learning Rate: 7.16e-05
2025-12-09 11:25:00 - INFO - Epoch: 12.81, Step: 50730, Train Loss: 1.3784, Learning Rate: 7.16e-05
2025-12-09 11:29:34 - INFO - Epoch: 12.81, Step: 50740, Train Loss: 1.3543, Learning Rate: 7.16e-05
2025-12-09 11:34:08 - INFO - Epoch: 12.81, Step: 50750, Train Loss: 1.4043, Learning Rate: 7.15e-05
2025-12-09 11:38:42 - INFO - Epoch: 12.81, Step: 50760, Train Loss: 1.3465, Learning Rate: 7.15e-05
2025-12-09 11:43:15 - INFO - Epoch: 12.82, Step: 50770, Train Loss: 1.3847, Learning Rate: 7.15e-05
2025-12-09 11:47:49 - INFO - Epoch: 12.82, Step: 50780, Train Loss: 1.3665, Learning Rate: 7.15e-05
2025-12-09 11:52:23 - INFO - Epoch: 12.82, Step: 50790, Train Loss: 1.4000, Learning Rate: 7.15e-05
2025-12-09 11:56:57 - INFO - Epoch: 12.83, Step: 50800, Train Loss: 1.4119, Learning Rate: 7.15e-05
2025-12-09 12:01:31 - INFO - Epoch: 12.83, Step: 50810, Train Loss: 1.4062, Learning Rate: 7.15e-05
2025-12-09 12:06:04 - INFO - Epoch: 12.83, Step: 50820, Train Loss: 1.3781, Learning Rate: 7.15e-05
2025-12-09 12:10:38 - INFO - Epoch: 12.83, Step: 50830, Train Loss: 1.4048, Learning Rate: 7.15e-05
2025-12-09 12:15:12 - INFO - Epoch: 12.84, Step: 50840, Train Loss: 1.4298, Learning Rate: 7.15e-05
2025-12-09 12:19:46 - INFO - Epoch: 12.84, Step: 50850, Train Loss: 1.4413, Learning Rate: 7.15e-05
2025-12-09 12:24:19 - INFO - Epoch: 12.84, Step: 50860, Train Loss: 1.3593, Learning Rate: 7.15e-05
2025-12-09 12:28:53 - INFO - Epoch: 12.84, Step: 50870, Train Loss: 1.4302, Learning Rate: 7.15e-05
2025-12-09 12:33:27 - INFO - Epoch: 12.85, Step: 50880, Train Loss: 1.3822, Learning Rate: 7.15e-05
2025-12-09 12:38:01 - INFO - Epoch: 12.85, Step: 50890, Train Loss: 1.3415, Learning Rate: 7.15e-05
2025-12-09 12:42:35 - INFO - Epoch: 12.85, Step: 50900, Train Loss: 1.3867, Learning Rate: 7.14e-05
2025-12-09 12:47:08 - INFO - Epoch: 12.85, Step: 50910, Train Loss: 1.3829, Learning Rate: 7.14e-05
2025-12-09 12:51:42 - INFO - Epoch: 12.86, Step: 50920, Train Loss: 1.3568, Learning Rate: 7.14e-05
2025-12-09 12:56:16 - INFO - Epoch: 12.86, Step: 50930, Train Loss: 1.4426, Learning Rate: 7.14e-05
2025-12-09 13:00:50 - INFO - Epoch: 12.86, Step: 50940, Train Loss: 1.4279, Learning Rate: 7.14e-05
2025-12-09 13:05:23 - INFO - Epoch: 12.86, Step: 50950, Train Loss: 1.4029, Learning Rate: 7.14e-05
2025-12-09 13:09:57 - INFO - Epoch: 12.87, Step: 50960, Train Loss: 1.3746, Learning Rate: 7.14e-05
2025-12-09 13:14:31 - INFO - Epoch: 12.87, Step: 50970, Train Loss: 1.3824, Learning Rate: 7.14e-05
2025-12-09 13:19:05 - INFO - Epoch: 12.87, Step: 50980, Train Loss: 1.3786, Learning Rate: 7.14e-05
2025-12-09 13:23:39 - INFO - Epoch: 12.87, Step: 50990, Train Loss: 1.3828, Learning Rate: 7.14e-05
2025-12-09 13:28:12 - INFO - Epoch: 12.88, Step: 51000, Train Loss: 1.3862, Learning Rate: 7.14e-05
2025-12-09 13:32:46 - INFO - Epoch: 12.88, Step: 51010, Train Loss: 1.3380, Learning Rate: 7.14e-05
2025-12-09 13:37:20 - INFO - Epoch: 12.88, Step: 51020, Train Loss: 1.3975, Learning Rate: 7.14e-05
2025-12-09 13:41:54 - INFO - Epoch: 12.88, Step: 51030, Train Loss: 1.3705, Learning Rate: 7.14e-05
2025-12-09 13:46:27 - INFO - Epoch: 12.89, Step: 51040, Train Loss: 1.4496, Learning Rate: 7.14e-05
2025-12-09 13:51:01 - INFO - Epoch: 12.89, Step: 51050, Train Loss: 1.3853, Learning Rate: 7.13e-05
2025-12-09 13:55:35 - INFO - Epoch: 12.89, Step: 51060, Train Loss: 1.4205, Learning Rate: 7.13e-05
2025-12-09 14:00:09 - INFO - Epoch: 12.89, Step: 51070, Train Loss: 1.4086, Learning Rate: 7.13e-05
2025-12-09 14:04:42 - INFO - Epoch: 12.90, Step: 51080, Train Loss: 1.4133, Learning Rate: 7.13e-05
2025-12-09 14:09:16 - INFO - Epoch: 12.90, Step: 51090, Train Loss: 1.3963, Learning Rate: 7.13e-05
2025-12-09 14:13:50 - INFO - Epoch: 12.90, Step: 51100, Train Loss: 1.3494, Learning Rate: 7.13e-05
2025-12-09 14:18:24 - INFO - Epoch: 12.90, Step: 51110, Train Loss: 1.4140, Learning Rate: 7.13e-05
2025-12-09 14:22:58 - INFO - Epoch: 12.91, Step: 51120, Train Loss: 1.3815, Learning Rate: 7.13e-05
2025-12-09 14:27:31 - INFO - Epoch: 12.91, Step: 51130, Train Loss: 1.3359, Learning Rate: 7.13e-05
2025-12-09 14:32:05 - INFO - Epoch: 12.91, Step: 51140, Train Loss: 1.3941, Learning Rate: 7.13e-05
2025-12-09 14:36:39 - INFO - Epoch: 12.91, Step: 51150, Train Loss: 1.3834, Learning Rate: 7.13e-05
2025-12-09 14:41:13 - INFO - Epoch: 12.92, Step: 51160, Train Loss: 1.4415, Learning Rate: 7.13e-05
2025-12-09 14:45:46 - INFO - Epoch: 12.92, Step: 51170, Train Loss: 1.4009, Learning Rate: 7.13e-05
2025-12-09 14:50:20 - INFO - Epoch: 12.92, Step: 51180, Train Loss: 1.3930, Learning Rate: 7.13e-05
2025-12-09 14:54:54 - INFO - Epoch: 12.92, Step: 51190, Train Loss: 1.3631, Learning Rate: 7.13e-05
2025-12-09 14:59:28 - INFO - Epoch: 12.93, Step: 51200, Train Loss: 1.4191, Learning Rate: 7.12e-05
2025-12-09 15:04:02 - INFO - Epoch: 12.93, Step: 51210, Train Loss: 1.4022, Learning Rate: 7.12e-05
2025-12-09 15:08:35 - INFO - Epoch: 12.93, Step: 51220, Train Loss: 1.3887, Learning Rate: 7.12e-05
2025-12-09 15:13:09 - INFO - Epoch: 12.93, Step: 51230, Train Loss: 1.4022, Learning Rate: 7.12e-05
2025-12-09 15:17:43 - INFO - Epoch: 12.94, Step: 51240, Train Loss: 1.4080, Learning Rate: 7.12e-05
2025-12-09 15:22:17 - INFO - Epoch: 12.94, Step: 51250, Train Loss: 1.3831, Learning Rate: 7.12e-05
2025-12-09 15:26:50 - INFO - Epoch: 12.94, Step: 51260, Train Loss: 1.3770, Learning Rate: 7.12e-05
2025-12-09 15:31:24 - INFO - Epoch: 12.94, Step: 51270, Train Loss: 1.3886, Learning Rate: 7.12e-05
2025-12-09 15:35:58 - INFO - Epoch: 12.95, Step: 51280, Train Loss: 1.3821, Learning Rate: 7.12e-05
2025-12-09 15:40:32 - INFO - Epoch: 12.95, Step: 51290, Train Loss: 1.4058, Learning Rate: 7.12e-05
2025-12-09 15:45:06 - INFO - Epoch: 12.95, Step: 51300, Train Loss: 1.4108, Learning Rate: 7.12e-05
2025-12-09 15:49:39 - INFO - Epoch: 12.95, Step: 51310, Train Loss: 1.4353, Learning Rate: 7.12e-05
2025-12-09 15:54:13 - INFO - Epoch: 12.96, Step: 51320, Train Loss: 1.3489, Learning Rate: 7.12e-05
2025-12-09 15:58:47 - INFO - Epoch: 12.96, Step: 51330, Train Loss: 1.3700, Learning Rate: 7.12e-05
2025-12-09 16:03:21 - INFO - Epoch: 12.96, Step: 51340, Train Loss: 1.4121, Learning Rate: 7.12e-05
2025-12-09 16:07:54 - INFO - Epoch: 12.96, Step: 51350, Train Loss: 1.3615, Learning Rate: 7.11e-05
2025-12-09 16:12:28 - INFO - Epoch: 12.97, Step: 51360, Train Loss: 1.3831, Learning Rate: 7.11e-05
2025-12-09 16:17:02 - INFO - Epoch: 12.97, Step: 51370, Train Loss: 1.3621, Learning Rate: 7.11e-05
2025-12-09 16:21:36 - INFO - Epoch: 12.97, Step: 51380, Train Loss: 1.3549, Learning Rate: 7.11e-05
2025-12-09 16:26:10 - INFO - Epoch: 12.97, Step: 51390, Train Loss: 1.4283, Learning Rate: 7.11e-05
2025-12-09 16:30:43 - INFO - Epoch: 12.98, Step: 51400, Train Loss: 1.3890, Learning Rate: 7.11e-05
2025-12-09 16:35:17 - INFO - Epoch: 12.98, Step: 51410, Train Loss: 1.3687, Learning Rate: 7.11e-05
2025-12-09 16:39:51 - INFO - Epoch: 12.98, Step: 51420, Train Loss: 1.4297, Learning Rate: 7.11e-05
2025-12-09 16:44:25 - INFO - Epoch: 12.98, Step: 51430, Train Loss: 1.4018, Learning Rate: 7.11e-05
2025-12-09 16:48:58 - INFO - Epoch: 12.99, Step: 51440, Train Loss: 1.3591, Learning Rate: 7.11e-05
2025-12-09 16:53:32 - INFO - Epoch: 12.99, Step: 51450, Train Loss: 1.4220, Learning Rate: 7.11e-05
2025-12-09 16:58:06 - INFO - Epoch: 12.99, Step: 51460, Train Loss: 1.4209, Learning Rate: 7.11e-05
2025-12-09 17:02:40 - INFO - Epoch: 12.99, Step: 51470, Train Loss: 1.3825, Learning Rate: 7.11e-05
2025-12-09 17:07:13 - INFO - Epoch: 13.00, Step: 51480, Train Loss: 1.4431, Learning Rate: 7.11e-05
2025-12-09 17:11:47 - INFO - Epoch: 13.00, Step: 51490, Train Loss: 1.3811, Learning Rate: 7.11e-05
2025-12-09 17:13:17 - INFO - Epoch: 13.00, Step: 51500, Train Loss: 1.3719, Learning Rate: 7.10e-05
2025-12-09 17:13:28 - INFO - Epoch: 13.00, Step: 51510, Train Loss: 1.3979, Learning Rate: 7.10e-05
2025-12-09 17:13:40 - INFO - Epoch: 13.01, Step: 51520, Train Loss: 1.3634, Learning Rate: 7.10e-05
2025-12-09 17:13:51 - INFO - Epoch: 13.01, Step: 51530, Train Loss: 1.3902, Learning Rate: 7.10e-05
2025-12-09 17:14:02 - INFO - Epoch: 13.01, Step: 51540, Train Loss: 1.3789, Learning Rate: 7.10e-05
2025-12-09 17:14:13 - INFO - Epoch: 13.01, Step: 51550, Train Loss: 1.3864, Learning Rate: 7.10e-05
2025-12-09 17:14:24 - INFO - Epoch: 13.02, Step: 51560, Train Loss: 1.3861, Learning Rate: 7.10e-05
2025-12-09 17:14:35 - INFO - Epoch: 13.02, Step: 51570, Train Loss: 1.4405, Learning Rate: 7.10e-05
2025-12-09 17:14:46 - INFO - Epoch: 13.02, Step: 51580, Train Loss: 1.4142, Learning Rate: 7.10e-05
2025-12-09 17:14:58 - INFO - Epoch: 13.02, Step: 51590, Train Loss: 1.3996, Learning Rate: 7.10e-05
2025-12-09 17:15:09 - INFO - Epoch: 13.03, Step: 51600, Train Loss: 1.3838, Learning Rate: 7.10e-05
2025-12-09 17:15:20 - INFO - Epoch: 13.03, Step: 51610, Train Loss: 1.3641, Learning Rate: 7.10e-05
2025-12-09 17:15:31 - INFO - Epoch: 13.03, Step: 51620, Train Loss: 1.4239, Learning Rate: 7.10e-05
2025-12-09 17:15:42 - INFO - Epoch: 13.03, Step: 51630, Train Loss: 1.4037, Learning Rate: 7.10e-05
2025-12-09 17:15:53 - INFO - Epoch: 13.04, Step: 51640, Train Loss: 1.3647, Learning Rate: 7.10e-05
2025-12-09 17:16:04 - INFO - Epoch: 13.04, Step: 51650, Train Loss: 1.3757, Learning Rate: 7.09e-05
2025-12-09 17:16:16 - INFO - Epoch: 13.04, Step: 51660, Train Loss: 1.3985, Learning Rate: 7.09e-05
2025-12-09 17:16:27 - INFO - Epoch: 13.04, Step: 51670, Train Loss: 1.3626, Learning Rate: 7.09e-05
2025-12-09 17:16:38 - INFO - Epoch: 13.05, Step: 51680, Train Loss: 1.3653, Learning Rate: 7.09e-05
2025-12-09 17:16:49 - INFO - Epoch: 13.05, Step: 51690, Train Loss: 1.4127, Learning Rate: 7.09e-05
2025-12-09 17:17:00 - INFO - Epoch: 13.05, Step: 51700, Train Loss: 1.3766, Learning Rate: 7.09e-05
2025-12-09 17:17:11 - INFO - Epoch: 13.05, Step: 51710, Train Loss: 1.3733, Learning Rate: 7.09e-05
2025-12-09 17:17:23 - INFO - Epoch: 13.06, Step: 51720, Train Loss: 1.3909, Learning Rate: 7.09e-05
2025-12-09 17:17:34 - INFO - Epoch: 13.06, Step: 51730, Train Loss: 1.4004, Learning Rate: 7.09e-05
2025-12-09 17:17:45 - INFO - Epoch: 13.06, Step: 51740, Train Loss: 1.3469, Learning Rate: 7.09e-05
2025-12-09 17:17:56 - INFO - Epoch: 13.06, Step: 51750, Train Loss: 1.3825, Learning Rate: 7.09e-05
2025-12-09 17:18:07 - INFO - Epoch: 13.07, Step: 51760, Train Loss: 1.4174, Learning Rate: 7.09e-05
2025-12-09 17:18:18 - INFO - Epoch: 13.07, Step: 51770, Train Loss: 1.4329, Learning Rate: 7.09e-05
2025-12-09 17:18:29 - INFO - Epoch: 13.07, Step: 51780, Train Loss: 1.3582, Learning Rate: 7.09e-05
2025-12-09 17:18:41 - INFO - Epoch: 13.07, Step: 51790, Train Loss: 1.4108, Learning Rate: 7.09e-05
2025-12-09 17:18:52 - INFO - Epoch: 13.08, Step: 51800, Train Loss: 1.4074, Learning Rate: 7.08e-05
2025-12-09 17:19:03 - INFO - Epoch: 13.08, Step: 51810, Train Loss: 1.4034, Learning Rate: 7.08e-05
2025-12-09 17:19:14 - INFO - Epoch: 13.08, Step: 51820, Train Loss: 1.4154, Learning Rate: 7.08e-05
2025-12-09 17:19:25 - INFO - Epoch: 13.09, Step: 51830, Train Loss: 1.3610, Learning Rate: 7.08e-05
2025-12-09 17:19:36 - INFO - Epoch: 13.09, Step: 51840, Train Loss: 1.4124, Learning Rate: 7.08e-05
2025-12-09 17:19:48 - INFO - Epoch: 13.09, Step: 51850, Train Loss: 1.3807, Learning Rate: 7.08e-05
2025-12-09 17:19:59 - INFO - Epoch: 13.09, Step: 51860, Train Loss: 1.4438, Learning Rate: 7.08e-05
2025-12-09 17:20:10 - INFO - Epoch: 13.10, Step: 51870, Train Loss: 1.3853, Learning Rate: 7.08e-05
2025-12-09 17:20:21 - INFO - Epoch: 13.10, Step: 51880, Train Loss: 1.3781, Learning Rate: 7.08e-05
2025-12-09 17:20:32 - INFO - Epoch: 13.10, Step: 51890, Train Loss: 1.4082, Learning Rate: 7.08e-05
2025-12-09 17:20:43 - INFO - Epoch: 13.10, Step: 51900, Train Loss: 1.3983, Learning Rate: 7.08e-05
2025-12-09 17:20:54 - INFO - Epoch: 13.11, Step: 51910, Train Loss: 1.3501, Learning Rate: 7.08e-05
2025-12-09 17:21:06 - INFO - Epoch: 13.11, Step: 51920, Train Loss: 1.3994, Learning Rate: 7.08e-05
2025-12-09 17:21:17 - INFO - Epoch: 13.11, Step: 51930, Train Loss: 1.4052, Learning Rate: 7.08e-05
2025-12-09 17:21:28 - INFO - Epoch: 13.11, Step: 51940, Train Loss: 1.3732, Learning Rate: 7.08e-05
2025-12-09 17:21:39 - INFO - Epoch: 13.12, Step: 51950, Train Loss: 1.3748, Learning Rate: 7.07e-05
2025-12-09 17:21:50 - INFO - Epoch: 13.12, Step: 51960, Train Loss: 1.3645, Learning Rate: 7.07e-05
2025-12-09 17:22:01 - INFO - Epoch: 13.12, Step: 51970, Train Loss: 1.3941, Learning Rate: 7.07e-05
2025-12-09 17:22:12 - INFO - Epoch: 13.12, Step: 51980, Train Loss: 1.3892, Learning Rate: 7.07e-05
2025-12-09 17:22:24 - INFO - Epoch: 13.13, Step: 51990, Train Loss: 1.4070, Learning Rate: 7.07e-05
2025-12-09 17:22:35 - INFO - Epoch: 13.13, Step: 52000, Train Loss: 1.3998, Learning Rate: 7.07e-05
2025-12-09 17:22:46 - INFO - Epoch: 13.13, Step: 52010, Train Loss: 1.3910, Learning Rate: 7.07e-05
2025-12-09 17:22:57 - INFO - Epoch: 13.13, Step: 52020, Train Loss: 1.4070, Learning Rate: 7.07e-05
2025-12-09 17:23:08 - INFO - Epoch: 13.14, Step: 52030, Train Loss: 1.3530, Learning Rate: 7.07e-05
2025-12-09 17:23:19 - INFO - Epoch: 13.14, Step: 52040, Train Loss: 1.4062, Learning Rate: 7.07e-05
2025-12-09 17:23:31 - INFO - Epoch: 13.14, Step: 52050, Train Loss: 1.4029, Learning Rate: 7.07e-05
2025-12-09 17:23:42 - INFO - Epoch: 13.14, Step: 52060, Train Loss: 1.3772, Learning Rate: 7.07e-05
2025-12-09 17:23:53 - INFO - Epoch: 13.15, Step: 52070, Train Loss: 1.3890, Learning Rate: 7.07e-05
2025-12-09 17:24:04 - INFO - Epoch: 13.15, Step: 52080, Train Loss: 1.3783, Learning Rate: 7.07e-05
2025-12-09 17:24:15 - INFO - Epoch: 13.15, Step: 52090, Train Loss: 1.3670, Learning Rate: 7.07e-05
2025-12-09 17:24:26 - INFO - Epoch: 13.15, Step: 52100, Train Loss: 1.3833, Learning Rate: 7.07e-05
2025-12-09 17:24:37 - INFO - Epoch: 13.16, Step: 52110, Train Loss: 1.4019, Learning Rate: 7.06e-05
2025-12-09 17:24:49 - INFO - Epoch: 13.16, Step: 52120, Train Loss: 1.4102, Learning Rate: 7.06e-05
2025-12-09 17:25:00 - INFO - Epoch: 13.16, Step: 52130, Train Loss: 1.4066, Learning Rate: 7.06e-05
2025-12-09 17:25:11 - INFO - Epoch: 13.16, Step: 52140, Train Loss: 1.3868, Learning Rate: 7.06e-05
2025-12-09 17:25:22 - INFO - Epoch: 13.17, Step: 52150, Train Loss: 1.3474, Learning Rate: 7.06e-05
2025-12-09 17:25:33 - INFO - Epoch: 13.17, Step: 52160, Train Loss: 1.3969, Learning Rate: 7.06e-05
2025-12-09 17:25:44 - INFO - Epoch: 13.17, Step: 52170, Train Loss: 1.4029, Learning Rate: 7.06e-05
2025-12-09 17:25:56 - INFO - Epoch: 13.17, Step: 52180, Train Loss: 1.3665, Learning Rate: 7.06e-05
2025-12-09 17:26:07 - INFO - Epoch: 13.18, Step: 52190, Train Loss: 1.3898, Learning Rate: 7.06e-05
2025-12-09 17:26:18 - INFO - Epoch: 13.18, Step: 52200, Train Loss: 1.3923, Learning Rate: 7.06e-05
2025-12-09 17:26:29 - INFO - Epoch: 13.18, Step: 52210, Train Loss: 1.4179, Learning Rate: 7.06e-05
2025-12-09 17:26:40 - INFO - Epoch: 13.18, Step: 52220, Train Loss: 1.3849, Learning Rate: 7.06e-05
2025-12-09 17:26:51 - INFO - Epoch: 13.19, Step: 52230, Train Loss: 1.4212, Learning Rate: 7.06e-05
2025-12-09 17:27:02 - INFO - Epoch: 13.19, Step: 52240, Train Loss: 1.3675, Learning Rate: 7.06e-05
2025-12-09 17:27:14 - INFO - Epoch: 13.19, Step: 52250, Train Loss: 1.3979, Learning Rate: 7.06e-05
2025-12-09 17:27:25 - INFO - Epoch: 13.19, Step: 52260, Train Loss: 1.3781, Learning Rate: 7.05e-05
2025-12-09 17:27:36 - INFO - Epoch: 13.20, Step: 52270, Train Loss: 1.4001, Learning Rate: 7.05e-05
2025-12-09 17:27:47 - INFO - Epoch: 13.20, Step: 52280, Train Loss: 1.3963, Learning Rate: 7.05e-05
2025-12-09 17:27:58 - INFO - Epoch: 13.20, Step: 52290, Train Loss: 1.3795, Learning Rate: 7.05e-05
2025-12-09 17:28:09 - INFO - Epoch: 13.20, Step: 52300, Train Loss: 1.3637, Learning Rate: 7.05e-05
2025-12-09 17:28:21 - INFO - Epoch: 13.21, Step: 52310, Train Loss: 1.4067, Learning Rate: 7.05e-05
2025-12-09 17:28:32 - INFO - Epoch: 13.21, Step: 52320, Train Loss: 1.3740, Learning Rate: 7.05e-05
2025-12-09 17:28:43 - INFO - Epoch: 13.21, Step: 52330, Train Loss: 1.3570, Learning Rate: 7.05e-05
2025-12-09 17:28:54 - INFO - Epoch: 13.21, Step: 52340, Train Loss: 1.3884, Learning Rate: 7.05e-05
2025-12-09 17:29:05 - INFO - Epoch: 13.22, Step: 52350, Train Loss: 1.4032, Learning Rate: 7.05e-05
2025-12-09 17:29:16 - INFO - Epoch: 13.22, Step: 52360, Train Loss: 1.3823, Learning Rate: 7.05e-05
2025-12-09 17:29:27 - INFO - Epoch: 13.22, Step: 52370, Train Loss: 1.4001, Learning Rate: 7.05e-05
2025-12-09 17:29:39 - INFO - Epoch: 13.22, Step: 52380, Train Loss: 1.3794, Learning Rate: 7.05e-05
2025-12-09 17:29:50 - INFO - Epoch: 13.23, Step: 52390, Train Loss: 1.3876, Learning Rate: 7.05e-05
2025-12-09 17:30:01 - INFO - Epoch: 13.23, Step: 52400, Train Loss: 1.3523, Learning Rate: 7.05e-05
2025-12-09 17:30:12 - INFO - Epoch: 13.23, Step: 52410, Train Loss: 1.3930, Learning Rate: 7.04e-05
2025-12-09 17:30:23 - INFO - Epoch: 13.23, Step: 52420, Train Loss: 1.4248, Learning Rate: 7.04e-05
2025-12-09 17:30:34 - INFO - Epoch: 13.24, Step: 52430, Train Loss: 1.3899, Learning Rate: 7.04e-05
2025-12-09 17:30:45 - INFO - Epoch: 13.24, Step: 52440, Train Loss: 1.3812, Learning Rate: 7.04e-05
2025-12-09 17:30:57 - INFO - Epoch: 13.24, Step: 52450, Train Loss: 1.4050, Learning Rate: 7.04e-05
2025-12-09 17:31:08 - INFO - Epoch: 13.24, Step: 52460, Train Loss: 1.3685, Learning Rate: 7.04e-05
2025-12-09 17:31:19 - INFO - Epoch: 13.25, Step: 52470, Train Loss: 1.3779, Learning Rate: 7.04e-05
2025-12-09 17:31:30 - INFO - Epoch: 13.25, Step: 52480, Train Loss: 1.3895, Learning Rate: 7.04e-05
2025-12-09 17:31:41 - INFO - Epoch: 13.25, Step: 52490, Train Loss: 1.3817, Learning Rate: 7.04e-05
2025-12-09 17:31:52 - INFO - Epoch: 13.25, Step: 52500, Train Loss: 1.3831, Learning Rate: 7.04e-05
2025-12-09 17:32:04 - INFO - Epoch: 13.26, Step: 52510, Train Loss: 1.3807, Learning Rate: 7.04e-05
2025-12-09 17:32:15 - INFO - Epoch: 13.26, Step: 52520, Train Loss: 1.3818, Learning Rate: 7.04e-05
2025-12-09 17:32:26 - INFO - Epoch: 13.26, Step: 52530, Train Loss: 1.3465, Learning Rate: 7.04e-05
2025-12-09 17:32:37 - INFO - Epoch: 13.26, Step: 52540, Train Loss: 1.3410, Learning Rate: 7.04e-05
2025-12-09 17:32:48 - INFO - Epoch: 13.27, Step: 52550, Train Loss: 1.4036, Learning Rate: 7.04e-05
2025-12-09 17:32:59 - INFO - Epoch: 13.27, Step: 52560, Train Loss: 1.4120, Learning Rate: 7.03e-05
2025-12-09 17:33:10 - INFO - Epoch: 13.27, Step: 52570, Train Loss: 1.3959, Learning Rate: 7.03e-05
2025-12-09 17:33:22 - INFO - Epoch: 13.27, Step: 52580, Train Loss: 1.4200, Learning Rate: 7.03e-05
2025-12-09 17:33:33 - INFO - Epoch: 13.28, Step: 52590, Train Loss: 1.3869, Learning Rate: 7.03e-05
2025-12-09 17:33:44 - INFO - Epoch: 13.28, Step: 52600, Train Loss: 1.4026, Learning Rate: 7.03e-05
2025-12-09 17:33:55 - INFO - Epoch: 13.28, Step: 52610, Train Loss: 1.3917, Learning Rate: 7.03e-05
2025-12-09 17:34:06 - INFO - Epoch: 13.28, Step: 52620, Train Loss: 1.4106, Learning Rate: 7.03e-05
2025-12-09 17:34:17 - INFO - Epoch: 13.29, Step: 52630, Train Loss: 1.3993, Learning Rate: 7.03e-05
2025-12-09 17:34:29 - INFO - Epoch: 13.29, Step: 52640, Train Loss: 1.3599, Learning Rate: 7.03e-05
2025-12-09 17:34:40 - INFO - Epoch: 13.29, Step: 52650, Train Loss: 1.3693, Learning Rate: 7.03e-05
2025-12-09 17:34:51 - INFO - Epoch: 13.29, Step: 52660, Train Loss: 1.3984, Learning Rate: 7.03e-05
2025-12-09 17:35:02 - INFO - Epoch: 13.30, Step: 52670, Train Loss: 1.4106, Learning Rate: 7.03e-05
2025-12-09 17:35:13 - INFO - Epoch: 13.30, Step: 52680, Train Loss: 1.3894, Learning Rate: 7.03e-05
2025-12-09 17:35:24 - INFO - Epoch: 13.30, Step: 52690, Train Loss: 1.4082, Learning Rate: 7.03e-05
2025-12-09 17:35:35 - INFO - Epoch: 13.30, Step: 52700, Train Loss: 1.3995, Learning Rate: 7.03e-05
2025-12-09 17:35:47 - INFO - Epoch: 13.31, Step: 52710, Train Loss: 1.4067, Learning Rate: 7.02e-05
2025-12-09 17:35:58 - INFO - Epoch: 13.31, Step: 52720, Train Loss: 1.4140, Learning Rate: 7.02e-05
2025-12-09 17:36:09 - INFO - Epoch: 13.31, Step: 52730, Train Loss: 1.3959, Learning Rate: 7.02e-05
2025-12-09 17:36:20 - INFO - Epoch: 13.31, Step: 52740, Train Loss: 1.3750, Learning Rate: 7.02e-05
2025-12-09 17:36:31 - INFO - Epoch: 13.32, Step: 52750, Train Loss: 1.4067, Learning Rate: 7.02e-05
2025-12-09 17:36:42 - INFO - Epoch: 13.32, Step: 52760, Train Loss: 1.4044, Learning Rate: 7.02e-05
2025-12-09 17:36:54 - INFO - Epoch: 13.32, Step: 52770, Train Loss: 1.4387, Learning Rate: 7.02e-05
2025-12-09 17:37:05 - INFO - Epoch: 13.32, Step: 52780, Train Loss: 1.3606, Learning Rate: 7.02e-05
2025-12-09 17:37:16 - INFO - Epoch: 13.33, Step: 52790, Train Loss: 1.3634, Learning Rate: 7.02e-05
2025-12-09 17:37:27 - INFO - Epoch: 13.33, Step: 52800, Train Loss: 1.3803, Learning Rate: 7.02e-05
2025-12-09 17:37:38 - INFO - Epoch: 13.33, Step: 52810, Train Loss: 1.3587, Learning Rate: 7.02e-05
2025-12-09 17:37:49 - INFO - Epoch: 13.34, Step: 52820, Train Loss: 1.3864, Learning Rate: 7.02e-05
2025-12-09 17:38:00 - INFO - Epoch: 13.34, Step: 52830, Train Loss: 1.3800, Learning Rate: 7.02e-05
2025-12-09 17:38:12 - INFO - Epoch: 13.34, Step: 52840, Train Loss: 1.4057, Learning Rate: 7.02e-05
2025-12-09 17:38:23 - INFO - Epoch: 13.34, Step: 52850, Train Loss: 1.3853, Learning Rate: 7.02e-05
2025-12-09 17:38:34 - INFO - Epoch: 13.35, Step: 52860, Train Loss: 1.3991, Learning Rate: 7.01e-05
2025-12-09 17:38:45 - INFO - Epoch: 13.35, Step: 52870, Train Loss: 1.3601, Learning Rate: 7.01e-05
2025-12-09 17:38:56 - INFO - Epoch: 13.35, Step: 52880, Train Loss: 1.3559, Learning Rate: 7.01e-05
2025-12-09 17:39:07 - INFO - Epoch: 13.35, Step: 52890, Train Loss: 1.4133, Learning Rate: 7.01e-05
2025-12-09 17:39:18 - INFO - Epoch: 13.36, Step: 52900, Train Loss: 1.4010, Learning Rate: 7.01e-05
2025-12-09 17:39:30 - INFO - Epoch: 13.36, Step: 52910, Train Loss: 1.3821, Learning Rate: 7.01e-05
2025-12-09 17:39:41 - INFO - Epoch: 13.36, Step: 52920, Train Loss: 1.3832, Learning Rate: 7.01e-05
2025-12-09 17:39:52 - INFO - Epoch: 13.36, Step: 52930, Train Loss: 1.4072, Learning Rate: 7.01e-05
2025-12-09 17:40:03 - INFO - Epoch: 13.37, Step: 52940, Train Loss: 1.3770, Learning Rate: 7.01e-05
2025-12-09 17:40:14 - INFO - Epoch: 13.37, Step: 52950, Train Loss: 1.3653, Learning Rate: 7.01e-05
2025-12-09 17:40:25 - INFO - Epoch: 13.37, Step: 52960, Train Loss: 1.4306, Learning Rate: 7.01e-05
2025-12-09 17:40:37 - INFO - Epoch: 13.37, Step: 52970, Train Loss: 1.3645, Learning Rate: 7.01e-05
2025-12-09 17:40:48 - INFO - Epoch: 13.38, Step: 52980, Train Loss: 1.3699, Learning Rate: 7.01e-05
2025-12-09 17:40:59 - INFO - Epoch: 13.38, Step: 52990, Train Loss: 1.3937, Learning Rate: 7.01e-05
2025-12-09 17:41:10 - INFO - Epoch: 13.38, Step: 53000, Train Loss: 1.3589, Learning Rate: 7.01e-05
2025-12-09 17:41:21 - INFO - Epoch: 13.38, Step: 53010, Train Loss: 1.3652, Learning Rate: 7.00e-05
2025-12-09 17:41:32 - INFO - Epoch: 13.39, Step: 53020, Train Loss: 1.3681, Learning Rate: 7.00e-05
2025-12-09 17:41:43 - INFO - Epoch: 13.39, Step: 53030, Train Loss: 1.3614, Learning Rate: 7.00e-05
2025-12-09 17:41:55 - INFO - Epoch: 13.39, Step: 53040, Train Loss: 1.3866, Learning Rate: 7.00e-05
2025-12-09 17:42:06 - INFO - Epoch: 13.39, Step: 53050, Train Loss: 1.3901, Learning Rate: 7.00e-05
2025-12-09 17:42:17 - INFO - Epoch: 13.40, Step: 53060, Train Loss: 1.4250, Learning Rate: 7.00e-05
2025-12-09 17:42:28 - INFO - Epoch: 13.40, Step: 53070, Train Loss: 1.3721, Learning Rate: 7.00e-05
2025-12-09 17:42:39 - INFO - Epoch: 13.40, Step: 53080, Train Loss: 1.3870, Learning Rate: 7.00e-05
2025-12-09 17:42:50 - INFO - Epoch: 13.40, Step: 53090, Train Loss: 1.4174, Learning Rate: 7.00e-05
2025-12-09 17:43:02 - INFO - Epoch: 13.41, Step: 53100, Train Loss: 1.4049, Learning Rate: 7.00e-05
2025-12-09 17:43:13 - INFO - Epoch: 13.41, Step: 53110, Train Loss: 1.3881, Learning Rate: 7.00e-05
2025-12-09 17:43:24 - INFO - Epoch: 13.41, Step: 53120, Train Loss: 1.3787, Learning Rate: 7.00e-05
2025-12-09 17:43:35 - INFO - Epoch: 13.41, Step: 53130, Train Loss: 1.3307, Learning Rate: 7.00e-05
2025-12-09 17:43:46 - INFO - Epoch: 13.42, Step: 53140, Train Loss: 1.3567, Learning Rate: 7.00e-05
2025-12-09 17:43:57 - INFO - Epoch: 13.42, Step: 53150, Train Loss: 1.3651, Learning Rate: 7.00e-05
2025-12-09 17:44:08 - INFO - Epoch: 13.42, Step: 53160, Train Loss: 1.3868, Learning Rate: 6.99e-05
2025-12-09 17:44:20 - INFO - Epoch: 13.42, Step: 53170, Train Loss: 1.3977, Learning Rate: 6.99e-05
2025-12-09 17:44:31 - INFO - Epoch: 13.43, Step: 53180, Train Loss: 1.4149, Learning Rate: 6.99e-05
2025-12-09 17:44:42 - INFO - Epoch: 13.43, Step: 53190, Train Loss: 1.3808, Learning Rate: 6.99e-05
2025-12-09 17:44:53 - INFO - Epoch: 13.43, Step: 53200, Train Loss: 1.3985, Learning Rate: 6.99e-05
2025-12-09 17:45:04 - INFO - Epoch: 13.43, Step: 53210, Train Loss: 1.4021, Learning Rate: 6.99e-05
2025-12-09 17:45:15 - INFO - Epoch: 13.44, Step: 53220, Train Loss: 1.4070, Learning Rate: 6.99e-05
2025-12-09 17:45:27 - INFO - Epoch: 13.44, Step: 53230, Train Loss: 1.3570, Learning Rate: 6.99e-05
2025-12-09 17:45:38 - INFO - Epoch: 13.44, Step: 53240, Train Loss: 1.3662, Learning Rate: 6.99e-05
2025-12-09 17:45:49 - INFO - Epoch: 13.44, Step: 53250, Train Loss: 1.3517, Learning Rate: 6.99e-05
2025-12-09 17:46:00 - INFO - Epoch: 13.45, Step: 53260, Train Loss: 1.4361, Learning Rate: 6.99e-05
2025-12-09 17:46:11 - INFO - Epoch: 13.45, Step: 53270, Train Loss: 1.3846, Learning Rate: 6.99e-05
2025-12-09 17:46:22 - INFO - Epoch: 13.45, Step: 53280, Train Loss: 1.3251, Learning Rate: 6.99e-05
2025-12-09 17:46:33 - INFO - Epoch: 13.45, Step: 53290, Train Loss: 1.3825, Learning Rate: 6.99e-05
2025-12-09 17:46:45 - INFO - Epoch: 13.46, Step: 53300, Train Loss: 1.4192, Learning Rate: 6.99e-05
2025-12-09 17:46:56 - INFO - Epoch: 13.46, Step: 53310, Train Loss: 1.4191, Learning Rate: 6.98e-05
2025-12-09 17:47:07 - INFO - Epoch: 13.46, Step: 53320, Train Loss: 1.3670, Learning Rate: 6.98e-05
2025-12-09 17:47:18 - INFO - Epoch: 13.46, Step: 53330, Train Loss: 1.3456, Learning Rate: 6.98e-05
2025-12-09 17:47:29 - INFO - Epoch: 13.47, Step: 53340, Train Loss: 1.3908, Learning Rate: 6.98e-05
2025-12-09 17:47:40 - INFO - Epoch: 13.47, Step: 53350, Train Loss: 1.3691, Learning Rate: 6.98e-05
2025-12-09 17:47:51 - INFO - Epoch: 13.47, Step: 53360, Train Loss: 1.3528, Learning Rate: 6.98e-05
2025-12-09 17:48:03 - INFO - Epoch: 13.47, Step: 53370, Train Loss: 1.4007, Learning Rate: 6.98e-05
2025-12-09 17:48:14 - INFO - Epoch: 13.48, Step: 53380, Train Loss: 1.4002, Learning Rate: 6.98e-05
2025-12-09 17:48:25 - INFO - Epoch: 13.48, Step: 53390, Train Loss: 1.3813, Learning Rate: 6.98e-05
2025-12-09 17:48:36 - INFO - Epoch: 13.48, Step: 53400, Train Loss: 1.3581, Learning Rate: 6.98e-05
2025-12-09 17:48:47 - INFO - Epoch: 13.48, Step: 53410, Train Loss: 1.4018, Learning Rate: 6.98e-05
2025-12-09 17:48:58 - INFO - Epoch: 13.49, Step: 53420, Train Loss: 1.3937, Learning Rate: 6.98e-05
2025-12-09 17:49:10 - INFO - Epoch: 13.49, Step: 53430, Train Loss: 1.3470, Learning Rate: 6.98e-05
2025-12-09 17:49:21 - INFO - Epoch: 13.49, Step: 53440, Train Loss: 1.4113, Learning Rate: 6.98e-05
2025-12-09 17:49:32 - INFO - Epoch: 13.49, Step: 53450, Train Loss: 1.4127, Learning Rate: 6.98e-05
2025-12-09 17:49:43 - INFO - Epoch: 13.50, Step: 53460, Train Loss: 1.3913, Learning Rate: 6.97e-05
2025-12-09 17:49:54 - INFO - Epoch: 13.50, Step: 53470, Train Loss: 1.4017, Learning Rate: 6.97e-05
2025-12-09 17:50:05 - INFO - Epoch: 13.50, Step: 53480, Train Loss: 1.3771, Learning Rate: 6.97e-05
2025-12-09 17:50:16 - INFO - Epoch: 13.50, Step: 53490, Train Loss: 1.3433, Learning Rate: 6.97e-05
2025-12-09 17:50:28 - INFO - Epoch: 13.51, Step: 53500, Train Loss: 1.3783, Learning Rate: 6.97e-05
2025-12-09 17:50:39 - INFO - Epoch: 13.51, Step: 53510, Train Loss: 1.3835, Learning Rate: 6.97e-05
2025-12-09 17:50:50 - INFO - Epoch: 13.51, Step: 53520, Train Loss: 1.3935, Learning Rate: 6.97e-05
2025-12-09 17:51:01 - INFO - Epoch: 13.51, Step: 53530, Train Loss: 1.3619, Learning Rate: 6.97e-05
2025-12-09 17:51:12 - INFO - Epoch: 13.52, Step: 53540, Train Loss: 1.3841, Learning Rate: 6.97e-05
2025-12-09 17:51:23 - INFO - Epoch: 13.52, Step: 53550, Train Loss: 1.4225, Learning Rate: 6.97e-05
2025-12-09 17:51:35 - INFO - Epoch: 13.52, Step: 53560, Train Loss: 1.3855, Learning Rate: 6.97e-05
2025-12-09 17:51:46 - INFO - Epoch: 13.52, Step: 53570, Train Loss: 1.3697, Learning Rate: 6.97e-05
2025-12-09 17:51:57 - INFO - Epoch: 13.53, Step: 53580, Train Loss: 1.4113, Learning Rate: 6.97e-05
2025-12-09 17:52:08 - INFO - Epoch: 13.53, Step: 53590, Train Loss: 1.4094, Learning Rate: 6.97e-05
2025-12-09 17:52:19 - INFO - Epoch: 13.53, Step: 53600, Train Loss: 1.4090, Learning Rate: 6.97e-05
2025-12-09 17:52:30 - INFO - Epoch: 13.53, Step: 53610, Train Loss: 1.3650, Learning Rate: 6.96e-05
2025-12-09 17:52:41 - INFO - Epoch: 13.54, Step: 53620, Train Loss: 1.3953, Learning Rate: 6.96e-05
2025-12-09 17:52:53 - INFO - Epoch: 13.54, Step: 53630, Train Loss: 1.3684, Learning Rate: 6.96e-05
2025-12-09 17:53:04 - INFO - Epoch: 13.54, Step: 53640, Train Loss: 1.3887, Learning Rate: 6.96e-05
2025-12-09 17:53:15 - INFO - Epoch: 13.54, Step: 53650, Train Loss: 1.3460, Learning Rate: 6.96e-05
2025-12-09 17:53:26 - INFO - Epoch: 13.55, Step: 53660, Train Loss: 1.4067, Learning Rate: 6.96e-05
2025-12-09 17:53:37 - INFO - Epoch: 13.55, Step: 53670, Train Loss: 1.3830, Learning Rate: 6.96e-05
2025-12-09 17:53:48 - INFO - Epoch: 13.55, Step: 53680, Train Loss: 1.3426, Learning Rate: 6.96e-05
2025-12-09 17:54:00 - INFO - Epoch: 13.55, Step: 53690, Train Loss: 1.4123, Learning Rate: 6.96e-05
2025-12-09 17:54:11 - INFO - Epoch: 13.56, Step: 53700, Train Loss: 1.4124, Learning Rate: 6.96e-05
2025-12-09 17:54:22 - INFO - Epoch: 13.56, Step: 53710, Train Loss: 1.3968, Learning Rate: 6.96e-05
2025-12-09 17:54:33 - INFO - Epoch: 13.56, Step: 53720, Train Loss: 1.3763, Learning Rate: 6.96e-05
2025-12-09 17:54:44 - INFO - Epoch: 13.56, Step: 53730, Train Loss: 1.3677, Learning Rate: 6.96e-05
2025-12-09 17:54:55 - INFO - Epoch: 13.57, Step: 53740, Train Loss: 1.4195, Learning Rate: 6.96e-05
2025-12-09 17:55:06 - INFO - Epoch: 13.57, Step: 53750, Train Loss: 1.3901, Learning Rate: 6.96e-05
2025-12-09 17:55:18 - INFO - Epoch: 13.57, Step: 53760, Train Loss: 1.3582, Learning Rate: 6.95e-05
2025-12-09 17:55:29 - INFO - Epoch: 13.57, Step: 53770, Train Loss: 1.3494, Learning Rate: 6.95e-05
2025-12-09 17:55:40 - INFO - Epoch: 13.58, Step: 53780, Train Loss: 1.3247, Learning Rate: 6.95e-05
2025-12-09 17:55:51 - INFO - Epoch: 13.58, Step: 53790, Train Loss: 1.3966, Learning Rate: 6.95e-05
2025-12-09 17:56:02 - INFO - Epoch: 13.58, Step: 53800, Train Loss: 1.3911, Learning Rate: 6.95e-05
2025-12-09 17:56:13 - INFO - Epoch: 13.58, Step: 53810, Train Loss: 1.3678, Learning Rate: 6.95e-05
2025-12-09 17:56:24 - INFO - Epoch: 13.59, Step: 53820, Train Loss: 1.3667, Learning Rate: 6.95e-05
2025-12-09 17:56:36 - INFO - Epoch: 13.59, Step: 53830, Train Loss: 1.3903, Learning Rate: 6.95e-05
2025-12-09 17:56:47 - INFO - Epoch: 13.59, Step: 53840, Train Loss: 1.3832, Learning Rate: 6.95e-05
2025-12-09 17:56:58 - INFO - Epoch: 13.60, Step: 53850, Train Loss: 1.3785, Learning Rate: 6.95e-05
2025-12-09 17:57:09 - INFO - Epoch: 13.60, Step: 53860, Train Loss: 1.3721, Learning Rate: 6.95e-05
2025-12-09 17:57:20 - INFO - Epoch: 13.60, Step: 53870, Train Loss: 1.3846, Learning Rate: 6.95e-05
2025-12-09 17:57:31 - INFO - Epoch: 13.60, Step: 53880, Train Loss: 1.4045, Learning Rate: 6.95e-05
2025-12-09 17:57:43 - INFO - Epoch: 13.61, Step: 53890, Train Loss: 1.3827, Learning Rate: 6.95e-05
2025-12-09 17:57:54 - INFO - Epoch: 13.61, Step: 53900, Train Loss: 1.4052, Learning Rate: 6.95e-05
2025-12-09 17:58:05 - INFO - Epoch: 13.61, Step: 53910, Train Loss: 1.3902, Learning Rate: 6.94e-05
2025-12-09 17:58:16 - INFO - Epoch: 13.61, Step: 53920, Train Loss: 1.3493, Learning Rate: 6.94e-05
2025-12-09 17:58:27 - INFO - Epoch: 13.62, Step: 53930, Train Loss: 1.3936, Learning Rate: 6.94e-05
2025-12-09 17:58:38 - INFO - Epoch: 13.62, Step: 53940, Train Loss: 1.3566, Learning Rate: 6.94e-05
2025-12-09 17:58:49 - INFO - Epoch: 13.62, Step: 53950, Train Loss: 1.3536, Learning Rate: 6.94e-05
2025-12-09 17:59:01 - INFO - Epoch: 13.62, Step: 53960, Train Loss: 1.3663, Learning Rate: 6.94e-05
2025-12-09 17:59:12 - INFO - Epoch: 13.63, Step: 53970, Train Loss: 1.3874, Learning Rate: 6.94e-05
2025-12-09 17:59:23 - INFO - Epoch: 13.63, Step: 53980, Train Loss: 1.3604, Learning Rate: 6.94e-05
2025-12-09 17:59:34 - INFO - Epoch: 13.63, Step: 53990, Train Loss: 1.3925, Learning Rate: 6.94e-05
2025-12-09 17:59:45 - INFO - Epoch: 13.63, Step: 54000, Train Loss: 1.3858, Learning Rate: 6.94e-05
2025-12-09 17:59:56 - INFO - Epoch: 13.64, Step: 54010, Train Loss: 1.3395, Learning Rate: 6.94e-05
2025-12-09 18:00:08 - INFO - Epoch: 13.64, Step: 54020, Train Loss: 1.3483, Learning Rate: 6.94e-05
2025-12-09 18:00:19 - INFO - Epoch: 13.64, Step: 54030, Train Loss: 1.3653, Learning Rate: 6.94e-05
2025-12-09 18:00:30 - INFO - Epoch: 13.64, Step: 54040, Train Loss: 1.3749, Learning Rate: 6.94e-05
2025-12-09 18:00:41 - INFO - Epoch: 13.65, Step: 54050, Train Loss: 1.3993, Learning Rate: 6.94e-05
2025-12-09 18:00:52 - INFO - Epoch: 13.65, Step: 54060, Train Loss: 1.3730, Learning Rate: 6.93e-05
2025-12-09 18:01:03 - INFO - Epoch: 13.65, Step: 54070, Train Loss: 1.3432, Learning Rate: 6.93e-05
2025-12-09 18:01:14 - INFO - Epoch: 13.65, Step: 54080, Train Loss: 1.4000, Learning Rate: 6.93e-05
2025-12-09 18:01:26 - INFO - Epoch: 13.66, Step: 54090, Train Loss: 1.4089, Learning Rate: 6.93e-05
2025-12-09 18:01:37 - INFO - Epoch: 13.66, Step: 54100, Train Loss: 1.4101, Learning Rate: 6.93e-05
2025-12-09 18:01:48 - INFO - Epoch: 13.66, Step: 54110, Train Loss: 1.3888, Learning Rate: 6.93e-05
2025-12-09 18:01:59 - INFO - Epoch: 13.66, Step: 54120, Train Loss: 1.3853, Learning Rate: 6.93e-05
2025-12-09 18:02:10 - INFO - Epoch: 13.67, Step: 54130, Train Loss: 1.3993, Learning Rate: 6.93e-05
2025-12-09 18:02:21 - INFO - Epoch: 13.67, Step: 54140, Train Loss: 1.3714, Learning Rate: 6.93e-05
2025-12-09 18:02:33 - INFO - Epoch: 13.67, Step: 54150, Train Loss: 1.3546, Learning Rate: 6.93e-05
2025-12-09 18:02:44 - INFO - Epoch: 13.67, Step: 54160, Train Loss: 1.3794, Learning Rate: 6.93e-05
2025-12-09 18:02:55 - INFO - Epoch: 13.68, Step: 54170, Train Loss: 1.3547, Learning Rate: 6.93e-05
2025-12-09 18:03:06 - INFO - Epoch: 13.68, Step: 54180, Train Loss: 1.3889, Learning Rate: 6.93e-05
2025-12-09 18:03:17 - INFO - Epoch: 13.68, Step: 54190, Train Loss: 1.3616, Learning Rate: 6.93e-05
2025-12-09 18:03:28 - INFO - Epoch: 13.68, Step: 54200, Train Loss: 1.3560, Learning Rate: 6.93e-05
2025-12-09 18:03:39 - INFO - Epoch: 13.69, Step: 54210, Train Loss: 1.3858, Learning Rate: 6.92e-05
2025-12-09 18:03:51 - INFO - Epoch: 13.69, Step: 54220, Train Loss: 1.3897, Learning Rate: 6.92e-05
2025-12-09 18:04:02 - INFO - Epoch: 13.69, Step: 54230, Train Loss: 1.3840, Learning Rate: 6.92e-05
2025-12-09 18:04:13 - INFO - Epoch: 13.69, Step: 54240, Train Loss: 1.3682, Learning Rate: 6.92e-05
2025-12-09 18:04:24 - INFO - Epoch: 13.70, Step: 54250, Train Loss: 1.3647, Learning Rate: 6.92e-05
2025-12-09 18:04:35 - INFO - Epoch: 13.70, Step: 54260, Train Loss: 1.3618, Learning Rate: 6.92e-05
2025-12-09 18:04:46 - INFO - Epoch: 13.70, Step: 54270, Train Loss: 1.3822, Learning Rate: 6.92e-05
2025-12-09 18:04:57 - INFO - Epoch: 13.70, Step: 54280, Train Loss: 1.3242, Learning Rate: 6.92e-05
2025-12-09 18:05:09 - INFO - Epoch: 13.71, Step: 54290, Train Loss: 1.3760, Learning Rate: 6.92e-05
2025-12-09 18:05:20 - INFO - Epoch: 13.71, Step: 54300, Train Loss: 1.3975, Learning Rate: 6.92e-05
2025-12-09 18:05:31 - INFO - Epoch: 13.71, Step: 54310, Train Loss: 1.3749, Learning Rate: 6.92e-05
2025-12-09 18:05:42 - INFO - Epoch: 13.71, Step: 54320, Train Loss: 1.3977, Learning Rate: 6.92e-05
2025-12-09 18:05:53 - INFO - Epoch: 13.72, Step: 54330, Train Loss: 1.3704, Learning Rate: 6.92e-05
2025-12-09 18:06:04 - INFO - Epoch: 13.72, Step: 54340, Train Loss: 1.3902, Learning Rate: 6.92e-05
2025-12-09 18:06:16 - INFO - Epoch: 13.72, Step: 54350, Train Loss: 1.3446, Learning Rate: 6.92e-05
2025-12-09 18:06:27 - INFO - Epoch: 13.72, Step: 54360, Train Loss: 1.3799, Learning Rate: 6.91e-05
2025-12-09 18:06:38 - INFO - Epoch: 13.73, Step: 54370, Train Loss: 1.3806, Learning Rate: 6.91e-05
2025-12-09 18:06:49 - INFO - Epoch: 13.73, Step: 54380, Train Loss: 1.3697, Learning Rate: 6.91e-05
2025-12-09 18:07:00 - INFO - Epoch: 13.73, Step: 54390, Train Loss: 1.3561, Learning Rate: 6.91e-05
2025-12-09 18:07:11 - INFO - Epoch: 13.73, Step: 54400, Train Loss: 1.3399, Learning Rate: 6.91e-05
2025-12-09 18:07:22 - INFO - Epoch: 13.74, Step: 54410, Train Loss: 1.3816, Learning Rate: 6.91e-05
2025-12-09 18:07:34 - INFO - Epoch: 13.74, Step: 54420, Train Loss: 1.3659, Learning Rate: 6.91e-05
2025-12-09 18:07:45 - INFO - Epoch: 13.74, Step: 54430, Train Loss: 1.3621, Learning Rate: 6.91e-05
2025-12-09 18:07:56 - INFO - Epoch: 13.74, Step: 54440, Train Loss: 1.3665, Learning Rate: 6.91e-05
2025-12-09 18:08:07 - INFO - Epoch: 13.75, Step: 54450, Train Loss: 1.3379, Learning Rate: 6.91e-05
2025-12-09 18:08:18 - INFO - Epoch: 13.75, Step: 54460, Train Loss: 1.4033, Learning Rate: 6.91e-05
2025-12-09 18:08:29 - INFO - Epoch: 13.75, Step: 54470, Train Loss: 1.3738, Learning Rate: 6.91e-05
2025-12-09 18:08:41 - INFO - Epoch: 13.75, Step: 54480, Train Loss: 1.3581, Learning Rate: 6.91e-05
2025-12-09 18:08:52 - INFO - Epoch: 13.76, Step: 54490, Train Loss: 1.3707, Learning Rate: 6.91e-05
2025-12-09 18:09:03 - INFO - Epoch: 13.76, Step: 54500, Train Loss: 1.3841, Learning Rate: 6.91e-05
2025-12-09 18:09:14 - INFO - Epoch: 13.76, Step: 54510, Train Loss: 1.3457, Learning Rate: 6.90e-05
2025-12-09 18:09:25 - INFO - Epoch: 13.76, Step: 54520, Train Loss: 1.3787, Learning Rate: 6.90e-05
2025-12-09 18:09:36 - INFO - Epoch: 13.77, Step: 54530, Train Loss: 1.3733, Learning Rate: 6.90e-05
2025-12-09 18:09:47 - INFO - Epoch: 13.77, Step: 54540, Train Loss: 1.3854, Learning Rate: 6.90e-05
2025-12-09 18:09:59 - INFO - Epoch: 13.77, Step: 54550, Train Loss: 1.3704, Learning Rate: 6.90e-05
2025-12-09 18:10:10 - INFO - Epoch: 13.77, Step: 54560, Train Loss: 1.4006, Learning Rate: 6.90e-05
2025-12-09 18:10:21 - INFO - Epoch: 13.78, Step: 54570, Train Loss: 1.3794, Learning Rate: 6.90e-05
2025-12-09 18:10:32 - INFO - Epoch: 13.78, Step: 54580, Train Loss: 1.3691, Learning Rate: 6.90e-05
2025-12-09 18:10:43 - INFO - Epoch: 13.78, Step: 54590, Train Loss: 1.3938, Learning Rate: 6.90e-05
2025-12-09 18:10:54 - INFO - Epoch: 13.78, Step: 54600, Train Loss: 1.3290, Learning Rate: 6.90e-05
2025-12-09 18:11:05 - INFO - Epoch: 13.79, Step: 54610, Train Loss: 1.4028, Learning Rate: 6.90e-05
2025-12-09 18:11:17 - INFO - Epoch: 13.79, Step: 54620, Train Loss: 1.3586, Learning Rate: 6.90e-05
2025-12-09 18:11:28 - INFO - Epoch: 13.79, Step: 54630, Train Loss: 1.3746, Learning Rate: 6.90e-05
2025-12-09 18:11:39 - INFO - Epoch: 13.79, Step: 54640, Train Loss: 1.3612, Learning Rate: 6.90e-05
2025-12-09 18:11:50 - INFO - Epoch: 13.80, Step: 54650, Train Loss: 1.3580, Learning Rate: 6.90e-05
2025-12-09 18:12:01 - INFO - Epoch: 13.80, Step: 54660, Train Loss: 1.4256, Learning Rate: 6.89e-05
2025-12-09 18:12:12 - INFO - Epoch: 13.80, Step: 54670, Train Loss: 1.3582, Learning Rate: 6.89e-05
2025-12-09 18:12:24 - INFO - Epoch: 13.80, Step: 54680, Train Loss: 1.3836, Learning Rate: 6.89e-05
2025-12-09 18:12:35 - INFO - Epoch: 13.81, Step: 54690, Train Loss: 1.3344, Learning Rate: 6.89e-05
2025-12-09 18:12:46 - INFO - Epoch: 13.81, Step: 54700, Train Loss: 1.3788, Learning Rate: 6.89e-05
2025-12-09 18:12:57 - INFO - Epoch: 13.81, Step: 54710, Train Loss: 1.3910, Learning Rate: 6.89e-05
2025-12-09 18:13:08 - INFO - Epoch: 13.81, Step: 54720, Train Loss: 1.3877, Learning Rate: 6.89e-05
2025-12-09 18:13:19 - INFO - Epoch: 13.82, Step: 54730, Train Loss: 1.3748, Learning Rate: 6.89e-05
2025-12-09 18:13:30 - INFO - Epoch: 13.82, Step: 54740, Train Loss: 1.3938, Learning Rate: 6.89e-05
2025-12-09 18:13:42 - INFO - Epoch: 13.82, Step: 54750, Train Loss: 1.3929, Learning Rate: 6.89e-05
2025-12-09 18:13:53 - INFO - Epoch: 13.82, Step: 54760, Train Loss: 1.3654, Learning Rate: 6.89e-05
2025-12-09 18:14:04 - INFO - Epoch: 13.83, Step: 54770, Train Loss: 1.4007, Learning Rate: 6.89e-05
2025-12-09 18:14:15 - INFO - Epoch: 13.83, Step: 54780, Train Loss: 1.3704, Learning Rate: 6.89e-05
2025-12-09 18:14:26 - INFO - Epoch: 13.83, Step: 54790, Train Loss: 1.3742, Learning Rate: 6.89e-05
2025-12-09 18:14:37 - INFO - Epoch: 13.83, Step: 54800, Train Loss: 1.3375, Learning Rate: 6.89e-05
2025-12-09 18:14:49 - INFO - Epoch: 13.84, Step: 54810, Train Loss: 1.3676, Learning Rate: 6.88e-05
2025-12-09 18:15:00 - INFO - Epoch: 13.84, Step: 54820, Train Loss: 1.3901, Learning Rate: 6.88e-05
2025-12-09 18:15:11 - INFO - Epoch: 13.84, Step: 54830, Train Loss: 1.3741, Learning Rate: 6.88e-05
2025-12-09 18:15:22 - INFO - Epoch: 13.84, Step: 54840, Train Loss: 1.3771, Learning Rate: 6.88e-05
2025-12-09 18:15:33 - INFO - Epoch: 13.85, Step: 54850, Train Loss: 1.3700, Learning Rate: 6.88e-05
2025-12-09 18:15:44 - INFO - Epoch: 13.85, Step: 54860, Train Loss: 1.3868, Learning Rate: 6.88e-05
2025-12-09 18:15:55 - INFO - Epoch: 13.85, Step: 54870, Train Loss: 1.4024, Learning Rate: 6.88e-05
2025-12-09 18:16:07 - INFO - Epoch: 13.86, Step: 54880, Train Loss: 1.3744, Learning Rate: 6.88e-05
2025-12-09 18:16:18 - INFO - Epoch: 13.86, Step: 54890, Train Loss: 1.3626, Learning Rate: 6.88e-05
2025-12-09 18:16:29 - INFO - Epoch: 13.86, Step: 54900, Train Loss: 1.3683, Learning Rate: 6.88e-05
2025-12-09 18:16:40 - INFO - Epoch: 13.86, Step: 54910, Train Loss: 1.3285, Learning Rate: 6.88e-05
2025-12-09 18:16:51 - INFO - Epoch: 13.87, Step: 54920, Train Loss: 1.3777, Learning Rate: 6.88e-05
2025-12-09 18:17:02 - INFO - Epoch: 13.87, Step: 54930, Train Loss: 1.3890, Learning Rate: 6.88e-05
2025-12-09 18:17:14 - INFO - Epoch: 13.87, Step: 54940, Train Loss: 1.4118, Learning Rate: 6.88e-05
2025-12-09 18:17:25 - INFO - Epoch: 13.87, Step: 54950, Train Loss: 1.3801, Learning Rate: 6.88e-05
2025-12-09 18:17:36 - INFO - Epoch: 13.88, Step: 54960, Train Loss: 1.3309, Learning Rate: 6.87e-05
2025-12-09 18:17:47 - INFO - Epoch: 13.88, Step: 54970, Train Loss: 1.3643, Learning Rate: 6.87e-05
2025-12-09 18:17:58 - INFO - Epoch: 13.88, Step: 54980, Train Loss: 1.3866, Learning Rate: 6.87e-05
2025-12-09 18:18:09 - INFO - Epoch: 13.88, Step: 54990, Train Loss: 1.3988, Learning Rate: 6.87e-05
2025-12-09 18:18:20 - INFO - Epoch: 13.89, Step: 55000, Train Loss: 1.3440, Learning Rate: 6.87e-05
2025-12-09 18:18:32 - INFO - Epoch: 13.89, Step: 55010, Train Loss: 1.4040, Learning Rate: 6.87e-05
2025-12-09 18:18:43 - INFO - Epoch: 13.89, Step: 55020, Train Loss: 1.3928, Learning Rate: 6.87e-05
2025-12-09 18:18:54 - INFO - Epoch: 13.89, Step: 55030, Train Loss: 1.3840, Learning Rate: 6.87e-05
2025-12-09 18:19:05 - INFO - Epoch: 13.90, Step: 55040, Train Loss: 1.4029, Learning Rate: 6.87e-05
2025-12-09 18:19:16 - INFO - Epoch: 13.90, Step: 55050, Train Loss: 1.3753, Learning Rate: 6.87e-05
2025-12-09 18:19:27 - INFO - Epoch: 13.90, Step: 55060, Train Loss: 1.4318, Learning Rate: 6.87e-05
2025-12-09 18:19:38 - INFO - Epoch: 13.90, Step: 55070, Train Loss: 1.3772, Learning Rate: 6.87e-05
2025-12-09 18:19:50 - INFO - Epoch: 13.91, Step: 55080, Train Loss: 1.3889, Learning Rate: 6.87e-05
2025-12-09 18:20:01 - INFO - Epoch: 13.91, Step: 55090, Train Loss: 1.3752, Learning Rate: 6.87e-05
2025-12-09 18:20:12 - INFO - Epoch: 13.91, Step: 55100, Train Loss: 1.3783, Learning Rate: 6.87e-05
2025-12-09 18:20:23 - INFO - Epoch: 13.91, Step: 55110, Train Loss: 1.3863, Learning Rate: 6.87e-05
2025-12-09 18:20:34 - INFO - Epoch: 13.92, Step: 55120, Train Loss: 1.3844, Learning Rate: 6.86e-05
2025-12-09 18:20:45 - INFO - Epoch: 13.92, Step: 55130, Train Loss: 1.3505, Learning Rate: 6.86e-05
2025-12-09 18:20:57 - INFO - Epoch: 13.92, Step: 55140, Train Loss: 1.3516, Learning Rate: 6.86e-05
2025-12-09 18:21:08 - INFO - Epoch: 13.92, Step: 55150, Train Loss: 1.3630, Learning Rate: 6.86e-05
2025-12-09 18:21:19 - INFO - Epoch: 13.93, Step: 55160, Train Loss: 1.3861, Learning Rate: 6.86e-05
2025-12-09 18:21:30 - INFO - Epoch: 13.93, Step: 55170, Train Loss: 1.3649, Learning Rate: 6.86e-05
2025-12-09 18:21:41 - INFO - Epoch: 13.93, Step: 55180, Train Loss: 1.3906, Learning Rate: 6.86e-05
2025-12-09 18:21:52 - INFO - Epoch: 13.93, Step: 55190, Train Loss: 1.3735, Learning Rate: 6.86e-05
2025-12-09 18:22:03 - INFO - Epoch: 13.94, Step: 55200, Train Loss: 1.3637, Learning Rate: 6.86e-05
2025-12-09 18:22:15 - INFO - Epoch: 13.94, Step: 55210, Train Loss: 1.3720, Learning Rate: 6.86e-05
2025-12-09 18:22:26 - INFO - Epoch: 13.94, Step: 55220, Train Loss: 1.4381, Learning Rate: 6.86e-05
2025-12-09 18:22:37 - INFO - Epoch: 13.94, Step: 55230, Train Loss: 1.3713, Learning Rate: 6.86e-05
2025-12-09 18:22:48 - INFO - Epoch: 13.95, Step: 55240, Train Loss: 1.3951, Learning Rate: 6.86e-05
2025-12-09 18:22:59 - INFO - Epoch: 13.95, Step: 55250, Train Loss: 1.3707, Learning Rate: 6.86e-05
2025-12-09 18:23:10 - INFO - Epoch: 13.95, Step: 55260, Train Loss: 1.3957, Learning Rate: 6.86e-05
2025-12-09 18:23:22 - INFO - Epoch: 13.95, Step: 55270, Train Loss: 1.3540, Learning Rate: 6.85e-05
2025-12-09 18:23:33 - INFO - Epoch: 13.96, Step: 55280, Train Loss: 1.3742, Learning Rate: 6.85e-05
2025-12-09 18:23:44 - INFO - Epoch: 13.96, Step: 55290, Train Loss: 1.3663, Learning Rate: 6.85e-05
2025-12-09 18:23:55 - INFO - Epoch: 13.96, Step: 55300, Train Loss: 1.3453, Learning Rate: 6.85e-05
2025-12-09 18:24:06 - INFO - Epoch: 13.96, Step: 55310, Train Loss: 1.3311, Learning Rate: 6.85e-05
2025-12-09 18:24:17 - INFO - Epoch: 13.97, Step: 55320, Train Loss: 1.4187, Learning Rate: 6.85e-05
2025-12-09 18:24:28 - INFO - Epoch: 13.97, Step: 55330, Train Loss: 1.3921, Learning Rate: 6.85e-05
2025-12-09 18:24:40 - INFO - Epoch: 13.97, Step: 55340, Train Loss: 1.3689, Learning Rate: 6.85e-05
2025-12-09 18:24:51 - INFO - Epoch: 13.97, Step: 55350, Train Loss: 1.4260, Learning Rate: 6.85e-05
2025-12-09 18:25:02 - INFO - Epoch: 13.98, Step: 55360, Train Loss: 1.3585, Learning Rate: 6.85e-05
2025-12-09 18:25:13 - INFO - Epoch: 13.98, Step: 55370, Train Loss: 1.4006, Learning Rate: 6.85e-05
2025-12-09 18:25:24 - INFO - Epoch: 13.98, Step: 55380, Train Loss: 1.4015, Learning Rate: 6.85e-05
2025-12-09 18:25:35 - INFO - Epoch: 13.98, Step: 55390, Train Loss: 1.3612, Learning Rate: 6.85e-05
2025-12-09 18:25:47 - INFO - Epoch: 13.99, Step: 55400, Train Loss: 1.3623, Learning Rate: 6.85e-05
2025-12-09 18:25:58 - INFO - Epoch: 13.99, Step: 55410, Train Loss: 1.3755, Learning Rate: 6.85e-05
2025-12-09 18:26:09 - INFO - Epoch: 13.99, Step: 55420, Train Loss: 1.3599, Learning Rate: 6.84e-05
2025-12-09 18:26:20 - INFO - Epoch: 13.99, Step: 55430, Train Loss: 1.4063, Learning Rate: 6.84e-05
2025-12-09 18:26:31 - INFO - Epoch: 14.00, Step: 55440, Train Loss: 1.3756, Learning Rate: 6.84e-05
2025-12-09 18:26:42 - INFO - Epoch: 14.00, Step: 55450, Train Loss: 1.3651, Learning Rate: 6.84e-05
2025-12-09 18:26:53 - INFO - Epoch: 14.00, Step: 55460, Train Loss: 1.3935, Learning Rate: 6.84e-05
2025-12-09 18:27:05 - INFO - Epoch: 14.00, Step: 55470, Train Loss: 1.3268, Learning Rate: 6.84e-05
2025-12-09 18:27:16 - INFO - Epoch: 14.01, Step: 55480, Train Loss: 1.3861, Learning Rate: 6.84e-05
2025-12-09 18:27:27 - INFO - Epoch: 14.01, Step: 55490, Train Loss: 1.3883, Learning Rate: 6.84e-05
2025-12-09 18:27:38 - INFO - Epoch: 14.01, Step: 55500, Train Loss: 1.3372, Learning Rate: 6.84e-05
2025-12-09 18:27:49 - INFO - Epoch: 14.01, Step: 55510, Train Loss: 1.3761, Learning Rate: 6.84e-05
2025-12-09 18:28:00 - INFO - Epoch: 14.02, Step: 55520, Train Loss: 1.3781, Learning Rate: 6.84e-05
2025-12-09 18:28:12 - INFO - Epoch: 14.02, Step: 55530, Train Loss: 1.4005, Learning Rate: 6.84e-05
2025-12-09 18:28:23 - INFO - Epoch: 14.02, Step: 55540, Train Loss: 1.3758, Learning Rate: 6.84e-05
2025-12-09 18:28:34 - INFO - Epoch: 14.02, Step: 55550, Train Loss: 1.3406, Learning Rate: 6.84e-05
2025-12-09 18:28:45 - INFO - Epoch: 14.03, Step: 55560, Train Loss: 1.3961, Learning Rate: 6.84e-05
2025-12-09 18:28:56 - INFO - Epoch: 14.03, Step: 55570, Train Loss: 1.3406, Learning Rate: 6.83e-05
2025-12-09 18:29:07 - INFO - Epoch: 14.03, Step: 55580, Train Loss: 1.3589, Learning Rate: 6.83e-05
2025-12-09 18:29:18 - INFO - Epoch: 14.03, Step: 55590, Train Loss: 1.3888, Learning Rate: 6.83e-05
2025-12-09 18:29:30 - INFO - Epoch: 14.04, Step: 55600, Train Loss: 1.3445, Learning Rate: 6.83e-05
2025-12-09 18:29:41 - INFO - Epoch: 14.04, Step: 55610, Train Loss: 1.4122, Learning Rate: 6.83e-05
2025-12-09 18:29:52 - INFO - Epoch: 14.04, Step: 55620, Train Loss: 1.3541, Learning Rate: 6.83e-05
2025-12-09 18:30:03 - INFO - Epoch: 14.04, Step: 55630, Train Loss: 1.3715, Learning Rate: 6.83e-05
2025-12-09 18:30:14 - INFO - Epoch: 14.05, Step: 55640, Train Loss: 1.3751, Learning Rate: 6.83e-05
2025-12-09 18:30:25 - INFO - Epoch: 14.05, Step: 55650, Train Loss: 1.3805, Learning Rate: 6.83e-05
2025-12-09 18:30:37 - INFO - Epoch: 14.05, Step: 55660, Train Loss: 1.3736, Learning Rate: 6.83e-05
2025-12-09 18:30:48 - INFO - Epoch: 14.05, Step: 55670, Train Loss: 1.3954, Learning Rate: 6.83e-05
2025-12-09 18:30:59 - INFO - Epoch: 14.06, Step: 55680, Train Loss: 1.3236, Learning Rate: 6.83e-05
2025-12-09 18:31:10 - INFO - Epoch: 14.06, Step: 55690, Train Loss: 1.3934, Learning Rate: 6.83e-05
2025-12-09 18:31:21 - INFO - Epoch: 14.06, Step: 55700, Train Loss: 1.3742, Learning Rate: 6.83e-05
2025-12-09 18:31:32 - INFO - Epoch: 14.06, Step: 55710, Train Loss: 1.3129, Learning Rate: 6.83e-05
2025-12-09 18:31:43 - INFO - Epoch: 14.07, Step: 55720, Train Loss: 1.4068, Learning Rate: 6.82e-05
2025-12-09 18:31:55 - INFO - Epoch: 14.07, Step: 55730, Train Loss: 1.3690, Learning Rate: 6.82e-05
2025-12-09 18:32:06 - INFO - Epoch: 14.07, Step: 55740, Train Loss: 1.3619, Learning Rate: 6.82e-05
2025-12-09 18:32:17 - INFO - Epoch: 14.07, Step: 55750, Train Loss: 1.3432, Learning Rate: 6.82e-05
2025-12-09 18:32:28 - INFO - Epoch: 14.08, Step: 55760, Train Loss: 1.3293, Learning Rate: 6.82e-05
2025-12-09 18:32:39 - INFO - Epoch: 14.08, Step: 55770, Train Loss: 1.3971, Learning Rate: 6.82e-05
2025-12-09 18:32:50 - INFO - Epoch: 14.08, Step: 55780, Train Loss: 1.3857, Learning Rate: 6.82e-05
2025-12-09 18:33:02 - INFO - Epoch: 14.08, Step: 55790, Train Loss: 1.3964, Learning Rate: 6.82e-05
2025-12-09 18:33:13 - INFO - Epoch: 14.09, Step: 55800, Train Loss: 1.4109, Learning Rate: 6.82e-05
2025-12-09 18:33:24 - INFO - Epoch: 14.09, Step: 55810, Train Loss: 1.3841, Learning Rate: 6.82e-05
2025-12-09 18:33:35 - INFO - Epoch: 14.09, Step: 55820, Train Loss: 1.3578, Learning Rate: 6.82e-05
2025-12-09 18:33:46 - INFO - Epoch: 14.09, Step: 55830, Train Loss: 1.3649, Learning Rate: 6.82e-05
2025-12-09 18:33:57 - INFO - Epoch: 14.10, Step: 55840, Train Loss: 1.3464, Learning Rate: 6.82e-05
2025-12-09 18:34:08 - INFO - Epoch: 14.10, Step: 55850, Train Loss: 1.4195, Learning Rate: 6.82e-05
2025-12-09 18:34:20 - INFO - Epoch: 14.10, Step: 55860, Train Loss: 1.3748, Learning Rate: 6.82e-05
2025-12-09 18:34:31 - INFO - Epoch: 14.11, Step: 55870, Train Loss: 1.3933, Learning Rate: 6.81e-05
2025-12-09 18:34:42 - INFO - Epoch: 14.11, Step: 55880, Train Loss: 1.3516, Learning Rate: 6.81e-05
2025-12-09 18:34:53 - INFO - Epoch: 14.11, Step: 55890, Train Loss: 1.3666, Learning Rate: 6.81e-05
2025-12-09 18:35:04 - INFO - Epoch: 14.11, Step: 55900, Train Loss: 1.3600, Learning Rate: 6.81e-05
2025-12-09 18:35:15 - INFO - Epoch: 14.12, Step: 55910, Train Loss: 1.3298, Learning Rate: 6.81e-05
2025-12-09 18:35:27 - INFO - Epoch: 14.12, Step: 55920, Train Loss: 1.3748, Learning Rate: 6.81e-05
2025-12-09 18:35:38 - INFO - Epoch: 14.12, Step: 55930, Train Loss: 1.3433, Learning Rate: 6.81e-05
2025-12-09 18:35:49 - INFO - Epoch: 14.12, Step: 55940, Train Loss: 1.3499, Learning Rate: 6.81e-05
2025-12-09 18:36:00 - INFO - Epoch: 14.13, Step: 55950, Train Loss: 1.3669, Learning Rate: 6.81e-05
2025-12-09 18:36:11 - INFO - Epoch: 14.13, Step: 55960, Train Loss: 1.3253, Learning Rate: 6.81e-05
2025-12-09 18:36:22 - INFO - Epoch: 14.13, Step: 55970, Train Loss: 1.3627, Learning Rate: 6.81e-05
2025-12-09 18:36:33 - INFO - Epoch: 14.13, Step: 55980, Train Loss: 1.3781, Learning Rate: 6.81e-05
2025-12-09 18:36:45 - INFO - Epoch: 14.14, Step: 55990, Train Loss: 1.3606, Learning Rate: 6.81e-05
2025-12-09 18:36:56 - INFO - Epoch: 14.14, Step: 56000, Train Loss: 1.3635, Learning Rate: 6.81e-05
2025-12-09 18:37:07 - INFO - Epoch: 14.14, Step: 56010, Train Loss: 1.3611, Learning Rate: 6.81e-05
2025-12-09 18:37:18 - INFO - Epoch: 14.14, Step: 56020, Train Loss: 1.3677, Learning Rate: 6.80e-05
2025-12-09 18:37:29 - INFO - Epoch: 14.15, Step: 56030, Train Loss: 1.3739, Learning Rate: 6.80e-05
2025-12-09 18:37:40 - INFO - Epoch: 14.15, Step: 56040, Train Loss: 1.3856, Learning Rate: 6.80e-05
2025-12-09 18:37:52 - INFO - Epoch: 14.15, Step: 56050, Train Loss: 1.3537, Learning Rate: 6.80e-05
2025-12-09 18:38:03 - INFO - Epoch: 14.15, Step: 56060, Train Loss: 1.3485, Learning Rate: 6.80e-05
2025-12-09 18:38:14 - INFO - Epoch: 14.16, Step: 56070, Train Loss: 1.3422, Learning Rate: 6.80e-05
2025-12-09 18:38:25 - INFO - Epoch: 14.16, Step: 56080, Train Loss: 1.3655, Learning Rate: 6.80e-05
2025-12-09 18:38:36 - INFO - Epoch: 14.16, Step: 56090, Train Loss: 1.3495, Learning Rate: 6.80e-05
2025-12-09 18:38:47 - INFO - Epoch: 14.16, Step: 56100, Train Loss: 1.3458, Learning Rate: 6.80e-05
2025-12-09 18:38:58 - INFO - Epoch: 14.17, Step: 56110, Train Loss: 1.3734, Learning Rate: 6.80e-05
2025-12-09 18:39:10 - INFO - Epoch: 14.17, Step: 56120, Train Loss: 1.3564, Learning Rate: 6.80e-05
2025-12-09 18:39:21 - INFO - Epoch: 14.17, Step: 56130, Train Loss: 1.3261, Learning Rate: 6.80e-05
2025-12-09 18:39:32 - INFO - Epoch: 14.17, Step: 56140, Train Loss: 1.3615, Learning Rate: 6.80e-05
2025-12-09 18:39:43 - INFO - Epoch: 14.18, Step: 56150, Train Loss: 1.3747, Learning Rate: 6.80e-05
2025-12-09 18:39:54 - INFO - Epoch: 14.18, Step: 56160, Train Loss: 1.3474, Learning Rate: 6.80e-05
2025-12-09 18:40:05 - INFO - Epoch: 14.18, Step: 56170, Train Loss: 1.3797, Learning Rate: 6.79e-05
2025-12-09 18:40:17 - INFO - Epoch: 14.18, Step: 56180, Train Loss: 1.3833, Learning Rate: 6.79e-05
2025-12-09 18:40:28 - INFO - Epoch: 14.19, Step: 56190, Train Loss: 1.3641, Learning Rate: 6.79e-05
2025-12-09 18:40:39 - INFO - Epoch: 14.19, Step: 56200, Train Loss: 1.3124, Learning Rate: 6.79e-05
2025-12-09 18:40:50 - INFO - Epoch: 14.19, Step: 56210, Train Loss: 1.3871, Learning Rate: 6.79e-05
2025-12-09 18:41:01 - INFO - Epoch: 14.19, Step: 56220, Train Loss: 1.4010, Learning Rate: 6.79e-05
2025-12-09 18:41:12 - INFO - Epoch: 14.20, Step: 56230, Train Loss: 1.3738, Learning Rate: 6.79e-05
2025-12-09 18:41:24 - INFO - Epoch: 14.20, Step: 56240, Train Loss: 1.3594, Learning Rate: 6.79e-05
2025-12-09 18:41:35 - INFO - Epoch: 14.20, Step: 56250, Train Loss: 1.3336, Learning Rate: 6.79e-05
2025-12-09 18:41:46 - INFO - Epoch: 14.20, Step: 56260, Train Loss: 1.3203, Learning Rate: 6.79e-05
2025-12-09 18:41:57 - INFO - Epoch: 14.21, Step: 56270, Train Loss: 1.3767, Learning Rate: 6.79e-05
2025-12-09 18:42:08 - INFO - Epoch: 14.21, Step: 56280, Train Loss: 1.3882, Learning Rate: 6.79e-05
2025-12-09 18:42:19 - INFO - Epoch: 14.21, Step: 56290, Train Loss: 1.3991, Learning Rate: 6.79e-05
2025-12-09 18:42:30 - INFO - Epoch: 14.21, Step: 56300, Train Loss: 1.3954, Learning Rate: 6.79e-05
2025-12-09 18:42:42 - INFO - Epoch: 14.22, Step: 56310, Train Loss: 1.3445, Learning Rate: 6.79e-05
2025-12-09 18:42:53 - INFO - Epoch: 14.22, Step: 56320, Train Loss: 1.3507, Learning Rate: 6.78e-05
2025-12-09 18:43:04 - INFO - Epoch: 14.22, Step: 56330, Train Loss: 1.3940, Learning Rate: 6.78e-05
2025-12-09 18:43:15 - INFO - Epoch: 14.22, Step: 56340, Train Loss: 1.3704, Learning Rate: 6.78e-05
2025-12-09 18:43:26 - INFO - Epoch: 14.23, Step: 56350, Train Loss: 1.4059, Learning Rate: 6.78e-05
2025-12-09 18:43:37 - INFO - Epoch: 14.23, Step: 56360, Train Loss: 1.3635, Learning Rate: 6.78e-05
2025-12-09 18:43:49 - INFO - Epoch: 14.23, Step: 56370, Train Loss: 1.3623, Learning Rate: 6.78e-05
2025-12-09 18:44:00 - INFO - Epoch: 14.23, Step: 56380, Train Loss: 1.3701, Learning Rate: 6.78e-05
2025-12-09 18:44:11 - INFO - Epoch: 14.24, Step: 56390, Train Loss: 1.3679, Learning Rate: 6.78e-05
2025-12-09 18:44:22 - INFO - Epoch: 14.24, Step: 56400, Train Loss: 1.3706, Learning Rate: 6.78e-05
2025-12-09 18:44:33 - INFO - Epoch: 14.24, Step: 56410, Train Loss: 1.3425, Learning Rate: 6.78e-05
2025-12-09 18:44:44 - INFO - Epoch: 14.24, Step: 56420, Train Loss: 1.3476, Learning Rate: 6.78e-05
2025-12-09 18:44:55 - INFO - Epoch: 14.25, Step: 56430, Train Loss: 1.3349, Learning Rate: 6.78e-05
2025-12-09 18:45:07 - INFO - Epoch: 14.25, Step: 56440, Train Loss: 1.3369, Learning Rate: 6.78e-05
2025-12-09 18:45:18 - INFO - Epoch: 14.25, Step: 56450, Train Loss: 1.3688, Learning Rate: 6.78e-05
2025-12-09 18:45:29 - INFO - Epoch: 14.25, Step: 56460, Train Loss: 1.3936, Learning Rate: 6.78e-05
2025-12-09 18:45:40 - INFO - Epoch: 14.26, Step: 56470, Train Loss: 1.3733, Learning Rate: 6.77e-05
2025-12-09 18:45:51 - INFO - Epoch: 14.26, Step: 56480, Train Loss: 1.3596, Learning Rate: 6.77e-05
2025-12-09 18:46:02 - INFO - Epoch: 14.26, Step: 56490, Train Loss: 1.3595, Learning Rate: 6.77e-05
2025-12-09 18:46:14 - INFO - Epoch: 14.26, Step: 56500, Train Loss: 1.3458, Learning Rate: 6.77e-05
2025-12-09 18:46:25 - INFO - Epoch: 14.27, Step: 56510, Train Loss: 1.4293, Learning Rate: 6.77e-05
2025-12-09 18:46:36 - INFO - Epoch: 14.27, Step: 56520, Train Loss: 1.3683, Learning Rate: 6.77e-05
2025-12-09 18:46:47 - INFO - Epoch: 14.27, Step: 56530, Train Loss: 1.3550, Learning Rate: 6.77e-05
2025-12-09 18:46:58 - INFO - Epoch: 14.27, Step: 56540, Train Loss: 1.3748, Learning Rate: 6.77e-05
2025-12-09 18:47:09 - INFO - Epoch: 14.28, Step: 56550, Train Loss: 1.4082, Learning Rate: 6.77e-05
2025-12-09 18:47:20 - INFO - Epoch: 14.28, Step: 56560, Train Loss: 1.3703, Learning Rate: 6.77e-05
2025-12-09 18:47:32 - INFO - Epoch: 14.28, Step: 56570, Train Loss: 1.3294, Learning Rate: 6.77e-05
2025-12-09 18:47:43 - INFO - Epoch: 14.28, Step: 56580, Train Loss: 1.3569, Learning Rate: 6.77e-05
2025-12-09 18:47:54 - INFO - Epoch: 14.29, Step: 56590, Train Loss: 1.3361, Learning Rate: 6.77e-05
2025-12-09 18:48:05 - INFO - Epoch: 14.29, Step: 56600, Train Loss: 1.3762, Learning Rate: 6.77e-05
2025-12-09 18:48:16 - INFO - Epoch: 14.29, Step: 56610, Train Loss: 1.3360, Learning Rate: 6.77e-05
2025-12-09 18:48:27 - INFO - Epoch: 14.29, Step: 56620, Train Loss: 1.3925, Learning Rate: 6.76e-05
2025-12-09 18:48:39 - INFO - Epoch: 14.30, Step: 56630, Train Loss: 1.3612, Learning Rate: 6.76e-05
2025-12-09 18:48:50 - INFO - Epoch: 14.30, Step: 56640, Train Loss: 1.3936, Learning Rate: 6.76e-05
2025-12-09 18:49:01 - INFO - Epoch: 14.30, Step: 56650, Train Loss: 1.4179, Learning Rate: 6.76e-05
2025-12-09 18:49:12 - INFO - Epoch: 14.30, Step: 56660, Train Loss: 1.3818, Learning Rate: 6.76e-05
2025-12-09 18:49:23 - INFO - Epoch: 14.31, Step: 56670, Train Loss: 1.3433, Learning Rate: 6.76e-05
2025-12-09 18:49:34 - INFO - Epoch: 14.31, Step: 56680, Train Loss: 1.3598, Learning Rate: 6.76e-05
2025-12-09 18:49:45 - INFO - Epoch: 14.31, Step: 56690, Train Loss: 1.3265, Learning Rate: 6.76e-05
2025-12-09 18:49:57 - INFO - Epoch: 14.31, Step: 56700, Train Loss: 1.3776, Learning Rate: 6.76e-05
2025-12-09 18:50:08 - INFO - Epoch: 14.32, Step: 56710, Train Loss: 1.3472, Learning Rate: 6.76e-05
2025-12-09 18:50:19 - INFO - Epoch: 14.32, Step: 56720, Train Loss: 1.3914, Learning Rate: 6.76e-05
2025-12-09 18:50:30 - INFO - Epoch: 14.32, Step: 56730, Train Loss: 1.3810, Learning Rate: 6.76e-05
2025-12-09 18:50:41 - INFO - Epoch: 14.32, Step: 56740, Train Loss: 1.3890, Learning Rate: 6.76e-05
2025-12-09 18:50:52 - INFO - Epoch: 14.33, Step: 56750, Train Loss: 1.3558, Learning Rate: 6.76e-05
2025-12-09 18:51:04 - INFO - Epoch: 14.33, Step: 56760, Train Loss: 1.3555, Learning Rate: 6.76e-05
2025-12-09 18:51:15 - INFO - Epoch: 14.33, Step: 56770, Train Loss: 1.3706, Learning Rate: 6.75e-05
2025-12-09 18:51:26 - INFO - Epoch: 14.33, Step: 56780, Train Loss: 1.3625, Learning Rate: 6.75e-05
2025-12-09 18:51:37 - INFO - Epoch: 14.34, Step: 56790, Train Loss: 1.3414, Learning Rate: 6.75e-05
2025-12-09 18:51:48 - INFO - Epoch: 14.34, Step: 56800, Train Loss: 1.3838, Learning Rate: 6.75e-05
2025-12-09 18:51:59 - INFO - Epoch: 14.34, Step: 56810, Train Loss: 1.3005, Learning Rate: 6.75e-05
2025-12-09 18:52:10 - INFO - Epoch: 14.34, Step: 56820, Train Loss: 1.3677, Learning Rate: 6.75e-05
2025-12-09 18:52:22 - INFO - Epoch: 14.35, Step: 56830, Train Loss: 1.3270, Learning Rate: 6.75e-05
2025-12-09 18:52:33 - INFO - Epoch: 14.35, Step: 56840, Train Loss: 1.3479, Learning Rate: 6.75e-05
2025-12-09 18:52:44 - INFO - Epoch: 14.35, Step: 56850, Train Loss: 1.3962, Learning Rate: 6.75e-05
2025-12-09 18:52:55 - INFO - Epoch: 14.35, Step: 56860, Train Loss: 1.3376, Learning Rate: 6.75e-05
2025-12-09 18:53:06 - INFO - Epoch: 14.36, Step: 56870, Train Loss: 1.3727, Learning Rate: 6.75e-05
2025-12-09 18:53:17 - INFO - Epoch: 14.36, Step: 56880, Train Loss: 1.3731, Learning Rate: 6.75e-05
2025-12-09 18:53:29 - INFO - Epoch: 14.36, Step: 56890, Train Loss: 1.3216, Learning Rate: 6.75e-05
2025-12-09 18:53:40 - INFO - Epoch: 14.37, Step: 56900, Train Loss: 1.3736, Learning Rate: 6.75e-05
2025-12-09 18:53:51 - INFO - Epoch: 14.37, Step: 56910, Train Loss: 1.3245, Learning Rate: 6.75e-05
2025-12-09 18:54:02 - INFO - Epoch: 14.37, Step: 56920, Train Loss: 1.3926, Learning Rate: 6.74e-05
2025-12-09 18:54:13 - INFO - Epoch: 14.37, Step: 56930, Train Loss: 1.3868, Learning Rate: 6.74e-05
2025-12-09 18:54:24 - INFO - Epoch: 14.38, Step: 56940, Train Loss: 1.3666, Learning Rate: 6.74e-05
2025-12-09 18:54:35 - INFO - Epoch: 14.38, Step: 56950, Train Loss: 1.3574, Learning Rate: 6.74e-05
2025-12-09 18:54:47 - INFO - Epoch: 14.38, Step: 56960, Train Loss: 1.3516, Learning Rate: 6.74e-05
2025-12-09 18:54:58 - INFO - Epoch: 14.38, Step: 56970, Train Loss: 1.3131, Learning Rate: 6.74e-05
2025-12-09 18:55:09 - INFO - Epoch: 14.39, Step: 56980, Train Loss: 1.3690, Learning Rate: 6.74e-05
2025-12-09 18:55:20 - INFO - Epoch: 14.39, Step: 56990, Train Loss: 1.3441, Learning Rate: 6.74e-05
2025-12-09 18:55:31 - INFO - Epoch: 14.39, Step: 57000, Train Loss: 1.3625, Learning Rate: 6.74e-05
2025-12-09 18:55:42 - INFO - Epoch: 14.39, Step: 57010, Train Loss: 1.3319, Learning Rate: 6.74e-05
2025-12-09 18:55:54 - INFO - Epoch: 14.40, Step: 57020, Train Loss: 1.3553, Learning Rate: 6.74e-05
2025-12-09 18:56:05 - INFO - Epoch: 14.40, Step: 57030, Train Loss: 1.3862, Learning Rate: 6.74e-05
2025-12-09 18:56:16 - INFO - Epoch: 14.40, Step: 57040, Train Loss: 1.3474, Learning Rate: 6.74e-05
2025-12-09 18:56:27 - INFO - Epoch: 14.40, Step: 57050, Train Loss: 1.3672, Learning Rate: 6.74e-05
2025-12-09 18:56:38 - INFO - Epoch: 14.41, Step: 57060, Train Loss: 1.3519, Learning Rate: 6.74e-05
2025-12-09 18:56:49 - INFO - Epoch: 14.41, Step: 57070, Train Loss: 1.3657, Learning Rate: 6.73e-05
2025-12-09 18:57:01 - INFO - Epoch: 14.41, Step: 57080, Train Loss: 1.3673, Learning Rate: 6.73e-05
2025-12-09 18:57:12 - INFO - Epoch: 14.41, Step: 57090, Train Loss: 1.3242, Learning Rate: 6.73e-05
2025-12-09 18:57:23 - INFO - Epoch: 14.42, Step: 57100, Train Loss: 1.3643, Learning Rate: 6.73e-05
2025-12-09 18:57:34 - INFO - Epoch: 14.42, Step: 57110, Train Loss: 1.3177, Learning Rate: 6.73e-05
2025-12-09 18:57:45 - INFO - Epoch: 14.42, Step: 57120, Train Loss: 1.3699, Learning Rate: 6.73e-05
2025-12-09 18:57:56 - INFO - Epoch: 14.42, Step: 57130, Train Loss: 1.3472, Learning Rate: 6.73e-05
2025-12-09 18:58:07 - INFO - Epoch: 14.43, Step: 57140, Train Loss: 1.3561, Learning Rate: 6.73e-05
2025-12-09 18:58:19 - INFO - Epoch: 14.43, Step: 57150, Train Loss: 1.3643, Learning Rate: 6.73e-05
2025-12-09 18:58:30 - INFO - Epoch: 14.43, Step: 57160, Train Loss: 1.3851, Learning Rate: 6.73e-05
2025-12-09 18:58:41 - INFO - Epoch: 14.43, Step: 57170, Train Loss: 1.3815, Learning Rate: 6.73e-05
2025-12-09 18:58:52 - INFO - Epoch: 14.44, Step: 57180, Train Loss: 1.3734, Learning Rate: 6.73e-05
2025-12-09 18:59:03 - INFO - Epoch: 14.44, Step: 57190, Train Loss: 1.3567, Learning Rate: 6.73e-05
2025-12-09 18:59:14 - INFO - Epoch: 14.44, Step: 57200, Train Loss: 1.3834, Learning Rate: 6.73e-05
2025-12-09 18:59:26 - INFO - Epoch: 14.44, Step: 57210, Train Loss: 1.3155, Learning Rate: 6.73e-05
2025-12-09 18:59:37 - INFO - Epoch: 14.45, Step: 57220, Train Loss: 1.3529, Learning Rate: 6.72e-05
2025-12-09 18:59:48 - INFO - Epoch: 14.45, Step: 57230, Train Loss: 1.3820, Learning Rate: 6.72e-05
2025-12-09 18:59:59 - INFO - Epoch: 14.45, Step: 57240, Train Loss: 1.3945, Learning Rate: 6.72e-05
2025-12-09 19:00:10 - INFO - Epoch: 14.45, Step: 57250, Train Loss: 1.3660, Learning Rate: 6.72e-05
2025-12-09 19:00:21 - INFO - Epoch: 14.46, Step: 57260, Train Loss: 1.3713, Learning Rate: 6.72e-05
2025-12-09 19:00:32 - INFO - Epoch: 14.46, Step: 57270, Train Loss: 1.3770, Learning Rate: 6.72e-05
2025-12-09 19:00:44 - INFO - Epoch: 14.46, Step: 57280, Train Loss: 1.3600, Learning Rate: 6.72e-05
2025-12-09 19:00:55 - INFO - Epoch: 14.46, Step: 57290, Train Loss: 1.3662, Learning Rate: 6.72e-05
2025-12-09 19:01:06 - INFO - Epoch: 14.47, Step: 57300, Train Loss: 1.4129, Learning Rate: 6.72e-05
2025-12-09 19:01:17 - INFO - Epoch: 14.47, Step: 57310, Train Loss: 1.4140, Learning Rate: 6.72e-05
2025-12-09 19:01:28 - INFO - Epoch: 14.47, Step: 57320, Train Loss: 1.3534, Learning Rate: 6.72e-05
2025-12-09 19:01:39 - INFO - Epoch: 14.47, Step: 57330, Train Loss: 1.3566, Learning Rate: 6.72e-05
2025-12-09 19:01:51 - INFO - Epoch: 14.48, Step: 57340, Train Loss: 1.3977, Learning Rate: 6.72e-05
2025-12-09 19:02:02 - INFO - Epoch: 14.48, Step: 57350, Train Loss: 1.3625, Learning Rate: 6.72e-05
2025-12-09 19:02:13 - INFO - Epoch: 14.48, Step: 57360, Train Loss: 1.3889, Learning Rate: 6.72e-05
2025-12-09 19:02:24 - INFO - Epoch: 14.48, Step: 57370, Train Loss: 1.3551, Learning Rate: 6.71e-05
2025-12-09 19:02:35 - INFO - Epoch: 14.49, Step: 57380, Train Loss: 1.3388, Learning Rate: 6.71e-05
2025-12-09 19:02:46 - INFO - Epoch: 14.49, Step: 57390, Train Loss: 1.3841, Learning Rate: 6.71e-05
2025-12-09 19:02:57 - INFO - Epoch: 14.49, Step: 57400, Train Loss: 1.3199, Learning Rate: 6.71e-05
2025-12-09 19:03:09 - INFO - Epoch: 14.49, Step: 57410, Train Loss: 1.3853, Learning Rate: 6.71e-05
2025-12-09 19:03:20 - INFO - Epoch: 14.50, Step: 57420, Train Loss: 1.3916, Learning Rate: 6.71e-05
2025-12-09 19:03:31 - INFO - Epoch: 14.50, Step: 57430, Train Loss: 1.3855, Learning Rate: 6.71e-05
2025-12-09 19:03:42 - INFO - Epoch: 14.50, Step: 57440, Train Loss: 1.3621, Learning Rate: 6.71e-05
2025-12-09 19:03:53 - INFO - Epoch: 14.50, Step: 57450, Train Loss: 1.3354, Learning Rate: 6.71e-05
2025-12-09 19:04:04 - INFO - Epoch: 14.51, Step: 57460, Train Loss: 1.3581, Learning Rate: 6.71e-05
2025-12-09 19:04:16 - INFO - Epoch: 14.51, Step: 57470, Train Loss: 1.3380, Learning Rate: 6.71e-05
2025-12-09 19:04:27 - INFO - Epoch: 14.51, Step: 57480, Train Loss: 1.3417, Learning Rate: 6.71e-05
2025-12-09 19:04:38 - INFO - Epoch: 14.51, Step: 57490, Train Loss: 1.3577, Learning Rate: 6.71e-05
2025-12-09 19:04:49 - INFO - Epoch: 14.52, Step: 57500, Train Loss: 1.4173, Learning Rate: 6.71e-05
2025-12-09 19:05:00 - INFO - Epoch: 14.52, Step: 57510, Train Loss: 1.3909, Learning Rate: 6.71e-05
2025-12-09 19:05:11 - INFO - Epoch: 14.52, Step: 57520, Train Loss: 1.3558, Learning Rate: 6.70e-05
2025-12-09 19:05:22 - INFO - Epoch: 14.52, Step: 57530, Train Loss: 1.3670, Learning Rate: 6.70e-05
2025-12-09 19:05:34 - INFO - Epoch: 14.53, Step: 57540, Train Loss: 1.3466, Learning Rate: 6.70e-05
2025-12-09 19:05:45 - INFO - Epoch: 14.53, Step: 57550, Train Loss: 1.3540, Learning Rate: 6.70e-05
2025-12-09 19:05:56 - INFO - Epoch: 14.53, Step: 57560, Train Loss: 1.4001, Learning Rate: 6.70e-05
2025-12-09 19:06:07 - INFO - Epoch: 14.53, Step: 57570, Train Loss: 1.3956, Learning Rate: 6.70e-05
2025-12-09 19:06:18 - INFO - Epoch: 14.54, Step: 57580, Train Loss: 1.3777, Learning Rate: 6.70e-05
2025-12-09 19:06:29 - INFO - Epoch: 14.54, Step: 57590, Train Loss: 1.3401, Learning Rate: 6.70e-05
2025-12-09 19:06:41 - INFO - Epoch: 14.54, Step: 57600, Train Loss: 1.3475, Learning Rate: 6.70e-05
2025-12-09 19:06:52 - INFO - Epoch: 14.54, Step: 57610, Train Loss: 1.3631, Learning Rate: 6.70e-05
2025-12-09 19:07:03 - INFO - Epoch: 14.55, Step: 57620, Train Loss: 1.3720, Learning Rate: 6.70e-05
2025-12-09 19:07:14 - INFO - Epoch: 14.55, Step: 57630, Train Loss: 1.3482, Learning Rate: 6.70e-05
2025-12-09 19:07:25 - INFO - Epoch: 14.55, Step: 57640, Train Loss: 1.3226, Learning Rate: 6.70e-05
2025-12-09 19:07:36 - INFO - Epoch: 14.55, Step: 57650, Train Loss: 1.4036, Learning Rate: 6.70e-05
2025-12-09 19:07:47 - INFO - Epoch: 14.56, Step: 57660, Train Loss: 1.3498, Learning Rate: 6.70e-05
2025-12-09 19:07:59 - INFO - Epoch: 14.56, Step: 57670, Train Loss: 1.4059, Learning Rate: 6.69e-05
2025-12-09 19:08:10 - INFO - Epoch: 14.56, Step: 57680, Train Loss: 1.3762, Learning Rate: 6.69e-05
2025-12-09 19:08:21 - INFO - Epoch: 14.56, Step: 57690, Train Loss: 1.3261, Learning Rate: 6.69e-05
2025-12-09 19:08:32 - INFO - Epoch: 14.57, Step: 57700, Train Loss: 1.3150, Learning Rate: 6.69e-05
2025-12-09 19:08:43 - INFO - Epoch: 14.57, Step: 57710, Train Loss: 1.4015, Learning Rate: 6.69e-05
2025-12-09 19:08:54 - INFO - Epoch: 14.57, Step: 57720, Train Loss: 1.3731, Learning Rate: 6.69e-05
2025-12-09 19:09:06 - INFO - Epoch: 14.57, Step: 57730, Train Loss: 1.3783, Learning Rate: 6.69e-05
2025-12-09 19:09:17 - INFO - Epoch: 14.58, Step: 57740, Train Loss: 1.3199, Learning Rate: 6.69e-05
2025-12-09 19:09:28 - INFO - Epoch: 14.58, Step: 57750, Train Loss: 1.3621, Learning Rate: 6.69e-05
2025-12-09 19:09:39 - INFO - Epoch: 14.58, Step: 57760, Train Loss: 1.4116, Learning Rate: 6.69e-05
2025-12-09 19:09:50 - INFO - Epoch: 14.58, Step: 57770, Train Loss: 1.3949, Learning Rate: 6.69e-05
2025-12-09 19:10:01 - INFO - Epoch: 14.59, Step: 57780, Train Loss: 1.3173, Learning Rate: 6.69e-05
2025-12-09 19:10:12 - INFO - Epoch: 14.59, Step: 57790, Train Loss: 1.3483, Learning Rate: 6.69e-05
2025-12-09 19:10:24 - INFO - Epoch: 14.59, Step: 57800, Train Loss: 1.3799, Learning Rate: 6.69e-05
2025-12-09 19:10:35 - INFO - Epoch: 14.59, Step: 57810, Train Loss: 1.3609, Learning Rate: 6.69e-05
2025-12-09 19:10:46 - INFO - Epoch: 14.60, Step: 57820, Train Loss: 1.3772, Learning Rate: 6.68e-05
2025-12-09 19:10:57 - INFO - Epoch: 14.60, Step: 57830, Train Loss: 1.3399, Learning Rate: 6.68e-05
2025-12-09 19:11:08 - INFO - Epoch: 14.60, Step: 57840, Train Loss: 1.3500, Learning Rate: 6.68e-05
2025-12-09 19:11:19 - INFO - Epoch: 14.60, Step: 57850, Train Loss: 1.3830, Learning Rate: 6.68e-05
2025-12-09 19:11:31 - INFO - Epoch: 14.61, Step: 57860, Train Loss: 1.3507, Learning Rate: 6.68e-05
2025-12-09 19:11:42 - INFO - Epoch: 14.61, Step: 57870, Train Loss: 1.3483, Learning Rate: 6.68e-05
2025-12-09 19:11:53 - INFO - Epoch: 14.61, Step: 57880, Train Loss: 1.3758, Learning Rate: 6.68e-05
2025-12-09 19:12:04 - INFO - Epoch: 14.61, Step: 57890, Train Loss: 1.3522, Learning Rate: 6.68e-05
2025-12-09 19:12:15 - INFO - Epoch: 14.62, Step: 57900, Train Loss: 1.3476, Learning Rate: 6.68e-05
2025-12-09 19:12:26 - INFO - Epoch: 14.62, Step: 57910, Train Loss: 1.3623, Learning Rate: 6.68e-05
2025-12-09 19:12:38 - INFO - Epoch: 14.62, Step: 57920, Train Loss: 1.3567, Learning Rate: 6.68e-05
2025-12-09 19:12:49 - INFO - Epoch: 14.63, Step: 57930, Train Loss: 1.3570, Learning Rate: 6.68e-05
2025-12-09 19:13:00 - INFO - Epoch: 14.63, Step: 57940, Train Loss: 1.3619, Learning Rate: 6.68e-05
2025-12-09 19:13:11 - INFO - Epoch: 14.63, Step: 57950, Train Loss: 1.3545, Learning Rate: 6.68e-05
2025-12-09 19:13:22 - INFO - Epoch: 14.63, Step: 57960, Train Loss: 1.3137, Learning Rate: 6.68e-05
2025-12-09 19:13:33 - INFO - Epoch: 14.64, Step: 57970, Train Loss: 1.3418, Learning Rate: 6.68e-05
2025-12-09 19:13:44 - INFO - Epoch: 14.64, Step: 57980, Train Loss: 1.3349, Learning Rate: 6.67e-05
2025-12-09 19:13:56 - INFO - Epoch: 14.64, Step: 57990, Train Loss: 1.3340, Learning Rate: 6.67e-05
2025-12-09 19:14:07 - INFO - Epoch: 14.64, Step: 58000, Train Loss: 1.3233, Learning Rate: 6.67e-05
2025-12-09 19:14:18 - INFO - Epoch: 14.65, Step: 58010, Train Loss: 1.3725, Learning Rate: 6.67e-05
2025-12-09 19:14:29 - INFO - Epoch: 14.65, Step: 58020, Train Loss: 1.3645, Learning Rate: 6.67e-05
2025-12-09 19:14:40 - INFO - Epoch: 14.65, Step: 58030, Train Loss: 1.3088, Learning Rate: 6.67e-05
2025-12-09 19:14:51 - INFO - Epoch: 14.65, Step: 58040, Train Loss: 1.3657, Learning Rate: 6.67e-05
2025-12-09 19:15:03 - INFO - Epoch: 14.66, Step: 58050, Train Loss: 1.3508, Learning Rate: 6.67e-05
2025-12-09 19:15:14 - INFO - Epoch: 14.66, Step: 58060, Train Loss: 1.3704, Learning Rate: 6.67e-05
2025-12-09 19:15:25 - INFO - Epoch: 14.66, Step: 58070, Train Loss: 1.3780, Learning Rate: 6.67e-05
2025-12-09 19:15:36 - INFO - Epoch: 14.66, Step: 58080, Train Loss: 1.3092, Learning Rate: 6.67e-05
2025-12-09 19:15:47 - INFO - Epoch: 14.67, Step: 58090, Train Loss: 1.3377, Learning Rate: 6.67e-05
2025-12-09 19:15:58 - INFO - Epoch: 14.67, Step: 58100, Train Loss: 1.3647, Learning Rate: 6.67e-05
2025-12-09 19:16:09 - INFO - Epoch: 14.67, Step: 58110, Train Loss: 1.3591, Learning Rate: 6.67e-05
2025-12-09 19:16:21 - INFO - Epoch: 14.67, Step: 58120, Train Loss: 1.3481, Learning Rate: 6.67e-05
2025-12-09 19:16:32 - INFO - Epoch: 14.68, Step: 58130, Train Loss: 1.3309, Learning Rate: 6.66e-05
2025-12-09 19:16:43 - INFO - Epoch: 14.68, Step: 58140, Train Loss: 1.3550, Learning Rate: 6.66e-05
2025-12-09 19:16:54 - INFO - Epoch: 14.68, Step: 58150, Train Loss: 1.3639, Learning Rate: 6.66e-05
2025-12-09 19:17:05 - INFO - Epoch: 14.68, Step: 58160, Train Loss: 1.3371, Learning Rate: 6.66e-05
2025-12-09 19:17:16 - INFO - Epoch: 14.69, Step: 58170, Train Loss: 1.3126, Learning Rate: 6.66e-05
2025-12-09 19:17:28 - INFO - Epoch: 14.69, Step: 58180, Train Loss: 1.3783, Learning Rate: 6.66e-05
2025-12-09 19:17:39 - INFO - Epoch: 14.69, Step: 58190, Train Loss: 1.3431, Learning Rate: 6.66e-05
2025-12-09 19:17:50 - INFO - Epoch: 14.69, Step: 58200, Train Loss: 1.3742, Learning Rate: 6.66e-05
2025-12-09 19:18:01 - INFO - Epoch: 14.70, Step: 58210, Train Loss: 1.3233, Learning Rate: 6.66e-05
2025-12-09 19:18:12 - INFO - Epoch: 14.70, Step: 58220, Train Loss: 1.3703, Learning Rate: 6.66e-05
2025-12-09 19:18:23 - INFO - Epoch: 14.70, Step: 58230, Train Loss: 1.3854, Learning Rate: 6.66e-05
2025-12-09 19:18:34 - INFO - Epoch: 14.70, Step: 58240, Train Loss: 1.3341, Learning Rate: 6.66e-05
2025-12-09 19:18:46 - INFO - Epoch: 14.71, Step: 58250, Train Loss: 1.3650, Learning Rate: 6.66e-05
2025-12-09 19:18:57 - INFO - Epoch: 14.71, Step: 58260, Train Loss: 1.3405, Learning Rate: 6.66e-05
2025-12-09 19:19:08 - INFO - Epoch: 14.71, Step: 58270, Train Loss: 1.3624, Learning Rate: 6.66e-05
2025-12-09 19:19:19 - INFO - Epoch: 14.71, Step: 58280, Train Loss: 1.3783, Learning Rate: 6.65e-05
2025-12-09 19:19:30 - INFO - Epoch: 14.72, Step: 58290, Train Loss: 1.3773, Learning Rate: 6.65e-05
2025-12-09 19:19:41 - INFO - Epoch: 14.72, Step: 58300, Train Loss: 1.3761, Learning Rate: 6.65e-05
2025-12-09 19:19:53 - INFO - Epoch: 14.72, Step: 58310, Train Loss: 1.3478, Learning Rate: 6.65e-05
2025-12-09 19:20:04 - INFO - Epoch: 14.72, Step: 58320, Train Loss: 1.3177, Learning Rate: 6.65e-05
2025-12-09 19:20:15 - INFO - Epoch: 14.73, Step: 58330, Train Loss: 1.3404, Learning Rate: 6.65e-05
2025-12-09 19:20:26 - INFO - Epoch: 14.73, Step: 58340, Train Loss: 1.3279, Learning Rate: 6.65e-05
2025-12-09 19:20:37 - INFO - Epoch: 14.73, Step: 58350, Train Loss: 1.3847, Learning Rate: 6.65e-05
2025-12-09 19:20:48 - INFO - Epoch: 14.73, Step: 58360, Train Loss: 1.2897, Learning Rate: 6.65e-05
2025-12-09 19:20:59 - INFO - Epoch: 14.74, Step: 58370, Train Loss: 1.3575, Learning Rate: 6.65e-05
2025-12-09 19:21:11 - INFO - Epoch: 14.74, Step: 58380, Train Loss: 1.3596, Learning Rate: 6.65e-05
2025-12-09 19:21:22 - INFO - Epoch: 14.74, Step: 58390, Train Loss: 1.3863, Learning Rate: 6.65e-05
2025-12-09 19:21:33 - INFO - Epoch: 14.74, Step: 58400, Train Loss: 1.3467, Learning Rate: 6.65e-05
2025-12-09 19:21:44 - INFO - Epoch: 14.75, Step: 58410, Train Loss: 1.3450, Learning Rate: 6.65e-05
2025-12-09 19:21:55 - INFO - Epoch: 14.75, Step: 58420, Train Loss: 1.3382, Learning Rate: 6.65e-05
2025-12-09 19:22:06 - INFO - Epoch: 14.75, Step: 58430, Train Loss: 1.3602, Learning Rate: 6.64e-05
2025-12-09 19:22:18 - INFO - Epoch: 14.75, Step: 58440, Train Loss: 1.3315, Learning Rate: 6.64e-05
2025-12-09 19:22:29 - INFO - Epoch: 14.76, Step: 58450, Train Loss: 1.3831, Learning Rate: 6.64e-05
2025-12-09 19:22:40 - INFO - Epoch: 14.76, Step: 58460, Train Loss: 1.3640, Learning Rate: 6.64e-05
2025-12-09 19:22:51 - INFO - Epoch: 14.76, Step: 58470, Train Loss: 1.3640, Learning Rate: 6.64e-05
2025-12-09 19:23:02 - INFO - Epoch: 14.76, Step: 58480, Train Loss: 1.3123, Learning Rate: 6.64e-05
2025-12-09 19:23:13 - INFO - Epoch: 14.77, Step: 58490, Train Loss: 1.3661, Learning Rate: 6.64e-05
2025-12-09 19:23:24 - INFO - Epoch: 14.77, Step: 58500, Train Loss: 1.3036, Learning Rate: 6.64e-05
2025-12-09 19:23:36 - INFO - Epoch: 14.77, Step: 58510, Train Loss: 1.3685, Learning Rate: 6.64e-05
2025-12-09 19:23:47 - INFO - Epoch: 14.77, Step: 58520, Train Loss: 1.3334, Learning Rate: 6.64e-05
2025-12-09 19:23:58 - INFO - Epoch: 14.78, Step: 58530, Train Loss: 1.3382, Learning Rate: 6.64e-05
2025-12-09 19:24:09 - INFO - Epoch: 14.78, Step: 58540, Train Loss: 1.3628, Learning Rate: 6.64e-05
2025-12-09 19:24:20 - INFO - Epoch: 14.78, Step: 58550, Train Loss: 1.3638, Learning Rate: 6.64e-05
2025-12-09 19:24:31 - INFO - Epoch: 14.78, Step: 58560, Train Loss: 1.3970, Learning Rate: 6.64e-05
2025-12-09 19:24:43 - INFO - Epoch: 14.79, Step: 58570, Train Loss: 1.3323, Learning Rate: 6.64e-05
2025-12-09 19:24:54 - INFO - Epoch: 14.79, Step: 58580, Train Loss: 1.3926, Learning Rate: 6.63e-05
2025-12-09 19:25:05 - INFO - Epoch: 14.79, Step: 58590, Train Loss: 1.3399, Learning Rate: 6.63e-05
2025-12-09 19:25:16 - INFO - Epoch: 14.79, Step: 58600, Train Loss: 1.3607, Learning Rate: 6.63e-05
2025-12-09 19:25:27 - INFO - Epoch: 14.80, Step: 58610, Train Loss: 1.3536, Learning Rate: 6.63e-05
2025-12-09 19:25:38 - INFO - Epoch: 14.80, Step: 58620, Train Loss: 1.3750, Learning Rate: 6.63e-05
2025-12-09 19:25:50 - INFO - Epoch: 14.80, Step: 58630, Train Loss: 1.3375, Learning Rate: 6.63e-05
2025-12-09 19:26:01 - INFO - Epoch: 14.80, Step: 58640, Train Loss: 1.3610, Learning Rate: 6.63e-05
2025-12-09 19:26:12 - INFO - Epoch: 14.81, Step: 58650, Train Loss: 1.3591, Learning Rate: 6.63e-05
2025-12-09 19:26:23 - INFO - Epoch: 14.81, Step: 58660, Train Loss: 1.3543, Learning Rate: 6.63e-05
2025-12-09 19:26:34 - INFO - Epoch: 14.81, Step: 58670, Train Loss: 1.3724, Learning Rate: 6.63e-05
2025-12-09 19:26:45 - INFO - Epoch: 14.81, Step: 58680, Train Loss: 1.3424, Learning Rate: 6.63e-05
2025-12-09 19:26:56 - INFO - Epoch: 14.82, Step: 58690, Train Loss: 1.3121, Learning Rate: 6.63e-05
2025-12-09 19:27:08 - INFO - Epoch: 14.82, Step: 58700, Train Loss: 1.3731, Learning Rate: 6.63e-05
2025-12-09 19:27:19 - INFO - Epoch: 14.82, Step: 58710, Train Loss: 1.3383, Learning Rate: 6.63e-05
2025-12-09 19:27:30 - INFO - Epoch: 14.82, Step: 58720, Train Loss: 1.3410, Learning Rate: 6.63e-05
2025-12-09 19:27:41 - INFO - Epoch: 14.83, Step: 58730, Train Loss: 1.3547, Learning Rate: 6.62e-05
2025-12-09 19:27:52 - INFO - Epoch: 14.83, Step: 58740, Train Loss: 1.3606, Learning Rate: 6.62e-05
2025-12-09 19:28:03 - INFO - Epoch: 14.83, Step: 58750, Train Loss: 1.3273, Learning Rate: 6.62e-05
2025-12-09 19:28:15 - INFO - Epoch: 14.83, Step: 58760, Train Loss: 1.3578, Learning Rate: 6.62e-05
2025-12-09 19:28:26 - INFO - Epoch: 14.84, Step: 58770, Train Loss: 1.3678, Learning Rate: 6.62e-05
2025-12-09 19:28:37 - INFO - Epoch: 14.84, Step: 58780, Train Loss: 1.3754, Learning Rate: 6.62e-05
2025-12-09 19:28:48 - INFO - Epoch: 14.84, Step: 58790, Train Loss: 1.3568, Learning Rate: 6.62e-05
2025-12-09 19:28:59 - INFO - Epoch: 14.84, Step: 58800, Train Loss: 1.3704, Learning Rate: 6.62e-05
2025-12-09 19:29:10 - INFO - Epoch: 14.85, Step: 58810, Train Loss: 1.3389, Learning Rate: 6.62e-05
2025-12-09 19:29:21 - INFO - Epoch: 14.85, Step: 58820, Train Loss: 1.3680, Learning Rate: 6.62e-05
2025-12-09 19:29:33 - INFO - Epoch: 14.85, Step: 58830, Train Loss: 1.3394, Learning Rate: 6.62e-05
2025-12-09 19:29:44 - INFO - Epoch: 14.85, Step: 58840, Train Loss: 1.3842, Learning Rate: 6.62e-05
2025-12-09 19:29:55 - INFO - Epoch: 14.86, Step: 58850, Train Loss: 1.3470, Learning Rate: 6.62e-05
2025-12-09 19:30:06 - INFO - Epoch: 14.86, Step: 58860, Train Loss: 1.3505, Learning Rate: 6.62e-05
2025-12-09 19:30:17 - INFO - Epoch: 14.86, Step: 58870, Train Loss: 1.3284, Learning Rate: 6.62e-05
2025-12-09 19:30:28 - INFO - Epoch: 14.86, Step: 58880, Train Loss: 1.3547, Learning Rate: 6.61e-05
2025-12-09 19:30:40 - INFO - Epoch: 14.87, Step: 58890, Train Loss: 1.3400, Learning Rate: 6.61e-05
2025-12-09 19:30:51 - INFO - Epoch: 14.87, Step: 58900, Train Loss: 1.3547, Learning Rate: 6.61e-05
2025-12-09 19:31:02 - INFO - Epoch: 14.87, Step: 58910, Train Loss: 1.3241, Learning Rate: 6.61e-05
2025-12-09 19:31:13 - INFO - Epoch: 14.88, Step: 58920, Train Loss: 1.3670, Learning Rate: 6.61e-05
2025-12-09 19:31:24 - INFO - Epoch: 14.88, Step: 58930, Train Loss: 1.3391, Learning Rate: 6.61e-05
2025-12-09 19:31:35 - INFO - Epoch: 14.88, Step: 58940, Train Loss: 1.3897, Learning Rate: 6.61e-05
2025-12-09 19:31:46 - INFO - Epoch: 14.88, Step: 58950, Train Loss: 1.3290, Learning Rate: 6.61e-05
2025-12-09 19:31:58 - INFO - Epoch: 14.89, Step: 58960, Train Loss: 1.3418, Learning Rate: 6.61e-05
2025-12-09 19:32:09 - INFO - Epoch: 14.89, Step: 58970, Train Loss: 1.3453, Learning Rate: 6.61e-05
2025-12-09 19:32:20 - INFO - Epoch: 14.89, Step: 58980, Train Loss: 1.3333, Learning Rate: 6.61e-05
2025-12-09 19:32:31 - INFO - Epoch: 14.89, Step: 58990, Train Loss: 1.3638, Learning Rate: 6.61e-05
2025-12-09 19:32:42 - INFO - Epoch: 14.90, Step: 59000, Train Loss: 1.3573, Learning Rate: 6.61e-05
2025-12-09 19:32:53 - INFO - Epoch: 14.90, Step: 59010, Train Loss: 1.3808, Learning Rate: 6.61e-05
2025-12-09 19:33:05 - INFO - Epoch: 14.90, Step: 59020, Train Loss: 1.3434, Learning Rate: 6.61e-05
2025-12-09 19:33:16 - INFO - Epoch: 14.90, Step: 59030, Train Loss: 1.3180, Learning Rate: 6.60e-05
2025-12-09 19:33:27 - INFO - Epoch: 14.91, Step: 59040, Train Loss: 1.3790, Learning Rate: 6.60e-05
2025-12-09 19:33:38 - INFO - Epoch: 14.91, Step: 59050, Train Loss: 1.3221, Learning Rate: 6.60e-05
2025-12-09 19:33:49 - INFO - Epoch: 14.91, Step: 59060, Train Loss: 1.3398, Learning Rate: 6.60e-05
2025-12-09 19:34:00 - INFO - Epoch: 14.91, Step: 59070, Train Loss: 1.3727, Learning Rate: 6.60e-05
2025-12-09 19:34:11 - INFO - Epoch: 14.92, Step: 59080, Train Loss: 1.3195, Learning Rate: 6.60e-05
2025-12-09 19:34:23 - INFO - Epoch: 14.92, Step: 59090, Train Loss: 1.3303, Learning Rate: 6.60e-05
2025-12-09 19:34:34 - INFO - Epoch: 14.92, Step: 59100, Train Loss: 1.3423, Learning Rate: 6.60e-05
2025-12-09 19:34:45 - INFO - Epoch: 14.92, Step: 59110, Train Loss: 1.4018, Learning Rate: 6.60e-05
2025-12-09 19:34:56 - INFO - Epoch: 14.93, Step: 59120, Train Loss: 1.3613, Learning Rate: 6.60e-05
2025-12-09 19:35:07 - INFO - Epoch: 14.93, Step: 59130, Train Loss: 1.3665, Learning Rate: 6.60e-05
2025-12-09 19:35:18 - INFO - Epoch: 14.93, Step: 59140, Train Loss: 1.3209, Learning Rate: 6.60e-05
2025-12-09 19:35:30 - INFO - Epoch: 14.93, Step: 59150, Train Loss: 1.3552, Learning Rate: 6.60e-05
2025-12-09 19:35:41 - INFO - Epoch: 14.94, Step: 59160, Train Loss: 1.3210, Learning Rate: 6.60e-05
2025-12-09 19:35:52 - INFO - Epoch: 14.94, Step: 59170, Train Loss: 1.3696, Learning Rate: 6.60e-05
2025-12-09 19:36:03 - INFO - Epoch: 14.94, Step: 59180, Train Loss: 1.3203, Learning Rate: 6.59e-05
2025-12-09 19:36:14 - INFO - Epoch: 14.94, Step: 59190, Train Loss: 1.3430, Learning Rate: 6.59e-05
2025-12-09 19:36:25 - INFO - Epoch: 14.95, Step: 59200, Train Loss: 1.3630, Learning Rate: 6.59e-05
2025-12-09 19:36:36 - INFO - Epoch: 14.95, Step: 59210, Train Loss: 1.3357, Learning Rate: 6.59e-05
2025-12-09 19:36:48 - INFO - Epoch: 14.95, Step: 59220, Train Loss: 1.3585, Learning Rate: 6.59e-05
2025-12-09 19:36:59 - INFO - Epoch: 14.95, Step: 59230, Train Loss: 1.3648, Learning Rate: 6.59e-05
2025-12-09 19:37:10 - INFO - Epoch: 14.96, Step: 59240, Train Loss: 1.3585, Learning Rate: 6.59e-05
2025-12-09 19:37:21 - INFO - Epoch: 14.96, Step: 59250, Train Loss: 1.3200, Learning Rate: 6.59e-05
2025-12-09 19:37:32 - INFO - Epoch: 14.96, Step: 59260, Train Loss: 1.3718, Learning Rate: 6.59e-05
2025-12-09 19:37:43 - INFO - Epoch: 14.96, Step: 59270, Train Loss: 1.3680, Learning Rate: 6.59e-05
2025-12-09 19:37:55 - INFO - Epoch: 14.97, Step: 59280, Train Loss: 1.3466, Learning Rate: 6.59e-05
2025-12-09 19:38:06 - INFO - Epoch: 14.97, Step: 59290, Train Loss: 1.3383, Learning Rate: 6.59e-05
2025-12-09 19:38:17 - INFO - Epoch: 14.97, Step: 59300, Train Loss: 1.2973, Learning Rate: 6.59e-05
2025-12-09 19:38:28 - INFO - Epoch: 14.97, Step: 59310, Train Loss: 1.3195, Learning Rate: 6.59e-05
2025-12-09 19:38:39 - INFO - Epoch: 14.98, Step: 59320, Train Loss: 1.3525, Learning Rate: 6.59e-05
2025-12-09 19:38:50 - INFO - Epoch: 14.98, Step: 59330, Train Loss: 1.3261, Learning Rate: 6.58e-05
2025-12-09 19:39:01 - INFO - Epoch: 14.98, Step: 59340, Train Loss: 1.3705, Learning Rate: 6.58e-05
2025-12-09 19:39:13 - INFO - Epoch: 14.98, Step: 59350, Train Loss: 1.3864, Learning Rate: 6.58e-05
2025-12-09 19:39:24 - INFO - Epoch: 14.99, Step: 59360, Train Loss: 1.3647, Learning Rate: 6.58e-05
2025-12-09 19:39:35 - INFO - Epoch: 14.99, Step: 59370, Train Loss: 1.3243, Learning Rate: 6.58e-05
2025-12-09 19:39:46 - INFO - Epoch: 14.99, Step: 59380, Train Loss: 1.3478, Learning Rate: 6.58e-05
2025-12-09 19:39:57 - INFO - Epoch: 14.99, Step: 59390, Train Loss: 1.3451, Learning Rate: 6.58e-05
2025-12-09 19:40:08 - INFO - Epoch: 15.00, Step: 59400, Train Loss: 1.3542, Learning Rate: 6.58e-05
2025-12-09 19:40:20 - INFO - Epoch: 15.00, Step: 59410, Train Loss: 1.3461, Learning Rate: 6.58e-05
2025-12-09 19:40:31 - INFO - Epoch: 15.00, Step: 59420, Train Loss: 1.3506, Learning Rate: 6.58e-05
2025-12-09 19:40:42 - INFO - Epoch: 15.00, Step: 59430, Train Loss: 1.3799, Learning Rate: 6.58e-05
2025-12-09 19:40:53 - INFO - Epoch: 15.01, Step: 59440, Train Loss: 1.3797, Learning Rate: 6.58e-05
2025-12-09 19:41:04 - INFO - Epoch: 15.01, Step: 59450, Train Loss: 1.3337, Learning Rate: 6.58e-05
2025-12-09 19:41:15 - INFO - Epoch: 15.01, Step: 59460, Train Loss: 1.3629, Learning Rate: 6.58e-05
2025-12-09 19:41:26 - INFO - Epoch: 15.01, Step: 59470, Train Loss: 1.3224, Learning Rate: 6.58e-05
2025-12-09 19:41:38 - INFO - Epoch: 15.02, Step: 59480, Train Loss: 1.3547, Learning Rate: 6.57e-05
2025-12-09 19:41:49 - INFO - Epoch: 15.02, Step: 59490, Train Loss: 1.3615, Learning Rate: 6.57e-05
2025-12-09 19:42:00 - INFO - Epoch: 15.02, Step: 59500, Train Loss: 1.3689, Learning Rate: 6.57e-05
2025-12-09 19:42:11 - INFO - Epoch: 15.02, Step: 59510, Train Loss: 1.3891, Learning Rate: 6.57e-05
2025-12-09 19:42:22 - INFO - Epoch: 15.03, Step: 59520, Train Loss: 1.3725, Learning Rate: 6.57e-05
2025-12-09 19:42:33 - INFO - Epoch: 15.03, Step: 59530, Train Loss: 1.3318, Learning Rate: 6.57e-05
2025-12-09 19:42:45 - INFO - Epoch: 15.03, Step: 59540, Train Loss: 1.3980, Learning Rate: 6.57e-05
2025-12-09 19:42:56 - INFO - Epoch: 15.03, Step: 59550, Train Loss: 1.3811, Learning Rate: 6.57e-05
2025-12-09 19:43:07 - INFO - Epoch: 15.04, Step: 59560, Train Loss: 1.3154, Learning Rate: 6.57e-05
2025-12-09 19:43:18 - INFO - Epoch: 15.04, Step: 59570, Train Loss: 1.3181, Learning Rate: 6.57e-05
2025-12-09 19:43:29 - INFO - Epoch: 15.04, Step: 59580, Train Loss: 1.3323, Learning Rate: 6.57e-05
2025-12-09 19:43:40 - INFO - Epoch: 15.04, Step: 59590, Train Loss: 1.3830, Learning Rate: 6.57e-05
2025-12-09 19:43:51 - INFO - Epoch: 15.05, Step: 59600, Train Loss: 1.3113, Learning Rate: 6.57e-05
2025-12-09 19:44:03 - INFO - Epoch: 15.05, Step: 59610, Train Loss: 1.3424, Learning Rate: 6.57e-05
2025-12-09 19:44:14 - INFO - Epoch: 15.05, Step: 59620, Train Loss: 1.3977, Learning Rate: 6.57e-05
2025-12-09 19:44:25 - INFO - Epoch: 15.05, Step: 59630, Train Loss: 1.3645, Learning Rate: 6.56e-05
2025-12-09 19:44:36 - INFO - Epoch: 15.06, Step: 59640, Train Loss: 1.3284, Learning Rate: 6.56e-05
2025-12-09 19:44:47 - INFO - Epoch: 15.06, Step: 59650, Train Loss: 1.3230, Learning Rate: 6.56e-05
2025-12-09 19:44:58 - INFO - Epoch: 15.06, Step: 59660, Train Loss: 1.3454, Learning Rate: 6.56e-05
2025-12-09 19:45:10 - INFO - Epoch: 15.06, Step: 59670, Train Loss: 1.3591, Learning Rate: 6.56e-05
2025-12-09 19:45:21 - INFO - Epoch: 15.07, Step: 59680, Train Loss: 1.3641, Learning Rate: 6.56e-05
2025-12-09 19:45:32 - INFO - Epoch: 15.07, Step: 59690, Train Loss: 1.3620, Learning Rate: 6.56e-05
2025-12-09 19:45:43 - INFO - Epoch: 15.07, Step: 59700, Train Loss: 1.3649, Learning Rate: 6.56e-05
2025-12-09 19:45:54 - INFO - Epoch: 15.07, Step: 59710, Train Loss: 1.3567, Learning Rate: 6.56e-05
2025-12-09 19:46:05 - INFO - Epoch: 15.08, Step: 59720, Train Loss: 1.3517, Learning Rate: 6.56e-05
2025-12-09 19:46:16 - INFO - Epoch: 15.08, Step: 59730, Train Loss: 1.3365, Learning Rate: 6.56e-05
2025-12-09 19:46:28 - INFO - Epoch: 15.08, Step: 59740, Train Loss: 1.3279, Learning Rate: 6.56e-05
2025-12-09 19:46:39 - INFO - Epoch: 15.08, Step: 59750, Train Loss: 1.3332, Learning Rate: 6.56e-05
2025-12-09 19:46:50 - INFO - Epoch: 15.09, Step: 59760, Train Loss: 1.3362, Learning Rate: 6.56e-05
2025-12-09 19:47:01 - INFO - Epoch: 15.09, Step: 59770, Train Loss: 1.3442, Learning Rate: 6.56e-05
2025-12-09 19:47:12 - INFO - Epoch: 15.09, Step: 59780, Train Loss: 1.3673, Learning Rate: 6.55e-05
2025-12-09 19:47:23 - INFO - Epoch: 15.09, Step: 59790, Train Loss: 1.3745, Learning Rate: 6.55e-05
2025-12-09 19:47:35 - INFO - Epoch: 15.10, Step: 59800, Train Loss: 1.3685, Learning Rate: 6.55e-05
2025-12-09 19:47:46 - INFO - Epoch: 15.10, Step: 59810, Train Loss: 1.3135, Learning Rate: 6.55e-05
2025-12-09 19:47:57 - INFO - Epoch: 15.10, Step: 59820, Train Loss: 1.3464, Learning Rate: 6.55e-05
2025-12-09 19:48:08 - INFO - Epoch: 15.10, Step: 59830, Train Loss: 1.3371, Learning Rate: 6.55e-05
2025-12-09 19:48:19 - INFO - Epoch: 15.11, Step: 59840, Train Loss: 1.3040, Learning Rate: 6.55e-05
2025-12-09 19:48:30 - INFO - Epoch: 15.11, Step: 59850, Train Loss: 1.3179, Learning Rate: 6.55e-05
2025-12-09 19:48:41 - INFO - Epoch: 15.11, Step: 59860, Train Loss: 1.3200, Learning Rate: 6.55e-05
2025-12-09 19:48:53 - INFO - Epoch: 15.11, Step: 59870, Train Loss: 1.3483, Learning Rate: 6.55e-05
2025-12-09 19:49:04 - INFO - Epoch: 15.12, Step: 59880, Train Loss: 1.3099, Learning Rate: 6.55e-05
2025-12-09 19:49:15 - INFO - Epoch: 15.12, Step: 59890, Train Loss: 1.3749, Learning Rate: 6.55e-05
2025-12-09 19:49:26 - INFO - Epoch: 15.12, Step: 59900, Train Loss: 1.2980, Learning Rate: 6.55e-05
2025-12-09 19:49:37 - INFO - Epoch: 15.12, Step: 59910, Train Loss: 1.3238, Learning Rate: 6.55e-05
2025-12-09 19:49:48 - INFO - Epoch: 15.13, Step: 59920, Train Loss: 1.3500, Learning Rate: 6.55e-05
2025-12-09 19:50:00 - INFO - Epoch: 15.13, Step: 59930, Train Loss: 1.3534, Learning Rate: 6.54e-05
2025-12-09 19:50:11 - INFO - Epoch: 15.13, Step: 59940, Train Loss: 1.3459, Learning Rate: 6.54e-05
2025-12-09 19:50:22 - INFO - Epoch: 15.14, Step: 59950, Train Loss: 1.3179, Learning Rate: 6.54e-05
2025-12-09 19:50:33 - INFO - Epoch: 15.14, Step: 59960, Train Loss: 1.3522, Learning Rate: 6.54e-05
2025-12-09 19:50:44 - INFO - Epoch: 15.14, Step: 59970, Train Loss: 1.3407, Learning Rate: 6.54e-05
2025-12-09 19:50:55 - INFO - Epoch: 15.14, Step: 59980, Train Loss: 1.3362, Learning Rate: 6.54e-05
2025-12-09 19:51:06 - INFO - Epoch: 15.15, Step: 59990, Train Loss: 1.3411, Learning Rate: 6.54e-05
2025-12-09 19:51:18 - INFO - Epoch: 15.15, Step: 60000, Train Loss: 1.3851, Learning Rate: 6.54e-05
2025-12-09 19:51:29 - INFO - Epoch: 15.15, Step: 60010, Train Loss: 1.3573, Learning Rate: 6.54e-05
2025-12-09 19:51:40 - INFO - Epoch: 15.15, Step: 60020, Train Loss: 1.3222, Learning Rate: 6.54e-05
2025-12-09 19:51:51 - INFO - Epoch: 15.16, Step: 60030, Train Loss: 1.3146, Learning Rate: 6.54e-05
2025-12-09 19:52:02 - INFO - Epoch: 15.16, Step: 60040, Train Loss: 1.3176, Learning Rate: 6.54e-05
2025-12-09 19:52:13 - INFO - Epoch: 15.16, Step: 60050, Train Loss: 1.3504, Learning Rate: 6.54e-05
2025-12-09 19:52:25 - INFO - Epoch: 15.16, Step: 60060, Train Loss: 1.3547, Learning Rate: 6.54e-05
2025-12-09 19:52:36 - INFO - Epoch: 15.17, Step: 60070, Train Loss: 1.3641, Learning Rate: 6.54e-05
2025-12-09 19:52:47 - INFO - Epoch: 15.17, Step: 60080, Train Loss: 1.3615, Learning Rate: 6.53e-05
2025-12-09 19:52:58 - INFO - Epoch: 15.17, Step: 60090, Train Loss: 1.3609, Learning Rate: 6.53e-05
2025-12-09 19:53:09 - INFO - Epoch: 15.17, Step: 60100, Train Loss: 1.3750, Learning Rate: 6.53e-05
2025-12-09 19:53:20 - INFO - Epoch: 15.18, Step: 60110, Train Loss: 1.3285, Learning Rate: 6.53e-05
2025-12-09 19:53:31 - INFO - Epoch: 15.18, Step: 60120, Train Loss: 1.3625, Learning Rate: 6.53e-05
2025-12-09 19:53:43 - INFO - Epoch: 15.18, Step: 60130, Train Loss: 1.3360, Learning Rate: 6.53e-05
2025-12-09 19:53:54 - INFO - Epoch: 15.18, Step: 60140, Train Loss: 1.3464, Learning Rate: 6.53e-05
2025-12-09 19:54:05 - INFO - Epoch: 15.19, Step: 60150, Train Loss: 1.3210, Learning Rate: 6.53e-05
2025-12-09 19:54:16 - INFO - Epoch: 15.19, Step: 60160, Train Loss: 1.3357, Learning Rate: 6.53e-05
2025-12-09 19:54:27 - INFO - Epoch: 15.19, Step: 60170, Train Loss: 1.3088, Learning Rate: 6.53e-05
2025-12-09 19:54:38 - INFO - Epoch: 15.19, Step: 60180, Train Loss: 1.3646, Learning Rate: 6.53e-05
2025-12-09 19:54:50 - INFO - Epoch: 15.20, Step: 60190, Train Loss: 1.3420, Learning Rate: 6.53e-05
2025-12-09 19:55:01 - INFO - Epoch: 15.20, Step: 60200, Train Loss: 1.3588, Learning Rate: 6.53e-05
2025-12-09 19:55:12 - INFO - Epoch: 15.20, Step: 60210, Train Loss: 1.3481, Learning Rate: 6.53e-05
2025-12-09 19:55:23 - INFO - Epoch: 15.20, Step: 60220, Train Loss: 1.3618, Learning Rate: 6.53e-05
2025-12-09 19:55:34 - INFO - Epoch: 15.21, Step: 60230, Train Loss: 1.3928, Learning Rate: 6.52e-05
2025-12-09 19:55:45 - INFO - Epoch: 15.21, Step: 60240, Train Loss: 1.3416, Learning Rate: 6.52e-05
2025-12-09 19:55:56 - INFO - Epoch: 15.21, Step: 60250, Train Loss: 1.3314, Learning Rate: 6.52e-05
2025-12-09 19:56:08 - INFO - Epoch: 15.21, Step: 60260, Train Loss: 1.3182, Learning Rate: 6.52e-05
2025-12-09 19:56:19 - INFO - Epoch: 15.22, Step: 60270, Train Loss: 1.3474, Learning Rate: 6.52e-05
2025-12-09 19:56:30 - INFO - Epoch: 15.22, Step: 60280, Train Loss: 1.3518, Learning Rate: 6.52e-05
2025-12-09 19:56:41 - INFO - Epoch: 15.22, Step: 60290, Train Loss: 1.2913, Learning Rate: 6.52e-05
2025-12-09 19:56:52 - INFO - Epoch: 15.22, Step: 60300, Train Loss: 1.3320, Learning Rate: 6.52e-05
2025-12-09 19:57:03 - INFO - Epoch: 15.23, Step: 60310, Train Loss: 1.3222, Learning Rate: 6.52e-05
2025-12-09 19:57:15 - INFO - Epoch: 15.23, Step: 60320, Train Loss: 1.3402, Learning Rate: 6.52e-05
2025-12-09 19:57:26 - INFO - Epoch: 15.23, Step: 60330, Train Loss: 1.3841, Learning Rate: 6.52e-05
2025-12-09 19:57:37 - INFO - Epoch: 15.23, Step: 60340, Train Loss: 1.3858, Learning Rate: 6.52e-05
2025-12-09 19:57:48 - INFO - Epoch: 15.24, Step: 60350, Train Loss: 1.3214, Learning Rate: 6.52e-05
2025-12-09 19:57:59 - INFO - Epoch: 15.24, Step: 60360, Train Loss: 1.3180, Learning Rate: 6.52e-05
2025-12-09 19:58:10 - INFO - Epoch: 15.24, Step: 60370, Train Loss: 1.3601, Learning Rate: 6.52e-05
2025-12-09 19:58:21 - INFO - Epoch: 15.24, Step: 60380, Train Loss: 1.3760, Learning Rate: 6.51e-05
2025-12-09 19:58:33 - INFO - Epoch: 15.25, Step: 60390, Train Loss: 1.3360, Learning Rate: 6.51e-05
2025-12-09 19:58:44 - INFO - Epoch: 15.25, Step: 60400, Train Loss: 1.3443, Learning Rate: 6.51e-05
2025-12-09 19:58:55 - INFO - Epoch: 15.25, Step: 60410, Train Loss: 1.3083, Learning Rate: 6.51e-05
2025-12-09 19:59:06 - INFO - Epoch: 15.25, Step: 60420, Train Loss: 1.3309, Learning Rate: 6.51e-05
2025-12-09 19:59:17 - INFO - Epoch: 15.26, Step: 60430, Train Loss: 1.3426, Learning Rate: 6.51e-05
2025-12-09 19:59:28 - INFO - Epoch: 15.26, Step: 60440, Train Loss: 1.3292, Learning Rate: 6.51e-05
2025-12-09 19:59:40 - INFO - Epoch: 15.26, Step: 60450, Train Loss: 1.3549, Learning Rate: 6.51e-05
2025-12-09 19:59:51 - INFO - Epoch: 15.26, Step: 60460, Train Loss: 1.3702, Learning Rate: 6.51e-05
2025-12-09 20:00:02 - INFO - Epoch: 15.27, Step: 60470, Train Loss: 1.3566, Learning Rate: 6.51e-05
2025-12-09 20:00:13 - INFO - Epoch: 15.27, Step: 60480, Train Loss: 1.3331, Learning Rate: 6.51e-05
2025-12-09 20:00:24 - INFO - Epoch: 15.27, Step: 60490, Train Loss: 1.3307, Learning Rate: 6.51e-05
2025-12-09 20:00:35 - INFO - Epoch: 15.27, Step: 60500, Train Loss: 1.3806, Learning Rate: 6.51e-05
2025-12-09 20:00:46 - INFO - Epoch: 15.28, Step: 60510, Train Loss: 1.3586, Learning Rate: 6.51e-05
2025-12-09 20:00:58 - INFO - Epoch: 15.28, Step: 60520, Train Loss: 1.3380, Learning Rate: 6.51e-05
2025-12-09 20:01:09 - INFO - Epoch: 15.28, Step: 60530, Train Loss: 1.3914, Learning Rate: 6.50e-05
2025-12-09 20:01:20 - INFO - Epoch: 15.28, Step: 60540, Train Loss: 1.3304, Learning Rate: 6.50e-05
2025-12-09 20:01:31 - INFO - Epoch: 15.29, Step: 60550, Train Loss: 1.3281, Learning Rate: 6.50e-05
2025-12-09 20:01:42 - INFO - Epoch: 15.29, Step: 60560, Train Loss: 1.3296, Learning Rate: 6.50e-05
2025-12-09 20:01:53 - INFO - Epoch: 15.29, Step: 60570, Train Loss: 1.3587, Learning Rate: 6.50e-05
2025-12-09 20:02:05 - INFO - Epoch: 15.29, Step: 60580, Train Loss: 1.3813, Learning Rate: 6.50e-05
2025-12-09 20:02:16 - INFO - Epoch: 15.30, Step: 60590, Train Loss: 1.3820, Learning Rate: 6.50e-05
2025-12-09 20:02:27 - INFO - Epoch: 15.30, Step: 60600, Train Loss: 1.3176, Learning Rate: 6.50e-05
2025-12-09 20:02:38 - INFO - Epoch: 15.30, Step: 60610, Train Loss: 1.3698, Learning Rate: 6.50e-05
2025-12-09 20:02:49 - INFO - Epoch: 15.30, Step: 60620, Train Loss: 1.3548, Learning Rate: 6.50e-05
2025-12-09 20:03:00 - INFO - Epoch: 15.31, Step: 60630, Train Loss: 1.3040, Learning Rate: 6.50e-05
2025-12-09 20:03:11 - INFO - Epoch: 15.31, Step: 60640, Train Loss: 1.3465, Learning Rate: 6.50e-05
2025-12-09 20:03:23 - INFO - Epoch: 15.31, Step: 60650, Train Loss: 1.3003, Learning Rate: 6.50e-05
2025-12-09 20:03:34 - INFO - Epoch: 15.31, Step: 60660, Train Loss: 1.2889, Learning Rate: 6.50e-05
2025-12-09 20:03:45 - INFO - Epoch: 15.32, Step: 60670, Train Loss: 1.3293, Learning Rate: 6.50e-05
2025-12-09 20:03:56 - INFO - Epoch: 15.32, Step: 60680, Train Loss: 1.3681, Learning Rate: 6.49e-05
2025-12-09 20:04:07 - INFO - Epoch: 15.32, Step: 60690, Train Loss: 1.3444, Learning Rate: 6.49e-05
2025-12-09 20:04:18 - INFO - Epoch: 15.32, Step: 60700, Train Loss: 1.3749, Learning Rate: 6.49e-05
2025-12-09 20:04:30 - INFO - Epoch: 15.33, Step: 60710, Train Loss: 1.3519, Learning Rate: 6.49e-05
2025-12-09 20:04:41 - INFO - Epoch: 15.33, Step: 60720, Train Loss: 1.3625, Learning Rate: 6.49e-05
2025-12-09 20:04:52 - INFO - Epoch: 15.33, Step: 60730, Train Loss: 1.3314, Learning Rate: 6.49e-05
2025-12-09 20:05:03 - INFO - Epoch: 15.33, Step: 60740, Train Loss: 1.3430, Learning Rate: 6.49e-05
2025-12-09 20:05:14 - INFO - Epoch: 15.34, Step: 60750, Train Loss: 1.3511, Learning Rate: 6.49e-05
2025-12-09 20:05:25 - INFO - Epoch: 15.34, Step: 60760, Train Loss: 1.3456, Learning Rate: 6.49e-05
2025-12-09 20:05:36 - INFO - Epoch: 15.34, Step: 60770, Train Loss: 1.3327, Learning Rate: 6.49e-05
2025-12-09 20:05:48 - INFO - Epoch: 15.34, Step: 60780, Train Loss: 1.3231, Learning Rate: 6.49e-05
2025-12-09 20:05:59 - INFO - Epoch: 15.35, Step: 60790, Train Loss: 1.3287, Learning Rate: 6.49e-05
2025-12-09 20:06:10 - INFO - Epoch: 15.35, Step: 60800, Train Loss: 1.3239, Learning Rate: 6.49e-05
2025-12-09 20:06:21 - INFO - Epoch: 15.35, Step: 60810, Train Loss: 1.3247, Learning Rate: 6.49e-05
2025-12-09 20:06:32 - INFO - Epoch: 15.35, Step: 60820, Train Loss: 1.2977, Learning Rate: 6.49e-05
2025-12-09 20:06:43 - INFO - Epoch: 15.36, Step: 60830, Train Loss: 1.3653, Learning Rate: 6.49e-05
2025-12-09 20:06:55 - INFO - Epoch: 15.36, Step: 60840, Train Loss: 1.3557, Learning Rate: 6.48e-05
2025-12-09 20:07:06 - INFO - Epoch: 15.36, Step: 60850, Train Loss: 1.3514, Learning Rate: 6.48e-05
2025-12-09 20:07:17 - INFO - Epoch: 15.36, Step: 60860, Train Loss: 1.3252, Learning Rate: 6.48e-05
2025-12-09 20:07:28 - INFO - Epoch: 15.37, Step: 60870, Train Loss: 1.3114, Learning Rate: 6.48e-05
2025-12-09 20:07:39 - INFO - Epoch: 15.37, Step: 60880, Train Loss: 1.3698, Learning Rate: 6.48e-05
2025-12-09 20:07:50 - INFO - Epoch: 15.37, Step: 60890, Train Loss: 1.3750, Learning Rate: 6.48e-05
2025-12-09 20:08:01 - INFO - Epoch: 15.37, Step: 60900, Train Loss: 1.3611, Learning Rate: 6.48e-05
2025-12-09 20:08:13 - INFO - Epoch: 15.38, Step: 60910, Train Loss: 1.3682, Learning Rate: 6.48e-05
2025-12-09 20:08:24 - INFO - Epoch: 15.38, Step: 60920, Train Loss: 1.3705, Learning Rate: 6.48e-05
2025-12-09 20:08:35 - INFO - Epoch: 15.38, Step: 60930, Train Loss: 1.3687, Learning Rate: 6.48e-05
2025-12-09 20:08:46 - INFO - Epoch: 15.39, Step: 60940, Train Loss: 1.3607, Learning Rate: 6.48e-05
2025-12-09 20:08:57 - INFO - Epoch: 15.39, Step: 60950, Train Loss: 1.3650, Learning Rate: 6.48e-05
2025-12-09 20:09:08 - INFO - Epoch: 15.39, Step: 60960, Train Loss: 1.3631, Learning Rate: 6.48e-05
2025-12-09 20:09:20 - INFO - Epoch: 15.39, Step: 60970, Train Loss: 1.3160, Learning Rate: 6.48e-05
2025-12-09 20:09:31 - INFO - Epoch: 15.40, Step: 60980, Train Loss: 1.3185, Learning Rate: 6.48e-05
2025-12-09 20:09:42 - INFO - Epoch: 15.40, Step: 60990, Train Loss: 1.3576, Learning Rate: 6.47e-05
2025-12-09 20:09:53 - INFO - Epoch: 15.40, Step: 61000, Train Loss: 1.3425, Learning Rate: 6.47e-05
2025-12-09 20:10:04 - INFO - Epoch: 15.40, Step: 61010, Train Loss: 1.3156, Learning Rate: 6.47e-05
2025-12-09 20:10:15 - INFO - Epoch: 15.41, Step: 61020, Train Loss: 1.3291, Learning Rate: 6.47e-05
2025-12-09 20:10:26 - INFO - Epoch: 15.41, Step: 61030, Train Loss: 1.3215, Learning Rate: 6.47e-05
2025-12-09 20:10:38 - INFO - Epoch: 15.41, Step: 61040, Train Loss: 1.3490, Learning Rate: 6.47e-05
2025-12-09 20:10:49 - INFO - Epoch: 15.41, Step: 61050, Train Loss: 1.3219, Learning Rate: 6.47e-05
2025-12-09 20:11:00 - INFO - Epoch: 15.42, Step: 61060, Train Loss: 1.3291, Learning Rate: 6.47e-05
2025-12-09 20:11:11 - INFO - Epoch: 15.42, Step: 61070, Train Loss: 1.3476, Learning Rate: 6.47e-05
2025-12-09 20:11:22 - INFO - Epoch: 15.42, Step: 61080, Train Loss: 1.3518, Learning Rate: 6.47e-05
2025-12-09 20:11:33 - INFO - Epoch: 15.42, Step: 61090, Train Loss: 1.3191, Learning Rate: 6.47e-05
2025-12-09 20:11:45 - INFO - Epoch: 15.43, Step: 61100, Train Loss: 1.3414, Learning Rate: 6.47e-05
2025-12-09 20:11:56 - INFO - Epoch: 15.43, Step: 61110, Train Loss: 1.3300, Learning Rate: 6.47e-05
2025-12-09 20:12:07 - INFO - Epoch: 15.43, Step: 61120, Train Loss: 1.3195, Learning Rate: 6.47e-05
2025-12-09 20:12:18 - INFO - Epoch: 15.43, Step: 61130, Train Loss: 1.3186, Learning Rate: 6.47e-05
2025-12-09 20:12:29 - INFO - Epoch: 15.44, Step: 61140, Train Loss: 1.3506, Learning Rate: 6.46e-05
2025-12-09 20:12:40 - INFO - Epoch: 15.44, Step: 61150, Train Loss: 1.3312, Learning Rate: 6.46e-05
2025-12-09 20:12:51 - INFO - Epoch: 15.44, Step: 61160, Train Loss: 1.3132, Learning Rate: 6.46e-05
2025-12-09 20:13:03 - INFO - Epoch: 15.44, Step: 61170, Train Loss: 1.3302, Learning Rate: 6.46e-05
2025-12-09 20:13:14 - INFO - Epoch: 15.45, Step: 61180, Train Loss: 1.3080, Learning Rate: 6.46e-05
2025-12-09 20:13:25 - INFO - Epoch: 15.45, Step: 61190, Train Loss: 1.3531, Learning Rate: 6.46e-05
2025-12-09 20:13:36 - INFO - Epoch: 15.45, Step: 61200, Train Loss: 1.3045, Learning Rate: 6.46e-05
2025-12-09 20:13:47 - INFO - Epoch: 15.45, Step: 61210, Train Loss: 1.3530, Learning Rate: 6.46e-05
2025-12-09 20:13:58 - INFO - Epoch: 15.46, Step: 61220, Train Loss: 1.3115, Learning Rate: 6.46e-05
2025-12-09 20:14:10 - INFO - Epoch: 15.46, Step: 61230, Train Loss: 1.3536, Learning Rate: 6.46e-05
2025-12-09 20:14:21 - INFO - Epoch: 15.46, Step: 61240, Train Loss: 1.3688, Learning Rate: 6.46e-05
2025-12-09 20:14:32 - INFO - Epoch: 15.46, Step: 61250, Train Loss: 1.3675, Learning Rate: 6.46e-05
2025-12-09 20:14:43 - INFO - Epoch: 15.47, Step: 61260, Train Loss: 1.3383, Learning Rate: 6.46e-05
2025-12-09 20:14:54 - INFO - Epoch: 15.47, Step: 61270, Train Loss: 1.3600, Learning Rate: 6.46e-05
2025-12-09 20:15:05 - INFO - Epoch: 15.47, Step: 61280, Train Loss: 1.3642, Learning Rate: 6.46e-05
2025-12-09 20:15:16 - INFO - Epoch: 15.47, Step: 61290, Train Loss: 1.3328, Learning Rate: 6.45e-05
2025-12-09 20:15:28 - INFO - Epoch: 15.48, Step: 61300, Train Loss: 1.3338, Learning Rate: 6.45e-05
2025-12-09 20:15:39 - INFO - Epoch: 15.48, Step: 61310, Train Loss: 1.3424, Learning Rate: 6.45e-05
2025-12-09 20:15:50 - INFO - Epoch: 15.48, Step: 61320, Train Loss: 1.3758, Learning Rate: 6.45e-05
2025-12-09 20:16:01 - INFO - Epoch: 15.48, Step: 61330, Train Loss: 1.3528, Learning Rate: 6.45e-05
2025-12-09 20:16:12 - INFO - Epoch: 15.49, Step: 61340, Train Loss: 1.3714, Learning Rate: 6.45e-05
2025-12-09 20:16:23 - INFO - Epoch: 15.49, Step: 61350, Train Loss: 1.3564, Learning Rate: 6.45e-05
2025-12-09 20:16:35 - INFO - Epoch: 15.49, Step: 61360, Train Loss: 1.3689, Learning Rate: 6.45e-05
2025-12-09 20:16:46 - INFO - Epoch: 15.49, Step: 61370, Train Loss: 1.3461, Learning Rate: 6.45e-05
2025-12-09 20:16:57 - INFO - Epoch: 15.50, Step: 61380, Train Loss: 1.3254, Learning Rate: 6.45e-05
2025-12-09 20:17:08 - INFO - Epoch: 15.50, Step: 61390, Train Loss: 1.3613, Learning Rate: 6.45e-05
2025-12-09 20:17:19 - INFO - Epoch: 15.50, Step: 61400, Train Loss: 1.3183, Learning Rate: 6.45e-05
2025-12-09 20:17:30 - INFO - Epoch: 15.50, Step: 61410, Train Loss: 1.3591, Learning Rate: 6.45e-05
2025-12-09 20:17:41 - INFO - Epoch: 15.51, Step: 61420, Train Loss: 1.3238, Learning Rate: 6.45e-05
2025-12-09 20:17:53 - INFO - Epoch: 15.51, Step: 61430, Train Loss: 1.3008, Learning Rate: 6.45e-05
2025-12-09 20:18:04 - INFO - Epoch: 15.51, Step: 61440, Train Loss: 1.3704, Learning Rate: 6.44e-05
2025-12-09 20:18:15 - INFO - Epoch: 15.51, Step: 61450, Train Loss: 1.3492, Learning Rate: 6.44e-05
2025-12-09 20:18:26 - INFO - Epoch: 15.52, Step: 61460, Train Loss: 1.3344, Learning Rate: 6.44e-05
2025-12-09 20:18:37 - INFO - Epoch: 15.52, Step: 61470, Train Loss: 1.3190, Learning Rate: 6.44e-05
2025-12-09 20:18:48 - INFO - Epoch: 15.52, Step: 61480, Train Loss: 1.3372, Learning Rate: 6.44e-05
2025-12-09 20:19:00 - INFO - Epoch: 15.52, Step: 61490, Train Loss: 1.3273, Learning Rate: 6.44e-05
2025-12-09 20:19:11 - INFO - Epoch: 15.53, Step: 61500, Train Loss: 1.3356, Learning Rate: 6.44e-05
2025-12-09 20:19:22 - INFO - Epoch: 15.53, Step: 61510, Train Loss: 1.3577, Learning Rate: 6.44e-05
2025-12-09 20:19:33 - INFO - Epoch: 15.53, Step: 61520, Train Loss: 1.3822, Learning Rate: 6.44e-05
2025-12-09 20:19:44 - INFO - Epoch: 15.53, Step: 61530, Train Loss: 1.2876, Learning Rate: 6.44e-05
2025-12-09 20:19:55 - INFO - Epoch: 15.54, Step: 61540, Train Loss: 1.3342, Learning Rate: 6.44e-05
2025-12-09 20:20:06 - INFO - Epoch: 15.54, Step: 61550, Train Loss: 1.2931, Learning Rate: 6.44e-05
2025-12-09 20:20:18 - INFO - Epoch: 15.54, Step: 61560, Train Loss: 1.3565, Learning Rate: 6.44e-05
2025-12-09 20:20:29 - INFO - Epoch: 15.54, Step: 61570, Train Loss: 1.3153, Learning Rate: 6.44e-05
2025-12-09 20:20:40 - INFO - Epoch: 15.55, Step: 61580, Train Loss: 1.3164, Learning Rate: 6.44e-05
2025-12-09 20:20:51 - INFO - Epoch: 15.55, Step: 61590, Train Loss: 1.3673, Learning Rate: 6.43e-05
2025-12-09 20:21:02 - INFO - Epoch: 15.55, Step: 61600, Train Loss: 1.3610, Learning Rate: 6.43e-05
2025-12-09 20:21:13 - INFO - Epoch: 15.55, Step: 61610, Train Loss: 1.3711, Learning Rate: 6.43e-05
2025-12-09 20:21:25 - INFO - Epoch: 15.56, Step: 61620, Train Loss: 1.3172, Learning Rate: 6.43e-05
2025-12-09 20:21:36 - INFO - Epoch: 15.56, Step: 61630, Train Loss: 1.3252, Learning Rate: 6.43e-05
2025-12-09 20:21:47 - INFO - Epoch: 15.56, Step: 61640, Train Loss: 1.3694, Learning Rate: 6.43e-05
2025-12-09 20:21:58 - INFO - Epoch: 15.56, Step: 61650, Train Loss: 1.3634, Learning Rate: 6.43e-05
2025-12-09 20:22:09 - INFO - Epoch: 15.57, Step: 61660, Train Loss: 1.3227, Learning Rate: 6.43e-05
2025-12-09 20:22:20 - INFO - Epoch: 15.57, Step: 61670, Train Loss: 1.3210, Learning Rate: 6.43e-05
2025-12-09 20:22:31 - INFO - Epoch: 15.57, Step: 61680, Train Loss: 1.3717, Learning Rate: 6.43e-05
2025-12-09 20:22:43 - INFO - Epoch: 15.57, Step: 61690, Train Loss: 1.3309, Learning Rate: 6.43e-05
2025-12-09 20:22:54 - INFO - Epoch: 15.58, Step: 61700, Train Loss: 1.3270, Learning Rate: 6.43e-05
2025-12-09 20:23:05 - INFO - Epoch: 15.58, Step: 61710, Train Loss: 1.3952, Learning Rate: 6.43e-05
2025-12-09 20:23:16 - INFO - Epoch: 15.58, Step: 61720, Train Loss: 1.3074, Learning Rate: 6.43e-05
2025-12-09 20:23:27 - INFO - Epoch: 15.58, Step: 61730, Train Loss: 1.3548, Learning Rate: 6.43e-05
2025-12-09 20:23:38 - INFO - Epoch: 15.59, Step: 61740, Train Loss: 1.3125, Learning Rate: 6.42e-05
2025-12-09 20:23:50 - INFO - Epoch: 15.59, Step: 61750, Train Loss: 1.3542, Learning Rate: 6.42e-05
2025-12-09 20:24:01 - INFO - Epoch: 15.59, Step: 61760, Train Loss: 1.3217, Learning Rate: 6.42e-05
2025-12-09 20:24:12 - INFO - Epoch: 15.59, Step: 61770, Train Loss: 1.3489, Learning Rate: 6.42e-05
2025-12-09 20:24:23 - INFO - Epoch: 15.60, Step: 61780, Train Loss: 1.3263, Learning Rate: 6.42e-05
2025-12-09 20:24:34 - INFO - Epoch: 15.60, Step: 61790, Train Loss: 1.3355, Learning Rate: 6.42e-05
2025-12-09 20:24:45 - INFO - Epoch: 15.60, Step: 61800, Train Loss: 1.3282, Learning Rate: 6.42e-05
2025-12-09 20:24:56 - INFO - Epoch: 15.60, Step: 61810, Train Loss: 1.3433, Learning Rate: 6.42e-05
2025-12-09 20:25:08 - INFO - Epoch: 15.61, Step: 61820, Train Loss: 1.3439, Learning Rate: 6.42e-05
2025-12-09 20:25:19 - INFO - Epoch: 15.61, Step: 61830, Train Loss: 1.2942, Learning Rate: 6.42e-05
2025-12-09 20:25:30 - INFO - Epoch: 15.61, Step: 61840, Train Loss: 1.3514, Learning Rate: 6.42e-05
2025-12-09 20:25:41 - INFO - Epoch: 15.61, Step: 61850, Train Loss: 1.3204, Learning Rate: 6.42e-05
2025-12-09 20:25:52 - INFO - Epoch: 15.62, Step: 61860, Train Loss: 1.3377, Learning Rate: 6.42e-05
2025-12-09 20:26:03 - INFO - Epoch: 15.62, Step: 61870, Train Loss: 1.3602, Learning Rate: 6.42e-05
2025-12-09 20:26:15 - INFO - Epoch: 15.62, Step: 61880, Train Loss: 1.3360, Learning Rate: 6.42e-05
2025-12-09 20:26:26 - INFO - Epoch: 15.62, Step: 61890, Train Loss: 1.3339, Learning Rate: 6.41e-05
2025-12-09 20:26:37 - INFO - Epoch: 15.63, Step: 61900, Train Loss: 1.3363, Learning Rate: 6.41e-05
2025-12-09 20:26:48 - INFO - Epoch: 15.63, Step: 61910, Train Loss: 1.3041, Learning Rate: 6.41e-05
2025-12-09 20:26:59 - INFO - Epoch: 15.63, Step: 61920, Train Loss: 1.3507, Learning Rate: 6.41e-05
2025-12-09 20:27:10 - INFO - Epoch: 15.63, Step: 61930, Train Loss: 1.3363, Learning Rate: 6.41e-05
2025-12-09 20:27:21 - INFO - Epoch: 15.64, Step: 61940, Train Loss: 1.3279, Learning Rate: 6.41e-05
2025-12-09 20:27:33 - INFO - Epoch: 15.64, Step: 61950, Train Loss: 1.3354, Learning Rate: 6.41e-05
2025-12-09 20:27:44 - INFO - Epoch: 15.64, Step: 61960, Train Loss: 1.3547, Learning Rate: 6.41e-05
2025-12-09 20:27:55 - INFO - Epoch: 15.65, Step: 61970, Train Loss: 1.3691, Learning Rate: 6.41e-05
2025-12-09 20:28:06 - INFO - Epoch: 15.65, Step: 61980, Train Loss: 1.3393, Learning Rate: 6.41e-05
2025-12-09 20:28:17 - INFO - Epoch: 15.65, Step: 61990, Train Loss: 1.3709, Learning Rate: 6.41e-05
2025-12-09 20:28:28 - INFO - Epoch: 15.65, Step: 62000, Train Loss: 1.3187, Learning Rate: 6.41e-05
2025-12-09 20:28:40 - INFO - Epoch: 15.66, Step: 62010, Train Loss: 1.3306, Learning Rate: 6.41e-05
2025-12-09 20:28:51 - INFO - Epoch: 15.66, Step: 62020, Train Loss: 1.3406, Learning Rate: 6.41e-05
2025-12-09 20:29:02 - INFO - Epoch: 15.66, Step: 62030, Train Loss: 1.3475, Learning Rate: 6.41e-05
2025-12-09 20:29:13 - INFO - Epoch: 15.66, Step: 62040, Train Loss: 1.3075, Learning Rate: 6.40e-05
2025-12-09 20:29:24 - INFO - Epoch: 15.67, Step: 62050, Train Loss: 1.3300, Learning Rate: 6.40e-05
2025-12-09 20:29:35 - INFO - Epoch: 15.67, Step: 62060, Train Loss: 1.3277, Learning Rate: 6.40e-05
2025-12-09 20:29:46 - INFO - Epoch: 15.67, Step: 62070, Train Loss: 1.3323, Learning Rate: 6.40e-05
2025-12-09 20:29:58 - INFO - Epoch: 15.67, Step: 62080, Train Loss: 1.3140, Learning Rate: 6.40e-05
2025-12-09 20:30:09 - INFO - Epoch: 15.68, Step: 62090, Train Loss: 1.3431, Learning Rate: 6.40e-05
2025-12-09 20:30:20 - INFO - Epoch: 15.68, Step: 62100, Train Loss: 1.3135, Learning Rate: 6.40e-05
2025-12-09 20:30:31 - INFO - Epoch: 15.68, Step: 62110, Train Loss: 1.3053, Learning Rate: 6.40e-05
2025-12-09 20:30:42 - INFO - Epoch: 15.68, Step: 62120, Train Loss: 1.3440, Learning Rate: 6.40e-05
2025-12-09 20:30:53 - INFO - Epoch: 15.69, Step: 62130, Train Loss: 1.3316, Learning Rate: 6.40e-05
2025-12-09 20:31:05 - INFO - Epoch: 15.69, Step: 62140, Train Loss: 1.3322, Learning Rate: 6.40e-05
2025-12-09 20:31:16 - INFO - Epoch: 15.69, Step: 62150, Train Loss: 1.3423, Learning Rate: 6.40e-05
2025-12-09 20:31:27 - INFO - Epoch: 15.69, Step: 62160, Train Loss: 1.3523, Learning Rate: 6.40e-05
2025-12-09 20:31:38 - INFO - Epoch: 15.70, Step: 62170, Train Loss: 1.3229, Learning Rate: 6.40e-05
2025-12-09 20:31:49 - INFO - Epoch: 15.70, Step: 62180, Train Loss: 1.3427, Learning Rate: 6.40e-05
2025-12-09 20:32:00 - INFO - Epoch: 15.70, Step: 62190, Train Loss: 1.3635, Learning Rate: 6.39e-05
2025-12-09 20:32:11 - INFO - Epoch: 15.70, Step: 62200, Train Loss: 1.3537, Learning Rate: 6.39e-05
2025-12-09 20:32:23 - INFO - Epoch: 15.71, Step: 62210, Train Loss: 1.3400, Learning Rate: 6.39e-05
2025-12-09 20:32:34 - INFO - Epoch: 15.71, Step: 62220, Train Loss: 1.3571, Learning Rate: 6.39e-05
2025-12-09 20:32:45 - INFO - Epoch: 15.71, Step: 62230, Train Loss: 1.3455, Learning Rate: 6.39e-05
2025-12-09 20:32:56 - INFO - Epoch: 15.71, Step: 62240, Train Loss: 1.3398, Learning Rate: 6.39e-05
2025-12-09 20:33:07 - INFO - Epoch: 15.72, Step: 62250, Train Loss: 1.3589, Learning Rate: 6.39e-05
2025-12-09 20:33:18 - INFO - Epoch: 15.72, Step: 62260, Train Loss: 1.3272, Learning Rate: 6.39e-05
2025-12-09 20:33:30 - INFO - Epoch: 15.72, Step: 62270, Train Loss: 1.3236, Learning Rate: 6.39e-05
2025-12-09 20:33:41 - INFO - Epoch: 15.72, Step: 62280, Train Loss: 1.3369, Learning Rate: 6.39e-05
2025-12-09 20:33:52 - INFO - Epoch: 15.73, Step: 62290, Train Loss: 1.3358, Learning Rate: 6.39e-05
2025-12-09 20:34:03 - INFO - Epoch: 15.73, Step: 62300, Train Loss: 1.3362, Learning Rate: 6.39e-05
2025-12-09 20:34:14 - INFO - Epoch: 15.73, Step: 62310, Train Loss: 1.3449, Learning Rate: 6.39e-05
2025-12-09 20:34:25 - INFO - Epoch: 15.73, Step: 62320, Train Loss: 1.2882, Learning Rate: 6.39e-05
2025-12-09 20:34:36 - INFO - Epoch: 15.74, Step: 62330, Train Loss: 1.3511, Learning Rate: 6.39e-05
2025-12-09 20:34:48 - INFO - Epoch: 15.74, Step: 62340, Train Loss: 1.3510, Learning Rate: 6.38e-05
2025-12-09 20:34:59 - INFO - Epoch: 15.74, Step: 62350, Train Loss: 1.3736, Learning Rate: 6.38e-05
2025-12-09 20:35:10 - INFO - Epoch: 15.74, Step: 62360, Train Loss: 1.3651, Learning Rate: 6.38e-05
2025-12-09 20:35:21 - INFO - Epoch: 15.75, Step: 62370, Train Loss: 1.3333, Learning Rate: 6.38e-05
2025-12-09 20:35:32 - INFO - Epoch: 15.75, Step: 62380, Train Loss: 1.3434, Learning Rate: 6.38e-05
2025-12-09 20:35:43 - INFO - Epoch: 15.75, Step: 62390, Train Loss: 1.3258, Learning Rate: 6.38e-05
2025-12-09 20:35:55 - INFO - Epoch: 15.75, Step: 62400, Train Loss: 1.3172, Learning Rate: 6.38e-05
2025-12-09 20:36:06 - INFO - Epoch: 15.76, Step: 62410, Train Loss: 1.3131, Learning Rate: 6.38e-05
2025-12-09 20:36:17 - INFO - Epoch: 15.76, Step: 62420, Train Loss: 1.3229, Learning Rate: 6.38e-05
2025-12-09 20:36:28 - INFO - Epoch: 15.76, Step: 62430, Train Loss: 1.3282, Learning Rate: 6.38e-05
2025-12-09 20:36:39 - INFO - Epoch: 15.76, Step: 62440, Train Loss: 1.3207, Learning Rate: 6.38e-05
2025-12-09 20:36:50 - INFO - Epoch: 15.77, Step: 62450, Train Loss: 1.3232, Learning Rate: 6.38e-05
2025-12-09 20:37:01 - INFO - Epoch: 15.77, Step: 62460, Train Loss: 1.3111, Learning Rate: 6.38e-05
2025-12-09 20:37:13 - INFO - Epoch: 15.77, Step: 62470, Train Loss: 1.3821, Learning Rate: 6.38e-05
2025-12-09 20:37:24 - INFO - Epoch: 15.77, Step: 62480, Train Loss: 1.3285, Learning Rate: 6.38e-05
2025-12-09 20:37:35 - INFO - Epoch: 15.78, Step: 62490, Train Loss: 1.3290, Learning Rate: 6.37e-05
2025-12-09 20:37:46 - INFO - Epoch: 15.78, Step: 62500, Train Loss: 1.3434, Learning Rate: 6.37e-05
2025-12-09 20:37:57 - INFO - Epoch: 15.78, Step: 62510, Train Loss: 1.3536, Learning Rate: 6.37e-05
2025-12-09 20:38:08 - INFO - Epoch: 15.78, Step: 62520, Train Loss: 1.3159, Learning Rate: 6.37e-05
2025-12-09 20:38:20 - INFO - Epoch: 15.79, Step: 62530, Train Loss: 1.3215, Learning Rate: 6.37e-05
2025-12-09 20:38:31 - INFO - Epoch: 15.79, Step: 62540, Train Loss: 1.3441, Learning Rate: 6.37e-05
2025-12-09 20:38:42 - INFO - Epoch: 15.79, Step: 62550, Train Loss: 1.3623, Learning Rate: 6.37e-05
2025-12-09 20:38:53 - INFO - Epoch: 15.79, Step: 62560, Train Loss: 1.3168, Learning Rate: 6.37e-05
2025-12-09 20:39:04 - INFO - Epoch: 15.80, Step: 62570, Train Loss: 1.3704, Learning Rate: 6.37e-05
2025-12-09 20:39:15 - INFO - Epoch: 15.80, Step: 62580, Train Loss: 1.3063, Learning Rate: 6.37e-05
2025-12-09 20:39:26 - INFO - Epoch: 15.80, Step: 62590, Train Loss: 1.3433, Learning Rate: 6.37e-05
2025-12-09 20:39:38 - INFO - Epoch: 15.80, Step: 62600, Train Loss: 1.3433, Learning Rate: 6.37e-05
2025-12-09 20:39:49 - INFO - Epoch: 15.81, Step: 62610, Train Loss: 1.3549, Learning Rate: 6.37e-05
2025-12-09 20:40:00 - INFO - Epoch: 15.81, Step: 62620, Train Loss: 1.3056, Learning Rate: 6.37e-05
2025-12-09 20:40:11 - INFO - Epoch: 15.81, Step: 62630, Train Loss: 1.3228, Learning Rate: 6.37e-05
2025-12-09 20:40:22 - INFO - Epoch: 15.81, Step: 62640, Train Loss: 1.3468, Learning Rate: 6.36e-05
2025-12-09 20:40:33 - INFO - Epoch: 15.82, Step: 62650, Train Loss: 1.2884, Learning Rate: 6.36e-05
2025-12-09 20:40:45 - INFO - Epoch: 15.82, Step: 62660, Train Loss: 1.3398, Learning Rate: 6.36e-05
2025-12-09 20:40:56 - INFO - Epoch: 15.82, Step: 62670, Train Loss: 1.3163, Learning Rate: 6.36e-05
2025-12-09 20:41:07 - INFO - Epoch: 15.82, Step: 62680, Train Loss: 1.3645, Learning Rate: 6.36e-05
2025-12-09 20:41:18 - INFO - Epoch: 15.83, Step: 62690, Train Loss: 1.3320, Learning Rate: 6.36e-05
2025-12-09 20:41:29 - INFO - Epoch: 15.83, Step: 62700, Train Loss: 1.3391, Learning Rate: 6.36e-05
2025-12-09 20:41:40 - INFO - Epoch: 15.83, Step: 62710, Train Loss: 1.3576, Learning Rate: 6.36e-05
2025-12-09 20:41:51 - INFO - Epoch: 15.83, Step: 62720, Train Loss: 1.3347, Learning Rate: 6.36e-05
2025-12-09 20:42:03 - INFO - Epoch: 15.84, Step: 62730, Train Loss: 1.3318, Learning Rate: 6.36e-05
2025-12-09 20:42:14 - INFO - Epoch: 15.84, Step: 62740, Train Loss: 1.3193, Learning Rate: 6.36e-05
2025-12-09 20:42:25 - INFO - Epoch: 15.84, Step: 62750, Train Loss: 1.3355, Learning Rate: 6.36e-05
2025-12-09 20:42:36 - INFO - Epoch: 15.84, Step: 62760, Train Loss: 1.3131, Learning Rate: 6.36e-05
2025-12-09 20:42:47 - INFO - Epoch: 15.85, Step: 62770, Train Loss: 1.3107, Learning Rate: 6.36e-05
2025-12-09 20:42:58 - INFO - Epoch: 15.85, Step: 62780, Train Loss: 1.3434, Learning Rate: 6.36e-05
2025-12-09 20:43:10 - INFO - Epoch: 15.85, Step: 62790, Train Loss: 1.3235, Learning Rate: 6.35e-05
2025-12-09 20:43:21 - INFO - Epoch: 15.85, Step: 62800, Train Loss: 1.3667, Learning Rate: 6.35e-05
2025-12-09 20:43:32 - INFO - Epoch: 15.86, Step: 62810, Train Loss: 1.3382, Learning Rate: 6.35e-05
2025-12-09 20:43:43 - INFO - Epoch: 15.86, Step: 62820, Train Loss: 1.3265, Learning Rate: 6.35e-05
2025-12-09 20:43:54 - INFO - Epoch: 15.86, Step: 62830, Train Loss: 1.2818, Learning Rate: 6.35e-05
2025-12-09 20:44:05 - INFO - Epoch: 15.86, Step: 62840, Train Loss: 1.3241, Learning Rate: 6.35e-05
2025-12-09 20:44:16 - INFO - Epoch: 15.87, Step: 62850, Train Loss: 1.3460, Learning Rate: 6.35e-05
2025-12-09 20:44:28 - INFO - Epoch: 15.87, Step: 62860, Train Loss: 1.3243, Learning Rate: 6.35e-05
2025-12-09 20:44:39 - INFO - Epoch: 15.87, Step: 62870, Train Loss: 1.3047, Learning Rate: 6.35e-05
2025-12-09 20:44:50 - INFO - Epoch: 15.87, Step: 62880, Train Loss: 1.3655, Learning Rate: 6.35e-05
2025-12-09 20:45:01 - INFO - Epoch: 15.88, Step: 62890, Train Loss: 1.3014, Learning Rate: 6.35e-05
2025-12-09 20:45:12 - INFO - Epoch: 15.88, Step: 62900, Train Loss: 1.3226, Learning Rate: 6.35e-05
2025-12-09 20:45:23 - INFO - Epoch: 15.88, Step: 62910, Train Loss: 1.3241, Learning Rate: 6.35e-05
2025-12-09 20:45:35 - INFO - Epoch: 15.88, Step: 62920, Train Loss: 1.3560, Learning Rate: 6.35e-05
2025-12-09 20:45:46 - INFO - Epoch: 15.89, Step: 62930, Train Loss: 1.3366, Learning Rate: 6.35e-05
2025-12-09 20:45:57 - INFO - Epoch: 15.89, Step: 62940, Train Loss: 1.3486, Learning Rate: 6.34e-05
2025-12-09 20:46:08 - INFO - Epoch: 15.89, Step: 62950, Train Loss: 1.3285, Learning Rate: 6.34e-05
2025-12-09 20:46:19 - INFO - Epoch: 15.89, Step: 62960, Train Loss: 1.2998, Learning Rate: 6.34e-05
2025-12-09 20:46:30 - INFO - Epoch: 15.90, Step: 62970, Train Loss: 1.3202, Learning Rate: 6.34e-05
2025-12-09 20:46:41 - INFO - Epoch: 15.90, Step: 62980, Train Loss: 1.3281, Learning Rate: 6.34e-05
2025-12-09 20:46:53 - INFO - Epoch: 15.90, Step: 62990, Train Loss: 1.3377, Learning Rate: 6.34e-05
2025-12-09 20:47:04 - INFO - Epoch: 15.91, Step: 63000, Train Loss: 1.3573, Learning Rate: 6.34e-05
2025-12-09 20:47:15 - INFO - Epoch: 15.91, Step: 63010, Train Loss: 1.3099, Learning Rate: 6.34e-05
2025-12-09 20:47:26 - INFO - Epoch: 15.91, Step: 63020, Train Loss: 1.2999, Learning Rate: 6.34e-05
2025-12-09 20:47:37 - INFO - Epoch: 15.91, Step: 63030, Train Loss: 1.3399, Learning Rate: 6.34e-05
2025-12-09 20:47:48 - INFO - Epoch: 15.92, Step: 63040, Train Loss: 1.3165, Learning Rate: 6.34e-05
2025-12-09 20:48:00 - INFO - Epoch: 15.92, Step: 63050, Train Loss: 1.3431, Learning Rate: 6.34e-05
2025-12-09 20:48:11 - INFO - Epoch: 15.92, Step: 63060, Train Loss: 1.2777, Learning Rate: 6.34e-05
2025-12-09 20:48:22 - INFO - Epoch: 15.92, Step: 63070, Train Loss: 1.3291, Learning Rate: 6.34e-05
2025-12-09 20:48:33 - INFO - Epoch: 15.93, Step: 63080, Train Loss: 1.3744, Learning Rate: 6.34e-05
2025-12-09 20:48:44 - INFO - Epoch: 15.93, Step: 63090, Train Loss: 1.2707, Learning Rate: 6.33e-05
2025-12-09 20:48:55 - INFO - Epoch: 15.93, Step: 63100, Train Loss: 1.3385, Learning Rate: 6.33e-05
2025-12-09 20:49:06 - INFO - Epoch: 15.93, Step: 63110, Train Loss: 1.3325, Learning Rate: 6.33e-05
2025-12-09 20:49:18 - INFO - Epoch: 15.94, Step: 63120, Train Loss: 1.3434, Learning Rate: 6.33e-05
2025-12-09 20:49:29 - INFO - Epoch: 15.94, Step: 63130, Train Loss: 1.3420, Learning Rate: 6.33e-05
2025-12-09 20:49:40 - INFO - Epoch: 15.94, Step: 63140, Train Loss: 1.3377, Learning Rate: 6.33e-05
2025-12-09 20:49:51 - INFO - Epoch: 15.94, Step: 63150, Train Loss: 1.2764, Learning Rate: 6.33e-05
2025-12-09 20:50:02 - INFO - Epoch: 15.95, Step: 63160, Train Loss: 1.3430, Learning Rate: 6.33e-05
2025-12-09 20:50:13 - INFO - Epoch: 15.95, Step: 63170, Train Loss: 1.3472, Learning Rate: 6.33e-05
2025-12-09 20:50:25 - INFO - Epoch: 15.95, Step: 63180, Train Loss: 1.3038, Learning Rate: 6.33e-05
2025-12-09 20:50:36 - INFO - Epoch: 15.95, Step: 63190, Train Loss: 1.3367, Learning Rate: 6.33e-05
2025-12-09 20:50:47 - INFO - Epoch: 15.96, Step: 63200, Train Loss: 1.3468, Learning Rate: 6.33e-05
2025-12-09 20:50:58 - INFO - Epoch: 15.96, Step: 63210, Train Loss: 1.3340, Learning Rate: 6.33e-05
2025-12-09 20:51:09 - INFO - Epoch: 15.96, Step: 63220, Train Loss: 1.3157, Learning Rate: 6.33e-05
2025-12-09 20:51:20 - INFO - Epoch: 15.96, Step: 63230, Train Loss: 1.3131, Learning Rate: 6.33e-05
2025-12-09 20:51:31 - INFO - Epoch: 15.97, Step: 63240, Train Loss: 1.3480, Learning Rate: 6.32e-05
2025-12-09 20:51:43 - INFO - Epoch: 15.97, Step: 63250, Train Loss: 1.3371, Learning Rate: 6.32e-05
2025-12-09 20:51:54 - INFO - Epoch: 15.97, Step: 63260, Train Loss: 1.3082, Learning Rate: 6.32e-05
2025-12-09 20:52:05 - INFO - Epoch: 15.97, Step: 63270, Train Loss: 1.2887, Learning Rate: 6.32e-05
2025-12-09 20:52:16 - INFO - Epoch: 15.98, Step: 63280, Train Loss: 1.3319, Learning Rate: 6.32e-05
2025-12-09 20:52:27 - INFO - Epoch: 15.98, Step: 63290, Train Loss: 1.3429, Learning Rate: 6.32e-05
2025-12-09 20:52:38 - INFO - Epoch: 15.98, Step: 63300, Train Loss: 1.3052, Learning Rate: 6.32e-05
2025-12-09 20:52:50 - INFO - Epoch: 15.98, Step: 63310, Train Loss: 1.3506, Learning Rate: 6.32e-05
2025-12-09 20:53:01 - INFO - Epoch: 15.99, Step: 63320, Train Loss: 1.3256, Learning Rate: 6.32e-05
2025-12-09 20:53:12 - INFO - Epoch: 15.99, Step: 63330, Train Loss: 1.3424, Learning Rate: 6.32e-05
2025-12-09 20:53:23 - INFO - Epoch: 15.99, Step: 63340, Train Loss: 1.3673, Learning Rate: 6.32e-05
2025-12-09 20:53:34 - INFO - Epoch: 15.99, Step: 63350, Train Loss: 1.3349, Learning Rate: 6.32e-05
2025-12-09 20:53:45 - INFO - Epoch: 16.00, Step: 63360, Train Loss: 1.3224, Learning Rate: 6.32e-05
2025-12-09 20:53:56 - INFO - Epoch: 16.00, Step: 63370, Train Loss: 1.3356, Learning Rate: 6.32e-05
2025-12-09 20:54:08 - INFO - Epoch: 16.00, Step: 63380, Train Loss: 1.3047, Learning Rate: 6.32e-05
2025-12-09 20:54:19 - INFO - Epoch: 16.00, Step: 63390, Train Loss: 1.3324, Learning Rate: 6.31e-05
2025-12-09 20:54:30 - INFO - Epoch: 16.01, Step: 63400, Train Loss: 1.3223, Learning Rate: 6.31e-05
2025-12-09 20:54:41 - INFO - Epoch: 16.01, Step: 63410, Train Loss: 1.3346, Learning Rate: 6.31e-05
2025-12-09 20:54:52 - INFO - Epoch: 16.01, Step: 63420, Train Loss: 1.3697, Learning Rate: 6.31e-05
2025-12-09 20:55:03 - INFO - Epoch: 16.01, Step: 63430, Train Loss: 1.3452, Learning Rate: 6.31e-05
2025-12-09 20:55:15 - INFO - Epoch: 16.02, Step: 63440, Train Loss: 1.3244, Learning Rate: 6.31e-05
2025-12-09 20:55:26 - INFO - Epoch: 16.02, Step: 63450, Train Loss: 1.3209, Learning Rate: 6.31e-05
2025-12-09 20:55:37 - INFO - Epoch: 16.02, Step: 63460, Train Loss: 1.3332, Learning Rate: 6.31e-05
2025-12-09 20:55:48 - INFO - Epoch: 16.02, Step: 63470, Train Loss: 1.3226, Learning Rate: 6.31e-05
2025-12-09 20:55:59 - INFO - Epoch: 16.03, Step: 63480, Train Loss: 1.3267, Learning Rate: 6.31e-05
2025-12-09 20:56:10 - INFO - Epoch: 16.03, Step: 63490, Train Loss: 1.3209, Learning Rate: 6.31e-05
2025-12-09 20:56:21 - INFO - Epoch: 16.03, Step: 63500, Train Loss: 1.2958, Learning Rate: 6.31e-05
2025-12-09 20:56:33 - INFO - Epoch: 16.03, Step: 63510, Train Loss: 1.3139, Learning Rate: 6.31e-05
2025-12-09 20:56:44 - INFO - Epoch: 16.04, Step: 63520, Train Loss: 1.2935, Learning Rate: 6.31e-05
2025-12-09 20:56:55 - INFO - Epoch: 16.04, Step: 63530, Train Loss: 1.3449, Learning Rate: 6.31e-05
2025-12-09 20:57:06 - INFO - Epoch: 16.04, Step: 63540, Train Loss: 1.2996, Learning Rate: 6.30e-05
2025-12-09 20:57:17 - INFO - Epoch: 16.04, Step: 63550, Train Loss: 1.3015, Learning Rate: 6.30e-05
2025-12-09 20:57:28 - INFO - Epoch: 16.05, Step: 63560, Train Loss: 1.3184, Learning Rate: 6.30e-05
2025-12-09 20:57:40 - INFO - Epoch: 16.05, Step: 63570, Train Loss: 1.3422, Learning Rate: 6.30e-05
2025-12-09 20:57:51 - INFO - Epoch: 16.05, Step: 63580, Train Loss: 1.3513, Learning Rate: 6.30e-05
2025-12-09 20:58:02 - INFO - Epoch: 16.05, Step: 63590, Train Loss: 1.3354, Learning Rate: 6.30e-05
2025-12-09 20:58:13 - INFO - Epoch: 16.06, Step: 63600, Train Loss: 1.2931, Learning Rate: 6.30e-05
2025-12-09 20:58:24 - INFO - Epoch: 16.06, Step: 63610, Train Loss: 1.3152, Learning Rate: 6.30e-05
2025-12-09 20:58:35 - INFO - Epoch: 16.06, Step: 63620, Train Loss: 1.3660, Learning Rate: 6.30e-05
2025-12-09 20:58:46 - INFO - Epoch: 16.06, Step: 63630, Train Loss: 1.3489, Learning Rate: 6.30e-05
2025-12-09 20:58:58 - INFO - Epoch: 16.07, Step: 63640, Train Loss: 1.3070, Learning Rate: 6.30e-05
2025-12-09 20:59:09 - INFO - Epoch: 16.07, Step: 63650, Train Loss: 1.3096, Learning Rate: 6.30e-05
2025-12-09 20:59:20 - INFO - Epoch: 16.07, Step: 63660, Train Loss: 1.3001, Learning Rate: 6.30e-05
2025-12-09 20:59:31 - INFO - Epoch: 16.07, Step: 63670, Train Loss: 1.3297, Learning Rate: 6.30e-05
2025-12-09 20:59:42 - INFO - Epoch: 16.08, Step: 63680, Train Loss: 1.2961, Learning Rate: 6.30e-05
2025-12-09 20:59:53 - INFO - Epoch: 16.08, Step: 63690, Train Loss: 1.3276, Learning Rate: 6.29e-05
2025-12-09 21:00:05 - INFO - Epoch: 16.08, Step: 63700, Train Loss: 1.3241, Learning Rate: 6.29e-05
2025-12-09 21:00:16 - INFO - Epoch: 16.08, Step: 63710, Train Loss: 1.3035, Learning Rate: 6.29e-05
2025-12-09 21:00:27 - INFO - Epoch: 16.09, Step: 63720, Train Loss: 1.3020, Learning Rate: 6.29e-05
2025-12-09 21:00:38 - INFO - Epoch: 16.09, Step: 63730, Train Loss: 1.3155, Learning Rate: 6.29e-05
2025-12-09 21:00:49 - INFO - Epoch: 16.09, Step: 63740, Train Loss: 1.3312, Learning Rate: 6.29e-05
2025-12-09 21:01:00 - INFO - Epoch: 16.09, Step: 63750, Train Loss: 1.2788, Learning Rate: 6.29e-05
2025-12-09 21:01:11 - INFO - Epoch: 16.10, Step: 63760, Train Loss: 1.3422, Learning Rate: 6.29e-05
2025-12-09 21:01:23 - INFO - Epoch: 16.10, Step: 63770, Train Loss: 1.2948, Learning Rate: 6.29e-05
2025-12-09 21:01:34 - INFO - Epoch: 16.10, Step: 63780, Train Loss: 1.3433, Learning Rate: 6.29e-05
2025-12-09 21:01:45 - INFO - Epoch: 16.10, Step: 63790, Train Loss: 1.3205, Learning Rate: 6.29e-05
2025-12-09 21:01:56 - INFO - Epoch: 16.11, Step: 63800, Train Loss: 1.3327, Learning Rate: 6.29e-05
2025-12-09 21:02:07 - INFO - Epoch: 16.11, Step: 63810, Train Loss: 1.3288, Learning Rate: 6.29e-05
2025-12-09 21:02:18 - INFO - Epoch: 16.11, Step: 63820, Train Loss: 1.3054, Learning Rate: 6.29e-05
2025-12-09 21:02:30 - INFO - Epoch: 16.11, Step: 63830, Train Loss: 1.3318, Learning Rate: 6.29e-05
2025-12-09 21:02:41 - INFO - Epoch: 16.12, Step: 63840, Train Loss: 1.3254, Learning Rate: 6.29e-05
2025-12-09 21:02:52 - INFO - Epoch: 16.12, Step: 63850, Train Loss: 1.3164, Learning Rate: 6.28e-05
2025-12-09 21:03:03 - INFO - Epoch: 16.12, Step: 63860, Train Loss: 1.2981, Learning Rate: 6.28e-05
2025-12-09 21:03:14 - INFO - Epoch: 16.12, Step: 63870, Train Loss: 1.3561, Learning Rate: 6.28e-05
2025-12-09 21:03:25 - INFO - Epoch: 16.13, Step: 63880, Train Loss: 1.3062, Learning Rate: 6.28e-05
2025-12-09 21:03:36 - INFO - Epoch: 16.13, Step: 63890, Train Loss: 1.3294, Learning Rate: 6.28e-05
2025-12-09 21:03:48 - INFO - Epoch: 16.13, Step: 63900, Train Loss: 1.3241, Learning Rate: 6.28e-05
2025-12-09 21:03:59 - INFO - Epoch: 16.13, Step: 63910, Train Loss: 1.3235, Learning Rate: 6.28e-05
2025-12-09 21:04:10 - INFO - Epoch: 16.14, Step: 63920, Train Loss: 1.3499, Learning Rate: 6.28e-05
2025-12-09 21:04:21 - INFO - Epoch: 16.14, Step: 63930, Train Loss: 1.3586, Learning Rate: 6.28e-05
2025-12-09 21:04:32 - INFO - Epoch: 16.14, Step: 63940, Train Loss: 1.3093, Learning Rate: 6.28e-05
2025-12-09 21:04:43 - INFO - Epoch: 16.14, Step: 63950, Train Loss: 1.3504, Learning Rate: 6.28e-05
2025-12-09 21:04:55 - INFO - Epoch: 16.15, Step: 63960, Train Loss: 1.3003, Learning Rate: 6.28e-05
2025-12-09 21:05:06 - INFO - Epoch: 16.15, Step: 63970, Train Loss: 1.3608, Learning Rate: 6.28e-05
2025-12-09 21:05:17 - INFO - Epoch: 16.15, Step: 63980, Train Loss: 1.3047, Learning Rate: 6.28e-05
2025-12-09 21:05:28 - INFO - Epoch: 16.16, Step: 63990, Train Loss: 1.3544, Learning Rate: 6.28e-05
2025-12-09 21:05:39 - INFO - Epoch: 16.16, Step: 64000, Train Loss: 1.3259, Learning Rate: 6.27e-05
2025-12-09 21:05:50 - INFO - Epoch: 16.16, Step: 64010, Train Loss: 1.3525, Learning Rate: 6.27e-05
2025-12-09 21:06:01 - INFO - Epoch: 16.16, Step: 64020, Train Loss: 1.3070, Learning Rate: 6.27e-05
2025-12-09 21:06:13 - INFO - Epoch: 16.17, Step: 64030, Train Loss: 1.3428, Learning Rate: 6.27e-05
2025-12-09 21:06:24 - INFO - Epoch: 16.17, Step: 64040, Train Loss: 1.3146, Learning Rate: 6.27e-05
2025-12-09 21:06:35 - INFO - Epoch: 16.17, Step: 64050, Train Loss: 1.3229, Learning Rate: 6.27e-05
2025-12-09 21:06:46 - INFO - Epoch: 16.17, Step: 64060, Train Loss: 1.3236, Learning Rate: 6.27e-05
2025-12-09 21:06:57 - INFO - Epoch: 16.18, Step: 64070, Train Loss: 1.3369, Learning Rate: 6.27e-05
2025-12-09 21:07:08 - INFO - Epoch: 16.18, Step: 64080, Train Loss: 1.3307, Learning Rate: 6.27e-05
2025-12-09 21:07:19 - INFO - Epoch: 16.18, Step: 64090, Train Loss: 1.3243, Learning Rate: 6.27e-05
2025-12-09 21:07:31 - INFO - Epoch: 16.18, Step: 64100, Train Loss: 1.3259, Learning Rate: 6.27e-05
2025-12-09 21:07:42 - INFO - Epoch: 16.19, Step: 64110, Train Loss: 1.3574, Learning Rate: 6.27e-05
2025-12-09 21:07:53 - INFO - Epoch: 16.19, Step: 64120, Train Loss: 1.3548, Learning Rate: 6.27e-05
2025-12-09 21:08:04 - INFO - Epoch: 16.19, Step: 64130, Train Loss: 1.3197, Learning Rate: 6.27e-05
2025-12-09 21:08:15 - INFO - Epoch: 16.19, Step: 64140, Train Loss: 1.3507, Learning Rate: 6.27e-05
2025-12-09 21:08:26 - INFO - Epoch: 16.20, Step: 64150, Train Loss: 1.3632, Learning Rate: 6.26e-05
2025-12-09 21:08:38 - INFO - Epoch: 16.20, Step: 64160, Train Loss: 1.3188, Learning Rate: 6.26e-05
2025-12-09 21:08:49 - INFO - Epoch: 16.20, Step: 64170, Train Loss: 1.2949, Learning Rate: 6.26e-05
2025-12-09 21:09:00 - INFO - Epoch: 16.20, Step: 64180, Train Loss: 1.3689, Learning Rate: 6.26e-05
2025-12-09 21:09:11 - INFO - Epoch: 16.21, Step: 64190, Train Loss: 1.2958, Learning Rate: 6.26e-05
2025-12-09 21:09:22 - INFO - Epoch: 16.21, Step: 64200, Train Loss: 1.3003, Learning Rate: 6.26e-05
2025-12-09 21:09:33 - INFO - Epoch: 16.21, Step: 64210, Train Loss: 1.3100, Learning Rate: 6.26e-05
2025-12-09 21:09:44 - INFO - Epoch: 16.21, Step: 64220, Train Loss: 1.3346, Learning Rate: 6.26e-05
2025-12-09 21:09:56 - INFO - Epoch: 16.22, Step: 64230, Train Loss: 1.3219, Learning Rate: 6.26e-05
2025-12-09 21:10:07 - INFO - Epoch: 16.22, Step: 64240, Train Loss: 1.2866, Learning Rate: 6.26e-05
2025-12-09 21:10:18 - INFO - Epoch: 16.22, Step: 64250, Train Loss: 1.3135, Learning Rate: 6.26e-05
2025-12-09 21:10:29 - INFO - Epoch: 16.22, Step: 64260, Train Loss: 1.3037, Learning Rate: 6.26e-05
2025-12-09 21:10:40 - INFO - Epoch: 16.23, Step: 64270, Train Loss: 1.3228, Learning Rate: 6.26e-05
2025-12-09 21:10:51 - INFO - Epoch: 16.23, Step: 64280, Train Loss: 1.2881, Learning Rate: 6.26e-05
2025-12-09 21:11:03 - INFO - Epoch: 16.23, Step: 64290, Train Loss: 1.3431, Learning Rate: 6.26e-05
2025-12-09 21:11:14 - INFO - Epoch: 16.23, Step: 64300, Train Loss: 1.3493, Learning Rate: 6.25e-05
2025-12-09 21:11:25 - INFO - Epoch: 16.24, Step: 64310, Train Loss: 1.3095, Learning Rate: 6.25e-05
2025-12-09 21:11:36 - INFO - Epoch: 16.24, Step: 64320, Train Loss: 1.3291, Learning Rate: 6.25e-05
2025-12-09 21:11:47 - INFO - Epoch: 16.24, Step: 64330, Train Loss: 1.3479, Learning Rate: 6.25e-05
2025-12-09 21:11:58 - INFO - Epoch: 16.24, Step: 64340, Train Loss: 1.3145, Learning Rate: 6.25e-05
2025-12-09 21:12:09 - INFO - Epoch: 16.25, Step: 64350, Train Loss: 1.2986, Learning Rate: 6.25e-05
2025-12-09 21:12:21 - INFO - Epoch: 16.25, Step: 64360, Train Loss: 1.3561, Learning Rate: 6.25e-05
2025-12-09 21:12:32 - INFO - Epoch: 16.25, Step: 64370, Train Loss: 1.3576, Learning Rate: 6.25e-05
2025-12-09 21:12:43 - INFO - Epoch: 16.25, Step: 64380, Train Loss: 1.3136, Learning Rate: 6.25e-05
2025-12-09 21:12:54 - INFO - Epoch: 16.26, Step: 64390, Train Loss: 1.2994, Learning Rate: 6.25e-05
2025-12-09 21:13:05 - INFO - Epoch: 16.26, Step: 64400, Train Loss: 1.3272, Learning Rate: 6.25e-05
2025-12-09 21:13:16 - INFO - Epoch: 16.26, Step: 64410, Train Loss: 1.3203, Learning Rate: 6.25e-05
2025-12-09 21:13:28 - INFO - Epoch: 16.26, Step: 64420, Train Loss: 1.3266, Learning Rate: 6.25e-05
2025-12-09 21:13:39 - INFO - Epoch: 16.27, Step: 64430, Train Loss: 1.3196, Learning Rate: 6.25e-05
2025-12-09 21:13:50 - INFO - Epoch: 16.27, Step: 64440, Train Loss: 1.3152, Learning Rate: 6.25e-05
2025-12-09 21:14:01 - INFO - Epoch: 16.27, Step: 64450, Train Loss: 1.3381, Learning Rate: 6.24e-05
2025-12-09 21:14:12 - INFO - Epoch: 16.27, Step: 64460, Train Loss: 1.3008, Learning Rate: 6.24e-05
2025-12-09 21:14:23 - INFO - Epoch: 16.28, Step: 64470, Train Loss: 1.3286, Learning Rate: 6.24e-05
2025-12-09 21:14:34 - INFO - Epoch: 16.28, Step: 64480, Train Loss: 1.3107, Learning Rate: 6.24e-05
2025-12-09 21:14:46 - INFO - Epoch: 16.28, Step: 64490, Train Loss: 1.3083, Learning Rate: 6.24e-05
2025-12-09 21:14:57 - INFO - Epoch: 16.28, Step: 64500, Train Loss: 1.3355, Learning Rate: 6.24e-05
2025-12-09 21:15:08 - INFO - Epoch: 16.29, Step: 64510, Train Loss: 1.3260, Learning Rate: 6.24e-05
2025-12-09 21:15:19 - INFO - Epoch: 16.29, Step: 64520, Train Loss: 1.3398, Learning Rate: 6.24e-05
2025-12-09 21:15:30 - INFO - Epoch: 16.29, Step: 64530, Train Loss: 1.3068, Learning Rate: 6.24e-05
2025-12-09 21:15:41 - INFO - Epoch: 16.29, Step: 64540, Train Loss: 1.2849, Learning Rate: 6.24e-05
2025-12-09 21:15:53 - INFO - Epoch: 16.30, Step: 64550, Train Loss: 1.3122, Learning Rate: 6.24e-05
2025-12-09 21:16:04 - INFO - Epoch: 16.30, Step: 64560, Train Loss: 1.3451, Learning Rate: 6.24e-05
2025-12-09 21:16:15 - INFO - Epoch: 16.30, Step: 64570, Train Loss: 1.2833, Learning Rate: 6.24e-05
2025-12-09 21:16:26 - INFO - Epoch: 16.30, Step: 64580, Train Loss: 1.2669, Learning Rate: 6.24e-05
2025-12-09 21:16:37 - INFO - Epoch: 16.31, Step: 64590, Train Loss: 1.3131, Learning Rate: 6.24e-05
2025-12-09 21:16:48 - INFO - Epoch: 16.31, Step: 64600, Train Loss: 1.3417, Learning Rate: 6.23e-05
2025-12-09 21:16:59 - INFO - Epoch: 16.31, Step: 64610, Train Loss: 1.3115, Learning Rate: 6.23e-05
2025-12-09 21:17:11 - INFO - Epoch: 16.31, Step: 64620, Train Loss: 1.3064, Learning Rate: 6.23e-05
2025-12-09 21:17:22 - INFO - Epoch: 16.32, Step: 64630, Train Loss: 1.3259, Learning Rate: 6.23e-05
2025-12-09 21:17:33 - INFO - Epoch: 16.32, Step: 64640, Train Loss: 1.3326, Learning Rate: 6.23e-05
2025-12-09 21:17:44 - INFO - Epoch: 16.32, Step: 64650, Train Loss: 1.3067, Learning Rate: 6.23e-05
2025-12-09 21:17:55 - INFO - Epoch: 16.32, Step: 64660, Train Loss: 1.3101, Learning Rate: 6.23e-05
2025-12-09 21:18:06 - INFO - Epoch: 16.33, Step: 64670, Train Loss: 1.3221, Learning Rate: 6.23e-05
2025-12-09 21:18:18 - INFO - Epoch: 16.33, Step: 64680, Train Loss: 1.2919, Learning Rate: 6.23e-05
2025-12-09 21:18:29 - INFO - Epoch: 16.33, Step: 64690, Train Loss: 1.3152, Learning Rate: 6.23e-05
2025-12-09 21:18:40 - INFO - Epoch: 16.33, Step: 64700, Train Loss: 1.3205, Learning Rate: 6.23e-05
2025-12-09 21:18:51 - INFO - Epoch: 16.34, Step: 64710, Train Loss: 1.3453, Learning Rate: 6.23e-05
2025-12-09 21:19:02 - INFO - Epoch: 16.34, Step: 64720, Train Loss: 1.3577, Learning Rate: 6.23e-05
2025-12-09 21:19:13 - INFO - Epoch: 16.34, Step: 64730, Train Loss: 1.3119, Learning Rate: 6.23e-05
2025-12-09 21:19:24 - INFO - Epoch: 16.34, Step: 64740, Train Loss: 1.3312, Learning Rate: 6.23e-05
2025-12-09 21:19:36 - INFO - Epoch: 16.35, Step: 64750, Train Loss: 1.3137, Learning Rate: 6.22e-05
2025-12-09 21:19:47 - INFO - Epoch: 16.35, Step: 64760, Train Loss: 1.3303, Learning Rate: 6.22e-05
2025-12-09 21:19:58 - INFO - Epoch: 16.35, Step: 64770, Train Loss: 1.3159, Learning Rate: 6.22e-05
2025-12-09 21:20:09 - INFO - Epoch: 16.35, Step: 64780, Train Loss: 1.3523, Learning Rate: 6.22e-05
2025-12-09 21:20:20 - INFO - Epoch: 16.36, Step: 64790, Train Loss: 1.3017, Learning Rate: 6.22e-05
2025-12-09 21:20:31 - INFO - Epoch: 16.36, Step: 64800, Train Loss: 1.2930, Learning Rate: 6.22e-05
2025-12-09 21:20:43 - INFO - Epoch: 16.36, Step: 64810, Train Loss: 1.2965, Learning Rate: 6.22e-05
2025-12-09 21:20:54 - INFO - Epoch: 16.36, Step: 64820, Train Loss: 1.3080, Learning Rate: 6.22e-05
2025-12-09 21:21:05 - INFO - Epoch: 16.37, Step: 64830, Train Loss: 1.3276, Learning Rate: 6.22e-05
2025-12-09 21:21:16 - INFO - Epoch: 16.37, Step: 64840, Train Loss: 1.3222, Learning Rate: 6.22e-05
2025-12-09 21:21:27 - INFO - Epoch: 16.37, Step: 64850, Train Loss: 1.3471, Learning Rate: 6.22e-05
2025-12-09 21:21:38 - INFO - Epoch: 16.37, Step: 64860, Train Loss: 1.3376, Learning Rate: 6.22e-05
2025-12-09 21:21:49 - INFO - Epoch: 16.38, Step: 64870, Train Loss: 1.3225, Learning Rate: 6.22e-05
2025-12-09 21:22:01 - INFO - Epoch: 16.38, Step: 64880, Train Loss: 1.3366, Learning Rate: 6.22e-05
2025-12-09 21:22:12 - INFO - Epoch: 16.38, Step: 64890, Train Loss: 1.3104, Learning Rate: 6.22e-05
2025-12-09 21:22:23 - INFO - Epoch: 16.38, Step: 64900, Train Loss: 1.3249, Learning Rate: 6.21e-05
2025-12-09 21:22:34 - INFO - Epoch: 16.39, Step: 64910, Train Loss: 1.2876, Learning Rate: 6.21e-05
2025-12-09 21:22:45 - INFO - Epoch: 16.39, Step: 64920, Train Loss: 1.3320, Learning Rate: 6.21e-05
2025-12-09 21:22:56 - INFO - Epoch: 16.39, Step: 64930, Train Loss: 1.3582, Learning Rate: 6.21e-05
2025-12-09 21:23:08 - INFO - Epoch: 16.39, Step: 64940, Train Loss: 1.3237, Learning Rate: 6.21e-05
2025-12-09 21:23:19 - INFO - Epoch: 16.40, Step: 64950, Train Loss: 1.3268, Learning Rate: 6.21e-05
2025-12-09 21:23:30 - INFO - Epoch: 16.40, Step: 64960, Train Loss: 1.3265, Learning Rate: 6.21e-05
2025-12-09 21:23:41 - INFO - Epoch: 16.40, Step: 64970, Train Loss: 1.3362, Learning Rate: 6.21e-05
2025-12-09 21:23:52 - INFO - Epoch: 16.40, Step: 64980, Train Loss: 1.3002, Learning Rate: 6.21e-05
2025-12-09 21:24:03 - INFO - Epoch: 16.41, Step: 64990, Train Loss: 1.3012, Learning Rate: 6.21e-05
2025-12-09 21:24:14 - INFO - Epoch: 16.41, Step: 65000, Train Loss: 1.3173, Learning Rate: 6.21e-05
2025-12-09 21:24:26 - INFO - Epoch: 16.41, Step: 65010, Train Loss: 1.3392, Learning Rate: 6.21e-05
2025-12-09 21:24:37 - INFO - Epoch: 16.42, Step: 65020, Train Loss: 1.3186, Learning Rate: 6.21e-05
2025-12-09 21:24:48 - INFO - Epoch: 16.42, Step: 65030, Train Loss: 1.3081, Learning Rate: 6.21e-05
2025-12-09 21:24:59 - INFO - Epoch: 16.42, Step: 65040, Train Loss: 1.3433, Learning Rate: 6.21e-05
2025-12-09 21:25:10 - INFO - Epoch: 16.42, Step: 65050, Train Loss: 1.3152, Learning Rate: 6.20e-05
2025-12-09 21:25:21 - INFO - Epoch: 16.43, Step: 65060, Train Loss: 1.3160, Learning Rate: 6.20e-05
2025-12-09 21:25:33 - INFO - Epoch: 16.43, Step: 65070, Train Loss: 1.2917, Learning Rate: 6.20e-05
2025-12-09 21:25:44 - INFO - Epoch: 16.43, Step: 65080, Train Loss: 1.3014, Learning Rate: 6.20e-05
2025-12-09 21:25:55 - INFO - Epoch: 16.43, Step: 65090, Train Loss: 1.3082, Learning Rate: 6.20e-05
2025-12-09 21:26:06 - INFO - Epoch: 16.44, Step: 65100, Train Loss: 1.3425, Learning Rate: 6.20e-05
2025-12-09 21:26:17 - INFO - Epoch: 16.44, Step: 65110, Train Loss: 1.2978, Learning Rate: 6.20e-05
2025-12-09 21:26:28 - INFO - Epoch: 16.44, Step: 65120, Train Loss: 1.3520, Learning Rate: 6.20e-05
2025-12-09 21:26:39 - INFO - Epoch: 16.44, Step: 65130, Train Loss: 1.3175, Learning Rate: 6.20e-05
2025-12-09 21:26:51 - INFO - Epoch: 16.45, Step: 65140, Train Loss: 1.3174, Learning Rate: 6.20e-05
2025-12-09 21:27:02 - INFO - Epoch: 16.45, Step: 65150, Train Loss: 1.3337, Learning Rate: 6.20e-05
2025-12-09 21:27:13 - INFO - Epoch: 16.45, Step: 65160, Train Loss: 1.3083, Learning Rate: 6.20e-05
2025-12-09 21:27:24 - INFO - Epoch: 16.45, Step: 65170, Train Loss: 1.3448, Learning Rate: 6.20e-05
2025-12-09 21:27:35 - INFO - Epoch: 16.46, Step: 65180, Train Loss: 1.3361, Learning Rate: 6.20e-05
2025-12-09 21:27:46 - INFO - Epoch: 16.46, Step: 65190, Train Loss: 1.3449, Learning Rate: 6.20e-05
2025-12-09 21:27:57 - INFO - Epoch: 16.46, Step: 65200, Train Loss: 1.2958, Learning Rate: 6.19e-05
2025-12-09 21:28:09 - INFO - Epoch: 16.46, Step: 65210, Train Loss: 1.2967, Learning Rate: 6.19e-05
2025-12-09 21:28:20 - INFO - Epoch: 16.47, Step: 65220, Train Loss: 1.3346, Learning Rate: 6.19e-05
2025-12-09 21:28:31 - INFO - Epoch: 16.47, Step: 65230, Train Loss: 1.2643, Learning Rate: 6.19e-05
2025-12-09 21:28:42 - INFO - Epoch: 16.47, Step: 65240, Train Loss: 1.3329, Learning Rate: 6.19e-05
2025-12-09 21:28:53 - INFO - Epoch: 16.47, Step: 65250, Train Loss: 1.3038, Learning Rate: 6.19e-05
2025-12-09 21:29:04 - INFO - Epoch: 16.48, Step: 65260, Train Loss: 1.2947, Learning Rate: 6.19e-05
2025-12-09 21:29:16 - INFO - Epoch: 16.48, Step: 65270, Train Loss: 1.3291, Learning Rate: 6.19e-05
2025-12-09 21:29:27 - INFO - Epoch: 16.48, Step: 65280, Train Loss: 1.3076, Learning Rate: 6.19e-05
2025-12-09 21:29:38 - INFO - Epoch: 16.48, Step: 65290, Train Loss: 1.3209, Learning Rate: 6.19e-05
2025-12-09 21:29:49 - INFO - Epoch: 16.49, Step: 65300, Train Loss: 1.3203, Learning Rate: 6.19e-05
2025-12-09 21:30:00 - INFO - Epoch: 16.49, Step: 65310, Train Loss: 1.3548, Learning Rate: 6.19e-05
2025-12-09 21:30:11 - INFO - Epoch: 16.49, Step: 65320, Train Loss: 1.2866, Learning Rate: 6.19e-05
2025-12-09 21:30:22 - INFO - Epoch: 16.49, Step: 65330, Train Loss: 1.3046, Learning Rate: 6.19e-05
2025-12-09 21:30:34 - INFO - Epoch: 16.50, Step: 65340, Train Loss: 1.3088, Learning Rate: 6.19e-05
2025-12-09 21:30:45 - INFO - Epoch: 16.50, Step: 65350, Train Loss: 1.3232, Learning Rate: 6.18e-05
2025-12-09 21:30:56 - INFO - Epoch: 16.50, Step: 65360, Train Loss: 1.3476, Learning Rate: 6.18e-05
2025-12-09 21:31:07 - INFO - Epoch: 16.50, Step: 65370, Train Loss: 1.3275, Learning Rate: 6.18e-05
2025-12-09 21:31:18 - INFO - Epoch: 16.51, Step: 65380, Train Loss: 1.3366, Learning Rate: 6.18e-05
2025-12-09 21:31:29 - INFO - Epoch: 16.51, Step: 65390, Train Loss: 1.3381, Learning Rate: 6.18e-05
2025-12-09 21:31:41 - INFO - Epoch: 16.51, Step: 65400, Train Loss: 1.3500, Learning Rate: 6.18e-05
2025-12-09 21:31:52 - INFO - Epoch: 16.51, Step: 65410, Train Loss: 1.3183, Learning Rate: 6.18e-05
2025-12-09 21:32:03 - INFO - Epoch: 16.52, Step: 65420, Train Loss: 1.3342, Learning Rate: 6.18e-05
2025-12-09 21:32:14 - INFO - Epoch: 16.52, Step: 65430, Train Loss: 1.3108, Learning Rate: 6.18e-05
2025-12-09 21:32:25 - INFO - Epoch: 16.52, Step: 65440, Train Loss: 1.3131, Learning Rate: 6.18e-05
2025-12-09 21:32:36 - INFO - Epoch: 16.52, Step: 65450, Train Loss: 1.3210, Learning Rate: 6.18e-05
2025-12-09 21:32:47 - INFO - Epoch: 16.53, Step: 65460, Train Loss: 1.3125, Learning Rate: 6.18e-05
2025-12-09 21:32:59 - INFO - Epoch: 16.53, Step: 65470, Train Loss: 1.3102, Learning Rate: 6.18e-05
2025-12-09 21:33:10 - INFO - Epoch: 16.53, Step: 65480, Train Loss: 1.3524, Learning Rate: 6.18e-05
2025-12-09 21:33:21 - INFO - Epoch: 16.53, Step: 65490, Train Loss: 1.3151, Learning Rate: 6.18e-05
2025-12-09 21:33:32 - INFO - Epoch: 16.54, Step: 65500, Train Loss: 1.3384, Learning Rate: 6.17e-05
2025-12-09 21:33:43 - INFO - Epoch: 16.54, Step: 65510, Train Loss: 1.3192, Learning Rate: 6.17e-05
2025-12-09 21:33:54 - INFO - Epoch: 16.54, Step: 65520, Train Loss: 1.3363, Learning Rate: 6.17e-05
2025-12-09 21:34:06 - INFO - Epoch: 16.54, Step: 65530, Train Loss: 1.3430, Learning Rate: 6.17e-05
2025-12-09 21:34:17 - INFO - Epoch: 16.55, Step: 65540, Train Loss: 1.2986, Learning Rate: 6.17e-05
2025-12-09 21:34:28 - INFO - Epoch: 16.55, Step: 65550, Train Loss: 1.3226, Learning Rate: 6.17e-05
2025-12-09 21:34:39 - INFO - Epoch: 16.55, Step: 65560, Train Loss: 1.3147, Learning Rate: 6.17e-05
2025-12-09 21:34:50 - INFO - Epoch: 16.55, Step: 65570, Train Loss: 1.3154, Learning Rate: 6.17e-05
2025-12-09 21:35:01 - INFO - Epoch: 16.56, Step: 65580, Train Loss: 1.2718, Learning Rate: 6.17e-05
2025-12-09 21:35:12 - INFO - Epoch: 16.56, Step: 65590, Train Loss: 1.2826, Learning Rate: 6.17e-05
2025-12-09 21:35:24 - INFO - Epoch: 16.56, Step: 65600, Train Loss: 1.3561, Learning Rate: 6.17e-05
2025-12-09 21:35:35 - INFO - Epoch: 16.56, Step: 65610, Train Loss: 1.3275, Learning Rate: 6.17e-05
2025-12-09 21:35:46 - INFO - Epoch: 16.57, Step: 65620, Train Loss: 1.3059, Learning Rate: 6.17e-05
2025-12-09 21:35:57 - INFO - Epoch: 16.57, Step: 65630, Train Loss: 1.3396, Learning Rate: 6.17e-05
2025-12-09 21:36:08 - INFO - Epoch: 16.57, Step: 65640, Train Loss: 1.3191, Learning Rate: 6.17e-05
2025-12-09 21:36:19 - INFO - Epoch: 16.57, Step: 65650, Train Loss: 1.3329, Learning Rate: 6.16e-05
2025-12-09 21:36:31 - INFO - Epoch: 16.58, Step: 65660, Train Loss: 1.3467, Learning Rate: 6.16e-05
2025-12-09 21:36:42 - INFO - Epoch: 16.58, Step: 65670, Train Loss: 1.3223, Learning Rate: 6.16e-05
2025-12-09 21:36:53 - INFO - Epoch: 16.58, Step: 65680, Train Loss: 1.3204, Learning Rate: 6.16e-05
2025-12-09 21:37:04 - INFO - Epoch: 16.58, Step: 65690, Train Loss: 1.3267, Learning Rate: 6.16e-05
2025-12-09 21:37:15 - INFO - Epoch: 16.59, Step: 65700, Train Loss: 1.3197, Learning Rate: 6.16e-05
2025-12-09 21:37:26 - INFO - Epoch: 16.59, Step: 65710, Train Loss: 1.3279, Learning Rate: 6.16e-05
2025-12-09 21:37:37 - INFO - Epoch: 16.59, Step: 65720, Train Loss: 1.3129, Learning Rate: 6.16e-05
2025-12-09 21:37:49 - INFO - Epoch: 16.59, Step: 65730, Train Loss: 1.2913, Learning Rate: 6.16e-05
2025-12-09 21:38:00 - INFO - Epoch: 16.60, Step: 65740, Train Loss: 1.3099, Learning Rate: 6.16e-05
2025-12-09 21:38:11 - INFO - Epoch: 16.60, Step: 65750, Train Loss: 1.3331, Learning Rate: 6.16e-05
2025-12-09 21:38:22 - INFO - Epoch: 16.60, Step: 65760, Train Loss: 1.2590, Learning Rate: 6.16e-05
2025-12-09 21:38:33 - INFO - Epoch: 16.60, Step: 65770, Train Loss: 1.2870, Learning Rate: 6.16e-05
2025-12-09 21:38:44 - INFO - Epoch: 16.61, Step: 65780, Train Loss: 1.3530, Learning Rate: 6.16e-05
2025-12-09 21:38:56 - INFO - Epoch: 16.61, Step: 65790, Train Loss: 1.3199, Learning Rate: 6.16e-05
2025-12-09 21:39:07 - INFO - Epoch: 16.61, Step: 65800, Train Loss: 1.3033, Learning Rate: 6.15e-05
2025-12-09 21:39:18 - INFO - Epoch: 16.61, Step: 65810, Train Loss: 1.3078, Learning Rate: 6.15e-05
2025-12-09 21:39:29 - INFO - Epoch: 16.62, Step: 65820, Train Loss: 1.3302, Learning Rate: 6.15e-05
2025-12-09 21:39:40 - INFO - Epoch: 16.62, Step: 65830, Train Loss: 1.3039, Learning Rate: 6.15e-05
2025-12-09 21:39:51 - INFO - Epoch: 16.62, Step: 65840, Train Loss: 1.3123, Learning Rate: 6.15e-05
2025-12-09 21:40:02 - INFO - Epoch: 16.62, Step: 65850, Train Loss: 1.3381, Learning Rate: 6.15e-05
2025-12-09 21:40:14 - INFO - Epoch: 16.63, Step: 65860, Train Loss: 1.3039, Learning Rate: 6.15e-05
2025-12-09 21:40:25 - INFO - Epoch: 16.63, Step: 65870, Train Loss: 1.2987, Learning Rate: 6.15e-05
2025-12-09 21:40:36 - INFO - Epoch: 16.63, Step: 65880, Train Loss: 1.2874, Learning Rate: 6.15e-05
2025-12-09 21:40:47 - INFO - Epoch: 16.63, Step: 65890, Train Loss: 1.2777, Learning Rate: 6.15e-05
2025-12-09 21:40:58 - INFO - Epoch: 16.64, Step: 65900, Train Loss: 1.2944, Learning Rate: 6.15e-05
2025-12-09 21:41:09 - INFO - Epoch: 16.64, Step: 65910, Train Loss: 1.3382, Learning Rate: 6.15e-05
2025-12-09 21:41:21 - INFO - Epoch: 16.64, Step: 65920, Train Loss: 1.2633, Learning Rate: 6.15e-05
2025-12-09 21:41:32 - INFO - Epoch: 16.64, Step: 65930, Train Loss: 1.3092, Learning Rate: 6.15e-05
2025-12-09 21:41:43 - INFO - Epoch: 16.65, Step: 65940, Train Loss: 1.3328, Learning Rate: 6.15e-05
2025-12-09 21:41:54 - INFO - Epoch: 16.65, Step: 65950, Train Loss: 1.3580, Learning Rate: 6.14e-05
2025-12-09 21:42:05 - INFO - Epoch: 16.65, Step: 65960, Train Loss: 1.3273, Learning Rate: 6.14e-05
2025-12-09 21:42:16 - INFO - Epoch: 16.65, Step: 65970, Train Loss: 1.3031, Learning Rate: 6.14e-05
2025-12-09 21:42:27 - INFO - Epoch: 16.66, Step: 65980, Train Loss: 1.3267, Learning Rate: 6.14e-05
2025-12-09 21:42:39 - INFO - Epoch: 16.66, Step: 65990, Train Loss: 1.2799, Learning Rate: 6.14e-05
2025-12-09 21:42:50 - INFO - Epoch: 16.66, Step: 66000, Train Loss: 1.3062, Learning Rate: 6.14e-05
2025-12-09 21:43:01 - INFO - Epoch: 16.66, Step: 66010, Train Loss: 1.3069, Learning Rate: 6.14e-05
2025-12-09 21:43:12 - INFO - Epoch: 16.67, Step: 66020, Train Loss: 1.3462, Learning Rate: 6.14e-05
2025-12-09 21:43:23 - INFO - Epoch: 16.67, Step: 66030, Train Loss: 1.3269, Learning Rate: 6.14e-05
2025-12-09 21:43:34 - INFO - Epoch: 16.67, Step: 66040, Train Loss: 1.3044, Learning Rate: 6.14e-05
2025-12-09 21:43:46 - INFO - Epoch: 16.68, Step: 66050, Train Loss: 1.3414, Learning Rate: 6.14e-05
2025-12-09 21:43:57 - INFO - Epoch: 16.68, Step: 66060, Train Loss: 1.2838, Learning Rate: 6.14e-05
2025-12-09 21:44:08 - INFO - Epoch: 16.68, Step: 66070, Train Loss: 1.3248, Learning Rate: 6.14e-05
2025-12-09 21:44:19 - INFO - Epoch: 16.68, Step: 66080, Train Loss: 1.3245, Learning Rate: 6.14e-05
2025-12-09 21:44:30 - INFO - Epoch: 16.69, Step: 66090, Train Loss: 1.3073, Learning Rate: 6.14e-05
2025-12-09 21:44:41 - INFO - Epoch: 16.69, Step: 66100, Train Loss: 1.2998, Learning Rate: 6.13e-05
2025-12-09 21:44:52 - INFO - Epoch: 16.69, Step: 66110, Train Loss: 1.3526, Learning Rate: 6.13e-05
2025-12-09 21:45:04 - INFO - Epoch: 16.69, Step: 66120, Train Loss: 1.3050, Learning Rate: 6.13e-05
2025-12-09 21:45:15 - INFO - Epoch: 16.70, Step: 66130, Train Loss: 1.3121, Learning Rate: 6.13e-05
2025-12-09 21:45:26 - INFO - Epoch: 16.70, Step: 66140, Train Loss: 1.3013, Learning Rate: 6.13e-05
2025-12-09 21:45:37 - INFO - Epoch: 16.70, Step: 66150, Train Loss: 1.3421, Learning Rate: 6.13e-05
2025-12-09 21:45:48 - INFO - Epoch: 16.70, Step: 66160, Train Loss: 1.3269, Learning Rate: 6.13e-05
2025-12-09 21:45:59 - INFO - Epoch: 16.71, Step: 66170, Train Loss: 1.3337, Learning Rate: 6.13e-05
2025-12-09 21:46:11 - INFO - Epoch: 16.71, Step: 66180, Train Loss: 1.3324, Learning Rate: 6.13e-05
2025-12-09 21:46:22 - INFO - Epoch: 16.71, Step: 66190, Train Loss: 1.3486, Learning Rate: 6.13e-05
2025-12-09 21:46:33 - INFO - Epoch: 16.71, Step: 66200, Train Loss: 1.3139, Learning Rate: 6.13e-05
2025-12-09 21:46:44 - INFO - Epoch: 16.72, Step: 66210, Train Loss: 1.3089, Learning Rate: 6.13e-05
2025-12-09 21:46:55 - INFO - Epoch: 16.72, Step: 66220, Train Loss: 1.3033, Learning Rate: 6.13e-05
2025-12-09 21:47:06 - INFO - Epoch: 16.72, Step: 66230, Train Loss: 1.3080, Learning Rate: 6.13e-05
2025-12-09 21:47:17 - INFO - Epoch: 16.72, Step: 66240, Train Loss: 1.3458, Learning Rate: 6.13e-05
2025-12-09 21:47:29 - INFO - Epoch: 16.73, Step: 66250, Train Loss: 1.3155, Learning Rate: 6.12e-05
2025-12-09 21:47:40 - INFO - Epoch: 16.73, Step: 66260, Train Loss: 1.2717, Learning Rate: 6.12e-05
2025-12-09 21:47:51 - INFO - Epoch: 16.73, Step: 66270, Train Loss: 1.2845, Learning Rate: 6.12e-05
2025-12-09 21:48:02 - INFO - Epoch: 16.73, Step: 66280, Train Loss: 1.3114, Learning Rate: 6.12e-05
2025-12-09 21:48:13 - INFO - Epoch: 16.74, Step: 66290, Train Loss: 1.3057, Learning Rate: 6.12e-05
2025-12-09 21:48:24 - INFO - Epoch: 16.74, Step: 66300, Train Loss: 1.3285, Learning Rate: 6.12e-05
2025-12-09 21:48:35 - INFO - Epoch: 16.74, Step: 66310, Train Loss: 1.3133, Learning Rate: 6.12e-05
2025-12-09 21:48:47 - INFO - Epoch: 16.74, Step: 66320, Train Loss: 1.2905, Learning Rate: 6.12e-05
2025-12-09 21:48:58 - INFO - Epoch: 16.75, Step: 66330, Train Loss: 1.3115, Learning Rate: 6.12e-05
2025-12-09 21:49:09 - INFO - Epoch: 16.75, Step: 66340, Train Loss: 1.3240, Learning Rate: 6.12e-05
2025-12-09 21:49:20 - INFO - Epoch: 16.75, Step: 66350, Train Loss: 1.2690, Learning Rate: 6.12e-05
2025-12-09 21:49:31 - INFO - Epoch: 16.75, Step: 66360, Train Loss: 1.3207, Learning Rate: 6.12e-05
2025-12-09 21:49:42 - INFO - Epoch: 16.76, Step: 66370, Train Loss: 1.3210, Learning Rate: 6.12e-05
2025-12-09 21:49:54 - INFO - Epoch: 16.76, Step: 66380, Train Loss: 1.3306, Learning Rate: 6.12e-05
2025-12-09 21:50:05 - INFO - Epoch: 16.76, Step: 66390, Train Loss: 1.3067, Learning Rate: 6.12e-05
2025-12-09 21:50:16 - INFO - Epoch: 16.76, Step: 66400, Train Loss: 1.3152, Learning Rate: 6.11e-05
2025-12-09 21:50:27 - INFO - Epoch: 16.77, Step: 66410, Train Loss: 1.2857, Learning Rate: 6.11e-05
2025-12-09 21:50:38 - INFO - Epoch: 16.77, Step: 66420, Train Loss: 1.3234, Learning Rate: 6.11e-05
2025-12-09 21:50:49 - INFO - Epoch: 16.77, Step: 66430, Train Loss: 1.3154, Learning Rate: 6.11e-05
2025-12-09 21:51:00 - INFO - Epoch: 16.77, Step: 66440, Train Loss: 1.3351, Learning Rate: 6.11e-05
2025-12-09 21:51:12 - INFO - Epoch: 16.78, Step: 66450, Train Loss: 1.3419, Learning Rate: 6.11e-05
2025-12-09 21:51:23 - INFO - Epoch: 16.78, Step: 66460, Train Loss: 1.3012, Learning Rate: 6.11e-05
2025-12-09 21:51:34 - INFO - Epoch: 16.78, Step: 66470, Train Loss: 1.2900, Learning Rate: 6.11e-05
2025-12-09 21:51:45 - INFO - Epoch: 16.78, Step: 66480, Train Loss: 1.2894, Learning Rate: 6.11e-05
2025-12-09 21:51:56 - INFO - Epoch: 16.79, Step: 66490, Train Loss: 1.2764, Learning Rate: 6.11e-05
2025-12-09 21:52:07 - INFO - Epoch: 16.79, Step: 66500, Train Loss: 1.3487, Learning Rate: 6.11e-05
2025-12-09 21:52:19 - INFO - Epoch: 16.79, Step: 66510, Train Loss: 1.3436, Learning Rate: 6.11e-05
2025-12-09 21:52:30 - INFO - Epoch: 16.79, Step: 66520, Train Loss: 1.3172, Learning Rate: 6.11e-05
2025-12-09 21:52:41 - INFO - Epoch: 16.80, Step: 66530, Train Loss: 1.3119, Learning Rate: 6.11e-05
2025-12-09 21:52:52 - INFO - Epoch: 16.80, Step: 66540, Train Loss: 1.2914, Learning Rate: 6.11e-05
2025-12-09 21:53:03 - INFO - Epoch: 16.80, Step: 66550, Train Loss: 1.3112, Learning Rate: 6.10e-05
2025-12-09 21:53:14 - INFO - Epoch: 16.80, Step: 66560, Train Loss: 1.3331, Learning Rate: 6.10e-05
2025-12-09 21:53:25 - INFO - Epoch: 16.81, Step: 66570, Train Loss: 1.2932, Learning Rate: 6.10e-05
2025-12-09 21:53:37 - INFO - Epoch: 16.81, Step: 66580, Train Loss: 1.3428, Learning Rate: 6.10e-05
2025-12-09 21:53:48 - INFO - Epoch: 16.81, Step: 66590, Train Loss: 1.2951, Learning Rate: 6.10e-05
2025-12-09 21:53:59 - INFO - Epoch: 16.81, Step: 66600, Train Loss: 1.2809, Learning Rate: 6.10e-05
2025-12-09 21:54:10 - INFO - Epoch: 16.82, Step: 66610, Train Loss: 1.3223, Learning Rate: 6.10e-05
2025-12-09 21:54:21 - INFO - Epoch: 16.82, Step: 66620, Train Loss: 1.3184, Learning Rate: 6.10e-05
2025-12-09 21:54:32 - INFO - Epoch: 16.82, Step: 66630, Train Loss: 1.3175, Learning Rate: 6.10e-05
2025-12-09 21:54:44 - INFO - Epoch: 16.82, Step: 66640, Train Loss: 1.3199, Learning Rate: 6.10e-05
2025-12-09 21:54:55 - INFO - Epoch: 16.83, Step: 66650, Train Loss: 1.2880, Learning Rate: 6.10e-05
2025-12-09 21:55:06 - INFO - Epoch: 16.83, Step: 66660, Train Loss: 1.3266, Learning Rate: 6.10e-05
2025-12-09 21:55:17 - INFO - Epoch: 16.83, Step: 66670, Train Loss: 1.3370, Learning Rate: 6.10e-05
2025-12-09 21:55:28 - INFO - Epoch: 16.83, Step: 66680, Train Loss: 1.3252, Learning Rate: 6.10e-05
2025-12-09 21:55:39 - INFO - Epoch: 16.84, Step: 66690, Train Loss: 1.3274, Learning Rate: 6.10e-05
2025-12-09 21:55:50 - INFO - Epoch: 16.84, Step: 66700, Train Loss: 1.2908, Learning Rate: 6.10e-05
2025-12-09 21:56:02 - INFO - Epoch: 16.84, Step: 66710, Train Loss: 1.3437, Learning Rate: 6.09e-05
2025-12-09 21:56:13 - INFO - Epoch: 16.84, Step: 66720, Train Loss: 1.3423, Learning Rate: 6.09e-05
2025-12-09 21:56:24 - INFO - Epoch: 16.85, Step: 66730, Train Loss: 1.3308, Learning Rate: 6.09e-05
2025-12-09 21:56:35 - INFO - Epoch: 16.85, Step: 66740, Train Loss: 1.3509, Learning Rate: 6.09e-05
2025-12-09 21:56:46 - INFO - Epoch: 16.85, Step: 66750, Train Loss: 1.2940, Learning Rate: 6.09e-05
2025-12-09 21:56:57 - INFO - Epoch: 16.85, Step: 66760, Train Loss: 1.2838, Learning Rate: 6.09e-05
2025-12-09 21:57:09 - INFO - Epoch: 16.86, Step: 66770, Train Loss: 1.2602, Learning Rate: 6.09e-05
2025-12-09 21:57:20 - INFO - Epoch: 16.86, Step: 66780, Train Loss: 1.3088, Learning Rate: 6.09e-05
2025-12-09 21:57:31 - INFO - Epoch: 16.86, Step: 66790, Train Loss: 1.3045, Learning Rate: 6.09e-05
2025-12-09 21:57:42 - INFO - Epoch: 16.86, Step: 66800, Train Loss: 1.2868, Learning Rate: 6.09e-05
2025-12-09 21:57:53 - INFO - Epoch: 16.87, Step: 66810, Train Loss: 1.2964, Learning Rate: 6.09e-05
2025-12-09 21:58:04 - INFO - Epoch: 16.87, Step: 66820, Train Loss: 1.3279, Learning Rate: 6.09e-05
2025-12-09 21:58:15 - INFO - Epoch: 16.87, Step: 66830, Train Loss: 1.3065, Learning Rate: 6.09e-05
2025-12-09 21:58:27 - INFO - Epoch: 16.87, Step: 66840, Train Loss: 1.2819, Learning Rate: 6.09e-05
2025-12-09 21:58:38 - INFO - Epoch: 16.88, Step: 66850, Train Loss: 1.3086, Learning Rate: 6.09e-05
2025-12-09 21:58:49 - INFO - Epoch: 16.88, Step: 66860, Train Loss: 1.3092, Learning Rate: 6.08e-05
2025-12-09 21:59:00 - INFO - Epoch: 16.88, Step: 66870, Train Loss: 1.3324, Learning Rate: 6.08e-05
2025-12-09 21:59:11 - INFO - Epoch: 16.88, Step: 66880, Train Loss: 1.3444, Learning Rate: 6.08e-05
2025-12-09 21:59:22 - INFO - Epoch: 16.89, Step: 66890, Train Loss: 1.3578, Learning Rate: 6.08e-05
2025-12-09 21:59:34 - INFO - Epoch: 16.89, Step: 66900, Train Loss: 1.3085, Learning Rate: 6.08e-05
2025-12-09 21:59:45 - INFO - Epoch: 16.89, Step: 66910, Train Loss: 1.3229, Learning Rate: 6.08e-05
2025-12-09 21:59:56 - INFO - Epoch: 16.89, Step: 66920, Train Loss: 1.2955, Learning Rate: 6.08e-05
2025-12-09 22:00:07 - INFO - Epoch: 16.90, Step: 66930, Train Loss: 1.2877, Learning Rate: 6.08e-05
2025-12-09 22:00:18 - INFO - Epoch: 16.90, Step: 66940, Train Loss: 1.3397, Learning Rate: 6.08e-05
2025-12-09 22:00:29 - INFO - Epoch: 16.90, Step: 66950, Train Loss: 1.3474, Learning Rate: 6.08e-05
2025-12-09 22:00:40 - INFO - Epoch: 16.90, Step: 66960, Train Loss: 1.3144, Learning Rate: 6.08e-05
2025-12-09 22:00:52 - INFO - Epoch: 16.91, Step: 66970, Train Loss: 1.3231, Learning Rate: 6.08e-05
2025-12-09 22:01:03 - INFO - Epoch: 16.91, Step: 66980, Train Loss: 1.3095, Learning Rate: 6.08e-05
2025-12-09 22:01:14 - INFO - Epoch: 16.91, Step: 66990, Train Loss: 1.2822, Learning Rate: 6.08e-05
2025-12-09 22:01:25 - INFO - Epoch: 16.91, Step: 67000, Train Loss: 1.3303, Learning Rate: 6.08e-05
2025-12-09 22:01:36 - INFO - Epoch: 16.92, Step: 67010, Train Loss: 1.2748, Learning Rate: 6.07e-05
2025-12-09 22:01:47 - INFO - Epoch: 16.92, Step: 67020, Train Loss: 1.3633, Learning Rate: 6.07e-05
2025-12-09 22:01:59 - INFO - Epoch: 16.92, Step: 67030, Train Loss: 1.2871, Learning Rate: 6.07e-05
2025-12-09 22:02:10 - INFO - Epoch: 16.93, Step: 67040, Train Loss: 1.2922, Learning Rate: 6.07e-05
2025-12-09 22:02:21 - INFO - Epoch: 16.93, Step: 67050, Train Loss: 1.3480, Learning Rate: 6.07e-05
2025-12-09 22:02:32 - INFO - Epoch: 16.93, Step: 67060, Train Loss: 1.3448, Learning Rate: 6.07e-05
2025-12-09 22:02:43 - INFO - Epoch: 16.93, Step: 67070, Train Loss: 1.2914, Learning Rate: 6.07e-05
2025-12-09 22:02:54 - INFO - Epoch: 16.94, Step: 67080, Train Loss: 1.3372, Learning Rate: 6.07e-05
2025-12-09 22:03:05 - INFO - Epoch: 16.94, Step: 67090, Train Loss: 1.3221, Learning Rate: 6.07e-05
2025-12-09 22:03:17 - INFO - Epoch: 16.94, Step: 67100, Train Loss: 1.3172, Learning Rate: 6.07e-05
2025-12-09 22:03:28 - INFO - Epoch: 16.94, Step: 67110, Train Loss: 1.2847, Learning Rate: 6.07e-05
2025-12-09 22:03:39 - INFO - Epoch: 16.95, Step: 67120, Train Loss: 1.3072, Learning Rate: 6.07e-05
2025-12-09 22:03:50 - INFO - Epoch: 16.95, Step: 67130, Train Loss: 1.2904, Learning Rate: 6.07e-05
2025-12-09 22:04:01 - INFO - Epoch: 16.95, Step: 67140, Train Loss: 1.3111, Learning Rate: 6.07e-05
2025-12-09 22:04:12 - INFO - Epoch: 16.95, Step: 67150, Train Loss: 1.3080, Learning Rate: 6.07e-05
2025-12-09 22:04:24 - INFO - Epoch: 16.96, Step: 67160, Train Loss: 1.3673, Learning Rate: 6.06e-05
2025-12-09 22:04:35 - INFO - Epoch: 16.96, Step: 67170, Train Loss: 1.3226, Learning Rate: 6.06e-05
2025-12-09 22:04:46 - INFO - Epoch: 16.96, Step: 67180, Train Loss: 1.3231, Learning Rate: 6.06e-05
2025-12-09 22:04:57 - INFO - Epoch: 16.96, Step: 67190, Train Loss: 1.3380, Learning Rate: 6.06e-05
2025-12-09 22:05:08 - INFO - Epoch: 16.97, Step: 67200, Train Loss: 1.2424, Learning Rate: 6.06e-05
2025-12-09 22:05:19 - INFO - Epoch: 16.97, Step: 67210, Train Loss: 1.2676, Learning Rate: 6.06e-05
2025-12-09 22:05:30 - INFO - Epoch: 16.97, Step: 67220, Train Loss: 1.3091, Learning Rate: 6.06e-05
2025-12-09 22:05:42 - INFO - Epoch: 16.97, Step: 67230, Train Loss: 1.3207, Learning Rate: 6.06e-05
2025-12-09 22:05:53 - INFO - Epoch: 16.98, Step: 67240, Train Loss: 1.3093, Learning Rate: 6.06e-05
2025-12-09 22:06:04 - INFO - Epoch: 16.98, Step: 67250, Train Loss: 1.3035, Learning Rate: 6.06e-05
2025-12-09 22:06:15 - INFO - Epoch: 16.98, Step: 67260, Train Loss: 1.3216, Learning Rate: 6.06e-05
2025-12-09 22:06:26 - INFO - Epoch: 16.98, Step: 67270, Train Loss: 1.3431, Learning Rate: 6.06e-05
2025-12-09 22:06:37 - INFO - Epoch: 16.99, Step: 67280, Train Loss: 1.3352, Learning Rate: 6.06e-05
2025-12-09 22:06:49 - INFO - Epoch: 16.99, Step: 67290, Train Loss: 1.2716, Learning Rate: 6.06e-05
2025-12-09 22:07:00 - INFO - Epoch: 16.99, Step: 67300, Train Loss: 1.3322, Learning Rate: 6.06e-05
2025-12-09 22:07:11 - INFO - Epoch: 16.99, Step: 67310, Train Loss: 1.3039, Learning Rate: 6.05e-05
2025-12-09 22:07:22 - INFO - Epoch: 17.00, Step: 67320, Train Loss: 1.3266, Learning Rate: 6.05e-05
2025-12-09 22:07:33 - INFO - Epoch: 17.00, Step: 67330, Train Loss: 1.3197, Learning Rate: 6.05e-05
2025-12-09 22:07:44 - INFO - Epoch: 17.00, Step: 67340, Train Loss: 1.3096, Learning Rate: 6.05e-05
2025-12-09 22:07:55 - INFO - Epoch: 17.00, Step: 67350, Train Loss: 1.3276, Learning Rate: 6.05e-05
2025-12-09 22:08:07 - INFO - Epoch: 17.01, Step: 67360, Train Loss: 1.3379, Learning Rate: 6.05e-05
2025-12-09 22:08:18 - INFO - Epoch: 17.01, Step: 67370, Train Loss: 1.3365, Learning Rate: 6.05e-05
2025-12-09 22:08:29 - INFO - Epoch: 17.01, Step: 67380, Train Loss: 1.3438, Learning Rate: 6.05e-05
2025-12-09 22:08:40 - INFO - Epoch: 17.01, Step: 67390, Train Loss: 1.2963, Learning Rate: 6.05e-05
2025-12-09 22:08:51 - INFO - Epoch: 17.02, Step: 67400, Train Loss: 1.2916, Learning Rate: 6.05e-05
2025-12-09 22:09:02 - INFO - Epoch: 17.02, Step: 67410, Train Loss: 1.3076, Learning Rate: 6.05e-05
2025-12-09 22:09:13 - INFO - Epoch: 17.02, Step: 67420, Train Loss: 1.3065, Learning Rate: 6.05e-05
2025-12-09 22:09:25 - INFO - Epoch: 17.02, Step: 67430, Train Loss: 1.3054, Learning Rate: 6.05e-05
2025-12-09 22:09:36 - INFO - Epoch: 17.03, Step: 67440, Train Loss: 1.2966, Learning Rate: 6.05e-05
2025-12-09 22:09:47 - INFO - Epoch: 17.03, Step: 67450, Train Loss: 1.2802, Learning Rate: 6.05e-05
2025-12-09 22:09:58 - INFO - Epoch: 17.03, Step: 67460, Train Loss: 1.2825, Learning Rate: 6.04e-05
2025-12-09 22:10:09 - INFO - Epoch: 17.03, Step: 67470, Train Loss: 1.3224, Learning Rate: 6.04e-05
2025-12-09 22:10:20 - INFO - Epoch: 17.04, Step: 67480, Train Loss: 1.3309, Learning Rate: 6.04e-05
2025-12-09 22:10:32 - INFO - Epoch: 17.04, Step: 67490, Train Loss: 1.3094, Learning Rate: 6.04e-05
2025-12-09 22:10:43 - INFO - Epoch: 17.04, Step: 67500, Train Loss: 1.3014, Learning Rate: 6.04e-05
2025-12-09 22:10:54 - INFO - Epoch: 17.04, Step: 67510, Train Loss: 1.3371, Learning Rate: 6.04e-05
2025-12-09 22:11:05 - INFO - Epoch: 17.05, Step: 67520, Train Loss: 1.3065, Learning Rate: 6.04e-05
2025-12-09 22:11:16 - INFO - Epoch: 17.05, Step: 67530, Train Loss: 1.2930, Learning Rate: 6.04e-05
2025-12-09 22:11:27 - INFO - Epoch: 17.05, Step: 67540, Train Loss: 1.3349, Learning Rate: 6.04e-05
2025-12-09 22:11:38 - INFO - Epoch: 17.05, Step: 67550, Train Loss: 1.2983, Learning Rate: 6.04e-05
2025-12-09 22:11:50 - INFO - Epoch: 17.06, Step: 67560, Train Loss: 1.3193, Learning Rate: 6.04e-05
2025-12-09 22:12:01 - INFO - Epoch: 17.06, Step: 67570, Train Loss: 1.3324, Learning Rate: 6.04e-05
2025-12-09 22:12:12 - INFO - Epoch: 17.06, Step: 67580, Train Loss: 1.2756, Learning Rate: 6.04e-05
2025-12-09 22:12:23 - INFO - Epoch: 17.06, Step: 67590, Train Loss: 1.3438, Learning Rate: 6.04e-05
2025-12-09 22:12:34 - INFO - Epoch: 17.07, Step: 67600, Train Loss: 1.3322, Learning Rate: 6.04e-05
2025-12-09 22:12:45 - INFO - Epoch: 17.07, Step: 67610, Train Loss: 1.3456, Learning Rate: 6.03e-05
2025-12-09 22:12:57 - INFO - Epoch: 17.07, Step: 67620, Train Loss: 1.3111, Learning Rate: 6.03e-05
2025-12-09 22:13:08 - INFO - Epoch: 17.07, Step: 67630, Train Loss: 1.3383, Learning Rate: 6.03e-05
2025-12-09 22:13:19 - INFO - Epoch: 17.08, Step: 67640, Train Loss: 1.2967, Learning Rate: 6.03e-05
2025-12-09 22:13:30 - INFO - Epoch: 17.08, Step: 67650, Train Loss: 1.3046, Learning Rate: 6.03e-05
2025-12-09 22:13:41 - INFO - Epoch: 17.08, Step: 67660, Train Loss: 1.3007, Learning Rate: 6.03e-05
2025-12-09 22:13:52 - INFO - Epoch: 17.08, Step: 67670, Train Loss: 1.3419, Learning Rate: 6.03e-05
2025-12-09 22:14:03 - INFO - Epoch: 17.09, Step: 67680, Train Loss: 1.2635, Learning Rate: 6.03e-05
2025-12-09 22:14:15 - INFO - Epoch: 17.09, Step: 67690, Train Loss: 1.2909, Learning Rate: 6.03e-05
2025-12-09 22:14:26 - INFO - Epoch: 17.09, Step: 67700, Train Loss: 1.2900, Learning Rate: 6.03e-05
2025-12-09 22:14:37 - INFO - Epoch: 17.09, Step: 67710, Train Loss: 1.2956, Learning Rate: 6.03e-05
2025-12-09 22:14:48 - INFO - Epoch: 17.10, Step: 67720, Train Loss: 1.3255, Learning Rate: 6.03e-05
2025-12-09 22:14:59 - INFO - Epoch: 17.10, Step: 67730, Train Loss: 1.2709, Learning Rate: 6.03e-05
2025-12-09 22:15:10 - INFO - Epoch: 17.10, Step: 67740, Train Loss: 1.2855, Learning Rate: 6.03e-05
2025-12-09 22:15:21 - INFO - Epoch: 17.10, Step: 67750, Train Loss: 1.3084, Learning Rate: 6.03e-05
2025-12-09 22:15:33 - INFO - Epoch: 17.11, Step: 67760, Train Loss: 1.3467, Learning Rate: 6.02e-05
2025-12-09 22:15:44 - INFO - Epoch: 17.11, Step: 67770, Train Loss: 1.3187, Learning Rate: 6.02e-05
2025-12-09 22:15:55 - INFO - Epoch: 17.11, Step: 67780, Train Loss: 1.3215, Learning Rate: 6.02e-05
2025-12-09 22:16:06 - INFO - Epoch: 17.11, Step: 67790, Train Loss: 1.2943, Learning Rate: 6.02e-05
2025-12-09 22:16:17 - INFO - Epoch: 17.12, Step: 67800, Train Loss: 1.2824, Learning Rate: 6.02e-05
2025-12-09 22:16:28 - INFO - Epoch: 17.12, Step: 67810, Train Loss: 1.2853, Learning Rate: 6.02e-05
2025-12-09 22:16:40 - INFO - Epoch: 17.12, Step: 67820, Train Loss: 1.3250, Learning Rate: 6.02e-05
2025-12-09 22:16:51 - INFO - Epoch: 17.12, Step: 67830, Train Loss: 1.2784, Learning Rate: 6.02e-05
2025-12-09 22:17:02 - INFO - Epoch: 17.13, Step: 67840, Train Loss: 1.3279, Learning Rate: 6.02e-05
2025-12-09 22:17:13 - INFO - Epoch: 17.13, Step: 67850, Train Loss: 1.3246, Learning Rate: 6.02e-05
2025-12-09 22:17:24 - INFO - Epoch: 17.13, Step: 67860, Train Loss: 1.3242, Learning Rate: 6.02e-05
2025-12-09 22:17:35 - INFO - Epoch: 17.13, Step: 67870, Train Loss: 1.3119, Learning Rate: 6.02e-05
2025-12-09 22:17:46 - INFO - Epoch: 17.14, Step: 67880, Train Loss: 1.2938, Learning Rate: 6.02e-05
2025-12-09 22:17:58 - INFO - Epoch: 17.14, Step: 67890, Train Loss: 1.3076, Learning Rate: 6.02e-05
2025-12-09 22:18:09 - INFO - Epoch: 17.14, Step: 67900, Train Loss: 1.2729, Learning Rate: 6.02e-05
2025-12-09 22:18:20 - INFO - Epoch: 17.14, Step: 67910, Train Loss: 1.3066, Learning Rate: 6.01e-05
2025-12-09 22:18:31 - INFO - Epoch: 17.15, Step: 67920, Train Loss: 1.2831, Learning Rate: 6.01e-05
2025-12-09 22:18:42 - INFO - Epoch: 17.15, Step: 67930, Train Loss: 1.2927, Learning Rate: 6.01e-05
2025-12-09 22:18:53 - INFO - Epoch: 17.15, Step: 67940, Train Loss: 1.3230, Learning Rate: 6.01e-05
2025-12-09 22:19:05 - INFO - Epoch: 17.15, Step: 67950, Train Loss: 1.2884, Learning Rate: 6.01e-05
2025-12-09 22:19:16 - INFO - Epoch: 17.16, Step: 67960, Train Loss: 1.3171, Learning Rate: 6.01e-05
2025-12-09 22:19:27 - INFO - Epoch: 17.16, Step: 67970, Train Loss: 1.3024, Learning Rate: 6.01e-05
2025-12-09 22:19:38 - INFO - Epoch: 17.16, Step: 67980, Train Loss: 1.2926, Learning Rate: 6.01e-05
2025-12-09 22:19:49 - INFO - Epoch: 17.16, Step: 67990, Train Loss: 1.3077, Learning Rate: 6.01e-05
2025-12-09 22:20:00 - INFO - Epoch: 17.17, Step: 68000, Train Loss: 1.2865, Learning Rate: 6.01e-05
2025-12-09 22:20:11 - INFO - Epoch: 17.17, Step: 68010, Train Loss: 1.3070, Learning Rate: 6.01e-05
2025-12-09 22:20:23 - INFO - Epoch: 17.17, Step: 68020, Train Loss: 1.2772, Learning Rate: 6.01e-05
2025-12-09 22:20:34 - INFO - Epoch: 17.17, Step: 68030, Train Loss: 1.3080, Learning Rate: 6.01e-05
2025-12-09 22:20:45 - INFO - Epoch: 17.18, Step: 68040, Train Loss: 1.2930, Learning Rate: 6.01e-05
2025-12-09 22:20:56 - INFO - Epoch: 17.18, Step: 68050, Train Loss: 1.3376, Learning Rate: 6.01e-05
2025-12-09 22:21:07 - INFO - Epoch: 17.18, Step: 68060, Train Loss: 1.2932, Learning Rate: 6.00e-05
2025-12-09 22:21:18 - INFO - Epoch: 17.19, Step: 68070, Train Loss: 1.3092, Learning Rate: 6.00e-05
2025-12-09 22:21:29 - INFO - Epoch: 17.19, Step: 68080, Train Loss: 1.3393, Learning Rate: 6.00e-05
2025-12-09 22:21:41 - INFO - Epoch: 17.19, Step: 68090, Train Loss: 1.2956, Learning Rate: 6.00e-05
2025-12-09 22:21:52 - INFO - Epoch: 17.19, Step: 68100, Train Loss: 1.3124, Learning Rate: 6.00e-05
2025-12-09 22:22:03 - INFO - Epoch: 17.20, Step: 68110, Train Loss: 1.3222, Learning Rate: 6.00e-05
2025-12-09 22:22:14 - INFO - Epoch: 17.20, Step: 68120, Train Loss: 1.3403, Learning Rate: 6.00e-05
2025-12-09 22:22:25 - INFO - Epoch: 17.20, Step: 68130, Train Loss: 1.2943, Learning Rate: 6.00e-05
2025-12-09 22:22:36 - INFO - Epoch: 17.20, Step: 68140, Train Loss: 1.3116, Learning Rate: 6.00e-05
2025-12-09 22:22:48 - INFO - Epoch: 17.21, Step: 68150, Train Loss: 1.3107, Learning Rate: 6.00e-05
2025-12-09 22:22:59 - INFO - Epoch: 17.21, Step: 68160, Train Loss: 1.3172, Learning Rate: 6.00e-05
2025-12-09 22:23:10 - INFO - Epoch: 17.21, Step: 68170, Train Loss: 1.2908, Learning Rate: 6.00e-05
2025-12-09 22:23:21 - INFO - Epoch: 17.21, Step: 68180, Train Loss: 1.3053, Learning Rate: 6.00e-05
2025-12-09 22:23:32 - INFO - Epoch: 17.22, Step: 68190, Train Loss: 1.3308, Learning Rate: 6.00e-05
2025-12-09 22:23:43 - INFO - Epoch: 17.22, Step: 68200, Train Loss: 1.3294, Learning Rate: 6.00e-05
2025-12-09 22:23:54 - INFO - Epoch: 17.22, Step: 68210, Train Loss: 1.2771, Learning Rate: 5.99e-05
2025-12-09 22:24:06 - INFO - Epoch: 17.22, Step: 68220, Train Loss: 1.3117, Learning Rate: 5.99e-05
2025-12-09 22:24:17 - INFO - Epoch: 17.23, Step: 68230, Train Loss: 1.3157, Learning Rate: 5.99e-05
2025-12-09 22:24:28 - INFO - Epoch: 17.23, Step: 68240, Train Loss: 1.3125, Learning Rate: 5.99e-05
2025-12-09 22:24:39 - INFO - Epoch: 17.23, Step: 68250, Train Loss: 1.3289, Learning Rate: 5.99e-05
2025-12-09 22:24:50 - INFO - Epoch: 17.23, Step: 68260, Train Loss: 1.2892, Learning Rate: 5.99e-05
2025-12-09 22:25:01 - INFO - Epoch: 17.24, Step: 68270, Train Loss: 1.3419, Learning Rate: 5.99e-05
2025-12-09 22:25:13 - INFO - Epoch: 17.24, Step: 68280, Train Loss: 1.3124, Learning Rate: 5.99e-05
2025-12-09 22:25:24 - INFO - Epoch: 17.24, Step: 68290, Train Loss: 1.2864, Learning Rate: 5.99e-05
2025-12-09 22:25:35 - INFO - Epoch: 17.24, Step: 68300, Train Loss: 1.3109, Learning Rate: 5.99e-05
2025-12-09 22:25:46 - INFO - Epoch: 17.25, Step: 68310, Train Loss: 1.2775, Learning Rate: 5.99e-05
2025-12-09 22:25:57 - INFO - Epoch: 17.25, Step: 68320, Train Loss: 1.3038, Learning Rate: 5.99e-05
2025-12-09 22:26:08 - INFO - Epoch: 17.25, Step: 68330, Train Loss: 1.3422, Learning Rate: 5.99e-05
2025-12-09 22:26:19 - INFO - Epoch: 17.25, Step: 68340, Train Loss: 1.3122, Learning Rate: 5.99e-05
2025-12-09 22:26:31 - INFO - Epoch: 17.26, Step: 68350, Train Loss: 1.3104, Learning Rate: 5.99e-05
2025-12-09 22:26:42 - INFO - Epoch: 17.26, Step: 68360, Train Loss: 1.3143, Learning Rate: 5.98e-05
2025-12-09 22:26:53 - INFO - Epoch: 17.26, Step: 68370, Train Loss: 1.3087, Learning Rate: 5.98e-05
2025-12-09 22:27:04 - INFO - Epoch: 17.26, Step: 68380, Train Loss: 1.2934, Learning Rate: 5.98e-05
2025-12-09 22:27:15 - INFO - Epoch: 17.27, Step: 68390, Train Loss: 1.3037, Learning Rate: 5.98e-05
2025-12-09 22:27:26 - INFO - Epoch: 17.27, Step: 68400, Train Loss: 1.3272, Learning Rate: 5.98e-05
2025-12-09 22:27:37 - INFO - Epoch: 17.27, Step: 68410, Train Loss: 1.3277, Learning Rate: 5.98e-05
2025-12-09 22:27:49 - INFO - Epoch: 17.27, Step: 68420, Train Loss: 1.3153, Learning Rate: 5.98e-05
2025-12-09 22:28:00 - INFO - Epoch: 17.28, Step: 68430, Train Loss: 1.2577, Learning Rate: 5.98e-05
2025-12-09 22:28:11 - INFO - Epoch: 17.28, Step: 68440, Train Loss: 1.3076, Learning Rate: 5.98e-05
2025-12-09 22:28:22 - INFO - Epoch: 17.28, Step: 68450, Train Loss: 1.3029, Learning Rate: 5.98e-05
2025-12-09 22:28:33 - INFO - Epoch: 17.28, Step: 68460, Train Loss: 1.2794, Learning Rate: 5.98e-05
2025-12-09 22:28:44 - INFO - Epoch: 17.29, Step: 68470, Train Loss: 1.2806, Learning Rate: 5.98e-05
2025-12-09 22:28:56 - INFO - Epoch: 17.29, Step: 68480, Train Loss: 1.3006, Learning Rate: 5.98e-05
2025-12-09 22:29:07 - INFO - Epoch: 17.29, Step: 68490, Train Loss: 1.3245, Learning Rate: 5.98e-05
2025-12-09 22:29:18 - INFO - Epoch: 17.29, Step: 68500, Train Loss: 1.3106, Learning Rate: 5.98e-05
2025-12-09 22:29:29 - INFO - Epoch: 17.30, Step: 68510, Train Loss: 1.2864, Learning Rate: 5.97e-05
2025-12-09 22:29:40 - INFO - Epoch: 17.30, Step: 68520, Train Loss: 1.3112, Learning Rate: 5.97e-05
2025-12-09 22:29:51 - INFO - Epoch: 17.30, Step: 68530, Train Loss: 1.2972, Learning Rate: 5.97e-05
2025-12-09 22:30:02 - INFO - Epoch: 17.30, Step: 68540, Train Loss: 1.3152, Learning Rate: 5.97e-05
2025-12-09 22:30:14 - INFO - Epoch: 17.31, Step: 68550, Train Loss: 1.2886, Learning Rate: 5.97e-05
2025-12-09 22:30:25 - INFO - Epoch: 17.31, Step: 68560, Train Loss: 1.3007, Learning Rate: 5.97e-05
2025-12-09 22:30:36 - INFO - Epoch: 17.31, Step: 68570, Train Loss: 1.3009, Learning Rate: 5.97e-05
2025-12-09 22:30:47 - INFO - Epoch: 17.31, Step: 68580, Train Loss: 1.3227, Learning Rate: 5.97e-05
2025-12-09 22:30:58 - INFO - Epoch: 17.32, Step: 68590, Train Loss: 1.3030, Learning Rate: 5.97e-05
2025-12-09 22:31:09 - INFO - Epoch: 17.32, Step: 68600, Train Loss: 1.2939, Learning Rate: 5.97e-05
2025-12-09 22:31:21 - INFO - Epoch: 17.32, Step: 68610, Train Loss: 1.3244, Learning Rate: 5.97e-05
2025-12-09 22:31:32 - INFO - Epoch: 17.32, Step: 68620, Train Loss: 1.3010, Learning Rate: 5.97e-05
2025-12-09 22:31:43 - INFO - Epoch: 17.33, Step: 68630, Train Loss: 1.3025, Learning Rate: 5.97e-05
2025-12-09 22:31:54 - INFO - Epoch: 17.33, Step: 68640, Train Loss: 1.3178, Learning Rate: 5.97e-05
2025-12-09 22:32:05 - INFO - Epoch: 17.33, Step: 68650, Train Loss: 1.2934, Learning Rate: 5.97e-05
2025-12-09 22:32:16 - INFO - Epoch: 17.33, Step: 68660, Train Loss: 1.3327, Learning Rate: 5.96e-05
2025-12-09 22:32:27 - INFO - Epoch: 17.34, Step: 68670, Train Loss: 1.2865, Learning Rate: 5.96e-05
2025-12-09 22:32:39 - INFO - Epoch: 17.34, Step: 68680, Train Loss: 1.3413, Learning Rate: 5.96e-05
2025-12-09 22:32:50 - INFO - Epoch: 17.34, Step: 68690, Train Loss: 1.2951, Learning Rate: 5.96e-05
2025-12-09 22:33:01 - INFO - Epoch: 17.34, Step: 68700, Train Loss: 1.3075, Learning Rate: 5.96e-05
2025-12-09 22:33:12 - INFO - Epoch: 17.35, Step: 68710, Train Loss: 1.2915, Learning Rate: 5.96e-05
2025-12-09 22:33:23 - INFO - Epoch: 17.35, Step: 68720, Train Loss: 1.2824, Learning Rate: 5.96e-05
2025-12-09 22:33:34 - INFO - Epoch: 17.35, Step: 68730, Train Loss: 1.2756, Learning Rate: 5.96e-05
2025-12-09 22:33:45 - INFO - Epoch: 17.35, Step: 68740, Train Loss: 1.3181, Learning Rate: 5.96e-05
2025-12-09 22:33:57 - INFO - Epoch: 17.36, Step: 68750, Train Loss: 1.3013, Learning Rate: 5.96e-05
2025-12-09 22:34:08 - INFO - Epoch: 17.36, Step: 68760, Train Loss: 1.3070, Learning Rate: 5.96e-05
2025-12-09 22:34:19 - INFO - Epoch: 17.36, Step: 68770, Train Loss: 1.3219, Learning Rate: 5.96e-05
2025-12-09 22:34:30 - INFO - Epoch: 17.36, Step: 68780, Train Loss: 1.3293, Learning Rate: 5.96e-05
2025-12-09 22:34:41 - INFO - Epoch: 17.37, Step: 68790, Train Loss: 1.2803, Learning Rate: 5.96e-05
2025-12-09 22:34:52 - INFO - Epoch: 17.37, Step: 68800, Train Loss: 1.2433, Learning Rate: 5.96e-05
2025-12-09 22:35:04 - INFO - Epoch: 17.37, Step: 68810, Train Loss: 1.2824, Learning Rate: 5.95e-05
2025-12-09 22:35:15 - INFO - Epoch: 17.37, Step: 68820, Train Loss: 1.3396, Learning Rate: 5.95e-05
2025-12-09 22:35:26 - INFO - Epoch: 17.38, Step: 68830, Train Loss: 1.3164, Learning Rate: 5.95e-05
2025-12-09 22:35:37 - INFO - Epoch: 17.38, Step: 68840, Train Loss: 1.3349, Learning Rate: 5.95e-05
2025-12-09 22:35:48 - INFO - Epoch: 17.38, Step: 68850, Train Loss: 1.2850, Learning Rate: 5.95e-05
2025-12-09 22:35:59 - INFO - Epoch: 17.38, Step: 68860, Train Loss: 1.3211, Learning Rate: 5.95e-05
2025-12-09 22:36:10 - INFO - Epoch: 17.39, Step: 68870, Train Loss: 1.3109, Learning Rate: 5.95e-05
2025-12-09 22:36:22 - INFO - Epoch: 17.39, Step: 68880, Train Loss: 1.3199, Learning Rate: 5.95e-05
2025-12-09 22:36:33 - INFO - Epoch: 17.39, Step: 68890, Train Loss: 1.3161, Learning Rate: 5.95e-05
2025-12-09 22:36:44 - INFO - Epoch: 17.39, Step: 68900, Train Loss: 1.2656, Learning Rate: 5.95e-05
2025-12-09 22:36:55 - INFO - Epoch: 17.40, Step: 68910, Train Loss: 1.3216, Learning Rate: 5.95e-05
2025-12-09 22:37:06 - INFO - Epoch: 17.40, Step: 68920, Train Loss: 1.2899, Learning Rate: 5.95e-05
2025-12-09 22:37:17 - INFO - Epoch: 17.40, Step: 68930, Train Loss: 1.3026, Learning Rate: 5.95e-05
2025-12-09 22:37:29 - INFO - Epoch: 17.40, Step: 68940, Train Loss: 1.3289, Learning Rate: 5.95e-05
2025-12-09 22:37:40 - INFO - Epoch: 17.41, Step: 68950, Train Loss: 1.2775, Learning Rate: 5.95e-05
2025-12-09 22:37:51 - INFO - Epoch: 17.41, Step: 68960, Train Loss: 1.2747, Learning Rate: 5.94e-05
2025-12-09 22:38:02 - INFO - Epoch: 17.41, Step: 68970, Train Loss: 1.2582, Learning Rate: 5.94e-05
2025-12-09 22:38:13 - INFO - Epoch: 17.41, Step: 68980, Train Loss: 1.3096, Learning Rate: 5.94e-05
2025-12-09 22:38:24 - INFO - Epoch: 17.42, Step: 68990, Train Loss: 1.2845, Learning Rate: 5.94e-05
2025-12-09 22:38:35 - INFO - Epoch: 17.42, Step: 69000, Train Loss: 1.2692, Learning Rate: 5.94e-05
2025-12-09 22:38:47 - INFO - Epoch: 17.42, Step: 69010, Train Loss: 1.3275, Learning Rate: 5.94e-05
2025-12-09 22:38:58 - INFO - Epoch: 17.42, Step: 69020, Train Loss: 1.2827, Learning Rate: 5.94e-05
2025-12-09 22:39:09 - INFO - Epoch: 17.43, Step: 69030, Train Loss: 1.3040, Learning Rate: 5.94e-05
2025-12-09 22:39:20 - INFO - Epoch: 17.43, Step: 69040, Train Loss: 1.3159, Learning Rate: 5.94e-05
2025-12-09 22:39:31 - INFO - Epoch: 17.43, Step: 69050, Train Loss: 1.2803, Learning Rate: 5.94e-05
2025-12-09 22:39:42 - INFO - Epoch: 17.43, Step: 69060, Train Loss: 1.3238, Learning Rate: 5.94e-05
2025-12-09 22:39:54 - INFO - Epoch: 17.44, Step: 69070, Train Loss: 1.3233, Learning Rate: 5.94e-05
2025-12-09 22:40:05 - INFO - Epoch: 17.44, Step: 69080, Train Loss: 1.3019, Learning Rate: 5.94e-05
2025-12-09 22:40:16 - INFO - Epoch: 17.44, Step: 69090, Train Loss: 1.2987, Learning Rate: 5.94e-05
2025-12-09 22:40:27 - INFO - Epoch: 17.45, Step: 69100, Train Loss: 1.2962, Learning Rate: 5.94e-05
2025-12-09 22:40:38 - INFO - Epoch: 17.45, Step: 69110, Train Loss: 1.3204, Learning Rate: 5.93e-05
2025-12-09 22:40:49 - INFO - Epoch: 17.45, Step: 69120, Train Loss: 1.2784, Learning Rate: 5.93e-05
2025-12-09 22:41:00 - INFO - Epoch: 17.45, Step: 69130, Train Loss: 1.2642, Learning Rate: 5.93e-05
2025-12-09 22:41:12 - INFO - Epoch: 17.46, Step: 69140, Train Loss: 1.2956, Learning Rate: 5.93e-05
2025-12-09 22:41:23 - INFO - Epoch: 17.46, Step: 69150, Train Loss: 1.3190, Learning Rate: 5.93e-05
2025-12-09 22:41:34 - INFO - Epoch: 17.46, Step: 69160, Train Loss: 1.3246, Learning Rate: 5.93e-05
2025-12-09 22:41:45 - INFO - Epoch: 17.46, Step: 69170, Train Loss: 1.3299, Learning Rate: 5.93e-05
2025-12-09 22:41:56 - INFO - Epoch: 17.47, Step: 69180, Train Loss: 1.3000, Learning Rate: 5.93e-05
2025-12-09 22:42:07 - INFO - Epoch: 17.47, Step: 69190, Train Loss: 1.2925, Learning Rate: 5.93e-05
2025-12-09 22:42:18 - INFO - Epoch: 17.47, Step: 69200, Train Loss: 1.3199, Learning Rate: 5.93e-05
2025-12-09 22:42:30 - INFO - Epoch: 17.47, Step: 69210, Train Loss: 1.2786, Learning Rate: 5.93e-05
2025-12-09 22:42:41 - INFO - Epoch: 17.48, Step: 69220, Train Loss: 1.3190, Learning Rate: 5.93e-05
2025-12-09 22:42:52 - INFO - Epoch: 17.48, Step: 69230, Train Loss: 1.2791, Learning Rate: 5.93e-05
2025-12-09 22:43:03 - INFO - Epoch: 17.48, Step: 69240, Train Loss: 1.3157, Learning Rate: 5.93e-05
2025-12-09 22:43:14 - INFO - Epoch: 17.48, Step: 69250, Train Loss: 1.3081, Learning Rate: 5.93e-05
2025-12-09 22:43:25 - INFO - Epoch: 17.49, Step: 69260, Train Loss: 1.3125, Learning Rate: 5.92e-05
2025-12-09 22:43:37 - INFO - Epoch: 17.49, Step: 69270, Train Loss: 1.3103, Learning Rate: 5.92e-05
2025-12-09 22:43:48 - INFO - Epoch: 17.49, Step: 69280, Train Loss: 1.3050, Learning Rate: 5.92e-05
2025-12-09 22:43:59 - INFO - Epoch: 17.49, Step: 69290, Train Loss: 1.2620, Learning Rate: 5.92e-05
2025-12-09 22:44:10 - INFO - Epoch: 17.50, Step: 69300, Train Loss: 1.3007, Learning Rate: 5.92e-05
2025-12-09 22:44:21 - INFO - Epoch: 17.50, Step: 69310, Train Loss: 1.2382, Learning Rate: 5.92e-05
2025-12-09 22:44:32 - INFO - Epoch: 17.50, Step: 69320, Train Loss: 1.3247, Learning Rate: 5.92e-05
2025-12-09 22:44:43 - INFO - Epoch: 17.50, Step: 69330, Train Loss: 1.3235, Learning Rate: 5.92e-05
2025-12-09 22:44:55 - INFO - Epoch: 17.51, Step: 69340, Train Loss: 1.2988, Learning Rate: 5.92e-05
2025-12-09 22:45:06 - INFO - Epoch: 17.51, Step: 69350, Train Loss: 1.3075, Learning Rate: 5.92e-05
2025-12-09 22:45:17 - INFO - Epoch: 17.51, Step: 69360, Train Loss: 1.3145, Learning Rate: 5.92e-05
2025-12-09 22:45:28 - INFO - Epoch: 17.51, Step: 69370, Train Loss: 1.3209, Learning Rate: 5.92e-05
2025-12-09 22:45:39 - INFO - Epoch: 17.52, Step: 69380, Train Loss: 1.3072, Learning Rate: 5.92e-05
2025-12-09 22:45:50 - INFO - Epoch: 17.52, Step: 69390, Train Loss: 1.3387, Learning Rate: 5.92e-05
2025-12-09 22:46:02 - INFO - Epoch: 17.52, Step: 69400, Train Loss: 1.2894, Learning Rate: 5.92e-05
2025-12-09 22:46:13 - INFO - Epoch: 17.52, Step: 69410, Train Loss: 1.3220, Learning Rate: 5.91e-05
2025-12-09 22:46:24 - INFO - Epoch: 17.53, Step: 69420, Train Loss: 1.3004, Learning Rate: 5.91e-05
2025-12-09 22:46:35 - INFO - Epoch: 17.53, Step: 69430, Train Loss: 1.3133, Learning Rate: 5.91e-05
2025-12-09 22:46:46 - INFO - Epoch: 17.53, Step: 69440, Train Loss: 1.2781, Learning Rate: 5.91e-05
2025-12-09 22:46:57 - INFO - Epoch: 17.53, Step: 69450, Train Loss: 1.3185, Learning Rate: 5.91e-05
2025-12-09 22:47:08 - INFO - Epoch: 17.54, Step: 69460, Train Loss: 1.3014, Learning Rate: 5.91e-05
2025-12-09 22:47:20 - INFO - Epoch: 17.54, Step: 69470, Train Loss: 1.2958, Learning Rate: 5.91e-05
2025-12-09 22:47:31 - INFO - Epoch: 17.54, Step: 69480, Train Loss: 1.2943, Learning Rate: 5.91e-05
2025-12-09 22:47:42 - INFO - Epoch: 17.54, Step: 69490, Train Loss: 1.2937, Learning Rate: 5.91e-05
2025-12-09 22:47:53 - INFO - Epoch: 17.55, Step: 69500, Train Loss: 1.3174, Learning Rate: 5.91e-05
2025-12-09 22:48:04 - INFO - Epoch: 17.55, Step: 69510, Train Loss: 1.3379, Learning Rate: 5.91e-05
2025-12-09 22:48:15 - INFO - Epoch: 17.55, Step: 69520, Train Loss: 1.3084, Learning Rate: 5.91e-05
2025-12-09 22:48:26 - INFO - Epoch: 17.55, Step: 69530, Train Loss: 1.3309, Learning Rate: 5.91e-05
2025-12-09 22:48:38 - INFO - Epoch: 17.56, Step: 69540, Train Loss: 1.2673, Learning Rate: 5.91e-05
2025-12-09 22:48:49 - INFO - Epoch: 17.56, Step: 69550, Train Loss: 1.2874, Learning Rate: 5.91e-05
2025-12-09 22:49:00 - INFO - Epoch: 17.56, Step: 69560, Train Loss: 1.2952, Learning Rate: 5.91e-05
2025-12-09 22:49:11 - INFO - Epoch: 17.56, Step: 69570, Train Loss: 1.3052, Learning Rate: 5.90e-05
2025-12-09 22:49:22 - INFO - Epoch: 17.57, Step: 69580, Train Loss: 1.2697, Learning Rate: 5.90e-05
2025-12-09 22:49:33 - INFO - Epoch: 17.57, Step: 69590, Train Loss: 1.3055, Learning Rate: 5.90e-05
2025-12-09 22:49:45 - INFO - Epoch: 17.57, Step: 69600, Train Loss: 1.2894, Learning Rate: 5.90e-05
2025-12-09 22:49:56 - INFO - Epoch: 17.57, Step: 69610, Train Loss: 1.3060, Learning Rate: 5.90e-05
2025-12-09 22:50:07 - INFO - Epoch: 17.58, Step: 69620, Train Loss: 1.2875, Learning Rate: 5.90e-05
2025-12-09 22:50:18 - INFO - Epoch: 17.58, Step: 69630, Train Loss: 1.3034, Learning Rate: 5.90e-05
2025-12-09 22:50:29 - INFO - Epoch: 17.58, Step: 69640, Train Loss: 1.3275, Learning Rate: 5.90e-05
2025-12-09 22:50:40 - INFO - Epoch: 17.58, Step: 69650, Train Loss: 1.2973, Learning Rate: 5.90e-05
2025-12-09 22:50:51 - INFO - Epoch: 17.59, Step: 69660, Train Loss: 1.3428, Learning Rate: 5.90e-05
2025-12-09 22:51:03 - INFO - Epoch: 17.59, Step: 69670, Train Loss: 1.3060, Learning Rate: 5.90e-05
2025-12-09 22:51:14 - INFO - Epoch: 17.59, Step: 69680, Train Loss: 1.3354, Learning Rate: 5.90e-05
2025-12-09 22:51:25 - INFO - Epoch: 17.59, Step: 69690, Train Loss: 1.3026, Learning Rate: 5.90e-05
2025-12-09 22:51:36 - INFO - Epoch: 17.60, Step: 69700, Train Loss: 1.3235, Learning Rate: 5.90e-05
2025-12-09 22:51:47 - INFO - Epoch: 17.60, Step: 69710, Train Loss: 1.3196, Learning Rate: 5.90e-05
2025-12-09 22:51:58 - INFO - Epoch: 17.60, Step: 69720, Train Loss: 1.2856, Learning Rate: 5.89e-05
2025-12-09 22:52:10 - INFO - Epoch: 17.60, Step: 69730, Train Loss: 1.3013, Learning Rate: 5.89e-05
2025-12-09 22:52:21 - INFO - Epoch: 17.61, Step: 69740, Train Loss: 1.3198, Learning Rate: 5.89e-05
2025-12-09 22:52:32 - INFO - Epoch: 17.61, Step: 69750, Train Loss: 1.2822, Learning Rate: 5.89e-05
2025-12-09 22:52:43 - INFO - Epoch: 17.61, Step: 69760, Train Loss: 1.3043, Learning Rate: 5.89e-05
2025-12-09 22:52:54 - INFO - Epoch: 17.61, Step: 69770, Train Loss: 1.3230, Learning Rate: 5.89e-05
2025-12-09 22:53:05 - INFO - Epoch: 17.62, Step: 69780, Train Loss: 1.2710, Learning Rate: 5.89e-05
2025-12-09 22:53:16 - INFO - Epoch: 17.62, Step: 69790, Train Loss: 1.3264, Learning Rate: 5.89e-05
2025-12-09 22:53:28 - INFO - Epoch: 17.62, Step: 69800, Train Loss: 1.3277, Learning Rate: 5.89e-05
2025-12-09 22:53:39 - INFO - Epoch: 17.62, Step: 69810, Train Loss: 1.3295, Learning Rate: 5.89e-05
2025-12-09 22:53:50 - INFO - Epoch: 17.63, Step: 69820, Train Loss: 1.3116, Learning Rate: 5.89e-05
2025-12-09 22:54:01 - INFO - Epoch: 17.63, Step: 69830, Train Loss: 1.2477, Learning Rate: 5.89e-05
2025-12-09 22:54:12 - INFO - Epoch: 17.63, Step: 69840, Train Loss: 1.3241, Learning Rate: 5.89e-05
2025-12-09 22:54:23 - INFO - Epoch: 17.63, Step: 69850, Train Loss: 1.2815, Learning Rate: 5.89e-05
2025-12-09 22:54:34 - INFO - Epoch: 17.64, Step: 69860, Train Loss: 1.2996, Learning Rate: 5.89e-05
2025-12-09 22:54:46 - INFO - Epoch: 17.64, Step: 69870, Train Loss: 1.2895, Learning Rate: 5.88e-05
2025-12-09 22:54:57 - INFO - Epoch: 17.64, Step: 69880, Train Loss: 1.3100, Learning Rate: 5.88e-05
2025-12-09 22:55:08 - INFO - Epoch: 17.64, Step: 69890, Train Loss: 1.2639, Learning Rate: 5.88e-05
2025-12-09 22:55:19 - INFO - Epoch: 17.65, Step: 69900, Train Loss: 1.3111, Learning Rate: 5.88e-05
2025-12-09 22:55:30 - INFO - Epoch: 17.65, Step: 69910, Train Loss: 1.2735, Learning Rate: 5.88e-05
2025-12-09 22:55:41 - INFO - Epoch: 17.65, Step: 69920, Train Loss: 1.3166, Learning Rate: 5.88e-05
2025-12-09 22:55:53 - INFO - Epoch: 17.65, Step: 69930, Train Loss: 1.3193, Learning Rate: 5.88e-05
2025-12-09 22:56:04 - INFO - Epoch: 17.66, Step: 69940, Train Loss: 1.2461, Learning Rate: 5.88e-05
2025-12-09 22:56:15 - INFO - Epoch: 17.66, Step: 69950, Train Loss: 1.2942, Learning Rate: 5.88e-05
2025-12-09 22:56:26 - INFO - Epoch: 17.66, Step: 69960, Train Loss: 1.3370, Learning Rate: 5.88e-05
2025-12-09 22:56:37 - INFO - Epoch: 17.66, Step: 69970, Train Loss: 1.2726, Learning Rate: 5.88e-05
2025-12-09 22:56:48 - INFO - Epoch: 17.67, Step: 69980, Train Loss: 1.3233, Learning Rate: 5.88e-05
2025-12-09 22:56:59 - INFO - Epoch: 17.67, Step: 69990, Train Loss: 1.2970, Learning Rate: 5.88e-05
2025-12-09 22:57:11 - INFO - Epoch: 17.67, Step: 70000, Train Loss: 1.3103, Learning Rate: 5.88e-05
2025-12-09 22:57:22 - INFO - Epoch: 17.67, Step: 70010, Train Loss: 1.2854, Learning Rate: 5.88e-05
2025-12-09 22:57:33 - INFO - Epoch: 17.68, Step: 70020, Train Loss: 1.2763, Learning Rate: 5.87e-05
2025-12-09 22:57:44 - INFO - Epoch: 17.68, Step: 70030, Train Loss: 1.3091, Learning Rate: 5.87e-05
2025-12-09 22:57:55 - INFO - Epoch: 17.68, Step: 70040, Train Loss: 1.2899, Learning Rate: 5.87e-05
2025-12-09 22:58:06 - INFO - Epoch: 17.68, Step: 70050, Train Loss: 1.2883, Learning Rate: 5.87e-05
2025-12-09 22:58:18 - INFO - Epoch: 17.69, Step: 70060, Train Loss: 1.3023, Learning Rate: 5.87e-05
2025-12-09 22:58:29 - INFO - Epoch: 17.69, Step: 70070, Train Loss: 1.2875, Learning Rate: 5.87e-05
2025-12-09 22:58:40 - INFO - Epoch: 17.69, Step: 70080, Train Loss: 1.3082, Learning Rate: 5.87e-05
2025-12-09 22:58:51 - INFO - Epoch: 17.70, Step: 70090, Train Loss: 1.3154, Learning Rate: 5.87e-05
2025-12-09 22:59:02 - INFO - Epoch: 17.70, Step: 70100, Train Loss: 1.2557, Learning Rate: 5.87e-05
2025-12-09 22:59:13 - INFO - Epoch: 17.70, Step: 70110, Train Loss: 1.2546, Learning Rate: 5.87e-05
2025-12-09 22:59:24 - INFO - Epoch: 17.70, Step: 70120, Train Loss: 1.2855, Learning Rate: 5.87e-05
2025-12-09 22:59:36 - INFO - Epoch: 17.71, Step: 70130, Train Loss: 1.3080, Learning Rate: 5.87e-05
2025-12-09 22:59:47 - INFO - Epoch: 17.71, Step: 70140, Train Loss: 1.3076, Learning Rate: 5.87e-05
2025-12-09 22:59:58 - INFO - Epoch: 17.71, Step: 70150, Train Loss: 1.2992, Learning Rate: 5.87e-05
2025-12-09 23:00:09 - INFO - Epoch: 17.71, Step: 70160, Train Loss: 1.3515, Learning Rate: 5.87e-05
2025-12-09 23:00:20 - INFO - Epoch: 17.72, Step: 70170, Train Loss: 1.3133, Learning Rate: 5.86e-05
2025-12-09 23:00:31 - INFO - Epoch: 17.72, Step: 70180, Train Loss: 1.3448, Learning Rate: 5.86e-05
2025-12-09 23:00:42 - INFO - Epoch: 17.72, Step: 70190, Train Loss: 1.2766, Learning Rate: 5.86e-05
2025-12-09 23:00:54 - INFO - Epoch: 17.72, Step: 70200, Train Loss: 1.3097, Learning Rate: 5.86e-05
2025-12-09 23:01:05 - INFO - Epoch: 17.73, Step: 70210, Train Loss: 1.3306, Learning Rate: 5.86e-05
2025-12-09 23:01:16 - INFO - Epoch: 17.73, Step: 70220, Train Loss: 1.2698, Learning Rate: 5.86e-05
2025-12-09 23:01:27 - INFO - Epoch: 17.73, Step: 70230, Train Loss: 1.3346, Learning Rate: 5.86e-05
2025-12-09 23:01:38 - INFO - Epoch: 17.73, Step: 70240, Train Loss: 1.3120, Learning Rate: 5.86e-05
2025-12-09 23:01:49 - INFO - Epoch: 17.74, Step: 70250, Train Loss: 1.3032, Learning Rate: 5.86e-05
2025-12-09 23:02:01 - INFO - Epoch: 17.74, Step: 70260, Train Loss: 1.2974, Learning Rate: 5.86e-05
2025-12-09 23:02:12 - INFO - Epoch: 17.74, Step: 70270, Train Loss: 1.3369, Learning Rate: 5.86e-05
2025-12-09 23:02:23 - INFO - Epoch: 17.74, Step: 70280, Train Loss: 1.3095, Learning Rate: 5.86e-05
2025-12-09 23:02:34 - INFO - Epoch: 17.75, Step: 70290, Train Loss: 1.2371, Learning Rate: 5.86e-05
2025-12-09 23:02:45 - INFO - Epoch: 17.75, Step: 70300, Train Loss: 1.3060, Learning Rate: 5.86e-05
2025-12-09 23:02:56 - INFO - Epoch: 17.75, Step: 70310, Train Loss: 1.2611, Learning Rate: 5.86e-05
2025-12-09 23:03:07 - INFO - Epoch: 17.75, Step: 70320, Train Loss: 1.3365, Learning Rate: 5.85e-05
2025-12-09 23:03:19 - INFO - Epoch: 17.76, Step: 70330, Train Loss: 1.2814, Learning Rate: 5.85e-05
2025-12-09 23:03:30 - INFO - Epoch: 17.76, Step: 70340, Train Loss: 1.3183, Learning Rate: 5.85e-05
2025-12-09 23:03:41 - INFO - Epoch: 17.76, Step: 70350, Train Loss: 1.2914, Learning Rate: 5.85e-05
2025-12-09 23:03:52 - INFO - Epoch: 17.76, Step: 70360, Train Loss: 1.3165, Learning Rate: 5.85e-05
2025-12-09 23:04:03 - INFO - Epoch: 17.77, Step: 70370, Train Loss: 1.3021, Learning Rate: 5.85e-05
2025-12-09 23:04:14 - INFO - Epoch: 17.77, Step: 70380, Train Loss: 1.3004, Learning Rate: 5.85e-05
2025-12-09 23:04:26 - INFO - Epoch: 17.77, Step: 70390, Train Loss: 1.2929, Learning Rate: 5.85e-05
2025-12-09 23:04:37 - INFO - Epoch: 17.77, Step: 70400, Train Loss: 1.2993, Learning Rate: 5.85e-05
2025-12-09 23:04:48 - INFO - Epoch: 17.78, Step: 70410, Train Loss: 1.2856, Learning Rate: 5.85e-05
2025-12-09 23:04:59 - INFO - Epoch: 17.78, Step: 70420, Train Loss: 1.2732, Learning Rate: 5.85e-05
2025-12-09 23:05:10 - INFO - Epoch: 17.78, Step: 70430, Train Loss: 1.2725, Learning Rate: 5.85e-05
2025-12-09 23:05:21 - INFO - Epoch: 17.78, Step: 70440, Train Loss: 1.3226, Learning Rate: 5.85e-05
2025-12-09 23:05:32 - INFO - Epoch: 17.79, Step: 70450, Train Loss: 1.3030, Learning Rate: 5.85e-05
2025-12-09 23:05:44 - INFO - Epoch: 17.79, Step: 70460, Train Loss: 1.2548, Learning Rate: 5.85e-05
2025-12-09 23:05:55 - INFO - Epoch: 17.79, Step: 70470, Train Loss: 1.2923, Learning Rate: 5.84e-05
2025-12-09 23:06:06 - INFO - Epoch: 17.79, Step: 70480, Train Loss: 1.2921, Learning Rate: 5.84e-05
2025-12-09 23:06:17 - INFO - Epoch: 17.80, Step: 70490, Train Loss: 1.3073, Learning Rate: 5.84e-05
2025-12-09 23:06:28 - INFO - Epoch: 17.80, Step: 70500, Train Loss: 1.2931, Learning Rate: 5.84e-05
2025-12-09 23:06:39 - INFO - Epoch: 17.80, Step: 70510, Train Loss: 1.2908, Learning Rate: 5.84e-05
2025-12-09 23:06:50 - INFO - Epoch: 17.80, Step: 70520, Train Loss: 1.3123, Learning Rate: 5.84e-05
2025-12-09 23:07:02 - INFO - Epoch: 17.81, Step: 70530, Train Loss: 1.2869, Learning Rate: 5.84e-05
2025-12-09 23:07:13 - INFO - Epoch: 17.81, Step: 70540, Train Loss: 1.3081, Learning Rate: 5.84e-05
2025-12-09 23:07:24 - INFO - Epoch: 17.81, Step: 70550, Train Loss: 1.2894, Learning Rate: 5.84e-05
2025-12-09 23:07:35 - INFO - Epoch: 17.81, Step: 70560, Train Loss: 1.3391, Learning Rate: 5.84e-05
2025-12-09 23:07:46 - INFO - Epoch: 17.82, Step: 70570, Train Loss: 1.2642, Learning Rate: 5.84e-05
2025-12-09 23:07:57 - INFO - Epoch: 17.82, Step: 70580, Train Loss: 1.2948, Learning Rate: 5.84e-05
2025-12-09 23:08:09 - INFO - Epoch: 17.82, Step: 70590, Train Loss: 1.3004, Learning Rate: 5.84e-05
2025-12-09 23:08:20 - INFO - Epoch: 17.82, Step: 70600, Train Loss: 1.2993, Learning Rate: 5.84e-05
2025-12-09 23:08:31 - INFO - Epoch: 17.83, Step: 70610, Train Loss: 1.3110, Learning Rate: 5.84e-05
2025-12-09 23:08:42 - INFO - Epoch: 17.83, Step: 70620, Train Loss: 1.3442, Learning Rate: 5.83e-05
2025-12-09 23:08:53 - INFO - Epoch: 17.83, Step: 70630, Train Loss: 1.3063, Learning Rate: 5.83e-05
2025-12-09 23:09:04 - INFO - Epoch: 17.83, Step: 70640, Train Loss: 1.2999, Learning Rate: 5.83e-05
2025-12-09 23:09:15 - INFO - Epoch: 17.84, Step: 70650, Train Loss: 1.2956, Learning Rate: 5.83e-05
2025-12-09 23:09:27 - INFO - Epoch: 17.84, Step: 70660, Train Loss: 1.3016, Learning Rate: 5.83e-05
2025-12-09 23:09:38 - INFO - Epoch: 17.84, Step: 70670, Train Loss: 1.3015, Learning Rate: 5.83e-05
2025-12-09 23:09:49 - INFO - Epoch: 17.84, Step: 70680, Train Loss: 1.3031, Learning Rate: 5.83e-05
2025-12-09 23:10:00 - INFO - Epoch: 17.85, Step: 70690, Train Loss: 1.3004, Learning Rate: 5.83e-05
2025-12-09 23:10:11 - INFO - Epoch: 17.85, Step: 70700, Train Loss: 1.2526, Learning Rate: 5.83e-05
2025-12-09 23:10:22 - INFO - Epoch: 17.85, Step: 70710, Train Loss: 1.3446, Learning Rate: 5.83e-05
2025-12-09 23:10:34 - INFO - Epoch: 17.85, Step: 70720, Train Loss: 1.2842, Learning Rate: 5.83e-05
2025-12-09 23:10:45 - INFO - Epoch: 17.86, Step: 70730, Train Loss: 1.2825, Learning Rate: 5.83e-05
2025-12-09 23:10:56 - INFO - Epoch: 17.86, Step: 70740, Train Loss: 1.3109, Learning Rate: 5.83e-05
2025-12-09 23:11:07 - INFO - Epoch: 17.86, Step: 70750, Train Loss: 1.3070, Learning Rate: 5.83e-05
2025-12-09 23:11:18 - INFO - Epoch: 17.86, Step: 70760, Train Loss: 1.2842, Learning Rate: 5.83e-05
2025-12-09 23:11:29 - INFO - Epoch: 17.87, Step: 70770, Train Loss: 1.2695, Learning Rate: 5.82e-05
2025-12-09 23:11:40 - INFO - Epoch: 17.87, Step: 70780, Train Loss: 1.3428, Learning Rate: 5.82e-05
2025-12-09 23:11:52 - INFO - Epoch: 17.87, Step: 70790, Train Loss: 1.3031, Learning Rate: 5.82e-05
2025-12-09 23:12:03 - INFO - Epoch: 17.87, Step: 70800, Train Loss: 1.2780, Learning Rate: 5.82e-05
2025-12-09 23:12:14 - INFO - Epoch: 17.88, Step: 70810, Train Loss: 1.3249, Learning Rate: 5.82e-05
2025-12-09 23:12:25 - INFO - Epoch: 17.88, Step: 70820, Train Loss: 1.2639, Learning Rate: 5.82e-05
2025-12-09 23:12:36 - INFO - Epoch: 17.88, Step: 70830, Train Loss: 1.2900, Learning Rate: 5.82e-05
2025-12-09 23:12:47 - INFO - Epoch: 17.88, Step: 70840, Train Loss: 1.2967, Learning Rate: 5.82e-05
2025-12-09 23:12:58 - INFO - Epoch: 17.89, Step: 70850, Train Loss: 1.2825, Learning Rate: 5.82e-05
2025-12-09 23:13:10 - INFO - Epoch: 17.89, Step: 70860, Train Loss: 1.2809, Learning Rate: 5.82e-05
2025-12-09 23:13:21 - INFO - Epoch: 17.89, Step: 70870, Train Loss: 1.2788, Learning Rate: 5.82e-05
2025-12-09 23:13:32 - INFO - Epoch: 17.89, Step: 70880, Train Loss: 1.3058, Learning Rate: 5.82e-05
2025-12-09 23:13:43 - INFO - Epoch: 17.90, Step: 70890, Train Loss: 1.2955, Learning Rate: 5.82e-05
2025-12-09 23:13:54 - INFO - Epoch: 17.90, Step: 70900, Train Loss: 1.3212, Learning Rate: 5.82e-05
2025-12-09 23:14:05 - INFO - Epoch: 17.90, Step: 70910, Train Loss: 1.3347, Learning Rate: 5.82e-05
2025-12-09 23:14:17 - INFO - Epoch: 17.90, Step: 70920, Train Loss: 1.3040, Learning Rate: 5.81e-05
2025-12-09 23:14:28 - INFO - Epoch: 17.91, Step: 70930, Train Loss: 1.2745, Learning Rate: 5.81e-05
2025-12-09 23:14:39 - INFO - Epoch: 17.91, Step: 70940, Train Loss: 1.3023, Learning Rate: 5.81e-05
2025-12-09 23:14:50 - INFO - Epoch: 17.91, Step: 70950, Train Loss: 1.3049, Learning Rate: 5.81e-05
2025-12-09 23:15:01 - INFO - Epoch: 17.91, Step: 70960, Train Loss: 1.2529, Learning Rate: 5.81e-05
2025-12-09 23:15:12 - INFO - Epoch: 17.92, Step: 70970, Train Loss: 1.3394, Learning Rate: 5.81e-05
2025-12-09 23:15:23 - INFO - Epoch: 17.92, Step: 70980, Train Loss: 1.2625, Learning Rate: 5.81e-05
2025-12-09 23:15:35 - INFO - Epoch: 17.92, Step: 70990, Train Loss: 1.3273, Learning Rate: 5.81e-05
2025-12-09 23:15:46 - INFO - Epoch: 17.92, Step: 71000, Train Loss: 1.3082, Learning Rate: 5.81e-05
2025-12-09 23:15:57 - INFO - Epoch: 17.93, Step: 71010, Train Loss: 1.3008, Learning Rate: 5.81e-05
2025-12-09 23:16:08 - INFO - Epoch: 17.93, Step: 71020, Train Loss: 1.2648, Learning Rate: 5.81e-05
2025-12-09 23:16:19 - INFO - Epoch: 17.93, Step: 71030, Train Loss: 1.3373, Learning Rate: 5.81e-05
2025-12-09 23:16:30 - INFO - Epoch: 17.93, Step: 71040, Train Loss: 1.3214, Learning Rate: 5.81e-05
2025-12-09 23:16:42 - INFO - Epoch: 17.94, Step: 71050, Train Loss: 1.2650, Learning Rate: 5.81e-05
2025-12-09 23:16:53 - INFO - Epoch: 17.94, Step: 71060, Train Loss: 1.3293, Learning Rate: 5.81e-05
2025-12-09 23:17:04 - INFO - Epoch: 17.94, Step: 71070, Train Loss: 1.3023, Learning Rate: 5.80e-05
2025-12-09 23:17:15 - INFO - Epoch: 17.94, Step: 71080, Train Loss: 1.2723, Learning Rate: 5.80e-05
2025-12-09 23:17:26 - INFO - Epoch: 17.95, Step: 71090, Train Loss: 1.2954, Learning Rate: 5.80e-05
2025-12-09 23:17:37 - INFO - Epoch: 17.95, Step: 71100, Train Loss: 1.2958, Learning Rate: 5.80e-05
2025-12-09 23:17:48 - INFO - Epoch: 17.95, Step: 71110, Train Loss: 1.3408, Learning Rate: 5.80e-05
2025-12-09 23:18:00 - INFO - Epoch: 17.96, Step: 71120, Train Loss: 1.3235, Learning Rate: 5.80e-05
2025-12-09 23:18:11 - INFO - Epoch: 17.96, Step: 71130, Train Loss: 1.3051, Learning Rate: 5.80e-05
2025-12-09 23:18:22 - INFO - Epoch: 17.96, Step: 71140, Train Loss: 1.2528, Learning Rate: 5.80e-05
2025-12-09 23:18:33 - INFO - Epoch: 17.96, Step: 71150, Train Loss: 1.2867, Learning Rate: 5.80e-05
2025-12-09 23:18:44 - INFO - Epoch: 17.97, Step: 71160, Train Loss: 1.2958, Learning Rate: 5.80e-05
2025-12-09 23:18:55 - INFO - Epoch: 17.97, Step: 71170, Train Loss: 1.2864, Learning Rate: 5.80e-05
2025-12-09 23:19:07 - INFO - Epoch: 17.97, Step: 71180, Train Loss: 1.2402, Learning Rate: 5.80e-05
2025-12-09 23:19:18 - INFO - Epoch: 17.97, Step: 71190, Train Loss: 1.2729, Learning Rate: 5.80e-05
2025-12-09 23:19:29 - INFO - Epoch: 17.98, Step: 71200, Train Loss: 1.2704, Learning Rate: 5.80e-05
2025-12-09 23:19:40 - INFO - Epoch: 17.98, Step: 71210, Train Loss: 1.2447, Learning Rate: 5.80e-05
2025-12-09 23:19:51 - INFO - Epoch: 17.98, Step: 71220, Train Loss: 1.2884, Learning Rate: 5.79e-05
2025-12-09 23:20:02 - INFO - Epoch: 17.98, Step: 71230, Train Loss: 1.2978, Learning Rate: 5.79e-05
2025-12-09 23:20:13 - INFO - Epoch: 17.99, Step: 71240, Train Loss: 1.2952, Learning Rate: 5.79e-05
2025-12-09 23:20:25 - INFO - Epoch: 17.99, Step: 71250, Train Loss: 1.3050, Learning Rate: 5.79e-05
2025-12-09 23:20:36 - INFO - Epoch: 17.99, Step: 71260, Train Loss: 1.3045, Learning Rate: 5.79e-05
2025-12-09 23:20:47 - INFO - Epoch: 17.99, Step: 71270, Train Loss: 1.2926, Learning Rate: 5.79e-05
2025-12-09 23:20:58 - INFO - Epoch: 18.00, Step: 71280, Train Loss: 1.2604, Learning Rate: 5.79e-05
2025-12-09 23:21:09 - INFO - Epoch: 18.00, Step: 71290, Train Loss: 1.2950, Learning Rate: 5.79e-05
2025-12-09 23:21:20 - INFO - Epoch: 18.00, Step: 71300, Train Loss: 1.2846, Learning Rate: 5.79e-05
2025-12-09 23:21:31 - INFO - Epoch: 18.00, Step: 71310, Train Loss: 1.2828, Learning Rate: 5.79e-05
2025-12-09 23:21:43 - INFO - Epoch: 18.01, Step: 71320, Train Loss: 1.2289, Learning Rate: 5.79e-05
2025-12-09 23:21:54 - INFO - Epoch: 18.01, Step: 71330, Train Loss: 1.2632, Learning Rate: 5.79e-05
2025-12-09 23:22:05 - INFO - Epoch: 18.01, Step: 71340, Train Loss: 1.3114, Learning Rate: 5.79e-05
2025-12-09 23:22:16 - INFO - Epoch: 18.01, Step: 71350, Train Loss: 1.3279, Learning Rate: 5.79e-05
2025-12-09 23:22:27 - INFO - Epoch: 18.02, Step: 71360, Train Loss: 1.2847, Learning Rate: 5.79e-05
2025-12-09 23:22:38 - INFO - Epoch: 18.02, Step: 71370, Train Loss: 1.2994, Learning Rate: 5.78e-05
2025-12-09 23:22:50 - INFO - Epoch: 18.02, Step: 71380, Train Loss: 1.3066, Learning Rate: 5.78e-05
2025-12-09 23:23:01 - INFO - Epoch: 18.02, Step: 71390, Train Loss: 1.2922, Learning Rate: 5.78e-05
2025-12-09 23:23:12 - INFO - Epoch: 18.03, Step: 71400, Train Loss: 1.2563, Learning Rate: 5.78e-05
2025-12-09 23:23:23 - INFO - Epoch: 18.03, Step: 71410, Train Loss: 1.3102, Learning Rate: 5.78e-05
2025-12-09 23:23:34 - INFO - Epoch: 18.03, Step: 71420, Train Loss: 1.2786, Learning Rate: 5.78e-05
2025-12-09 23:23:45 - INFO - Epoch: 18.03, Step: 71430, Train Loss: 1.3017, Learning Rate: 5.78e-05
2025-12-09 23:23:56 - INFO - Epoch: 18.04, Step: 71440, Train Loss: 1.2333, Learning Rate: 5.78e-05
2025-12-09 23:24:08 - INFO - Epoch: 18.04, Step: 71450, Train Loss: 1.3016, Learning Rate: 5.78e-05
2025-12-09 23:24:19 - INFO - Epoch: 18.04, Step: 71460, Train Loss: 1.2726, Learning Rate: 5.78e-05
2025-12-09 23:24:30 - INFO - Epoch: 18.04, Step: 71470, Train Loss: 1.2722, Learning Rate: 5.78e-05
2025-12-09 23:24:41 - INFO - Epoch: 18.05, Step: 71480, Train Loss: 1.3250, Learning Rate: 5.78e-05
2025-12-09 23:24:52 - INFO - Epoch: 18.05, Step: 71490, Train Loss: 1.2820, Learning Rate: 5.78e-05
2025-12-09 23:25:03 - INFO - Epoch: 18.05, Step: 71500, Train Loss: 1.2806, Learning Rate: 5.78e-05
2025-12-09 23:25:14 - INFO - Epoch: 18.05, Step: 71510, Train Loss: 1.3148, Learning Rate: 5.78e-05
2025-12-09 23:25:26 - INFO - Epoch: 18.06, Step: 71520, Train Loss: 1.2855, Learning Rate: 5.77e-05
2025-12-09 23:25:37 - INFO - Epoch: 18.06, Step: 71530, Train Loss: 1.2698, Learning Rate: 5.77e-05
2025-12-09 23:25:48 - INFO - Epoch: 18.06, Step: 71540, Train Loss: 1.3560, Learning Rate: 5.77e-05
2025-12-09 23:25:59 - INFO - Epoch: 18.06, Step: 71550, Train Loss: 1.3051, Learning Rate: 5.77e-05
2025-12-09 23:26:10 - INFO - Epoch: 18.07, Step: 71560, Train Loss: 1.3234, Learning Rate: 5.77e-05
2025-12-09 23:26:21 - INFO - Epoch: 18.07, Step: 71570, Train Loss: 1.2633, Learning Rate: 5.77e-05
2025-12-09 23:26:33 - INFO - Epoch: 18.07, Step: 71580, Train Loss: 1.3135, Learning Rate: 5.77e-05
2025-12-09 23:26:44 - INFO - Epoch: 18.07, Step: 71590, Train Loss: 1.3122, Learning Rate: 5.77e-05
2025-12-09 23:26:55 - INFO - Epoch: 18.08, Step: 71600, Train Loss: 1.2772, Learning Rate: 5.77e-05
2025-12-09 23:27:06 - INFO - Epoch: 18.08, Step: 71610, Train Loss: 1.3187, Learning Rate: 5.77e-05
2025-12-09 23:27:17 - INFO - Epoch: 18.08, Step: 71620, Train Loss: 1.3135, Learning Rate: 5.77e-05
2025-12-09 23:27:28 - INFO - Epoch: 18.08, Step: 71630, Train Loss: 1.3119, Learning Rate: 5.77e-05
2025-12-09 23:27:39 - INFO - Epoch: 18.09, Step: 71640, Train Loss: 1.2695, Learning Rate: 5.77e-05
2025-12-09 23:27:51 - INFO - Epoch: 18.09, Step: 71650, Train Loss: 1.2822, Learning Rate: 5.77e-05
2025-12-09 23:28:02 - INFO - Epoch: 18.09, Step: 71660, Train Loss: 1.2648, Learning Rate: 5.77e-05
2025-12-09 23:28:13 - INFO - Epoch: 18.09, Step: 71670, Train Loss: 1.2859, Learning Rate: 5.76e-05
2025-12-09 23:28:24 - INFO - Epoch: 18.10, Step: 71680, Train Loss: 1.3198, Learning Rate: 5.76e-05
2025-12-09 23:28:35 - INFO - Epoch: 18.10, Step: 71690, Train Loss: 1.2854, Learning Rate: 5.76e-05
2025-12-09 23:28:46 - INFO - Epoch: 18.10, Step: 71700, Train Loss: 1.3472, Learning Rate: 5.76e-05
2025-12-09 23:28:58 - INFO - Epoch: 18.10, Step: 71710, Train Loss: 1.3244, Learning Rate: 5.76e-05
2025-12-09 23:29:09 - INFO - Epoch: 18.11, Step: 71720, Train Loss: 1.2761, Learning Rate: 5.76e-05
2025-12-09 23:29:20 - INFO - Epoch: 18.11, Step: 71730, Train Loss: 1.3034, Learning Rate: 5.76e-05
2025-12-09 23:29:31 - INFO - Epoch: 18.11, Step: 71740, Train Loss: 1.2916, Learning Rate: 5.76e-05
2025-12-09 23:29:42 - INFO - Epoch: 18.11, Step: 71750, Train Loss: 1.3133, Learning Rate: 5.76e-05
2025-12-09 23:29:53 - INFO - Epoch: 18.12, Step: 71760, Train Loss: 1.3004, Learning Rate: 5.76e-05
2025-12-09 23:30:04 - INFO - Epoch: 18.12, Step: 71770, Train Loss: 1.2451, Learning Rate: 5.76e-05
2025-12-09 23:30:16 - INFO - Epoch: 18.12, Step: 71780, Train Loss: 1.3060, Learning Rate: 5.76e-05
2025-12-09 23:30:27 - INFO - Epoch: 18.12, Step: 71790, Train Loss: 1.3015, Learning Rate: 5.76e-05
2025-12-09 23:30:38 - INFO - Epoch: 18.13, Step: 71800, Train Loss: 1.3000, Learning Rate: 5.76e-05
2025-12-09 23:30:49 - INFO - Epoch: 18.13, Step: 71810, Train Loss: 1.2956, Learning Rate: 5.76e-05
2025-12-09 23:31:00 - INFO - Epoch: 18.13, Step: 71820, Train Loss: 1.2957, Learning Rate: 5.75e-05
2025-12-09 23:31:11 - INFO - Epoch: 18.13, Step: 71830, Train Loss: 1.2635, Learning Rate: 5.75e-05
2025-12-09 23:31:22 - INFO - Epoch: 18.14, Step: 71840, Train Loss: 1.2915, Learning Rate: 5.75e-05
2025-12-09 23:31:34 - INFO - Epoch: 18.14, Step: 71850, Train Loss: 1.3375, Learning Rate: 5.75e-05
2025-12-09 23:31:45 - INFO - Epoch: 18.14, Step: 71860, Train Loss: 1.2977, Learning Rate: 5.75e-05
2025-12-09 23:31:56 - INFO - Epoch: 18.14, Step: 71870, Train Loss: 1.3272, Learning Rate: 5.75e-05
2025-12-09 23:32:07 - INFO - Epoch: 18.15, Step: 71880, Train Loss: 1.3081, Learning Rate: 5.75e-05
2025-12-09 23:32:18 - INFO - Epoch: 18.15, Step: 71890, Train Loss: 1.2565, Learning Rate: 5.75e-05
2025-12-09 23:32:29 - INFO - Epoch: 18.15, Step: 71900, Train Loss: 1.2457, Learning Rate: 5.75e-05
2025-12-09 23:32:41 - INFO - Epoch: 18.15, Step: 71910, Train Loss: 1.2857, Learning Rate: 5.75e-05
2025-12-09 23:32:52 - INFO - Epoch: 18.16, Step: 71920, Train Loss: 1.3058, Learning Rate: 5.75e-05
2025-12-09 23:33:03 - INFO - Epoch: 18.16, Step: 71930, Train Loss: 1.2900, Learning Rate: 5.75e-05
2025-12-09 23:33:14 - INFO - Epoch: 18.16, Step: 71940, Train Loss: 1.3031, Learning Rate: 5.75e-05
2025-12-09 23:33:25 - INFO - Epoch: 18.16, Step: 71950, Train Loss: 1.2894, Learning Rate: 5.75e-05
2025-12-09 23:33:36 - INFO - Epoch: 18.17, Step: 71960, Train Loss: 1.3450, Learning Rate: 5.75e-05
2025-12-09 23:33:47 - INFO - Epoch: 18.17, Step: 71970, Train Loss: 1.2959, Learning Rate: 5.74e-05
2025-12-09 23:33:59 - INFO - Epoch: 18.17, Step: 71980, Train Loss: 1.2978, Learning Rate: 5.74e-05
2025-12-09 23:34:10 - INFO - Epoch: 18.17, Step: 71990, Train Loss: 1.3070, Learning Rate: 5.74e-05
2025-12-09 23:34:21 - INFO - Epoch: 18.18, Step: 72000, Train Loss: 1.3213, Learning Rate: 5.74e-05
2025-12-09 23:34:32 - INFO - Epoch: 18.18, Step: 72010, Train Loss: 1.2987, Learning Rate: 5.74e-05
2025-12-09 23:34:43 - INFO - Epoch: 18.18, Step: 72020, Train Loss: 1.2811, Learning Rate: 5.74e-05
2025-12-09 23:34:54 - INFO - Epoch: 18.18, Step: 72030, Train Loss: 1.2780, Learning Rate: 5.74e-05
2025-12-09 23:35:06 - INFO - Epoch: 18.19, Step: 72040, Train Loss: 1.2843, Learning Rate: 5.74e-05
2025-12-09 23:35:17 - INFO - Epoch: 18.19, Step: 72050, Train Loss: 1.2818, Learning Rate: 5.74e-05
2025-12-09 23:35:28 - INFO - Epoch: 18.19, Step: 72060, Train Loss: 1.2809, Learning Rate: 5.74e-05
2025-12-09 23:35:39 - INFO - Epoch: 18.19, Step: 72070, Train Loss: 1.2698, Learning Rate: 5.74e-05
2025-12-09 23:35:50 - INFO - Epoch: 18.20, Step: 72080, Train Loss: 1.3034, Learning Rate: 5.74e-05
2025-12-09 23:36:01 - INFO - Epoch: 18.20, Step: 72090, Train Loss: 1.2928, Learning Rate: 5.74e-05
2025-12-09 23:36:12 - INFO - Epoch: 18.20, Step: 72100, Train Loss: 1.3309, Learning Rate: 5.74e-05
2025-12-09 23:36:24 - INFO - Epoch: 18.20, Step: 72110, Train Loss: 1.2908, Learning Rate: 5.74e-05
2025-12-09 23:36:35 - INFO - Epoch: 18.21, Step: 72120, Train Loss: 1.2545, Learning Rate: 5.73e-05
2025-12-09 23:36:46 - INFO - Epoch: 18.21, Step: 72130, Train Loss: 1.2765, Learning Rate: 5.73e-05
2025-12-09 23:36:57 - INFO - Epoch: 18.21, Step: 72140, Train Loss: 1.2611, Learning Rate: 5.73e-05
2025-12-09 23:37:08 - INFO - Epoch: 18.22, Step: 72150, Train Loss: 1.2768, Learning Rate: 5.73e-05
2025-12-09 23:37:19 - INFO - Epoch: 18.22, Step: 72160, Train Loss: 1.3015, Learning Rate: 5.73e-05
2025-12-09 23:37:30 - INFO - Epoch: 18.22, Step: 72170, Train Loss: 1.2815, Learning Rate: 5.73e-05
2025-12-09 23:37:42 - INFO - Epoch: 18.22, Step: 72180, Train Loss: 1.2992, Learning Rate: 5.73e-05
2025-12-09 23:37:53 - INFO - Epoch: 18.23, Step: 72190, Train Loss: 1.2820, Learning Rate: 5.73e-05
2025-12-09 23:38:04 - INFO - Epoch: 18.23, Step: 72200, Train Loss: 1.2870, Learning Rate: 5.73e-05
2025-12-09 23:38:15 - INFO - Epoch: 18.23, Step: 72210, Train Loss: 1.3112, Learning Rate: 5.73e-05
2025-12-09 23:38:26 - INFO - Epoch: 18.23, Step: 72220, Train Loss: 1.3567, Learning Rate: 5.73e-05
2025-12-09 23:38:37 - INFO - Epoch: 18.24, Step: 72230, Train Loss: 1.2834, Learning Rate: 5.73e-05
2025-12-09 23:38:49 - INFO - Epoch: 18.24, Step: 72240, Train Loss: 1.2998, Learning Rate: 5.73e-05
2025-12-09 23:39:00 - INFO - Epoch: 18.24, Step: 72250, Train Loss: 1.2651, Learning Rate: 5.73e-05
2025-12-09 23:39:11 - INFO - Epoch: 18.24, Step: 72260, Train Loss: 1.2802, Learning Rate: 5.73e-05
2025-12-09 23:39:22 - INFO - Epoch: 18.25, Step: 72270, Train Loss: 1.2831, Learning Rate: 5.72e-05
2025-12-09 23:39:33 - INFO - Epoch: 18.25, Step: 72280, Train Loss: 1.2935, Learning Rate: 5.72e-05
2025-12-09 23:39:44 - INFO - Epoch: 18.25, Step: 72290, Train Loss: 1.2829, Learning Rate: 5.72e-05
2025-12-09 23:39:55 - INFO - Epoch: 18.25, Step: 72300, Train Loss: 1.3175, Learning Rate: 5.72e-05
2025-12-09 23:40:07 - INFO - Epoch: 18.26, Step: 72310, Train Loss: 1.2760, Learning Rate: 5.72e-05
2025-12-09 23:40:18 - INFO - Epoch: 18.26, Step: 72320, Train Loss: 1.2945, Learning Rate: 5.72e-05
2025-12-09 23:40:29 - INFO - Epoch: 18.26, Step: 72330, Train Loss: 1.3157, Learning Rate: 5.72e-05
2025-12-09 23:40:40 - INFO - Epoch: 18.26, Step: 72340, Train Loss: 1.2866, Learning Rate: 5.72e-05
2025-12-09 23:40:51 - INFO - Epoch: 18.27, Step: 72350, Train Loss: 1.3050, Learning Rate: 5.72e-05
2025-12-09 23:41:02 - INFO - Epoch: 18.27, Step: 72360, Train Loss: 1.3138, Learning Rate: 5.72e-05
2025-12-09 23:41:13 - INFO - Epoch: 18.27, Step: 72370, Train Loss: 1.3006, Learning Rate: 5.72e-05
2025-12-09 23:41:25 - INFO - Epoch: 18.27, Step: 72380, Train Loss: 1.2873, Learning Rate: 5.72e-05
2025-12-09 23:41:36 - INFO - Epoch: 18.28, Step: 72390, Train Loss: 1.2841, Learning Rate: 5.72e-05
2025-12-09 23:41:47 - INFO - Epoch: 18.28, Step: 72400, Train Loss: 1.2451, Learning Rate: 5.72e-05
2025-12-09 23:41:58 - INFO - Epoch: 18.28, Step: 72410, Train Loss: 1.2644, Learning Rate: 5.72e-05
2025-12-09 23:42:09 - INFO - Epoch: 18.28, Step: 72420, Train Loss: 1.3056, Learning Rate: 5.71e-05
2025-12-09 23:42:20 - INFO - Epoch: 18.29, Step: 72430, Train Loss: 1.2480, Learning Rate: 5.71e-05
2025-12-09 23:42:32 - INFO - Epoch: 18.29, Step: 72440, Train Loss: 1.2732, Learning Rate: 5.71e-05
2025-12-09 23:42:43 - INFO - Epoch: 18.29, Step: 72450, Train Loss: 1.2963, Learning Rate: 5.71e-05
2025-12-09 23:42:54 - INFO - Epoch: 18.29, Step: 72460, Train Loss: 1.2955, Learning Rate: 5.71e-05
2025-12-09 23:43:05 - INFO - Epoch: 18.30, Step: 72470, Train Loss: 1.2717, Learning Rate: 5.71e-05
2025-12-09 23:43:16 - INFO - Epoch: 18.30, Step: 72480, Train Loss: 1.2621, Learning Rate: 5.71e-05
2025-12-09 23:43:27 - INFO - Epoch: 18.30, Step: 72490, Train Loss: 1.3247, Learning Rate: 5.71e-05
2025-12-09 23:43:38 - INFO - Epoch: 18.30, Step: 72500, Train Loss: 1.3015, Learning Rate: 5.71e-05
2025-12-09 23:43:50 - INFO - Epoch: 18.31, Step: 72510, Train Loss: 1.2777, Learning Rate: 5.71e-05
2025-12-09 23:44:01 - INFO - Epoch: 18.31, Step: 72520, Train Loss: 1.2351, Learning Rate: 5.71e-05
2025-12-09 23:44:12 - INFO - Epoch: 18.31, Step: 72530, Train Loss: 1.3424, Learning Rate: 5.71e-05
2025-12-09 23:44:23 - INFO - Epoch: 18.31, Step: 72540, Train Loss: 1.2962, Learning Rate: 5.71e-05
2025-12-09 23:44:34 - INFO - Epoch: 18.32, Step: 72550, Train Loss: 1.2960, Learning Rate: 5.71e-05
2025-12-09 23:44:45 - INFO - Epoch: 18.32, Step: 72560, Train Loss: 1.2747, Learning Rate: 5.71e-05
2025-12-09 23:44:57 - INFO - Epoch: 18.32, Step: 72570, Train Loss: 1.2715, Learning Rate: 5.71e-05
2025-12-09 23:45:08 - INFO - Epoch: 18.32, Step: 72580, Train Loss: 1.3125, Learning Rate: 5.70e-05
2025-12-09 23:45:19 - INFO - Epoch: 18.33, Step: 72590, Train Loss: 1.2731, Learning Rate: 5.70e-05
2025-12-09 23:45:30 - INFO - Epoch: 18.33, Step: 72600, Train Loss: 1.2755, Learning Rate: 5.70e-05
2025-12-09 23:45:41 - INFO - Epoch: 18.33, Step: 72610, Train Loss: 1.2793, Learning Rate: 5.70e-05
2025-12-09 23:45:52 - INFO - Epoch: 18.33, Step: 72620, Train Loss: 1.2818, Learning Rate: 5.70e-05
2025-12-09 23:46:03 - INFO - Epoch: 18.34, Step: 72630, Train Loss: 1.3232, Learning Rate: 5.70e-05
2025-12-09 23:46:15 - INFO - Epoch: 18.34, Step: 72640, Train Loss: 1.2812, Learning Rate: 5.70e-05
2025-12-09 23:46:26 - INFO - Epoch: 18.34, Step: 72650, Train Loss: 1.2199, Learning Rate: 5.70e-05
2025-12-09 23:46:37 - INFO - Epoch: 18.34, Step: 72660, Train Loss: 1.2962, Learning Rate: 5.70e-05
2025-12-09 23:46:48 - INFO - Epoch: 18.35, Step: 72670, Train Loss: 1.2729, Learning Rate: 5.70e-05
2025-12-09 23:46:59 - INFO - Epoch: 18.35, Step: 72680, Train Loss: 1.2815, Learning Rate: 5.70e-05
2025-12-09 23:47:10 - INFO - Epoch: 18.35, Step: 72690, Train Loss: 1.2654, Learning Rate: 5.70e-05
2025-12-09 23:47:21 - INFO - Epoch: 18.35, Step: 72700, Train Loss: 1.2770, Learning Rate: 5.70e-05
2025-12-09 23:47:33 - INFO - Epoch: 18.36, Step: 72710, Train Loss: 1.2981, Learning Rate: 5.70e-05
2025-12-09 23:47:44 - INFO - Epoch: 18.36, Step: 72720, Train Loss: 1.2577, Learning Rate: 5.70e-05
2025-12-09 23:47:55 - INFO - Epoch: 18.36, Step: 72730, Train Loss: 1.3370, Learning Rate: 5.69e-05
2025-12-09 23:48:06 - INFO - Epoch: 18.36, Step: 72740, Train Loss: 1.2646, Learning Rate: 5.69e-05
2025-12-09 23:48:17 - INFO - Epoch: 18.37, Step: 72750, Train Loss: 1.2976, Learning Rate: 5.69e-05
2025-12-09 23:48:28 - INFO - Epoch: 18.37, Step: 72760, Train Loss: 1.3043, Learning Rate: 5.69e-05
2025-12-09 23:48:40 - INFO - Epoch: 18.37, Step: 72770, Train Loss: 1.2859, Learning Rate: 5.69e-05
2025-12-09 23:48:51 - INFO - Epoch: 18.37, Step: 72780, Train Loss: 1.2803, Learning Rate: 5.69e-05
2025-12-09 23:49:02 - INFO - Epoch: 18.38, Step: 72790, Train Loss: 1.2822, Learning Rate: 5.69e-05
2025-12-09 23:49:13 - INFO - Epoch: 18.38, Step: 72800, Train Loss: 1.3097, Learning Rate: 5.69e-05
2025-12-09 23:49:24 - INFO - Epoch: 18.38, Step: 72810, Train Loss: 1.2679, Learning Rate: 5.69e-05
2025-12-09 23:49:35 - INFO - Epoch: 18.38, Step: 72820, Train Loss: 1.2880, Learning Rate: 5.69e-05
2025-12-09 23:49:46 - INFO - Epoch: 18.39, Step: 72830, Train Loss: 1.2737, Learning Rate: 5.69e-05
2025-12-09 23:49:58 - INFO - Epoch: 18.39, Step: 72840, Train Loss: 1.2736, Learning Rate: 5.69e-05
2025-12-09 23:50:09 - INFO - Epoch: 18.39, Step: 72850, Train Loss: 1.2978, Learning Rate: 5.69e-05
2025-12-09 23:50:20 - INFO - Epoch: 18.39, Step: 72860, Train Loss: 1.2955, Learning Rate: 5.69e-05
2025-12-09 23:50:31 - INFO - Epoch: 18.40, Step: 72870, Train Loss: 1.2996, Learning Rate: 5.69e-05
2025-12-09 23:50:42 - INFO - Epoch: 18.40, Step: 72880, Train Loss: 1.2959, Learning Rate: 5.68e-05
2025-12-09 23:50:53 - INFO - Epoch: 18.40, Step: 72890, Train Loss: 1.2680, Learning Rate: 5.68e-05
2025-12-09 23:51:05 - INFO - Epoch: 18.40, Step: 72900, Train Loss: 1.3000, Learning Rate: 5.68e-05
2025-12-09 23:51:16 - INFO - Epoch: 18.41, Step: 72910, Train Loss: 1.2092, Learning Rate: 5.68e-05
2025-12-09 23:51:27 - INFO - Epoch: 18.41, Step: 72920, Train Loss: 1.2633, Learning Rate: 5.68e-05
2025-12-09 23:51:38 - INFO - Epoch: 18.41, Step: 72930, Train Loss: 1.2804, Learning Rate: 5.68e-05
2025-12-09 23:51:49 - INFO - Epoch: 18.41, Step: 72940, Train Loss: 1.2719, Learning Rate: 5.68e-05
2025-12-09 23:52:00 - INFO - Epoch: 18.42, Step: 72950, Train Loss: 1.2685, Learning Rate: 5.68e-05
2025-12-09 23:52:11 - INFO - Epoch: 18.42, Step: 72960, Train Loss: 1.2904, Learning Rate: 5.68e-05
2025-12-09 23:52:23 - INFO - Epoch: 18.42, Step: 72970, Train Loss: 1.3229, Learning Rate: 5.68e-05
2025-12-09 23:52:34 - INFO - Epoch: 18.42, Step: 72980, Train Loss: 1.3007, Learning Rate: 5.68e-05
2025-12-09 23:52:45 - INFO - Epoch: 18.43, Step: 72990, Train Loss: 1.2441, Learning Rate: 5.68e-05
2025-12-09 23:52:56 - INFO - Epoch: 18.43, Step: 73000, Train Loss: 1.3121, Learning Rate: 5.68e-05
2025-12-09 23:53:07 - INFO - Epoch: 18.43, Step: 73010, Train Loss: 1.2848, Learning Rate: 5.68e-05
2025-12-09 23:53:18 - INFO - Epoch: 18.43, Step: 73020, Train Loss: 1.2454, Learning Rate: 5.68e-05
2025-12-09 23:53:29 - INFO - Epoch: 18.44, Step: 73030, Train Loss: 1.2523, Learning Rate: 5.67e-05
2025-12-09 23:53:41 - INFO - Epoch: 18.44, Step: 73040, Train Loss: 1.2585, Learning Rate: 5.67e-05
2025-12-09 23:53:52 - INFO - Epoch: 18.44, Step: 73050, Train Loss: 1.2822, Learning Rate: 5.67e-05
2025-12-09 23:54:03 - INFO - Epoch: 18.44, Step: 73060, Train Loss: 1.2621, Learning Rate: 5.67e-05
2025-12-09 23:54:14 - INFO - Epoch: 18.45, Step: 73070, Train Loss: 1.2767, Learning Rate: 5.67e-05
2025-12-09 23:54:25 - INFO - Epoch: 18.45, Step: 73080, Train Loss: 1.3191, Learning Rate: 5.67e-05
2025-12-09 23:54:36 - INFO - Epoch: 18.45, Step: 73090, Train Loss: 1.2991, Learning Rate: 5.67e-05
2025-12-09 23:54:48 - INFO - Epoch: 18.45, Step: 73100, Train Loss: 1.2864, Learning Rate: 5.67e-05
2025-12-09 23:54:59 - INFO - Epoch: 18.46, Step: 73110, Train Loss: 1.2771, Learning Rate: 5.67e-05
2025-12-09 23:55:10 - INFO - Epoch: 18.46, Step: 73120, Train Loss: 1.2753, Learning Rate: 5.67e-05
2025-12-09 23:55:21 - INFO - Epoch: 18.46, Step: 73130, Train Loss: 1.2974, Learning Rate: 5.67e-05
2025-12-09 23:55:32 - INFO - Epoch: 18.47, Step: 73140, Train Loss: 1.2915, Learning Rate: 5.67e-05
2025-12-09 23:55:43 - INFO - Epoch: 18.47, Step: 73150, Train Loss: 1.2924, Learning Rate: 5.67e-05
2025-12-09 23:55:54 - INFO - Epoch: 18.47, Step: 73160, Train Loss: 1.2701, Learning Rate: 5.67e-05
2025-12-09 23:56:06 - INFO - Epoch: 18.47, Step: 73170, Train Loss: 1.3043, Learning Rate: 5.67e-05
2025-12-09 23:56:17 - INFO - Epoch: 18.48, Step: 73180, Train Loss: 1.2244, Learning Rate: 5.66e-05
2025-12-09 23:56:28 - INFO - Epoch: 18.48, Step: 73190, Train Loss: 1.2819, Learning Rate: 5.66e-05
2025-12-09 23:56:39 - INFO - Epoch: 18.48, Step: 73200, Train Loss: 1.2849, Learning Rate: 5.66e-05
2025-12-09 23:56:50 - INFO - Epoch: 18.48, Step: 73210, Train Loss: 1.2850, Learning Rate: 5.66e-05
2025-12-09 23:57:01 - INFO - Epoch: 18.49, Step: 73220, Train Loss: 1.3011, Learning Rate: 5.66e-05
2025-12-09 23:57:12 - INFO - Epoch: 18.49, Step: 73230, Train Loss: 1.2620, Learning Rate: 5.66e-05
2025-12-09 23:57:24 - INFO - Epoch: 18.49, Step: 73240, Train Loss: 1.2671, Learning Rate: 5.66e-05
2025-12-09 23:57:35 - INFO - Epoch: 18.49, Step: 73250, Train Loss: 1.3119, Learning Rate: 5.66e-05
2025-12-09 23:57:46 - INFO - Epoch: 18.50, Step: 73260, Train Loss: 1.3182, Learning Rate: 5.66e-05
2025-12-09 23:57:57 - INFO - Epoch: 18.50, Step: 73270, Train Loss: 1.2674, Learning Rate: 5.66e-05
2025-12-09 23:58:08 - INFO - Epoch: 18.50, Step: 73280, Train Loss: 1.2977, Learning Rate: 5.66e-05
2025-12-09 23:58:19 - INFO - Epoch: 18.50, Step: 73290, Train Loss: 1.2802, Learning Rate: 5.66e-05
2025-12-09 23:58:31 - INFO - Epoch: 18.51, Step: 73300, Train Loss: 1.3168, Learning Rate: 5.66e-05
2025-12-09 23:58:42 - INFO - Epoch: 18.51, Step: 73310, Train Loss: 1.3057, Learning Rate: 5.66e-05
2025-12-09 23:58:53 - INFO - Epoch: 18.51, Step: 73320, Train Loss: 1.2937, Learning Rate: 5.66e-05
2025-12-09 23:59:04 - INFO - Epoch: 18.51, Step: 73330, Train Loss: 1.2526, Learning Rate: 5.65e-05
2025-12-09 23:59:15 - INFO - Epoch: 18.52, Step: 73340, Train Loss: 1.3254, Learning Rate: 5.65e-05
2025-12-09 23:59:26 - INFO - Epoch: 18.52, Step: 73350, Train Loss: 1.3450, Learning Rate: 5.65e-05
2025-12-09 23:59:37 - INFO - Epoch: 18.52, Step: 73360, Train Loss: 1.3076, Learning Rate: 5.65e-05
2025-12-09 23:59:49 - INFO - Epoch: 18.52, Step: 73370, Train Loss: 1.2825, Learning Rate: 5.65e-05
2025-12-10 00:00:00 - INFO - Epoch: 18.53, Step: 73380, Train Loss: 1.2741, Learning Rate: 5.65e-05
2025-12-10 00:00:11 - INFO - Epoch: 18.53, Step: 73390, Train Loss: 1.3095, Learning Rate: 5.65e-05
2025-12-10 00:00:22 - INFO - Epoch: 18.53, Step: 73400, Train Loss: 1.2837, Learning Rate: 5.65e-05
2025-12-10 00:00:33 - INFO - Epoch: 18.53, Step: 73410, Train Loss: 1.3406, Learning Rate: 5.65e-05
2025-12-10 00:00:44 - INFO - Epoch: 18.54, Step: 73420, Train Loss: 1.2519, Learning Rate: 5.65e-05
2025-12-10 00:00:56 - INFO - Epoch: 18.54, Step: 73430, Train Loss: 1.2878, Learning Rate: 5.65e-05
2025-12-10 00:01:07 - INFO - Epoch: 18.54, Step: 73440, Train Loss: 1.2896, Learning Rate: 5.65e-05
2025-12-10 00:01:18 - INFO - Epoch: 18.54, Step: 73450, Train Loss: 1.2858, Learning Rate: 5.65e-05
2025-12-10 00:01:29 - INFO - Epoch: 18.55, Step: 73460, Train Loss: 1.3103, Learning Rate: 5.65e-05
2025-12-10 00:01:40 - INFO - Epoch: 18.55, Step: 73470, Train Loss: 1.2980, Learning Rate: 5.65e-05
2025-12-10 00:01:51 - INFO - Epoch: 18.55, Step: 73480, Train Loss: 1.2759, Learning Rate: 5.64e-05
2025-12-10 00:02:02 - INFO - Epoch: 18.55, Step: 73490, Train Loss: 1.2952, Learning Rate: 5.64e-05
2025-12-10 00:02:14 - INFO - Epoch: 18.56, Step: 73500, Train Loss: 1.2876, Learning Rate: 5.64e-05
2025-12-10 00:02:25 - INFO - Epoch: 18.56, Step: 73510, Train Loss: 1.3174, Learning Rate: 5.64e-05
2025-12-10 00:02:36 - INFO - Epoch: 18.56, Step: 73520, Train Loss: 1.2913, Learning Rate: 5.64e-05
2025-12-10 00:02:47 - INFO - Epoch: 18.56, Step: 73530, Train Loss: 1.3283, Learning Rate: 5.64e-05
2025-12-10 00:02:58 - INFO - Epoch: 18.57, Step: 73540, Train Loss: 1.2757, Learning Rate: 5.64e-05
2025-12-10 00:03:09 - INFO - Epoch: 18.57, Step: 73550, Train Loss: 1.2979, Learning Rate: 5.64e-05
2025-12-10 00:03:20 - INFO - Epoch: 18.57, Step: 73560, Train Loss: 1.3063, Learning Rate: 5.64e-05
2025-12-10 00:03:32 - INFO - Epoch: 18.57, Step: 73570, Train Loss: 1.3012, Learning Rate: 5.64e-05
2025-12-10 00:03:43 - INFO - Epoch: 18.58, Step: 73580, Train Loss: 1.2984, Learning Rate: 5.64e-05
2025-12-10 00:03:54 - INFO - Epoch: 18.58, Step: 73590, Train Loss: 1.3117, Learning Rate: 5.64e-05
2025-12-10 00:04:05 - INFO - Epoch: 18.58, Step: 73600, Train Loss: 1.2339, Learning Rate: 5.64e-05
2025-12-10 00:04:16 - INFO - Epoch: 18.58, Step: 73610, Train Loss: 1.2944, Learning Rate: 5.64e-05
2025-12-10 00:04:27 - INFO - Epoch: 18.59, Step: 73620, Train Loss: 1.2647, Learning Rate: 5.64e-05
2025-12-10 00:04:39 - INFO - Epoch: 18.59, Step: 73630, Train Loss: 1.3207, Learning Rate: 5.63e-05
2025-12-10 00:04:50 - INFO - Epoch: 18.59, Step: 73640, Train Loss: 1.2680, Learning Rate: 5.63e-05
2025-12-10 00:05:01 - INFO - Epoch: 18.59, Step: 73650, Train Loss: 1.3224, Learning Rate: 5.63e-05
2025-12-10 00:05:12 - INFO - Epoch: 18.60, Step: 73660, Train Loss: 1.3246, Learning Rate: 5.63e-05
2025-12-10 00:05:23 - INFO - Epoch: 18.60, Step: 73670, Train Loss: 1.3205, Learning Rate: 5.63e-05
2025-12-10 00:05:34 - INFO - Epoch: 18.60, Step: 73680, Train Loss: 1.2730, Learning Rate: 5.63e-05
2025-12-10 00:05:45 - INFO - Epoch: 18.60, Step: 73690, Train Loss: 1.2567, Learning Rate: 5.63e-05
2025-12-10 00:05:57 - INFO - Epoch: 18.61, Step: 73700, Train Loss: 1.3278, Learning Rate: 5.63e-05
2025-12-10 00:06:08 - INFO - Epoch: 18.61, Step: 73710, Train Loss: 1.2547, Learning Rate: 5.63e-05
2025-12-10 00:06:19 - INFO - Epoch: 18.61, Step: 73720, Train Loss: 1.2897, Learning Rate: 5.63e-05
2025-12-10 00:06:30 - INFO - Epoch: 18.61, Step: 73730, Train Loss: 1.2477, Learning Rate: 5.63e-05
2025-12-10 00:06:41 - INFO - Epoch: 18.62, Step: 73740, Train Loss: 1.2972, Learning Rate: 5.63e-05
2025-12-10 00:06:52 - INFO - Epoch: 18.62, Step: 73750, Train Loss: 1.2829, Learning Rate: 5.63e-05
2025-12-10 00:07:04 - INFO - Epoch: 18.62, Step: 73760, Train Loss: 1.2833, Learning Rate: 5.63e-05
2025-12-10 00:07:15 - INFO - Epoch: 18.62, Step: 73770, Train Loss: 1.2749, Learning Rate: 5.63e-05
2025-12-10 00:07:26 - INFO - Epoch: 18.63, Step: 73780, Train Loss: 1.2552, Learning Rate: 5.62e-05
2025-12-10 00:07:37 - INFO - Epoch: 18.63, Step: 73790, Train Loss: 1.2567, Learning Rate: 5.62e-05
2025-12-10 00:07:48 - INFO - Epoch: 18.63, Step: 73800, Train Loss: 1.2849, Learning Rate: 5.62e-05
2025-12-10 00:07:59 - INFO - Epoch: 18.63, Step: 73810, Train Loss: 1.3058, Learning Rate: 5.62e-05
2025-12-10 00:08:10 - INFO - Epoch: 18.64, Step: 73820, Train Loss: 1.2686, Learning Rate: 5.62e-05
2025-12-10 00:08:22 - INFO - Epoch: 18.64, Step: 73830, Train Loss: 1.2945, Learning Rate: 5.62e-05
2025-12-10 00:08:33 - INFO - Epoch: 18.64, Step: 73840, Train Loss: 1.3204, Learning Rate: 5.62e-05
2025-12-10 00:08:44 - INFO - Epoch: 18.64, Step: 73850, Train Loss: 1.3142, Learning Rate: 5.62e-05
2025-12-10 00:08:55 - INFO - Epoch: 18.65, Step: 73860, Train Loss: 1.2794, Learning Rate: 5.62e-05
2025-12-10 00:09:06 - INFO - Epoch: 18.65, Step: 73870, Train Loss: 1.2985, Learning Rate: 5.62e-05
2025-12-10 00:09:17 - INFO - Epoch: 18.65, Step: 73880, Train Loss: 1.2645, Learning Rate: 5.62e-05
2025-12-10 00:09:28 - INFO - Epoch: 18.65, Step: 73890, Train Loss: 1.2769, Learning Rate: 5.62e-05
2025-12-10 00:09:40 - INFO - Epoch: 18.66, Step: 73900, Train Loss: 1.3003, Learning Rate: 5.62e-05
2025-12-10 00:09:51 - INFO - Epoch: 18.66, Step: 73910, Train Loss: 1.2940, Learning Rate: 5.62e-05
2025-12-10 00:10:02 - INFO - Epoch: 18.66, Step: 73920, Train Loss: 1.2673, Learning Rate: 5.62e-05
2025-12-10 00:10:13 - INFO - Epoch: 18.66, Step: 73930, Train Loss: 1.2851, Learning Rate: 5.61e-05
2025-12-10 00:10:24 - INFO - Epoch: 18.67, Step: 73940, Train Loss: 1.3166, Learning Rate: 5.61e-05
2025-12-10 00:10:35 - INFO - Epoch: 18.67, Step: 73950, Train Loss: 1.2868, Learning Rate: 5.61e-05
2025-12-10 00:10:47 - INFO - Epoch: 18.67, Step: 73960, Train Loss: 1.3042, Learning Rate: 5.61e-05
2025-12-10 00:10:58 - INFO - Epoch: 18.67, Step: 73970, Train Loss: 1.2529, Learning Rate: 5.61e-05
2025-12-10 00:11:09 - INFO - Epoch: 18.68, Step: 73980, Train Loss: 1.2941, Learning Rate: 5.61e-05
2025-12-10 00:11:20 - INFO - Epoch: 18.68, Step: 73990, Train Loss: 1.3235, Learning Rate: 5.61e-05
2025-12-10 00:11:31 - INFO - Epoch: 18.68, Step: 74000, Train Loss: 1.3103, Learning Rate: 5.61e-05
2025-12-10 00:11:42 - INFO - Epoch: 18.68, Step: 74010, Train Loss: 1.2904, Learning Rate: 5.61e-05
2025-12-10 00:11:53 - INFO - Epoch: 18.69, Step: 74020, Train Loss: 1.2252, Learning Rate: 5.61e-05
2025-12-10 00:12:05 - INFO - Epoch: 18.69, Step: 74030, Train Loss: 1.3175, Learning Rate: 5.61e-05
2025-12-10 00:12:16 - INFO - Epoch: 18.69, Step: 74040, Train Loss: 1.2803, Learning Rate: 5.61e-05
2025-12-10 00:12:27 - INFO - Epoch: 18.69, Step: 74050, Train Loss: 1.2539, Learning Rate: 5.61e-05
2025-12-10 00:12:38 - INFO - Epoch: 18.70, Step: 74060, Train Loss: 1.2937, Learning Rate: 5.61e-05
2025-12-10 00:12:49 - INFO - Epoch: 18.70, Step: 74070, Train Loss: 1.3244, Learning Rate: 5.61e-05
2025-12-10 00:13:00 - INFO - Epoch: 18.70, Step: 74080, Train Loss: 1.2916, Learning Rate: 5.60e-05
2025-12-10 00:13:11 - INFO - Epoch: 18.70, Step: 74090, Train Loss: 1.2678, Learning Rate: 5.60e-05
2025-12-10 00:13:23 - INFO - Epoch: 18.71, Step: 74100, Train Loss: 1.3097, Learning Rate: 5.60e-05
2025-12-10 00:13:34 - INFO - Epoch: 18.71, Step: 74110, Train Loss: 1.2807, Learning Rate: 5.60e-05
2025-12-10 00:13:45 - INFO - Epoch: 18.71, Step: 74120, Train Loss: 1.3125, Learning Rate: 5.60e-05
2025-12-10 00:13:56 - INFO - Epoch: 18.71, Step: 74130, Train Loss: 1.2660, Learning Rate: 5.60e-05
2025-12-10 00:14:07 - INFO - Epoch: 18.72, Step: 74140, Train Loss: 1.2928, Learning Rate: 5.60e-05
2025-12-10 00:14:18 - INFO - Epoch: 18.72, Step: 74150, Train Loss: 1.2912, Learning Rate: 5.60e-05
2025-12-10 00:14:30 - INFO - Epoch: 18.72, Step: 74160, Train Loss: 1.2955, Learning Rate: 5.60e-05
2025-12-10 00:14:41 - INFO - Epoch: 18.73, Step: 74170, Train Loss: 1.3361, Learning Rate: 5.60e-05
2025-12-10 00:14:52 - INFO - Epoch: 18.73, Step: 74180, Train Loss: 1.3111, Learning Rate: 5.60e-05
2025-12-10 00:15:03 - INFO - Epoch: 18.73, Step: 74190, Train Loss: 1.2630, Learning Rate: 5.60e-05
2025-12-10 00:15:14 - INFO - Epoch: 18.73, Step: 74200, Train Loss: 1.2808, Learning Rate: 5.60e-05
2025-12-10 00:15:25 - INFO - Epoch: 18.74, Step: 74210, Train Loss: 1.2541, Learning Rate: 5.60e-05
2025-12-10 00:15:36 - INFO - Epoch: 18.74, Step: 74220, Train Loss: 1.3068, Learning Rate: 5.60e-05
2025-12-10 00:15:48 - INFO - Epoch: 18.74, Step: 74230, Train Loss: 1.2945, Learning Rate: 5.59e-05
2025-12-10 00:15:59 - INFO - Epoch: 18.74, Step: 74240, Train Loss: 1.2807, Learning Rate: 5.59e-05
2025-12-10 00:16:10 - INFO - Epoch: 18.75, Step: 74250, Train Loss: 1.2913, Learning Rate: 5.59e-05
2025-12-10 00:16:21 - INFO - Epoch: 18.75, Step: 74260, Train Loss: 1.2439, Learning Rate: 5.59e-05
2025-12-10 00:16:32 - INFO - Epoch: 18.75, Step: 74270, Train Loss: 1.2972, Learning Rate: 5.59e-05
2025-12-10 00:16:43 - INFO - Epoch: 18.75, Step: 74280, Train Loss: 1.3120, Learning Rate: 5.59e-05
2025-12-10 00:16:55 - INFO - Epoch: 18.76, Step: 74290, Train Loss: 1.3199, Learning Rate: 5.59e-05
2025-12-10 00:17:06 - INFO - Epoch: 18.76, Step: 74300, Train Loss: 1.2537, Learning Rate: 5.59e-05
2025-12-10 00:17:17 - INFO - Epoch: 18.76, Step: 74310, Train Loss: 1.3091, Learning Rate: 5.59e-05
2025-12-10 00:17:28 - INFO - Epoch: 18.76, Step: 74320, Train Loss: 1.2962, Learning Rate: 5.59e-05
2025-12-10 00:17:39 - INFO - Epoch: 18.77, Step: 74330, Train Loss: 1.3060, Learning Rate: 5.59e-05
2025-12-10 00:17:50 - INFO - Epoch: 18.77, Step: 74340, Train Loss: 1.2953, Learning Rate: 5.59e-05
2025-12-10 00:18:01 - INFO - Epoch: 18.77, Step: 74350, Train Loss: 1.2556, Learning Rate: 5.59e-05
2025-12-10 00:18:13 - INFO - Epoch: 18.77, Step: 74360, Train Loss: 1.2880, Learning Rate: 5.59e-05
2025-12-10 00:18:24 - INFO - Epoch: 18.78, Step: 74370, Train Loss: 1.2691, Learning Rate: 5.59e-05
2025-12-10 00:18:35 - INFO - Epoch: 18.78, Step: 74380, Train Loss: 1.2692, Learning Rate: 5.58e-05
2025-12-10 00:18:46 - INFO - Epoch: 18.78, Step: 74390, Train Loss: 1.2991, Learning Rate: 5.58e-05
2025-12-10 00:18:57 - INFO - Epoch: 18.78, Step: 74400, Train Loss: 1.2591, Learning Rate: 5.58e-05
2025-12-10 00:19:08 - INFO - Epoch: 18.79, Step: 74410, Train Loss: 1.2670, Learning Rate: 5.58e-05
2025-12-10 00:19:19 - INFO - Epoch: 18.79, Step: 74420, Train Loss: 1.2856, Learning Rate: 5.58e-05
2025-12-10 00:19:31 - INFO - Epoch: 18.79, Step: 74430, Train Loss: 1.2609, Learning Rate: 5.58e-05
2025-12-10 00:19:42 - INFO - Epoch: 18.79, Step: 74440, Train Loss: 1.2544, Learning Rate: 5.58e-05
2025-12-10 00:19:53 - INFO - Epoch: 18.80, Step: 74450, Train Loss: 1.2712, Learning Rate: 5.58e-05
2025-12-10 00:20:04 - INFO - Epoch: 18.80, Step: 74460, Train Loss: 1.2842, Learning Rate: 5.58e-05
2025-12-10 00:20:15 - INFO - Epoch: 18.80, Step: 74470, Train Loss: 1.2702, Learning Rate: 5.58e-05
2025-12-10 00:20:26 - INFO - Epoch: 18.80, Step: 74480, Train Loss: 1.2657, Learning Rate: 5.58e-05
2025-12-10 00:20:38 - INFO - Epoch: 18.81, Step: 74490, Train Loss: 1.2499, Learning Rate: 5.58e-05
2025-12-10 00:20:49 - INFO - Epoch: 18.81, Step: 74500, Train Loss: 1.3470, Learning Rate: 5.58e-05
2025-12-10 00:21:00 - INFO - Epoch: 18.81, Step: 74510, Train Loss: 1.2839, Learning Rate: 5.58e-05
2025-12-10 00:21:11 - INFO - Epoch: 18.81, Step: 74520, Train Loss: 1.2968, Learning Rate: 5.58e-05
2025-12-10 00:21:22 - INFO - Epoch: 18.82, Step: 74530, Train Loss: 1.2667, Learning Rate: 5.57e-05
2025-12-10 00:21:33 - INFO - Epoch: 18.82, Step: 74540, Train Loss: 1.2550, Learning Rate: 5.57e-05
2025-12-10 00:21:44 - INFO - Epoch: 18.82, Step: 74550, Train Loss: 1.2917, Learning Rate: 5.57e-05
2025-12-10 00:21:56 - INFO - Epoch: 18.82, Step: 74560, Train Loss: 1.2576, Learning Rate: 5.57e-05
2025-12-10 00:22:07 - INFO - Epoch: 18.83, Step: 74570, Train Loss: 1.2852, Learning Rate: 5.57e-05
2025-12-10 00:22:18 - INFO - Epoch: 18.83, Step: 74580, Train Loss: 1.2483, Learning Rate: 5.57e-05
2025-12-10 00:22:29 - INFO - Epoch: 18.83, Step: 74590, Train Loss: 1.2561, Learning Rate: 5.57e-05
2025-12-10 00:22:40 - INFO - Epoch: 18.83, Step: 74600, Train Loss: 1.2802, Learning Rate: 5.57e-05
2025-12-10 00:22:51 - INFO - Epoch: 18.84, Step: 74610, Train Loss: 1.2518, Learning Rate: 5.57e-05
2025-12-10 00:23:03 - INFO - Epoch: 18.84, Step: 74620, Train Loss: 1.2887, Learning Rate: 5.57e-05
2025-12-10 00:23:14 - INFO - Epoch: 18.84, Step: 74630, Train Loss: 1.2812, Learning Rate: 5.57e-05
2025-12-10 00:23:25 - INFO - Epoch: 18.84, Step: 74640, Train Loss: 1.2525, Learning Rate: 5.57e-05
2025-12-10 00:23:36 - INFO - Epoch: 18.85, Step: 74650, Train Loss: 1.2813, Learning Rate: 5.57e-05
2025-12-10 00:23:47 - INFO - Epoch: 18.85, Step: 74660, Train Loss: 1.3013, Learning Rate: 5.57e-05
2025-12-10 00:23:58 - INFO - Epoch: 18.85, Step: 74670, Train Loss: 1.2866, Learning Rate: 5.57e-05
2025-12-10 00:24:09 - INFO - Epoch: 18.85, Step: 74680, Train Loss: 1.2639, Learning Rate: 5.56e-05
2025-12-10 00:24:21 - INFO - Epoch: 18.86, Step: 74690, Train Loss: 1.2743, Learning Rate: 5.56e-05
2025-12-10 00:24:32 - INFO - Epoch: 18.86, Step: 74700, Train Loss: 1.2627, Learning Rate: 5.56e-05
2025-12-10 00:24:43 - INFO - Epoch: 18.86, Step: 74710, Train Loss: 1.2748, Learning Rate: 5.56e-05
2025-12-10 00:24:54 - INFO - Epoch: 18.86, Step: 74720, Train Loss: 1.3034, Learning Rate: 5.56e-05
2025-12-10 00:25:05 - INFO - Epoch: 18.87, Step: 74730, Train Loss: 1.2942, Learning Rate: 5.56e-05
2025-12-10 00:25:16 - INFO - Epoch: 18.87, Step: 74740, Train Loss: 1.2838, Learning Rate: 5.56e-05
2025-12-10 00:25:27 - INFO - Epoch: 18.87, Step: 74750, Train Loss: 1.2342, Learning Rate: 5.56e-05
2025-12-10 00:25:39 - INFO - Epoch: 18.87, Step: 74760, Train Loss: 1.3165, Learning Rate: 5.56e-05
2025-12-10 00:25:50 - INFO - Epoch: 18.88, Step: 74770, Train Loss: 1.2888, Learning Rate: 5.56e-05
2025-12-10 00:26:01 - INFO - Epoch: 18.88, Step: 74780, Train Loss: 1.2261, Learning Rate: 5.56e-05
2025-12-10 00:26:12 - INFO - Epoch: 18.88, Step: 74790, Train Loss: 1.2321, Learning Rate: 5.56e-05
2025-12-10 00:26:23 - INFO - Epoch: 18.88, Step: 74800, Train Loss: 1.2568, Learning Rate: 5.56e-05
2025-12-10 00:26:34 - INFO - Epoch: 18.89, Step: 74810, Train Loss: 1.3054, Learning Rate: 5.56e-05
2025-12-10 00:26:46 - INFO - Epoch: 18.89, Step: 74820, Train Loss: 1.2998, Learning Rate: 5.56e-05
2025-12-10 00:26:57 - INFO - Epoch: 18.89, Step: 74830, Train Loss: 1.3249, Learning Rate: 5.55e-05
2025-12-10 00:27:08 - INFO - Epoch: 18.89, Step: 74840, Train Loss: 1.2943, Learning Rate: 5.55e-05
2025-12-10 00:27:19 - INFO - Epoch: 18.90, Step: 74850, Train Loss: 1.2987, Learning Rate: 5.55e-05
2025-12-10 00:27:30 - INFO - Epoch: 18.90, Step: 74860, Train Loss: 1.2822, Learning Rate: 5.55e-05
2025-12-10 00:27:41 - INFO - Epoch: 18.90, Step: 74870, Train Loss: 1.2776, Learning Rate: 5.55e-05
2025-12-10 00:27:52 - INFO - Epoch: 18.90, Step: 74880, Train Loss: 1.2770, Learning Rate: 5.55e-05
2025-12-10 00:28:04 - INFO - Epoch: 18.91, Step: 74890, Train Loss: 1.2998, Learning Rate: 5.55e-05
2025-12-10 00:28:15 - INFO - Epoch: 18.91, Step: 74900, Train Loss: 1.2998, Learning Rate: 5.55e-05
2025-12-10 00:28:26 - INFO - Epoch: 18.91, Step: 74910, Train Loss: 1.2845, Learning Rate: 5.55e-05
2025-12-10 00:28:37 - INFO - Epoch: 18.91, Step: 74920, Train Loss: 1.2462, Learning Rate: 5.55e-05
2025-12-10 00:28:48 - INFO - Epoch: 18.92, Step: 74930, Train Loss: 1.3288, Learning Rate: 5.55e-05
2025-12-10 00:28:59 - INFO - Epoch: 18.92, Step: 74940, Train Loss: 1.3090, Learning Rate: 5.55e-05
2025-12-10 00:29:10 - INFO - Epoch: 18.92, Step: 74950, Train Loss: 1.2751, Learning Rate: 5.55e-05
2025-12-10 00:29:22 - INFO - Epoch: 18.92, Step: 74960, Train Loss: 1.2849, Learning Rate: 5.55e-05
2025-12-10 00:29:33 - INFO - Epoch: 18.93, Step: 74970, Train Loss: 1.2873, Learning Rate: 5.55e-05
2025-12-10 00:29:44 - INFO - Epoch: 18.93, Step: 74980, Train Loss: 1.2798, Learning Rate: 5.54e-05
2025-12-10 00:29:55 - INFO - Epoch: 18.93, Step: 74990, Train Loss: 1.2506, Learning Rate: 5.54e-05
2025-12-10 00:30:06 - INFO - Epoch: 18.93, Step: 75000, Train Loss: 1.3357, Learning Rate: 5.54e-05
2025-12-10 00:30:17 - INFO - Epoch: 18.94, Step: 75010, Train Loss: 1.2935, Learning Rate: 5.54e-05
2025-12-10 00:30:29 - INFO - Epoch: 18.94, Step: 75020, Train Loss: 1.2828, Learning Rate: 5.54e-05
2025-12-10 00:30:40 - INFO - Epoch: 18.94, Step: 75030, Train Loss: 1.2938, Learning Rate: 5.54e-05
2025-12-10 00:30:51 - INFO - Epoch: 18.94, Step: 75040, Train Loss: 1.2976, Learning Rate: 5.54e-05
2025-12-10 00:31:02 - INFO - Epoch: 18.95, Step: 75050, Train Loss: 1.2627, Learning Rate: 5.54e-05
2025-12-10 00:31:13 - INFO - Epoch: 18.95, Step: 75060, Train Loss: 1.2564, Learning Rate: 5.54e-05
2025-12-10 00:31:24 - INFO - Epoch: 18.95, Step: 75070, Train Loss: 1.2042, Learning Rate: 5.54e-05
2025-12-10 00:31:35 - INFO - Epoch: 18.95, Step: 75080, Train Loss: 1.3064, Learning Rate: 5.54e-05
2025-12-10 00:31:47 - INFO - Epoch: 18.96, Step: 75090, Train Loss: 1.2640, Learning Rate: 5.54e-05
2025-12-10 00:31:58 - INFO - Epoch: 18.96, Step: 75100, Train Loss: 1.2586, Learning Rate: 5.54e-05
2025-12-10 00:32:09 - INFO - Epoch: 18.96, Step: 75110, Train Loss: 1.2705, Learning Rate: 5.54e-05
2025-12-10 00:32:20 - INFO - Epoch: 18.96, Step: 75120, Train Loss: 1.2895, Learning Rate: 5.54e-05
2025-12-10 00:32:31 - INFO - Epoch: 18.97, Step: 75130, Train Loss: 1.2399, Learning Rate: 5.53e-05
2025-12-10 00:32:42 - INFO - Epoch: 18.97, Step: 75140, Train Loss: 1.3223, Learning Rate: 5.53e-05
2025-12-10 00:32:54 - INFO - Epoch: 18.97, Step: 75150, Train Loss: 1.3116, Learning Rate: 5.53e-05
2025-12-10 00:33:05 - INFO - Epoch: 18.98, Step: 75160, Train Loss: 1.2934, Learning Rate: 5.53e-05
2025-12-10 00:33:16 - INFO - Epoch: 18.98, Step: 75170, Train Loss: 1.2907, Learning Rate: 5.53e-05
2025-12-10 00:33:27 - INFO - Epoch: 18.98, Step: 75180, Train Loss: 1.2698, Learning Rate: 5.53e-05
2025-12-10 00:33:38 - INFO - Epoch: 18.98, Step: 75190, Train Loss: 1.2743, Learning Rate: 5.53e-05
2025-12-10 00:33:49 - INFO - Epoch: 18.99, Step: 75200, Train Loss: 1.2547, Learning Rate: 5.53e-05
2025-12-10 00:34:00 - INFO - Epoch: 18.99, Step: 75210, Train Loss: 1.2693, Learning Rate: 5.53e-05
2025-12-10 00:34:12 - INFO - Epoch: 18.99, Step: 75220, Train Loss: 1.3193, Learning Rate: 5.53e-05
2025-12-10 00:34:23 - INFO - Epoch: 18.99, Step: 75230, Train Loss: 1.2420, Learning Rate: 5.53e-05
2025-12-10 00:34:34 - INFO - Epoch: 19.00, Step: 75240, Train Loss: 1.2617, Learning Rate: 5.53e-05
2025-12-10 00:34:45 - INFO - Epoch: 19.00, Step: 75250, Train Loss: 1.2489, Learning Rate: 5.53e-05
2025-12-10 00:34:56 - INFO - Epoch: 19.00, Step: 75260, Train Loss: 1.2749, Learning Rate: 5.53e-05
2025-12-10 00:35:07 - INFO - Epoch: 19.00, Step: 75270, Train Loss: 1.2714, Learning Rate: 5.53e-05
2025-12-10 00:35:18 - INFO - Epoch: 19.01, Step: 75280, Train Loss: 1.2607, Learning Rate: 5.52e-05
2025-12-10 00:35:30 - INFO - Epoch: 19.01, Step: 75290, Train Loss: 1.2877, Learning Rate: 5.52e-05
2025-12-10 00:35:41 - INFO - Epoch: 19.01, Step: 75300, Train Loss: 1.2418, Learning Rate: 5.52e-05
2025-12-10 00:35:52 - INFO - Epoch: 19.01, Step: 75310, Train Loss: 1.2471, Learning Rate: 5.52e-05
2025-12-10 00:36:03 - INFO - Epoch: 19.02, Step: 75320, Train Loss: 1.3091, Learning Rate: 5.52e-05
2025-12-10 00:36:14 - INFO - Epoch: 19.02, Step: 75330, Train Loss: 1.2907, Learning Rate: 5.52e-05
2025-12-10 00:36:25 - INFO - Epoch: 19.02, Step: 75340, Train Loss: 1.2793, Learning Rate: 5.52e-05
2025-12-10 00:36:37 - INFO - Epoch: 19.02, Step: 75350, Train Loss: 1.3303, Learning Rate: 5.52e-05
2025-12-10 00:36:48 - INFO - Epoch: 19.03, Step: 75360, Train Loss: 1.2412, Learning Rate: 5.52e-05
2025-12-10 00:36:59 - INFO - Epoch: 19.03, Step: 75370, Train Loss: 1.2626, Learning Rate: 5.52e-05
2025-12-10 00:37:10 - INFO - Epoch: 19.03, Step: 75380, Train Loss: 1.2913, Learning Rate: 5.52e-05
2025-12-10 00:37:21 - INFO - Epoch: 19.03, Step: 75390, Train Loss: 1.2925, Learning Rate: 5.52e-05
2025-12-10 00:37:32 - INFO - Epoch: 19.04, Step: 75400, Train Loss: 1.2399, Learning Rate: 5.52e-05
2025-12-10 00:37:43 - INFO - Epoch: 19.04, Step: 75410, Train Loss: 1.2658, Learning Rate: 5.52e-05
2025-12-10 00:37:55 - INFO - Epoch: 19.04, Step: 75420, Train Loss: 1.2563, Learning Rate: 5.52e-05
2025-12-10 00:38:06 - INFO - Epoch: 19.04, Step: 75430, Train Loss: 1.2149, Learning Rate: 5.52e-05
2025-12-10 00:38:17 - INFO - Epoch: 19.05, Step: 75440, Train Loss: 1.2694, Learning Rate: 5.51e-05
2025-12-10 00:38:28 - INFO - Epoch: 19.05, Step: 75450, Train Loss: 1.2580, Learning Rate: 5.51e-05
2025-12-10 00:38:39 - INFO - Epoch: 19.05, Step: 75460, Train Loss: 1.2905, Learning Rate: 5.51e-05
2025-12-10 00:38:50 - INFO - Epoch: 19.05, Step: 75470, Train Loss: 1.2700, Learning Rate: 5.51e-05
2025-12-10 00:39:02 - INFO - Epoch: 19.06, Step: 75480, Train Loss: 1.3001, Learning Rate: 5.51e-05
2025-12-10 00:39:13 - INFO - Epoch: 19.06, Step: 75490, Train Loss: 1.2481, Learning Rate: 5.51e-05
2025-12-10 00:39:24 - INFO - Epoch: 19.06, Step: 75500, Train Loss: 1.2804, Learning Rate: 5.51e-05
2025-12-10 00:39:35 - INFO - Epoch: 19.06, Step: 75510, Train Loss: 1.2601, Learning Rate: 5.51e-05
2025-12-10 00:39:46 - INFO - Epoch: 19.07, Step: 75520, Train Loss: 1.2668, Learning Rate: 5.51e-05
2025-12-10 00:39:57 - INFO - Epoch: 19.07, Step: 75530, Train Loss: 1.2611, Learning Rate: 5.51e-05
2025-12-10 00:40:08 - INFO - Epoch: 19.07, Step: 75540, Train Loss: 1.2851, Learning Rate: 5.51e-05
2025-12-10 00:40:20 - INFO - Epoch: 19.07, Step: 75550, Train Loss: 1.2462, Learning Rate: 5.51e-05
2025-12-10 00:40:31 - INFO - Epoch: 19.08, Step: 75560, Train Loss: 1.3339, Learning Rate: 5.51e-05
2025-12-10 00:40:42 - INFO - Epoch: 19.08, Step: 75570, Train Loss: 1.2878, Learning Rate: 5.51e-05
2025-12-10 00:40:53 - INFO - Epoch: 19.08, Step: 75580, Train Loss: 1.3161, Learning Rate: 5.51e-05
2025-12-10 00:41:04 - INFO - Epoch: 19.08, Step: 75590, Train Loss: 1.2619, Learning Rate: 5.50e-05
2025-12-10 00:41:15 - INFO - Epoch: 19.09, Step: 75600, Train Loss: 1.2746, Learning Rate: 5.50e-05
2025-12-10 00:41:27 - INFO - Epoch: 19.09, Step: 75610, Train Loss: 1.3130, Learning Rate: 5.50e-05
2025-12-10 00:41:38 - INFO - Epoch: 19.09, Step: 75620, Train Loss: 1.2749, Learning Rate: 5.50e-05
2025-12-10 00:41:49 - INFO - Epoch: 19.09, Step: 75630, Train Loss: 1.2909, Learning Rate: 5.50e-05
2025-12-10 00:42:00 - INFO - Epoch: 19.10, Step: 75640, Train Loss: 1.2825, Learning Rate: 5.50e-05
2025-12-10 00:42:11 - INFO - Epoch: 19.10, Step: 75650, Train Loss: 1.2781, Learning Rate: 5.50e-05
2025-12-10 00:42:22 - INFO - Epoch: 19.10, Step: 75660, Train Loss: 1.2555, Learning Rate: 5.50e-05
2025-12-10 00:42:33 - INFO - Epoch: 19.10, Step: 75670, Train Loss: 1.2785, Learning Rate: 5.50e-05
2025-12-10 00:42:45 - INFO - Epoch: 19.11, Step: 75680, Train Loss: 1.2740, Learning Rate: 5.50e-05
2025-12-10 00:42:56 - INFO - Epoch: 19.11, Step: 75690, Train Loss: 1.2812, Learning Rate: 5.50e-05
2025-12-10 00:43:07 - INFO - Epoch: 19.11, Step: 75700, Train Loss: 1.2458, Learning Rate: 5.50e-05
2025-12-10 00:43:18 - INFO - Epoch: 19.11, Step: 75710, Train Loss: 1.2803, Learning Rate: 5.50e-05
2025-12-10 00:43:29 - INFO - Epoch: 19.12, Step: 75720, Train Loss: 1.2983, Learning Rate: 5.50e-05
2025-12-10 00:43:40 - INFO - Epoch: 19.12, Step: 75730, Train Loss: 1.2978, Learning Rate: 5.50e-05
2025-12-10 00:43:52 - INFO - Epoch: 19.12, Step: 75740, Train Loss: 1.2352, Learning Rate: 5.49e-05
2025-12-10 00:44:03 - INFO - Epoch: 19.12, Step: 75750, Train Loss: 1.2968, Learning Rate: 5.49e-05
2025-12-10 00:44:14 - INFO - Epoch: 19.13, Step: 75760, Train Loss: 1.2662, Learning Rate: 5.49e-05
2025-12-10 00:44:25 - INFO - Epoch: 19.13, Step: 75770, Train Loss: 1.2805, Learning Rate: 5.49e-05
2025-12-10 00:44:36 - INFO - Epoch: 19.13, Step: 75780, Train Loss: 1.2851, Learning Rate: 5.49e-05
2025-12-10 00:44:47 - INFO - Epoch: 19.13, Step: 75790, Train Loss: 1.2820, Learning Rate: 5.49e-05
2025-12-10 00:44:58 - INFO - Epoch: 19.14, Step: 75800, Train Loss: 1.2833, Learning Rate: 5.49e-05
2025-12-10 00:45:10 - INFO - Epoch: 19.14, Step: 75810, Train Loss: 1.3072, Learning Rate: 5.49e-05
2025-12-10 00:45:21 - INFO - Epoch: 19.14, Step: 75820, Train Loss: 1.2808, Learning Rate: 5.49e-05
2025-12-10 00:45:32 - INFO - Epoch: 19.14, Step: 75830, Train Loss: 1.2615, Learning Rate: 5.49e-05
2025-12-10 00:45:43 - INFO - Epoch: 19.15, Step: 75840, Train Loss: 1.2462, Learning Rate: 5.49e-05
2025-12-10 00:45:54 - INFO - Epoch: 19.15, Step: 75850, Train Loss: 1.2513, Learning Rate: 5.49e-05
2025-12-10 00:46:05 - INFO - Epoch: 19.15, Step: 75860, Train Loss: 1.2899, Learning Rate: 5.49e-05
2025-12-10 00:46:17 - INFO - Epoch: 19.15, Step: 75870, Train Loss: 1.2834, Learning Rate: 5.49e-05
2025-12-10 00:46:28 - INFO - Epoch: 19.16, Step: 75880, Train Loss: 1.2837, Learning Rate: 5.49e-05
2025-12-10 00:46:39 - INFO - Epoch: 19.16, Step: 75890, Train Loss: 1.3060, Learning Rate: 5.48e-05
2025-12-10 00:46:50 - INFO - Epoch: 19.16, Step: 75900, Train Loss: 1.2341, Learning Rate: 5.48e-05
2025-12-10 00:47:01 - INFO - Epoch: 19.16, Step: 75910, Train Loss: 1.2677, Learning Rate: 5.48e-05
2025-12-10 00:47:12 - INFO - Epoch: 19.17, Step: 75920, Train Loss: 1.2443, Learning Rate: 5.48e-05
2025-12-10 00:47:23 - INFO - Epoch: 19.17, Step: 75930, Train Loss: 1.2975, Learning Rate: 5.48e-05
2025-12-10 00:47:35 - INFO - Epoch: 19.17, Step: 75940, Train Loss: 1.2984, Learning Rate: 5.48e-05
2025-12-10 00:47:46 - INFO - Epoch: 19.17, Step: 75950, Train Loss: 1.3120, Learning Rate: 5.48e-05
2025-12-10 00:47:57 - INFO - Epoch: 19.18, Step: 75960, Train Loss: 1.2841, Learning Rate: 5.48e-05
2025-12-10 00:48:08 - INFO - Epoch: 19.18, Step: 75970, Train Loss: 1.2891, Learning Rate: 5.48e-05
2025-12-10 00:48:19 - INFO - Epoch: 19.18, Step: 75980, Train Loss: 1.2644, Learning Rate: 5.48e-05
2025-12-10 00:48:30 - INFO - Epoch: 19.18, Step: 75990, Train Loss: 1.3009, Learning Rate: 5.48e-05
2025-12-10 00:48:41 - INFO - Epoch: 19.19, Step: 76000, Train Loss: 1.2644, Learning Rate: 5.48e-05
2025-12-10 00:48:53 - INFO - Epoch: 19.19, Step: 76010, Train Loss: 1.2896, Learning Rate: 5.48e-05
2025-12-10 00:49:04 - INFO - Epoch: 19.19, Step: 76020, Train Loss: 1.2830, Learning Rate: 5.48e-05
2025-12-10 00:49:15 - INFO - Epoch: 19.19, Step: 76030, Train Loss: 1.2923, Learning Rate: 5.48e-05
2025-12-10 00:49:26 - INFO - Epoch: 19.20, Step: 76040, Train Loss: 1.2569, Learning Rate: 5.47e-05
2025-12-10 00:49:37 - INFO - Epoch: 19.20, Step: 76050, Train Loss: 1.2635, Learning Rate: 5.47e-05
2025-12-10 00:49:48 - INFO - Epoch: 19.20, Step: 76060, Train Loss: 1.2450, Learning Rate: 5.47e-05
2025-12-10 00:50:00 - INFO - Epoch: 19.20, Step: 76070, Train Loss: 1.2909, Learning Rate: 5.47e-05
2025-12-10 00:50:11 - INFO - Epoch: 19.21, Step: 76080, Train Loss: 1.2967, Learning Rate: 5.47e-05
2025-12-10 00:50:22 - INFO - Epoch: 19.21, Step: 76090, Train Loss: 1.2669, Learning Rate: 5.47e-05
2025-12-10 00:50:33 - INFO - Epoch: 19.21, Step: 76100, Train Loss: 1.2459, Learning Rate: 5.47e-05
2025-12-10 00:50:44 - INFO - Epoch: 19.21, Step: 76110, Train Loss: 1.3059, Learning Rate: 5.47e-05
2025-12-10 00:50:55 - INFO - Epoch: 19.22, Step: 76120, Train Loss: 1.2677, Learning Rate: 5.47e-05
2025-12-10 00:51:06 - INFO - Epoch: 19.22, Step: 76130, Train Loss: 1.2907, Learning Rate: 5.47e-05
2025-12-10 00:51:18 - INFO - Epoch: 19.22, Step: 76140, Train Loss: 1.2565, Learning Rate: 5.47e-05
2025-12-10 00:51:29 - INFO - Epoch: 19.22, Step: 76150, Train Loss: 1.2996, Learning Rate: 5.47e-05
2025-12-10 00:51:40 - INFO - Epoch: 19.23, Step: 76160, Train Loss: 1.2641, Learning Rate: 5.47e-05
2025-12-10 00:51:51 - INFO - Epoch: 19.23, Step: 76170, Train Loss: 1.2576, Learning Rate: 5.47e-05
2025-12-10 00:52:02 - INFO - Epoch: 19.23, Step: 76180, Train Loss: 1.2777, Learning Rate: 5.47e-05
2025-12-10 00:52:13 - INFO - Epoch: 19.24, Step: 76190, Train Loss: 1.2470, Learning Rate: 5.46e-05
2025-12-10 00:52:25 - INFO - Epoch: 19.24, Step: 76200, Train Loss: 1.2769, Learning Rate: 5.46e-05
2025-12-10 00:52:36 - INFO - Epoch: 19.24, Step: 76210, Train Loss: 1.2625, Learning Rate: 5.46e-05
2025-12-10 00:52:47 - INFO - Epoch: 19.24, Step: 76220, Train Loss: 1.2821, Learning Rate: 5.46e-05
2025-12-10 00:52:58 - INFO - Epoch: 19.25, Step: 76230, Train Loss: 1.2552, Learning Rate: 5.46e-05
2025-12-10 00:53:09 - INFO - Epoch: 19.25, Step: 76240, Train Loss: 1.2851, Learning Rate: 5.46e-05
2025-12-10 00:53:20 - INFO - Epoch: 19.25, Step: 76250, Train Loss: 1.2869, Learning Rate: 5.46e-05
2025-12-10 00:53:31 - INFO - Epoch: 19.25, Step: 76260, Train Loss: 1.2839, Learning Rate: 5.46e-05
2025-12-10 00:53:43 - INFO - Epoch: 19.26, Step: 76270, Train Loss: 1.2727, Learning Rate: 5.46e-05
2025-12-10 00:53:54 - INFO - Epoch: 19.26, Step: 76280, Train Loss: 1.2932, Learning Rate: 5.46e-05
2025-12-10 00:54:05 - INFO - Epoch: 19.26, Step: 76290, Train Loss: 1.2804, Learning Rate: 5.46e-05
2025-12-10 00:54:16 - INFO - Epoch: 19.26, Step: 76300, Train Loss: 1.2735, Learning Rate: 5.46e-05
2025-12-10 00:54:27 - INFO - Epoch: 19.27, Step: 76310, Train Loss: 1.3057, Learning Rate: 5.46e-05
2025-12-10 00:54:38 - INFO - Epoch: 19.27, Step: 76320, Train Loss: 1.2684, Learning Rate: 5.46e-05
2025-12-10 00:54:50 - INFO - Epoch: 19.27, Step: 76330, Train Loss: 1.2959, Learning Rate: 5.46e-05
2025-12-10 00:55:01 - INFO - Epoch: 19.27, Step: 76340, Train Loss: 1.2750, Learning Rate: 5.45e-05
2025-12-10 00:55:12 - INFO - Epoch: 19.28, Step: 76350, Train Loss: 1.2810, Learning Rate: 5.45e-05
2025-12-10 00:55:23 - INFO - Epoch: 19.28, Step: 76360, Train Loss: 1.2729, Learning Rate: 5.45e-05
2025-12-10 00:55:34 - INFO - Epoch: 19.28, Step: 76370, Train Loss: 1.2944, Learning Rate: 5.45e-05
2025-12-10 00:55:45 - INFO - Epoch: 19.28, Step: 76380, Train Loss: 1.2934, Learning Rate: 5.45e-05
2025-12-10 00:55:56 - INFO - Epoch: 19.29, Step: 76390, Train Loss: 1.2564, Learning Rate: 5.45e-05
2025-12-10 00:56:08 - INFO - Epoch: 19.29, Step: 76400, Train Loss: 1.2667, Learning Rate: 5.45e-05
2025-12-10 00:56:19 - INFO - Epoch: 19.29, Step: 76410, Train Loss: 1.2390, Learning Rate: 5.45e-05
2025-12-10 00:56:30 - INFO - Epoch: 19.29, Step: 76420, Train Loss: 1.2754, Learning Rate: 5.45e-05
2025-12-10 00:56:41 - INFO - Epoch: 19.30, Step: 76430, Train Loss: 1.2886, Learning Rate: 5.45e-05
2025-12-10 00:56:52 - INFO - Epoch: 19.30, Step: 76440, Train Loss: 1.2434, Learning Rate: 5.45e-05
2025-12-10 00:57:03 - INFO - Epoch: 19.30, Step: 76450, Train Loss: 1.2407, Learning Rate: 5.45e-05
2025-12-10 00:57:15 - INFO - Epoch: 19.30, Step: 76460, Train Loss: 1.2471, Learning Rate: 5.45e-05
2025-12-10 00:57:26 - INFO - Epoch: 19.31, Step: 76470, Train Loss: 1.3266, Learning Rate: 5.45e-05
2025-12-10 00:57:37 - INFO - Epoch: 19.31, Step: 76480, Train Loss: 1.2688, Learning Rate: 5.45e-05
2025-12-10 00:57:48 - INFO - Epoch: 19.31, Step: 76490, Train Loss: 1.2794, Learning Rate: 5.44e-05
2025-12-10 00:57:59 - INFO - Epoch: 19.31, Step: 76500, Train Loss: 1.3013, Learning Rate: 5.44e-05
2025-12-10 00:58:10 - INFO - Epoch: 19.32, Step: 76510, Train Loss: 1.2983, Learning Rate: 5.44e-05
2025-12-10 00:58:21 - INFO - Epoch: 19.32, Step: 76520, Train Loss: 1.2921, Learning Rate: 5.44e-05
2025-12-10 00:58:33 - INFO - Epoch: 19.32, Step: 76530, Train Loss: 1.2902, Learning Rate: 5.44e-05
2025-12-10 00:58:44 - INFO - Epoch: 19.32, Step: 76540, Train Loss: 1.2951, Learning Rate: 5.44e-05
2025-12-10 00:58:55 - INFO - Epoch: 19.33, Step: 76550, Train Loss: 1.2545, Learning Rate: 5.44e-05
2025-12-10 00:59:06 - INFO - Epoch: 19.33, Step: 76560, Train Loss: 1.2891, Learning Rate: 5.44e-05
2025-12-10 00:59:17 - INFO - Epoch: 19.33, Step: 76570, Train Loss: 1.3064, Learning Rate: 5.44e-05
2025-12-10 00:59:28 - INFO - Epoch: 19.33, Step: 76580, Train Loss: 1.2544, Learning Rate: 5.44e-05
2025-12-10 00:59:40 - INFO - Epoch: 19.34, Step: 76590, Train Loss: 1.2882, Learning Rate: 5.44e-05
2025-12-10 00:59:51 - INFO - Epoch: 19.34, Step: 76600, Train Loss: 1.2696, Learning Rate: 5.44e-05
2025-12-10 01:00:02 - INFO - Epoch: 19.34, Step: 76610, Train Loss: 1.2340, Learning Rate: 5.44e-05
2025-12-10 01:00:13 - INFO - Epoch: 19.34, Step: 76620, Train Loss: 1.2662, Learning Rate: 5.44e-05
2025-12-10 01:00:24 - INFO - Epoch: 19.35, Step: 76630, Train Loss: 1.2688, Learning Rate: 5.44e-05
2025-12-10 01:00:35 - INFO - Epoch: 19.35, Step: 76640, Train Loss: 1.2468, Learning Rate: 5.43e-05
2025-12-10 01:00:46 - INFO - Epoch: 19.35, Step: 76650, Train Loss: 1.2763, Learning Rate: 5.43e-05
2025-12-10 01:00:58 - INFO - Epoch: 19.35, Step: 76660, Train Loss: 1.2513, Learning Rate: 5.43e-05
2025-12-10 01:01:09 - INFO - Epoch: 19.36, Step: 76670, Train Loss: 1.3133, Learning Rate: 5.43e-05
2025-12-10 01:01:20 - INFO - Epoch: 19.36, Step: 76680, Train Loss: 1.2567, Learning Rate: 5.43e-05
2025-12-10 01:01:31 - INFO - Epoch: 19.36, Step: 76690, Train Loss: 1.2902, Learning Rate: 5.43e-05
2025-12-10 01:01:42 - INFO - Epoch: 19.36, Step: 76700, Train Loss: 1.2700, Learning Rate: 5.43e-05
2025-12-10 01:01:53 - INFO - Epoch: 19.37, Step: 76710, Train Loss: 1.2282, Learning Rate: 5.43e-05
2025-12-10 01:02:04 - INFO - Epoch: 19.37, Step: 76720, Train Loss: 1.2302, Learning Rate: 5.43e-05
2025-12-10 01:02:16 - INFO - Epoch: 19.37, Step: 76730, Train Loss: 1.2144, Learning Rate: 5.43e-05
2025-12-10 01:02:27 - INFO - Epoch: 19.37, Step: 76740, Train Loss: 1.2564, Learning Rate: 5.43e-05
2025-12-10 01:02:38 - INFO - Epoch: 19.38, Step: 76750, Train Loss: 1.2690, Learning Rate: 5.43e-05
2025-12-10 01:02:49 - INFO - Epoch: 19.38, Step: 76760, Train Loss: 1.3192, Learning Rate: 5.43e-05
2025-12-10 01:03:00 - INFO - Epoch: 19.38, Step: 76770, Train Loss: 1.2727, Learning Rate: 5.43e-05
2025-12-10 01:03:11 - INFO - Epoch: 19.38, Step: 76780, Train Loss: 1.3031, Learning Rate: 5.43e-05
2025-12-10 01:03:23 - INFO - Epoch: 19.39, Step: 76790, Train Loss: 1.2847, Learning Rate: 5.42e-05
2025-12-10 01:03:34 - INFO - Epoch: 19.39, Step: 76800, Train Loss: 1.2521, Learning Rate: 5.42e-05
2025-12-10 01:03:45 - INFO - Epoch: 19.39, Step: 76810, Train Loss: 1.2849, Learning Rate: 5.42e-05
2025-12-10 01:03:56 - INFO - Epoch: 19.39, Step: 76820, Train Loss: 1.3063, Learning Rate: 5.42e-05
2025-12-10 01:04:07 - INFO - Epoch: 19.40, Step: 76830, Train Loss: 1.2538, Learning Rate: 5.42e-05
2025-12-10 01:04:18 - INFO - Epoch: 19.40, Step: 76840, Train Loss: 1.2810, Learning Rate: 5.42e-05
2025-12-10 01:04:29 - INFO - Epoch: 19.40, Step: 76850, Train Loss: 1.2723, Learning Rate: 5.42e-05
2025-12-10 01:04:41 - INFO - Epoch: 19.40, Step: 76860, Train Loss: 1.2333, Learning Rate: 5.42e-05
2025-12-10 01:04:52 - INFO - Epoch: 19.41, Step: 76870, Train Loss: 1.2501, Learning Rate: 5.42e-05
2025-12-10 01:05:03 - INFO - Epoch: 19.41, Step: 76880, Train Loss: 1.2893, Learning Rate: 5.42e-05
2025-12-10 01:05:14 - INFO - Epoch: 19.41, Step: 76890, Train Loss: 1.2525, Learning Rate: 5.42e-05
2025-12-10 01:05:25 - INFO - Epoch: 19.41, Step: 76900, Train Loss: 1.2567, Learning Rate: 5.42e-05
2025-12-10 01:05:36 - INFO - Epoch: 19.42, Step: 76910, Train Loss: 1.2558, Learning Rate: 5.42e-05
2025-12-10 01:05:48 - INFO - Epoch: 19.42, Step: 76920, Train Loss: 1.2944, Learning Rate: 5.42e-05
2025-12-10 01:05:59 - INFO - Epoch: 19.42, Step: 76930, Train Loss: 1.2643, Learning Rate: 5.42e-05
2025-12-10 01:06:10 - INFO - Epoch: 19.42, Step: 76940, Train Loss: 1.2694, Learning Rate: 5.41e-05
2025-12-10 01:06:21 - INFO - Epoch: 19.43, Step: 76950, Train Loss: 1.2686, Learning Rate: 5.41e-05
2025-12-10 01:06:32 - INFO - Epoch: 19.43, Step: 76960, Train Loss: 1.2571, Learning Rate: 5.41e-05
2025-12-10 01:06:43 - INFO - Epoch: 19.43, Step: 76970, Train Loss: 1.3019, Learning Rate: 5.41e-05
2025-12-10 01:06:54 - INFO - Epoch: 19.43, Step: 76980, Train Loss: 1.2592, Learning Rate: 5.41e-05
2025-12-10 01:07:06 - INFO - Epoch: 19.44, Step: 76990, Train Loss: 1.2826, Learning Rate: 5.41e-05
2025-12-10 01:07:17 - INFO - Epoch: 19.44, Step: 77000, Train Loss: 1.2747, Learning Rate: 5.41e-05
2025-12-10 01:07:28 - INFO - Epoch: 19.44, Step: 77010, Train Loss: 1.2956, Learning Rate: 5.41e-05
2025-12-10 01:07:39 - INFO - Epoch: 19.44, Step: 77020, Train Loss: 1.2306, Learning Rate: 5.41e-05
2025-12-10 01:07:50 - INFO - Epoch: 19.45, Step: 77030, Train Loss: 1.2474, Learning Rate: 5.41e-05
2025-12-10 01:08:01 - INFO - Epoch: 19.45, Step: 77040, Train Loss: 1.2683, Learning Rate: 5.41e-05
2025-12-10 01:08:13 - INFO - Epoch: 19.45, Step: 77050, Train Loss: 1.2253, Learning Rate: 5.41e-05
2025-12-10 01:08:24 - INFO - Epoch: 19.45, Step: 77060, Train Loss: 1.2717, Learning Rate: 5.41e-05
2025-12-10 01:08:35 - INFO - Epoch: 19.46, Step: 77070, Train Loss: 1.2905, Learning Rate: 5.41e-05
2025-12-10 01:08:46 - INFO - Epoch: 19.46, Step: 77080, Train Loss: 1.3150, Learning Rate: 5.41e-05
2025-12-10 01:08:57 - INFO - Epoch: 19.46, Step: 77090, Train Loss: 1.2677, Learning Rate: 5.40e-05
2025-12-10 01:09:08 - INFO - Epoch: 19.46, Step: 77100, Train Loss: 1.2648, Learning Rate: 5.40e-05
2025-12-10 01:09:19 - INFO - Epoch: 19.47, Step: 77110, Train Loss: 1.2878, Learning Rate: 5.40e-05
2025-12-10 01:09:31 - INFO - Epoch: 19.47, Step: 77120, Train Loss: 1.2948, Learning Rate: 5.40e-05
2025-12-10 01:09:42 - INFO - Epoch: 19.47, Step: 77130, Train Loss: 1.2713, Learning Rate: 5.40e-05
2025-12-10 01:09:53 - INFO - Epoch: 19.47, Step: 77140, Train Loss: 1.3140, Learning Rate: 5.40e-05
2025-12-10 01:10:04 - INFO - Epoch: 19.48, Step: 77150, Train Loss: 1.2750, Learning Rate: 5.40e-05
2025-12-10 01:10:15 - INFO - Epoch: 19.48, Step: 77160, Train Loss: 1.2978, Learning Rate: 5.40e-05
2025-12-10 01:10:26 - INFO - Epoch: 19.48, Step: 77170, Train Loss: 1.2780, Learning Rate: 5.40e-05
2025-12-10 01:10:38 - INFO - Epoch: 19.48, Step: 77180, Train Loss: 1.2811, Learning Rate: 5.40e-05
2025-12-10 01:10:49 - INFO - Epoch: 19.49, Step: 77190, Train Loss: 1.2457, Learning Rate: 5.40e-05
2025-12-10 01:11:00 - INFO - Epoch: 19.49, Step: 77200, Train Loss: 1.2521, Learning Rate: 5.40e-05
2025-12-10 01:11:11 - INFO - Epoch: 19.49, Step: 77210, Train Loss: 1.3055, Learning Rate: 5.40e-05
2025-12-10 01:11:22 - INFO - Epoch: 19.50, Step: 77220, Train Loss: 1.2636, Learning Rate: 5.40e-05
2025-12-10 01:11:33 - INFO - Epoch: 19.50, Step: 77230, Train Loss: 1.2662, Learning Rate: 5.40e-05
2025-12-10 01:11:44 - INFO - Epoch: 19.50, Step: 77240, Train Loss: 1.2789, Learning Rate: 5.39e-05
2025-12-10 01:11:56 - INFO - Epoch: 19.50, Step: 77250, Train Loss: 1.2818, Learning Rate: 5.39e-05
2025-12-10 01:12:07 - INFO - Epoch: 19.51, Step: 77260, Train Loss: 1.2743, Learning Rate: 5.39e-05
2025-12-10 01:12:18 - INFO - Epoch: 19.51, Step: 77270, Train Loss: 1.2982, Learning Rate: 5.39e-05
2025-12-10 01:12:29 - INFO - Epoch: 19.51, Step: 77280, Train Loss: 1.2737, Learning Rate: 5.39e-05
2025-12-10 01:12:40 - INFO - Epoch: 19.51, Step: 77290, Train Loss: 1.2584, Learning Rate: 5.39e-05
2025-12-10 01:12:51 - INFO - Epoch: 19.52, Step: 77300, Train Loss: 1.2913, Learning Rate: 5.39e-05
2025-12-10 01:13:02 - INFO - Epoch: 19.52, Step: 77310, Train Loss: 1.2867, Learning Rate: 5.39e-05
2025-12-10 01:13:14 - INFO - Epoch: 19.52, Step: 77320, Train Loss: 1.2826, Learning Rate: 5.39e-05
2025-12-10 01:13:25 - INFO - Epoch: 19.52, Step: 77330, Train Loss: 1.2678, Learning Rate: 5.39e-05
2025-12-10 01:13:36 - INFO - Epoch: 19.53, Step: 77340, Train Loss: 1.2999, Learning Rate: 5.39e-05
2025-12-10 01:13:47 - INFO - Epoch: 19.53, Step: 77350, Train Loss: 1.2688, Learning Rate: 5.39e-05
2025-12-10 01:13:58 - INFO - Epoch: 19.53, Step: 77360, Train Loss: 1.2632, Learning Rate: 5.39e-05
2025-12-10 01:14:09 - INFO - Epoch: 19.53, Step: 77370, Train Loss: 1.2612, Learning Rate: 5.39e-05
2025-12-10 01:14:21 - INFO - Epoch: 19.54, Step: 77380, Train Loss: 1.2785, Learning Rate: 5.39e-05
2025-12-10 01:14:32 - INFO - Epoch: 19.54, Step: 77390, Train Loss: 1.3140, Learning Rate: 5.38e-05
2025-12-10 01:14:43 - INFO - Epoch: 19.54, Step: 77400, Train Loss: 1.2777, Learning Rate: 5.38e-05
2025-12-10 01:14:54 - INFO - Epoch: 19.54, Step: 77410, Train Loss: 1.2757, Learning Rate: 5.38e-05
2025-12-10 01:15:05 - INFO - Epoch: 19.55, Step: 77420, Train Loss: 1.2558, Learning Rate: 5.38e-05
2025-12-10 01:15:16 - INFO - Epoch: 19.55, Step: 77430, Train Loss: 1.2421, Learning Rate: 5.38e-05
2025-12-10 01:15:27 - INFO - Epoch: 19.55, Step: 77440, Train Loss: 1.2790, Learning Rate: 5.38e-05
2025-12-10 01:15:39 - INFO - Epoch: 19.55, Step: 77450, Train Loss: 1.2461, Learning Rate: 5.38e-05
2025-12-10 01:15:50 - INFO - Epoch: 19.56, Step: 77460, Train Loss: 1.2669, Learning Rate: 5.38e-05
2025-12-10 01:16:01 - INFO - Epoch: 19.56, Step: 77470, Train Loss: 1.2891, Learning Rate: 5.38e-05
2025-12-10 01:16:12 - INFO - Epoch: 19.56, Step: 77480, Train Loss: 1.2994, Learning Rate: 5.38e-05
2025-12-10 01:16:23 - INFO - Epoch: 19.56, Step: 77490, Train Loss: 1.2761, Learning Rate: 5.38e-05
2025-12-10 01:16:34 - INFO - Epoch: 19.57, Step: 77500, Train Loss: 1.2480, Learning Rate: 5.38e-05
2025-12-10 01:16:46 - INFO - Epoch: 19.57, Step: 77510, Train Loss: 1.2702, Learning Rate: 5.38e-05
2025-12-10 01:16:57 - INFO - Epoch: 19.57, Step: 77520, Train Loss: 1.2889, Learning Rate: 5.38e-05
2025-12-10 01:17:08 - INFO - Epoch: 19.57, Step: 77530, Train Loss: 1.2768, Learning Rate: 5.38e-05
2025-12-10 01:17:19 - INFO - Epoch: 19.58, Step: 77540, Train Loss: 1.2864, Learning Rate: 5.37e-05
2025-12-10 01:17:30 - INFO - Epoch: 19.58, Step: 77550, Train Loss: 1.2943, Learning Rate: 5.37e-05
2025-12-10 01:17:41 - INFO - Epoch: 19.58, Step: 77560, Train Loss: 1.2675, Learning Rate: 5.37e-05
2025-12-10 01:17:52 - INFO - Epoch: 19.58, Step: 77570, Train Loss: 1.2976, Learning Rate: 5.37e-05
2025-12-10 01:18:04 - INFO - Epoch: 19.59, Step: 77580, Train Loss: 1.3010, Learning Rate: 5.37e-05
2025-12-10 01:18:15 - INFO - Epoch: 19.59, Step: 77590, Train Loss: 1.2835, Learning Rate: 5.37e-05
2025-12-10 01:18:26 - INFO - Epoch: 19.59, Step: 77600, Train Loss: 1.2777, Learning Rate: 5.37e-05
2025-12-10 01:18:37 - INFO - Epoch: 19.59, Step: 77610, Train Loss: 1.2713, Learning Rate: 5.37e-05
2025-12-10 01:18:48 - INFO - Epoch: 19.60, Step: 77620, Train Loss: 1.2679, Learning Rate: 5.37e-05
2025-12-10 01:18:59 - INFO - Epoch: 19.60, Step: 77630, Train Loss: 1.2537, Learning Rate: 5.37e-05
2025-12-10 01:19:11 - INFO - Epoch: 19.60, Step: 77640, Train Loss: 1.2855, Learning Rate: 5.37e-05
2025-12-10 01:19:22 - INFO - Epoch: 19.60, Step: 77650, Train Loss: 1.2871, Learning Rate: 5.37e-05
2025-12-10 01:19:33 - INFO - Epoch: 19.61, Step: 77660, Train Loss: 1.2737, Learning Rate: 5.37e-05
2025-12-10 01:19:44 - INFO - Epoch: 19.61, Step: 77670, Train Loss: 1.2718, Learning Rate: 5.37e-05
2025-12-10 01:19:55 - INFO - Epoch: 19.61, Step: 77680, Train Loss: 1.2801, Learning Rate: 5.37e-05
2025-12-10 01:20:06 - INFO - Epoch: 19.61, Step: 77690, Train Loss: 1.3155, Learning Rate: 5.36e-05
2025-12-10 01:20:17 - INFO - Epoch: 19.62, Step: 77700, Train Loss: 1.2564, Learning Rate: 5.36e-05
2025-12-10 01:20:29 - INFO - Epoch: 19.62, Step: 77710, Train Loss: 1.2530, Learning Rate: 5.36e-05
2025-12-10 01:20:40 - INFO - Epoch: 19.62, Step: 77720, Train Loss: 1.3210, Learning Rate: 5.36e-05
2025-12-10 01:20:51 - INFO - Epoch: 19.62, Step: 77730, Train Loss: 1.2660, Learning Rate: 5.36e-05
2025-12-10 01:21:02 - INFO - Epoch: 19.63, Step: 77740, Train Loss: 1.2717, Learning Rate: 5.36e-05
2025-12-10 01:21:13 - INFO - Epoch: 19.63, Step: 77750, Train Loss: 1.2638, Learning Rate: 5.36e-05
2025-12-10 01:21:24 - INFO - Epoch: 19.63, Step: 77760, Train Loss: 1.2451, Learning Rate: 5.36e-05
2025-12-10 01:21:36 - INFO - Epoch: 19.63, Step: 77770, Train Loss: 1.2756, Learning Rate: 5.36e-05
2025-12-10 01:21:47 - INFO - Epoch: 19.64, Step: 77780, Train Loss: 1.2555, Learning Rate: 5.36e-05
2025-12-10 01:21:58 - INFO - Epoch: 19.64, Step: 77790, Train Loss: 1.2460, Learning Rate: 5.36e-05
2025-12-10 01:22:09 - INFO - Epoch: 19.64, Step: 77800, Train Loss: 1.2349, Learning Rate: 5.36e-05
2025-12-10 01:22:20 - INFO - Epoch: 19.64, Step: 77810, Train Loss: 1.2924, Learning Rate: 5.36e-05
2025-12-10 01:22:31 - INFO - Epoch: 19.65, Step: 77820, Train Loss: 1.2979, Learning Rate: 5.36e-05
2025-12-10 01:22:42 - INFO - Epoch: 19.65, Step: 77830, Train Loss: 1.2677, Learning Rate: 5.36e-05
2025-12-10 01:22:54 - INFO - Epoch: 19.65, Step: 77840, Train Loss: 1.2771, Learning Rate: 5.35e-05
2025-12-10 01:23:05 - INFO - Epoch: 19.65, Step: 77850, Train Loss: 1.3007, Learning Rate: 5.35e-05
2025-12-10 01:23:16 - INFO - Epoch: 19.66, Step: 77860, Train Loss: 1.2606, Learning Rate: 5.35e-05
2025-12-10 01:23:27 - INFO - Epoch: 19.66, Step: 77870, Train Loss: 1.2327, Learning Rate: 5.35e-05
2025-12-10 01:23:38 - INFO - Epoch: 19.66, Step: 77880, Train Loss: 1.2416, Learning Rate: 5.35e-05
2025-12-10 01:23:49 - INFO - Epoch: 19.66, Step: 77890, Train Loss: 1.2248, Learning Rate: 5.35e-05
2025-12-10 01:24:01 - INFO - Epoch: 19.67, Step: 77900, Train Loss: 1.3050, Learning Rate: 5.35e-05
2025-12-10 01:24:12 - INFO - Epoch: 19.67, Step: 77910, Train Loss: 1.2780, Learning Rate: 5.35e-05
2025-12-10 01:24:23 - INFO - Epoch: 19.67, Step: 77920, Train Loss: 1.2789, Learning Rate: 5.35e-05
2025-12-10 01:24:34 - INFO - Epoch: 19.67, Step: 77930, Train Loss: 1.2640, Learning Rate: 5.35e-05
2025-12-10 01:24:45 - INFO - Epoch: 19.68, Step: 77940, Train Loss: 1.2582, Learning Rate: 5.35e-05
2025-12-10 01:24:56 - INFO - Epoch: 19.68, Step: 77950, Train Loss: 1.2341, Learning Rate: 5.35e-05
2025-12-10 01:25:07 - INFO - Epoch: 19.68, Step: 77960, Train Loss: 1.2995, Learning Rate: 5.35e-05
2025-12-10 01:25:19 - INFO - Epoch: 19.68, Step: 77970, Train Loss: 1.2721, Learning Rate: 5.35e-05
2025-12-10 01:25:30 - INFO - Epoch: 19.69, Step: 77980, Train Loss: 1.2143, Learning Rate: 5.35e-05
2025-12-10 01:25:41 - INFO - Epoch: 19.69, Step: 77990, Train Loss: 1.2488, Learning Rate: 5.34e-05
2025-12-10 01:25:52 - INFO - Epoch: 19.69, Step: 78000, Train Loss: 1.3124, Learning Rate: 5.34e-05
2025-12-10 01:26:03 - INFO - Epoch: 19.69, Step: 78010, Train Loss: 1.2877, Learning Rate: 5.34e-05
2025-12-10 01:26:14 - INFO - Epoch: 19.70, Step: 78020, Train Loss: 1.2524, Learning Rate: 5.34e-05
2025-12-10 01:26:25 - INFO - Epoch: 19.70, Step: 78030, Train Loss: 1.2789, Learning Rate: 5.34e-05
2025-12-10 01:26:37 - INFO - Epoch: 19.70, Step: 78040, Train Loss: 1.2584, Learning Rate: 5.34e-05
2025-12-10 01:26:48 - INFO - Epoch: 19.70, Step: 78050, Train Loss: 1.3215, Learning Rate: 5.34e-05
2025-12-10 01:26:59 - INFO - Epoch: 19.71, Step: 78060, Train Loss: 1.2574, Learning Rate: 5.34e-05
2025-12-10 01:27:10 - INFO - Epoch: 19.71, Step: 78070, Train Loss: 1.2822, Learning Rate: 5.34e-05
2025-12-10 01:27:21 - INFO - Epoch: 19.71, Step: 78080, Train Loss: 1.3121, Learning Rate: 5.34e-05
2025-12-10 01:27:32 - INFO - Epoch: 19.71, Step: 78090, Train Loss: 1.2967, Learning Rate: 5.34e-05
2025-12-10 01:27:44 - INFO - Epoch: 19.72, Step: 78100, Train Loss: 1.2833, Learning Rate: 5.34e-05
2025-12-10 01:27:55 - INFO - Epoch: 19.72, Step: 78110, Train Loss: 1.2674, Learning Rate: 5.34e-05
2025-12-10 01:28:06 - INFO - Epoch: 19.72, Step: 78120, Train Loss: 1.2713, Learning Rate: 5.34e-05
2025-12-10 01:28:17 - INFO - Epoch: 19.72, Step: 78130, Train Loss: 1.2714, Learning Rate: 5.34e-05
2025-12-10 01:28:28 - INFO - Epoch: 19.73, Step: 78140, Train Loss: 1.2551, Learning Rate: 5.33e-05
2025-12-10 01:28:39 - INFO - Epoch: 19.73, Step: 78150, Train Loss: 1.2335, Learning Rate: 5.33e-05
2025-12-10 01:28:50 - INFO - Epoch: 19.73, Step: 78160, Train Loss: 1.2494, Learning Rate: 5.33e-05
2025-12-10 01:29:02 - INFO - Epoch: 19.73, Step: 78170, Train Loss: 1.2656, Learning Rate: 5.33e-05
2025-12-10 01:29:13 - INFO - Epoch: 19.74, Step: 78180, Train Loss: 1.2353, Learning Rate: 5.33e-05
2025-12-10 01:29:24 - INFO - Epoch: 19.74, Step: 78190, Train Loss: 1.3054, Learning Rate: 5.33e-05
2025-12-10 01:29:35 - INFO - Epoch: 19.74, Step: 78200, Train Loss: 1.2693, Learning Rate: 5.33e-05
2025-12-10 01:29:46 - INFO - Epoch: 19.75, Step: 78210, Train Loss: 1.2722, Learning Rate: 5.33e-05
2025-12-10 01:29:57 - INFO - Epoch: 19.75, Step: 78220, Train Loss: 1.2679, Learning Rate: 5.33e-05
2025-12-10 01:30:09 - INFO - Epoch: 19.75, Step: 78230, Train Loss: 1.2322, Learning Rate: 5.33e-05
2025-12-10 01:30:20 - INFO - Epoch: 19.75, Step: 78240, Train Loss: 1.2552, Learning Rate: 5.33e-05
2025-12-10 01:30:31 - INFO - Epoch: 19.76, Step: 78250, Train Loss: 1.2817, Learning Rate: 5.33e-05
2025-12-10 01:30:42 - INFO - Epoch: 19.76, Step: 78260, Train Loss: 1.2234, Learning Rate: 5.33e-05
2025-12-10 01:30:53 - INFO - Epoch: 19.76, Step: 78270, Train Loss: 1.2613, Learning Rate: 5.33e-05
2025-12-10 01:31:04 - INFO - Epoch: 19.76, Step: 78280, Train Loss: 1.2927, Learning Rate: 5.33e-05
2025-12-10 01:31:15 - INFO - Epoch: 19.77, Step: 78290, Train Loss: 1.2650, Learning Rate: 5.33e-05
2025-12-10 01:31:27 - INFO - Epoch: 19.77, Step: 78300, Train Loss: 1.2669, Learning Rate: 5.32e-05
2025-12-10 01:31:38 - INFO - Epoch: 19.77, Step: 78310, Train Loss: 1.2620, Learning Rate: 5.32e-05
2025-12-10 01:31:49 - INFO - Epoch: 19.77, Step: 78320, Train Loss: 1.2722, Learning Rate: 5.32e-05
2025-12-10 01:32:00 - INFO - Epoch: 19.78, Step: 78330, Train Loss: 1.2616, Learning Rate: 5.32e-05
2025-12-10 01:32:11 - INFO - Epoch: 19.78, Step: 78340, Train Loss: 1.2712, Learning Rate: 5.32e-05
2025-12-10 01:32:22 - INFO - Epoch: 19.78, Step: 78350, Train Loss: 1.2380, Learning Rate: 5.32e-05
2025-12-10 01:32:34 - INFO - Epoch: 19.78, Step: 78360, Train Loss: 1.2694, Learning Rate: 5.32e-05
2025-12-10 01:32:45 - INFO - Epoch: 19.79, Step: 78370, Train Loss: 1.2949, Learning Rate: 5.32e-05
2025-12-10 01:32:56 - INFO - Epoch: 19.79, Step: 78380, Train Loss: 1.2576, Learning Rate: 5.32e-05
2025-12-10 01:33:07 - INFO - Epoch: 19.79, Step: 78390, Train Loss: 1.2949, Learning Rate: 5.32e-05
2025-12-10 01:33:18 - INFO - Epoch: 19.79, Step: 78400, Train Loss: 1.2431, Learning Rate: 5.32e-05
2025-12-10 01:33:29 - INFO - Epoch: 19.80, Step: 78410, Train Loss: 1.2732, Learning Rate: 5.32e-05
2025-12-10 01:33:40 - INFO - Epoch: 19.80, Step: 78420, Train Loss: 1.2829, Learning Rate: 5.32e-05
2025-12-10 01:33:52 - INFO - Epoch: 19.80, Step: 78430, Train Loss: 1.3048, Learning Rate: 5.32e-05
2025-12-10 01:34:03 - INFO - Epoch: 19.80, Step: 78440, Train Loss: 1.3186, Learning Rate: 5.32e-05
2025-12-10 01:34:14 - INFO - Epoch: 19.81, Step: 78450, Train Loss: 1.2604, Learning Rate: 5.31e-05
2025-12-10 01:34:25 - INFO - Epoch: 19.81, Step: 78460, Train Loss: 1.2755, Learning Rate: 5.31e-05
2025-12-10 01:34:36 - INFO - Epoch: 19.81, Step: 78470, Train Loss: 1.2628, Learning Rate: 5.31e-05
2025-12-10 01:34:47 - INFO - Epoch: 19.81, Step: 78480, Train Loss: 1.2816, Learning Rate: 5.31e-05
2025-12-10 01:34:59 - INFO - Epoch: 19.82, Step: 78490, Train Loss: 1.2330, Learning Rate: 5.31e-05
2025-12-10 01:35:10 - INFO - Epoch: 19.82, Step: 78500, Train Loss: 1.2650, Learning Rate: 5.31e-05
2025-12-10 01:35:21 - INFO - Epoch: 19.82, Step: 78510, Train Loss: 1.2412, Learning Rate: 5.31e-05
2025-12-10 01:35:32 - INFO - Epoch: 19.82, Step: 78520, Train Loss: 1.2953, Learning Rate: 5.31e-05
2025-12-10 01:35:43 - INFO - Epoch: 19.83, Step: 78530, Train Loss: 1.2705, Learning Rate: 5.31e-05
2025-12-10 01:35:54 - INFO - Epoch: 19.83, Step: 78540, Train Loss: 1.2508, Learning Rate: 5.31e-05
2025-12-10 01:36:05 - INFO - Epoch: 19.83, Step: 78550, Train Loss: 1.2644, Learning Rate: 5.31e-05
2025-12-10 01:36:17 - INFO - Epoch: 19.83, Step: 78560, Train Loss: 1.2606, Learning Rate: 5.31e-05
2025-12-10 01:36:28 - INFO - Epoch: 19.84, Step: 78570, Train Loss: 1.2709, Learning Rate: 5.31e-05
2025-12-10 01:36:39 - INFO - Epoch: 19.84, Step: 78580, Train Loss: 1.2946, Learning Rate: 5.31e-05
2025-12-10 01:36:50 - INFO - Epoch: 19.84, Step: 78590, Train Loss: 1.2690, Learning Rate: 5.31e-05
2025-12-10 01:37:01 - INFO - Epoch: 19.84, Step: 78600, Train Loss: 1.2866, Learning Rate: 5.30e-05
2025-12-10 01:37:12 - INFO - Epoch: 19.85, Step: 78610, Train Loss: 1.2916, Learning Rate: 5.30e-05
2025-12-10 01:37:24 - INFO - Epoch: 19.85, Step: 78620, Train Loss: 1.2801, Learning Rate: 5.30e-05
2025-12-10 01:37:35 - INFO - Epoch: 19.85, Step: 78630, Train Loss: 1.2776, Learning Rate: 5.30e-05
2025-12-10 01:37:46 - INFO - Epoch: 19.85, Step: 78640, Train Loss: 1.2730, Learning Rate: 5.30e-05
2025-12-10 01:37:57 - INFO - Epoch: 19.86, Step: 78650, Train Loss: 1.2758, Learning Rate: 5.30e-05
2025-12-10 01:38:08 - INFO - Epoch: 19.86, Step: 78660, Train Loss: 1.2919, Learning Rate: 5.30e-05
2025-12-10 01:38:19 - INFO - Epoch: 19.86, Step: 78670, Train Loss: 1.2791, Learning Rate: 5.30e-05
2025-12-10 01:38:30 - INFO - Epoch: 19.86, Step: 78680, Train Loss: 1.3146, Learning Rate: 5.30e-05
2025-12-10 01:38:42 - INFO - Epoch: 19.87, Step: 78690, Train Loss: 1.2924, Learning Rate: 5.30e-05
2025-12-10 01:38:53 - INFO - Epoch: 19.87, Step: 78700, Train Loss: 1.2268, Learning Rate: 5.30e-05
2025-12-10 01:39:04 - INFO - Epoch: 19.87, Step: 78710, Train Loss: 1.2735, Learning Rate: 5.30e-05
2025-12-10 01:39:15 - INFO - Epoch: 19.87, Step: 78720, Train Loss: 1.2768, Learning Rate: 5.30e-05
2025-12-10 01:39:26 - INFO - Epoch: 19.88, Step: 78730, Train Loss: 1.2592, Learning Rate: 5.30e-05
2025-12-10 01:39:37 - INFO - Epoch: 19.88, Step: 78740, Train Loss: 1.3142, Learning Rate: 5.30e-05
2025-12-10 01:39:48 - INFO - Epoch: 19.88, Step: 78750, Train Loss: 1.2555, Learning Rate: 5.29e-05
2025-12-10 01:40:00 - INFO - Epoch: 19.88, Step: 78760, Train Loss: 1.2739, Learning Rate: 5.29e-05
2025-12-10 01:40:11 - INFO - Epoch: 19.89, Step: 78770, Train Loss: 1.2577, Learning Rate: 5.29e-05
2025-12-10 01:40:22 - INFO - Epoch: 19.89, Step: 78780, Train Loss: 1.2543, Learning Rate: 5.29e-05
2025-12-10 01:40:33 - INFO - Epoch: 19.89, Step: 78790, Train Loss: 1.2521, Learning Rate: 5.29e-05
2025-12-10 01:40:44 - INFO - Epoch: 19.89, Step: 78800, Train Loss: 1.2523, Learning Rate: 5.29e-05
2025-12-10 01:40:55 - INFO - Epoch: 19.90, Step: 78810, Train Loss: 1.2559, Learning Rate: 5.29e-05
2025-12-10 01:41:07 - INFO - Epoch: 19.90, Step: 78820, Train Loss: 1.2696, Learning Rate: 5.29e-05
2025-12-10 01:41:18 - INFO - Epoch: 19.90, Step: 78830, Train Loss: 1.2914, Learning Rate: 5.29e-05
2025-12-10 01:41:29 - INFO - Epoch: 19.90, Step: 78840, Train Loss: 1.2512, Learning Rate: 5.29e-05
2025-12-10 01:41:40 - INFO - Epoch: 19.91, Step: 78850, Train Loss: 1.2493, Learning Rate: 5.29e-05
2025-12-10 01:41:51 - INFO - Epoch: 19.91, Step: 78860, Train Loss: 1.2595, Learning Rate: 5.29e-05
2025-12-10 01:42:02 - INFO - Epoch: 19.91, Step: 78870, Train Loss: 1.2523, Learning Rate: 5.29e-05
2025-12-10 01:42:13 - INFO - Epoch: 19.91, Step: 78880, Train Loss: 1.2637, Learning Rate: 5.29e-05
2025-12-10 01:42:25 - INFO - Epoch: 19.92, Step: 78890, Train Loss: 1.2747, Learning Rate: 5.29e-05
2025-12-10 01:42:36 - INFO - Epoch: 19.92, Step: 78900, Train Loss: 1.2658, Learning Rate: 5.28e-05
2025-12-10 01:42:47 - INFO - Epoch: 19.92, Step: 78910, Train Loss: 1.2498, Learning Rate: 5.28e-05
2025-12-10 01:42:58 - INFO - Epoch: 19.92, Step: 78920, Train Loss: 1.2642, Learning Rate: 5.28e-05
2025-12-10 01:43:09 - INFO - Epoch: 19.93, Step: 78930, Train Loss: 1.2784, Learning Rate: 5.28e-05
2025-12-10 01:43:20 - INFO - Epoch: 19.93, Step: 78940, Train Loss: 1.2814, Learning Rate: 5.28e-05
2025-12-10 01:43:32 - INFO - Epoch: 19.93, Step: 78950, Train Loss: 1.2322, Learning Rate: 5.28e-05
2025-12-10 01:43:43 - INFO - Epoch: 19.93, Step: 78960, Train Loss: 1.2370, Learning Rate: 5.28e-05
2025-12-10 01:43:54 - INFO - Epoch: 19.94, Step: 78970, Train Loss: 1.2600, Learning Rate: 5.28e-05
2025-12-10 01:44:05 - INFO - Epoch: 19.94, Step: 78980, Train Loss: 1.2849, Learning Rate: 5.28e-05
2025-12-10 01:44:16 - INFO - Epoch: 19.94, Step: 78990, Train Loss: 1.3000, Learning Rate: 5.28e-05
2025-12-10 01:44:27 - INFO - Epoch: 19.94, Step: 79000, Train Loss: 1.2385, Learning Rate: 5.28e-05
2025-12-10 01:44:38 - INFO - Epoch: 19.95, Step: 79010, Train Loss: 1.2806, Learning Rate: 5.28e-05
2025-12-10 01:44:50 - INFO - Epoch: 19.95, Step: 79020, Train Loss: 1.2306, Learning Rate: 5.28e-05
2025-12-10 01:45:01 - INFO - Epoch: 19.95, Step: 79030, Train Loss: 1.2682, Learning Rate: 5.28e-05
2025-12-10 01:45:12 - INFO - Epoch: 19.95, Step: 79040, Train Loss: 1.2551, Learning Rate: 5.28e-05
2025-12-10 01:45:23 - INFO - Epoch: 19.96, Step: 79050, Train Loss: 1.2728, Learning Rate: 5.27e-05
2025-12-10 01:45:34 - INFO - Epoch: 19.96, Step: 79060, Train Loss: 1.2854, Learning Rate: 5.27e-05
2025-12-10 01:45:45 - INFO - Epoch: 19.96, Step: 79070, Train Loss: 1.2259, Learning Rate: 5.27e-05
2025-12-10 01:45:57 - INFO - Epoch: 19.96, Step: 79080, Train Loss: 1.2804, Learning Rate: 5.27e-05
2025-12-10 01:46:08 - INFO - Epoch: 19.97, Step: 79090, Train Loss: 1.2844, Learning Rate: 5.27e-05
2025-12-10 01:46:19 - INFO - Epoch: 19.97, Step: 79100, Train Loss: 1.2326, Learning Rate: 5.27e-05
2025-12-10 01:46:30 - INFO - Epoch: 19.97, Step: 79110, Train Loss: 1.2232, Learning Rate: 5.27e-05
2025-12-10 01:46:41 - INFO - Epoch: 19.97, Step: 79120, Train Loss: 1.2920, Learning Rate: 5.27e-05
2025-12-10 01:46:52 - INFO - Epoch: 19.98, Step: 79130, Train Loss: 1.2726, Learning Rate: 5.27e-05
2025-12-10 01:47:03 - INFO - Epoch: 19.98, Step: 79140, Train Loss: 1.2551, Learning Rate: 5.27e-05
2025-12-10 01:47:15 - INFO - Epoch: 19.98, Step: 79150, Train Loss: 1.2756, Learning Rate: 5.27e-05
2025-12-10 01:47:26 - INFO - Epoch: 19.98, Step: 79160, Train Loss: 1.2579, Learning Rate: 5.27e-05
2025-12-10 01:47:37 - INFO - Epoch: 19.99, Step: 79170, Train Loss: 1.2650, Learning Rate: 5.27e-05
2025-12-10 01:47:48 - INFO - Epoch: 19.99, Step: 79180, Train Loss: 1.2843, Learning Rate: 5.27e-05
2025-12-10 01:47:59 - INFO - Epoch: 19.99, Step: 79190, Train Loss: 1.2582, Learning Rate: 5.27e-05
2025-12-10 01:48:10 - INFO - Epoch: 19.99, Step: 79200, Train Loss: 1.2461, Learning Rate: 5.26e-05
2025-12-10 01:48:22 - INFO - Epoch: 20.00, Step: 79210, Train Loss: 1.2482, Learning Rate: 5.26e-05
2025-12-10 01:48:33 - INFO - Epoch: 20.00, Step: 79220, Train Loss: 1.2731, Learning Rate: 5.26e-05
2025-12-10 01:48:44 - INFO - Epoch: 20.00, Step: 79230, Train Loss: 1.2511, Learning Rate: 5.26e-05
2025-12-10 01:48:55 - INFO - Epoch: 20.01, Step: 79240, Train Loss: 1.2766, Learning Rate: 5.26e-05
2025-12-10 01:49:06 - INFO - Epoch: 20.01, Step: 79250, Train Loss: 1.2984, Learning Rate: 5.26e-05
2025-12-10 01:49:17 - INFO - Epoch: 20.01, Step: 79260, Train Loss: 1.3029, Learning Rate: 5.26e-05
2025-12-10 01:49:28 - INFO - Epoch: 20.01, Step: 79270, Train Loss: 1.3092, Learning Rate: 5.26e-05
2025-12-10 01:49:40 - INFO - Epoch: 20.02, Step: 79280, Train Loss: 1.2535, Learning Rate: 5.26e-05
2025-12-10 01:49:51 - INFO - Epoch: 20.02, Step: 79290, Train Loss: 1.2364, Learning Rate: 5.26e-05
2025-12-10 01:50:02 - INFO - Epoch: 20.02, Step: 79300, Train Loss: 1.2663, Learning Rate: 5.26e-05
2025-12-10 01:50:13 - INFO - Epoch: 20.02, Step: 79310, Train Loss: 1.3042, Learning Rate: 5.26e-05
2025-12-10 01:50:24 - INFO - Epoch: 20.03, Step: 79320, Train Loss: 1.2787, Learning Rate: 5.26e-05
2025-12-10 01:50:35 - INFO - Epoch: 20.03, Step: 79330, Train Loss: 1.2650, Learning Rate: 5.26e-05
2025-12-10 01:50:47 - INFO - Epoch: 20.03, Step: 79340, Train Loss: 1.2538, Learning Rate: 5.26e-05
2025-12-10 01:50:58 - INFO - Epoch: 20.03, Step: 79350, Train Loss: 1.2622, Learning Rate: 5.25e-05
2025-12-10 01:51:09 - INFO - Epoch: 20.04, Step: 79360, Train Loss: 1.2689, Learning Rate: 5.25e-05
2025-12-10 01:51:20 - INFO - Epoch: 20.04, Step: 79370, Train Loss: 1.2829, Learning Rate: 5.25e-05
2025-12-10 01:51:31 - INFO - Epoch: 20.04, Step: 79380, Train Loss: 1.2448, Learning Rate: 5.25e-05
2025-12-10 01:51:42 - INFO - Epoch: 20.04, Step: 79390, Train Loss: 1.2635, Learning Rate: 5.25e-05
2025-12-10 01:51:53 - INFO - Epoch: 20.05, Step: 79400, Train Loss: 1.2551, Learning Rate: 5.25e-05
2025-12-10 01:52:05 - INFO - Epoch: 20.05, Step: 79410, Train Loss: 1.2572, Learning Rate: 5.25e-05
2025-12-10 01:52:16 - INFO - Epoch: 20.05, Step: 79420, Train Loss: 1.2431, Learning Rate: 5.25e-05
2025-12-10 01:52:27 - INFO - Epoch: 20.05, Step: 79430, Train Loss: 1.2770, Learning Rate: 5.25e-05
2025-12-10 01:52:38 - INFO - Epoch: 20.06, Step: 79440, Train Loss: 1.2713, Learning Rate: 5.25e-05
2025-12-10 01:52:49 - INFO - Epoch: 20.06, Step: 79450, Train Loss: 1.3011, Learning Rate: 5.25e-05
2025-12-10 01:53:00 - INFO - Epoch: 20.06, Step: 79460, Train Loss: 1.2325, Learning Rate: 5.25e-05
2025-12-10 01:53:12 - INFO - Epoch: 20.06, Step: 79470, Train Loss: 1.2609, Learning Rate: 5.25e-05
2025-12-10 01:53:23 - INFO - Epoch: 20.07, Step: 79480, Train Loss: 1.2506, Learning Rate: 5.25e-05
2025-12-10 01:53:34 - INFO - Epoch: 20.07, Step: 79490, Train Loss: 1.2147, Learning Rate: 5.25e-05
2025-12-10 01:53:45 - INFO - Epoch: 20.07, Step: 79500, Train Loss: 1.2398, Learning Rate: 5.24e-05
2025-12-10 01:53:56 - INFO - Epoch: 20.07, Step: 79510, Train Loss: 1.2545, Learning Rate: 5.24e-05
2025-12-10 01:54:07 - INFO - Epoch: 20.08, Step: 79520, Train Loss: 1.2606, Learning Rate: 5.24e-05
2025-12-10 01:54:19 - INFO - Epoch: 20.08, Step: 79530, Train Loss: 1.2782, Learning Rate: 5.24e-05
2025-12-10 01:54:30 - INFO - Epoch: 20.08, Step: 79540, Train Loss: 1.3108, Learning Rate: 5.24e-05
2025-12-10 01:54:41 - INFO - Epoch: 20.08, Step: 79550, Train Loss: 1.2529, Learning Rate: 5.24e-05
2025-12-10 01:54:52 - INFO - Epoch: 20.09, Step: 79560, Train Loss: 1.2719, Learning Rate: 5.24e-05
2025-12-10 01:55:03 - INFO - Epoch: 20.09, Step: 79570, Train Loss: 1.2458, Learning Rate: 5.24e-05
2025-12-10 01:55:14 - INFO - Epoch: 20.09, Step: 79580, Train Loss: 1.2619, Learning Rate: 5.24e-05
2025-12-10 01:55:25 - INFO - Epoch: 20.09, Step: 79590, Train Loss: 1.2593, Learning Rate: 5.24e-05
2025-12-10 01:55:37 - INFO - Epoch: 20.10, Step: 79600, Train Loss: 1.2782, Learning Rate: 5.24e-05
2025-12-10 01:55:48 - INFO - Epoch: 20.10, Step: 79610, Train Loss: 1.2445, Learning Rate: 5.24e-05
2025-12-10 01:55:59 - INFO - Epoch: 20.10, Step: 79620, Train Loss: 1.2372, Learning Rate: 5.24e-05
2025-12-10 01:56:10 - INFO - Epoch: 20.10, Step: 79630, Train Loss: 1.2217, Learning Rate: 5.24e-05
2025-12-10 01:56:21 - INFO - Epoch: 20.11, Step: 79640, Train Loss: 1.2635, Learning Rate: 5.24e-05
2025-12-10 01:56:32 - INFO - Epoch: 20.11, Step: 79650, Train Loss: 1.2558, Learning Rate: 5.23e-05
2025-12-10 01:56:44 - INFO - Epoch: 20.11, Step: 79660, Train Loss: 1.2893, Learning Rate: 5.23e-05
2025-12-10 01:56:55 - INFO - Epoch: 20.11, Step: 79670, Train Loss: 1.2395, Learning Rate: 5.23e-05
2025-12-10 01:57:06 - INFO - Epoch: 20.12, Step: 79680, Train Loss: 1.2761, Learning Rate: 5.23e-05
2025-12-10 01:57:17 - INFO - Epoch: 20.12, Step: 79690, Train Loss: 1.2845, Learning Rate: 5.23e-05
2025-12-10 01:57:28 - INFO - Epoch: 20.12, Step: 79700, Train Loss: 1.2344, Learning Rate: 5.23e-05
2025-12-10 01:57:39 - INFO - Epoch: 20.12, Step: 79710, Train Loss: 1.2752, Learning Rate: 5.23e-05
2025-12-10 01:57:50 - INFO - Epoch: 20.13, Step: 79720, Train Loss: 1.2500, Learning Rate: 5.23e-05
2025-12-10 01:58:02 - INFO - Epoch: 20.13, Step: 79730, Train Loss: 1.2575, Learning Rate: 5.23e-05
2025-12-10 01:58:13 - INFO - Epoch: 20.13, Step: 79740, Train Loss: 1.2387, Learning Rate: 5.23e-05
2025-12-10 01:58:24 - INFO - Epoch: 20.13, Step: 79750, Train Loss: 1.2340, Learning Rate: 5.23e-05
2025-12-10 01:58:35 - INFO - Epoch: 20.14, Step: 79760, Train Loss: 1.2670, Learning Rate: 5.23e-05
2025-12-10 01:58:46 - INFO - Epoch: 20.14, Step: 79770, Train Loss: 1.2471, Learning Rate: 5.23e-05
2025-12-10 01:58:57 - INFO - Epoch: 20.14, Step: 79780, Train Loss: 1.2808, Learning Rate: 5.23e-05
2025-12-10 01:59:09 - INFO - Epoch: 20.14, Step: 79790, Train Loss: 1.2531, Learning Rate: 5.23e-05
2025-12-10 01:59:20 - INFO - Epoch: 20.15, Step: 79800, Train Loss: 1.2441, Learning Rate: 5.22e-05
2025-12-10 01:59:31 - INFO - Epoch: 20.15, Step: 79810, Train Loss: 1.2609, Learning Rate: 5.22e-05
2025-12-10 01:59:42 - INFO - Epoch: 20.15, Step: 79820, Train Loss: 1.2619, Learning Rate: 5.22e-05
2025-12-10 01:59:53 - INFO - Epoch: 20.15, Step: 79830, Train Loss: 1.2704, Learning Rate: 5.22e-05
2025-12-10 02:00:04 - INFO - Epoch: 20.16, Step: 79840, Train Loss: 1.2675, Learning Rate: 5.22e-05
2025-12-10 02:00:16 - INFO - Epoch: 20.16, Step: 79850, Train Loss: 1.2928, Learning Rate: 5.22e-05
2025-12-10 02:00:27 - INFO - Epoch: 20.16, Step: 79860, Train Loss: 1.2257, Learning Rate: 5.22e-05
2025-12-10 02:00:38 - INFO - Epoch: 20.16, Step: 79870, Train Loss: 1.2753, Learning Rate: 5.22e-05
2025-12-10 02:00:49 - INFO - Epoch: 20.17, Step: 79880, Train Loss: 1.2951, Learning Rate: 5.22e-05
2025-12-10 02:01:00 - INFO - Epoch: 20.17, Step: 79890, Train Loss: 1.2824, Learning Rate: 5.22e-05
2025-12-10 02:01:11 - INFO - Epoch: 20.17, Step: 79900, Train Loss: 1.2475, Learning Rate: 5.22e-05
2025-12-10 02:01:22 - INFO - Epoch: 20.17, Step: 79910, Train Loss: 1.2590, Learning Rate: 5.22e-05
2025-12-10 02:01:34 - INFO - Epoch: 20.18, Step: 79920, Train Loss: 1.2339, Learning Rate: 5.22e-05
2025-12-10 02:01:45 - INFO - Epoch: 20.18, Step: 79930, Train Loss: 1.2836, Learning Rate: 5.22e-05
2025-12-10 02:01:56 - INFO - Epoch: 20.18, Step: 79940, Train Loss: 1.2424, Learning Rate: 5.22e-05
2025-12-10 02:02:07 - INFO - Epoch: 20.18, Step: 79950, Train Loss: 1.2753, Learning Rate: 5.21e-05
2025-12-10 02:02:18 - INFO - Epoch: 20.19, Step: 79960, Train Loss: 1.2575, Learning Rate: 5.21e-05
2025-12-10 02:02:29 - INFO - Epoch: 20.19, Step: 79970, Train Loss: 1.2713, Learning Rate: 5.21e-05
2025-12-10 02:02:41 - INFO - Epoch: 20.19, Step: 79980, Train Loss: 1.2545, Learning Rate: 5.21e-05
2025-12-10 02:02:52 - INFO - Epoch: 20.19, Step: 79990, Train Loss: 1.2485, Learning Rate: 5.21e-05
2025-12-10 02:03:03 - INFO - Epoch: 20.20, Step: 80000, Train Loss: 1.2299, Learning Rate: 5.21e-05
2025-12-10 02:03:14 - INFO - Epoch: 20.20, Step: 80010, Train Loss: 1.2955, Learning Rate: 5.21e-05
2025-12-10 02:03:25 - INFO - Epoch: 20.20, Step: 80020, Train Loss: 1.2798, Learning Rate: 5.21e-05
2025-12-10 02:03:36 - INFO - Epoch: 20.20, Step: 80030, Train Loss: 1.2558, Learning Rate: 5.21e-05
2025-12-10 02:03:47 - INFO - Epoch: 20.21, Step: 80040, Train Loss: 1.2284, Learning Rate: 5.21e-05
2025-12-10 02:03:59 - INFO - Epoch: 20.21, Step: 80050, Train Loss: 1.2536, Learning Rate: 5.21e-05
2025-12-10 02:04:10 - INFO - Epoch: 20.21, Step: 80060, Train Loss: 1.2610, Learning Rate: 5.21e-05
2025-12-10 02:04:21 - INFO - Epoch: 20.21, Step: 80070, Train Loss: 1.2154, Learning Rate: 5.21e-05
2025-12-10 02:04:32 - INFO - Epoch: 20.22, Step: 80080, Train Loss: 1.2776, Learning Rate: 5.21e-05
2025-12-10 02:04:43 - INFO - Epoch: 20.22, Step: 80090, Train Loss: 1.2569, Learning Rate: 5.21e-05
2025-12-10 02:04:54 - INFO - Epoch: 20.22, Step: 80100, Train Loss: 1.2804, Learning Rate: 5.20e-05
2025-12-10 02:05:06 - INFO - Epoch: 20.22, Step: 80110, Train Loss: 1.2388, Learning Rate: 5.20e-05
2025-12-10 02:05:17 - INFO - Epoch: 20.23, Step: 80120, Train Loss: 1.2521, Learning Rate: 5.20e-05
2025-12-10 02:05:28 - INFO - Epoch: 20.23, Step: 80130, Train Loss: 1.2342, Learning Rate: 5.20e-05
2025-12-10 02:05:39 - INFO - Epoch: 20.23, Step: 80140, Train Loss: 1.2557, Learning Rate: 5.20e-05
2025-12-10 02:05:50 - INFO - Epoch: 20.23, Step: 80150, Train Loss: 1.2471, Learning Rate: 5.20e-05
2025-12-10 02:06:01 - INFO - Epoch: 20.24, Step: 80160, Train Loss: 1.2718, Learning Rate: 5.20e-05
2025-12-10 02:06:13 - INFO - Epoch: 20.24, Step: 80170, Train Loss: 1.2513, Learning Rate: 5.20e-05
2025-12-10 02:06:24 - INFO - Epoch: 20.24, Step: 80180, Train Loss: 1.2508, Learning Rate: 5.20e-05
2025-12-10 02:06:35 - INFO - Epoch: 20.24, Step: 80190, Train Loss: 1.2615, Learning Rate: 5.20e-05
2025-12-10 02:06:46 - INFO - Epoch: 20.25, Step: 80200, Train Loss: 1.2403, Learning Rate: 5.20e-05
2025-12-10 02:06:57 - INFO - Epoch: 20.25, Step: 80210, Train Loss: 1.2865, Learning Rate: 5.20e-05
2025-12-10 02:07:08 - INFO - Epoch: 20.25, Step: 80220, Train Loss: 1.2567, Learning Rate: 5.20e-05
2025-12-10 02:07:19 - INFO - Epoch: 20.25, Step: 80230, Train Loss: 1.2947, Learning Rate: 5.20e-05
2025-12-10 02:07:31 - INFO - Epoch: 20.26, Step: 80240, Train Loss: 1.2611, Learning Rate: 5.20e-05
2025-12-10 02:07:42 - INFO - Epoch: 20.26, Step: 80250, Train Loss: 1.2620, Learning Rate: 5.19e-05
2025-12-10 02:07:53 - INFO - Epoch: 20.26, Step: 80260, Train Loss: 1.2684, Learning Rate: 5.19e-05
2025-12-10 02:08:04 - INFO - Epoch: 20.27, Step: 80270, Train Loss: 1.2663, Learning Rate: 5.19e-05
2025-12-10 02:08:15 - INFO - Epoch: 20.27, Step: 80280, Train Loss: 1.2594, Learning Rate: 5.19e-05
2025-12-10 02:08:26 - INFO - Epoch: 20.27, Step: 80290, Train Loss: 1.2530, Learning Rate: 5.19e-05
2025-12-10 02:08:38 - INFO - Epoch: 20.27, Step: 80300, Train Loss: 1.2833, Learning Rate: 5.19e-05
2025-12-10 02:08:49 - INFO - Epoch: 20.28, Step: 80310, Train Loss: 1.2736, Learning Rate: 5.19e-05
2025-12-10 02:09:00 - INFO - Epoch: 20.28, Step: 80320, Train Loss: 1.2533, Learning Rate: 5.19e-05
2025-12-10 02:09:11 - INFO - Epoch: 20.28, Step: 80330, Train Loss: 1.2538, Learning Rate: 5.19e-05
2025-12-10 02:09:22 - INFO - Epoch: 20.28, Step: 80340, Train Loss: 1.3144, Learning Rate: 5.19e-05
2025-12-10 02:09:33 - INFO - Epoch: 20.29, Step: 80350, Train Loss: 1.3070, Learning Rate: 5.19e-05
2025-12-10 02:09:45 - INFO - Epoch: 20.29, Step: 80360, Train Loss: 1.2360, Learning Rate: 5.19e-05
2025-12-10 02:09:56 - INFO - Epoch: 20.29, Step: 80370, Train Loss: 1.2877, Learning Rate: 5.19e-05
2025-12-10 02:10:07 - INFO - Epoch: 20.29, Step: 80380, Train Loss: 1.2713, Learning Rate: 5.19e-05
2025-12-10 02:10:18 - INFO - Epoch: 20.30, Step: 80390, Train Loss: 1.2752, Learning Rate: 5.19e-05
2025-12-10 02:10:29 - INFO - Epoch: 20.30, Step: 80400, Train Loss: 1.2872, Learning Rate: 5.18e-05
2025-12-10 02:10:40 - INFO - Epoch: 20.30, Step: 80410, Train Loss: 1.2355, Learning Rate: 5.18e-05
2025-12-10 02:10:51 - INFO - Epoch: 20.30, Step: 80420, Train Loss: 1.2403, Learning Rate: 5.18e-05
2025-12-10 02:11:03 - INFO - Epoch: 20.31, Step: 80430, Train Loss: 1.2772, Learning Rate: 5.18e-05
2025-12-10 02:11:14 - INFO - Epoch: 20.31, Step: 80440, Train Loss: 1.3003, Learning Rate: 5.18e-05
2025-12-10 02:11:25 - INFO - Epoch: 20.31, Step: 80450, Train Loss: 1.2663, Learning Rate: 5.18e-05
2025-12-10 02:11:36 - INFO - Epoch: 20.31, Step: 80460, Train Loss: 1.2681, Learning Rate: 5.18e-05
2025-12-10 02:11:47 - INFO - Epoch: 20.32, Step: 80470, Train Loss: 1.2708, Learning Rate: 5.18e-05
2025-12-10 02:11:58 - INFO - Epoch: 20.32, Step: 80480, Train Loss: 1.2751, Learning Rate: 5.18e-05
2025-12-10 02:12:10 - INFO - Epoch: 20.32, Step: 80490, Train Loss: 1.2503, Learning Rate: 5.18e-05
2025-12-10 02:12:21 - INFO - Epoch: 20.32, Step: 80500, Train Loss: 1.2569, Learning Rate: 5.18e-05
2025-12-10 02:12:32 - INFO - Epoch: 20.33, Step: 80510, Train Loss: 1.2849, Learning Rate: 5.18e-05
2025-12-10 02:12:43 - INFO - Epoch: 20.33, Step: 80520, Train Loss: 1.2592, Learning Rate: 5.18e-05
2025-12-10 02:12:54 - INFO - Epoch: 20.33, Step: 80530, Train Loss: 1.2757, Learning Rate: 5.18e-05
2025-12-10 02:13:05 - INFO - Epoch: 20.33, Step: 80540, Train Loss: 1.2591, Learning Rate: 5.18e-05
2025-12-10 02:13:16 - INFO - Epoch: 20.34, Step: 80550, Train Loss: 1.2309, Learning Rate: 5.17e-05
2025-12-10 02:13:28 - INFO - Epoch: 20.34, Step: 80560, Train Loss: 1.2736, Learning Rate: 5.17e-05
2025-12-10 02:13:39 - INFO - Epoch: 20.34, Step: 80570, Train Loss: 1.2671, Learning Rate: 5.17e-05
2025-12-10 02:13:50 - INFO - Epoch: 20.34, Step: 80580, Train Loss: 1.2507, Learning Rate: 5.17e-05
2025-12-10 02:14:01 - INFO - Epoch: 20.35, Step: 80590, Train Loss: 1.2504, Learning Rate: 5.17e-05
2025-12-10 02:14:12 - INFO - Epoch: 20.35, Step: 80600, Train Loss: 1.2572, Learning Rate: 5.17e-05
2025-12-10 02:14:23 - INFO - Epoch: 20.35, Step: 80610, Train Loss: 1.2629, Learning Rate: 5.17e-05
2025-12-10 02:14:35 - INFO - Epoch: 20.35, Step: 80620, Train Loss: 1.3041, Learning Rate: 5.17e-05
2025-12-10 02:14:46 - INFO - Epoch: 20.36, Step: 80630, Train Loss: 1.2246, Learning Rate: 5.17e-05
2025-12-10 02:14:57 - INFO - Epoch: 20.36, Step: 80640, Train Loss: 1.2784, Learning Rate: 5.17e-05
2025-12-10 02:15:08 - INFO - Epoch: 20.36, Step: 80650, Train Loss: 1.2538, Learning Rate: 5.17e-05
2025-12-10 02:15:19 - INFO - Epoch: 20.36, Step: 80660, Train Loss: 1.2628, Learning Rate: 5.17e-05
2025-12-10 02:15:30 - INFO - Epoch: 20.37, Step: 80670, Train Loss: 1.2779, Learning Rate: 5.17e-05
2025-12-10 02:15:42 - INFO - Epoch: 20.37, Step: 80680, Train Loss: 1.2732, Learning Rate: 5.17e-05
2025-12-10 02:15:53 - INFO - Epoch: 20.37, Step: 80690, Train Loss: 1.2491, Learning Rate: 5.17e-05
2025-12-10 02:16:04 - INFO - Epoch: 20.37, Step: 80700, Train Loss: 1.2984, Learning Rate: 5.16e-05
2025-12-10 02:16:15 - INFO - Epoch: 20.38, Step: 80710, Train Loss: 1.2532, Learning Rate: 5.16e-05
2025-12-10 02:16:26 - INFO - Epoch: 20.38, Step: 80720, Train Loss: 1.2470, Learning Rate: 5.16e-05
2025-12-10 02:16:37 - INFO - Epoch: 20.38, Step: 80730, Train Loss: 1.2300, Learning Rate: 5.16e-05
2025-12-10 02:16:48 - INFO - Epoch: 20.38, Step: 80740, Train Loss: 1.2939, Learning Rate: 5.16e-05
2025-12-10 02:17:00 - INFO - Epoch: 20.39, Step: 80750, Train Loss: 1.2329, Learning Rate: 5.16e-05
2025-12-10 02:17:11 - INFO - Epoch: 20.39, Step: 80760, Train Loss: 1.2876, Learning Rate: 5.16e-05
2025-12-10 02:17:22 - INFO - Epoch: 20.39, Step: 80770, Train Loss: 1.2924, Learning Rate: 5.16e-05
2025-12-10 02:17:33 - INFO - Epoch: 20.39, Step: 80780, Train Loss: 1.2821, Learning Rate: 5.16e-05
2025-12-10 02:17:44 - INFO - Epoch: 20.40, Step: 80790, Train Loss: 1.2853, Learning Rate: 5.16e-05
2025-12-10 02:17:55 - INFO - Epoch: 20.40, Step: 80800, Train Loss: 1.2165, Learning Rate: 5.16e-05
2025-12-10 02:18:07 - INFO - Epoch: 20.40, Step: 80810, Train Loss: 1.2813, Learning Rate: 5.16e-05
2025-12-10 02:18:18 - INFO - Epoch: 20.40, Step: 80820, Train Loss: 1.2313, Learning Rate: 5.16e-05
2025-12-10 02:18:29 - INFO - Epoch: 20.41, Step: 80830, Train Loss: 1.2186, Learning Rate: 5.16e-05
2025-12-10 02:18:40 - INFO - Epoch: 20.41, Step: 80840, Train Loss: 1.2293, Learning Rate: 5.16e-05
2025-12-10 02:18:51 - INFO - Epoch: 20.41, Step: 80850, Train Loss: 1.2743, Learning Rate: 5.15e-05
2025-12-10 02:19:02 - INFO - Epoch: 20.41, Step: 80860, Train Loss: 1.2140, Learning Rate: 5.15e-05
2025-12-10 02:19:13 - INFO - Epoch: 20.42, Step: 80870, Train Loss: 1.2614, Learning Rate: 5.15e-05
2025-12-10 02:19:25 - INFO - Epoch: 20.42, Step: 80880, Train Loss: 1.2819, Learning Rate: 5.15e-05
2025-12-10 02:19:36 - INFO - Epoch: 20.42, Step: 80890, Train Loss: 1.2402, Learning Rate: 5.15e-05
2025-12-10 02:19:47 - INFO - Epoch: 20.42, Step: 80900, Train Loss: 1.2774, Learning Rate: 5.15e-05
2025-12-10 02:19:58 - INFO - Epoch: 20.43, Step: 80910, Train Loss: 1.2645, Learning Rate: 5.15e-05
2025-12-10 02:20:09 - INFO - Epoch: 20.43, Step: 80920, Train Loss: 1.3056, Learning Rate: 5.15e-05
2025-12-10 02:20:20 - INFO - Epoch: 20.43, Step: 80930, Train Loss: 1.2052, Learning Rate: 5.15e-05
2025-12-10 02:20:32 - INFO - Epoch: 20.43, Step: 80940, Train Loss: 1.2901, Learning Rate: 5.15e-05
2025-12-10 02:20:43 - INFO - Epoch: 20.44, Step: 80950, Train Loss: 1.2675, Learning Rate: 5.15e-05
2025-12-10 02:20:54 - INFO - Epoch: 20.44, Step: 80960, Train Loss: 1.2668, Learning Rate: 5.15e-05
2025-12-10 02:21:05 - INFO - Epoch: 20.44, Step: 80970, Train Loss: 1.2714, Learning Rate: 5.15e-05
2025-12-10 02:21:16 - INFO - Epoch: 20.44, Step: 80980, Train Loss: 1.2686, Learning Rate: 5.15e-05
2025-12-10 02:21:27 - INFO - Epoch: 20.45, Step: 80990, Train Loss: 1.2843, Learning Rate: 5.15e-05
2025-12-10 02:21:39 - INFO - Epoch: 20.45, Step: 81000, Train Loss: 1.2871, Learning Rate: 5.14e-05
2025-12-10 02:21:50 - INFO - Epoch: 20.45, Step: 81010, Train Loss: 1.2871, Learning Rate: 5.14e-05
2025-12-10 02:22:01 - INFO - Epoch: 20.45, Step: 81020, Train Loss: 1.2810, Learning Rate: 5.14e-05
2025-12-10 02:22:12 - INFO - Epoch: 20.46, Step: 81030, Train Loss: 1.2830, Learning Rate: 5.14e-05
2025-12-10 02:22:23 - INFO - Epoch: 20.46, Step: 81040, Train Loss: 1.2454, Learning Rate: 5.14e-05
2025-12-10 02:22:34 - INFO - Epoch: 20.46, Step: 81050, Train Loss: 1.2716, Learning Rate: 5.14e-05
2025-12-10 02:22:45 - INFO - Epoch: 20.46, Step: 81060, Train Loss: 1.2857, Learning Rate: 5.14e-05
2025-12-10 02:22:57 - INFO - Epoch: 20.47, Step: 81070, Train Loss: 1.2439, Learning Rate: 5.14e-05
2025-12-10 02:23:08 - INFO - Epoch: 20.47, Step: 81080, Train Loss: 1.2259, Learning Rate: 5.14e-05
2025-12-10 02:23:19 - INFO - Epoch: 20.47, Step: 81090, Train Loss: 1.2757, Learning Rate: 5.14e-05
2025-12-10 02:23:30 - INFO - Epoch: 20.47, Step: 81100, Train Loss: 1.2960, Learning Rate: 5.14e-05
2025-12-10 02:23:41 - INFO - Epoch: 20.48, Step: 81110, Train Loss: 1.2490, Learning Rate: 5.14e-05
2025-12-10 02:23:52 - INFO - Epoch: 20.48, Step: 81120, Train Loss: 1.2353, Learning Rate: 5.14e-05
2025-12-10 02:24:04 - INFO - Epoch: 20.48, Step: 81130, Train Loss: 1.2370, Learning Rate: 5.14e-05
2025-12-10 02:24:15 - INFO - Epoch: 20.48, Step: 81140, Train Loss: 1.2701, Learning Rate: 5.14e-05
2025-12-10 02:24:26 - INFO - Epoch: 20.49, Step: 81150, Train Loss: 1.2766, Learning Rate: 5.14e-05
2025-12-10 02:24:37 - INFO - Epoch: 20.49, Step: 81160, Train Loss: 1.2664, Learning Rate: 5.13e-05
2025-12-10 02:24:48 - INFO - Epoch: 20.49, Step: 81170, Train Loss: 1.2363, Learning Rate: 5.13e-05
2025-12-10 02:24:59 - INFO - Epoch: 20.49, Step: 81180, Train Loss: 1.2752, Learning Rate: 5.13e-05
2025-12-10 02:25:10 - INFO - Epoch: 20.50, Step: 81190, Train Loss: 1.2710, Learning Rate: 5.13e-05
2025-12-10 02:25:22 - INFO - Epoch: 20.50, Step: 81200, Train Loss: 1.2399, Learning Rate: 5.13e-05
2025-12-10 02:25:33 - INFO - Epoch: 20.50, Step: 81210, Train Loss: 1.2716, Learning Rate: 5.13e-05
2025-12-10 02:25:44 - INFO - Epoch: 20.50, Step: 81220, Train Loss: 1.2630, Learning Rate: 5.13e-05
2025-12-10 02:25:55 - INFO - Epoch: 20.51, Step: 81230, Train Loss: 1.2212, Learning Rate: 5.13e-05
2025-12-10 02:26:06 - INFO - Epoch: 20.51, Step: 81240, Train Loss: 1.2708, Learning Rate: 5.13e-05
2025-12-10 02:26:17 - INFO - Epoch: 20.51, Step: 81250, Train Loss: 1.2319, Learning Rate: 5.13e-05
2025-12-10 02:26:29 - INFO - Epoch: 20.52, Step: 81260, Train Loss: 1.2556, Learning Rate: 5.13e-05
2025-12-10 02:26:40 - INFO - Epoch: 20.52, Step: 81270, Train Loss: 1.2629, Learning Rate: 5.13e-05
2025-12-10 02:26:51 - INFO - Epoch: 20.52, Step: 81280, Train Loss: 1.2584, Learning Rate: 5.13e-05
2025-12-10 02:27:02 - INFO - Epoch: 20.52, Step: 81290, Train Loss: 1.2875, Learning Rate: 5.13e-05
2025-12-10 02:27:13 - INFO - Epoch: 20.53, Step: 81300, Train Loss: 1.2666, Learning Rate: 5.13e-05
2025-12-10 02:27:24 - INFO - Epoch: 20.53, Step: 81310, Train Loss: 1.2159, Learning Rate: 5.12e-05
2025-12-10 02:27:36 - INFO - Epoch: 20.53, Step: 81320, Train Loss: 1.2482, Learning Rate: 5.12e-05
2025-12-10 02:27:47 - INFO - Epoch: 20.53, Step: 81330, Train Loss: 1.2408, Learning Rate: 5.12e-05
2025-12-10 02:27:58 - INFO - Epoch: 20.54, Step: 81340, Train Loss: 1.2599, Learning Rate: 5.12e-05
2025-12-10 02:28:09 - INFO - Epoch: 20.54, Step: 81350, Train Loss: 1.2354, Learning Rate: 5.12e-05
2025-12-10 02:28:20 - INFO - Epoch: 20.54, Step: 81360, Train Loss: 1.2531, Learning Rate: 5.12e-05
2025-12-10 02:28:31 - INFO - Epoch: 20.54, Step: 81370, Train Loss: 1.2328, Learning Rate: 5.12e-05
2025-12-10 02:28:42 - INFO - Epoch: 20.55, Step: 81380, Train Loss: 1.2538, Learning Rate: 5.12e-05
2025-12-10 02:28:54 - INFO - Epoch: 20.55, Step: 81390, Train Loss: 1.2463, Learning Rate: 5.12e-05
2025-12-10 02:29:05 - INFO - Epoch: 20.55, Step: 81400, Train Loss: 1.2980, Learning Rate: 5.12e-05
2025-12-10 02:29:16 - INFO - Epoch: 20.55, Step: 81410, Train Loss: 1.2614, Learning Rate: 5.12e-05
2025-12-10 02:29:27 - INFO - Epoch: 20.56, Step: 81420, Train Loss: 1.2368, Learning Rate: 5.12e-05
2025-12-10 02:29:38 - INFO - Epoch: 20.56, Step: 81430, Train Loss: 1.2348, Learning Rate: 5.12e-05
2025-12-10 02:29:49 - INFO - Epoch: 20.56, Step: 81440, Train Loss: 1.2610, Learning Rate: 5.12e-05
2025-12-10 02:30:01 - INFO - Epoch: 20.56, Step: 81450, Train Loss: 1.2574, Learning Rate: 5.12e-05
2025-12-10 02:30:12 - INFO - Epoch: 20.57, Step: 81460, Train Loss: 1.2672, Learning Rate: 5.11e-05
2025-12-10 02:30:23 - INFO - Epoch: 20.57, Step: 81470, Train Loss: 1.2960, Learning Rate: 5.11e-05
2025-12-10 02:30:34 - INFO - Epoch: 20.57, Step: 81480, Train Loss: 1.2621, Learning Rate: 5.11e-05
2025-12-10 02:30:45 - INFO - Epoch: 20.57, Step: 81490, Train Loss: 1.2201, Learning Rate: 5.11e-05
2025-12-10 02:30:56 - INFO - Epoch: 20.58, Step: 81500, Train Loss: 1.2789, Learning Rate: 5.11e-05
2025-12-10 02:31:07 - INFO - Epoch: 20.58, Step: 81510, Train Loss: 1.2464, Learning Rate: 5.11e-05
2025-12-10 02:31:19 - INFO - Epoch: 20.58, Step: 81520, Train Loss: 1.2493, Learning Rate: 5.11e-05
2025-12-10 02:31:30 - INFO - Epoch: 20.58, Step: 81530, Train Loss: 1.2646, Learning Rate: 5.11e-05
2025-12-10 02:31:41 - INFO - Epoch: 20.59, Step: 81540, Train Loss: 1.2708, Learning Rate: 5.11e-05
2025-12-10 02:31:52 - INFO - Epoch: 20.59, Step: 81550, Train Loss: 1.3040, Learning Rate: 5.11e-05
2025-12-10 02:32:03 - INFO - Epoch: 20.59, Step: 81560, Train Loss: 1.2583, Learning Rate: 5.11e-05
2025-12-10 02:32:14 - INFO - Epoch: 20.59, Step: 81570, Train Loss: 1.2802, Learning Rate: 5.11e-05
2025-12-10 02:32:26 - INFO - Epoch: 20.60, Step: 81580, Train Loss: 1.2863, Learning Rate: 5.11e-05
2025-12-10 02:32:37 - INFO - Epoch: 20.60, Step: 81590, Train Loss: 1.2451, Learning Rate: 5.11e-05
2025-12-10 02:32:48 - INFO - Epoch: 20.60, Step: 81600, Train Loss: 1.2620, Learning Rate: 5.11e-05
2025-12-10 02:32:59 - INFO - Epoch: 20.60, Step: 81610, Train Loss: 1.2203, Learning Rate: 5.10e-05
2025-12-10 02:33:10 - INFO - Epoch: 20.61, Step: 81620, Train Loss: 1.2288, Learning Rate: 5.10e-05
2025-12-10 02:33:21 - INFO - Epoch: 20.61, Step: 81630, Train Loss: 1.2623, Learning Rate: 5.10e-05
2025-12-10 02:33:33 - INFO - Epoch: 20.61, Step: 81640, Train Loss: 1.2750, Learning Rate: 5.10e-05
2025-12-10 02:33:44 - INFO - Epoch: 20.61, Step: 81650, Train Loss: 1.2688, Learning Rate: 5.10e-05
2025-12-10 02:33:55 - INFO - Epoch: 20.62, Step: 81660, Train Loss: 1.2429, Learning Rate: 5.10e-05
2025-12-10 02:34:06 - INFO - Epoch: 20.62, Step: 81670, Train Loss: 1.2468, Learning Rate: 5.10e-05
2025-12-10 02:34:17 - INFO - Epoch: 20.62, Step: 81680, Train Loss: 1.2863, Learning Rate: 5.10e-05
2025-12-10 02:34:28 - INFO - Epoch: 20.62, Step: 81690, Train Loss: 1.2519, Learning Rate: 5.10e-05
2025-12-10 02:34:39 - INFO - Epoch: 20.63, Step: 81700, Train Loss: 1.2691, Learning Rate: 5.10e-05
2025-12-10 02:34:51 - INFO - Epoch: 20.63, Step: 81710, Train Loss: 1.2715, Learning Rate: 5.10e-05
2025-12-10 02:35:02 - INFO - Epoch: 20.63, Step: 81720, Train Loss: 1.2853, Learning Rate: 5.10e-05
2025-12-10 02:35:13 - INFO - Epoch: 20.63, Step: 81730, Train Loss: 1.2421, Learning Rate: 5.10e-05
2025-12-10 02:35:24 - INFO - Epoch: 20.64, Step: 81740, Train Loss: 1.2558, Learning Rate: 5.10e-05
2025-12-10 02:35:35 - INFO - Epoch: 20.64, Step: 81750, Train Loss: 1.2948, Learning Rate: 5.10e-05
2025-12-10 02:35:46 - INFO - Epoch: 20.64, Step: 81760, Train Loss: 1.2612, Learning Rate: 5.09e-05
2025-12-10 02:35:58 - INFO - Epoch: 20.64, Step: 81770, Train Loss: 1.2365, Learning Rate: 5.09e-05
2025-12-10 02:36:09 - INFO - Epoch: 20.65, Step: 81780, Train Loss: 1.2635, Learning Rate: 5.09e-05
2025-12-10 02:36:20 - INFO - Epoch: 20.65, Step: 81790, Train Loss: 1.2892, Learning Rate: 5.09e-05
2025-12-10 02:36:31 - INFO - Epoch: 20.65, Step: 81800, Train Loss: 1.2992, Learning Rate: 5.09e-05
2025-12-10 02:36:42 - INFO - Epoch: 20.65, Step: 81810, Train Loss: 1.2793, Learning Rate: 5.09e-05
2025-12-10 02:36:53 - INFO - Epoch: 20.66, Step: 81820, Train Loss: 1.2521, Learning Rate: 5.09e-05
2025-12-10 02:37:04 - INFO - Epoch: 20.66, Step: 81830, Train Loss: 1.2582, Learning Rate: 5.09e-05
2025-12-10 02:37:16 - INFO - Epoch: 20.66, Step: 81840, Train Loss: 1.2564, Learning Rate: 5.09e-05
2025-12-10 02:37:27 - INFO - Epoch: 20.66, Step: 81850, Train Loss: 1.2869, Learning Rate: 5.09e-05
2025-12-10 02:37:38 - INFO - Epoch: 20.67, Step: 81860, Train Loss: 1.2591, Learning Rate: 5.09e-05
2025-12-10 02:37:49 - INFO - Epoch: 20.67, Step: 81870, Train Loss: 1.2552, Learning Rate: 5.09e-05
2025-12-10 02:38:00 - INFO - Epoch: 20.67, Step: 81880, Train Loss: 1.2260, Learning Rate: 5.09e-05
2025-12-10 02:38:11 - INFO - Epoch: 20.67, Step: 81890, Train Loss: 1.2627, Learning Rate: 5.09e-05
2025-12-10 02:38:23 - INFO - Epoch: 20.68, Step: 81900, Train Loss: 1.2716, Learning Rate: 5.09e-05
2025-12-10 02:38:34 - INFO - Epoch: 20.68, Step: 81910, Train Loss: 1.2612, Learning Rate: 5.08e-05
2025-12-10 02:38:45 - INFO - Epoch: 20.68, Step: 81920, Train Loss: 1.2257, Learning Rate: 5.08e-05
2025-12-10 02:38:56 - INFO - Epoch: 20.68, Step: 81930, Train Loss: 1.2307, Learning Rate: 5.08e-05
2025-12-10 02:39:07 - INFO - Epoch: 20.69, Step: 81940, Train Loss: 1.2682, Learning Rate: 5.08e-05
2025-12-10 02:39:18 - INFO - Epoch: 20.69, Step: 81950, Train Loss: 1.2609, Learning Rate: 5.08e-05
2025-12-10 02:39:30 - INFO - Epoch: 20.69, Step: 81960, Train Loss: 1.2512, Learning Rate: 5.08e-05
2025-12-10 02:39:41 - INFO - Epoch: 20.69, Step: 81970, Train Loss: 1.2676, Learning Rate: 5.08e-05
2025-12-10 02:39:52 - INFO - Epoch: 20.70, Step: 81980, Train Loss: 1.2315, Learning Rate: 5.08e-05
2025-12-10 02:40:03 - INFO - Epoch: 20.70, Step: 81990, Train Loss: 1.2912, Learning Rate: 5.08e-05
2025-12-10 02:40:14 - INFO - Epoch: 20.70, Step: 82000, Train Loss: 1.2566, Learning Rate: 5.08e-05
2025-12-10 02:40:25 - INFO - Epoch: 20.70, Step: 82010, Train Loss: 1.2501, Learning Rate: 5.08e-05
2025-12-10 02:40:36 - INFO - Epoch: 20.71, Step: 82020, Train Loss: 1.2844, Learning Rate: 5.08e-05
2025-12-10 02:40:48 - INFO - Epoch: 20.71, Step: 82030, Train Loss: 1.2466, Learning Rate: 5.08e-05
2025-12-10 02:40:59 - INFO - Epoch: 20.71, Step: 82040, Train Loss: 1.2549, Learning Rate: 5.08e-05
2025-12-10 02:41:10 - INFO - Epoch: 20.71, Step: 82050, Train Loss: 1.2403, Learning Rate: 5.08e-05
2025-12-10 02:41:21 - INFO - Epoch: 20.72, Step: 82060, Train Loss: 1.2772, Learning Rate: 5.07e-05
2025-12-10 02:41:32 - INFO - Epoch: 20.72, Step: 82070, Train Loss: 1.2548, Learning Rate: 5.07e-05
2025-12-10 02:41:43 - INFO - Epoch: 20.72, Step: 82080, Train Loss: 1.2693, Learning Rate: 5.07e-05
2025-12-10 02:41:55 - INFO - Epoch: 20.72, Step: 82090, Train Loss: 1.2612, Learning Rate: 5.07e-05
2025-12-10 02:42:06 - INFO - Epoch: 20.73, Step: 82100, Train Loss: 1.2402, Learning Rate: 5.07e-05
2025-12-10 02:42:17 - INFO - Epoch: 20.73, Step: 82110, Train Loss: 1.2847, Learning Rate: 5.07e-05
2025-12-10 02:42:28 - INFO - Epoch: 20.73, Step: 82120, Train Loss: 1.2434, Learning Rate: 5.07e-05
2025-12-10 02:42:39 - INFO - Epoch: 20.73, Step: 82130, Train Loss: 1.2474, Learning Rate: 5.07e-05
2025-12-10 02:42:50 - INFO - Epoch: 20.74, Step: 82140, Train Loss: 1.2336, Learning Rate: 5.07e-05
2025-12-10 02:43:01 - INFO - Epoch: 20.74, Step: 82150, Train Loss: 1.2238, Learning Rate: 5.07e-05
2025-12-10 02:43:13 - INFO - Epoch: 20.74, Step: 82160, Train Loss: 1.2083, Learning Rate: 5.07e-05
2025-12-10 02:43:24 - INFO - Epoch: 20.74, Step: 82170, Train Loss: 1.2647, Learning Rate: 5.07e-05
2025-12-10 02:43:35 - INFO - Epoch: 20.75, Step: 82180, Train Loss: 1.2481, Learning Rate: 5.07e-05
2025-12-10 02:43:46 - INFO - Epoch: 20.75, Step: 82190, Train Loss: 1.2529, Learning Rate: 5.07e-05
2025-12-10 02:43:57 - INFO - Epoch: 20.75, Step: 82200, Train Loss: 1.2657, Learning Rate: 5.07e-05
2025-12-10 02:44:08 - INFO - Epoch: 20.75, Step: 82210, Train Loss: 1.2388, Learning Rate: 5.06e-05
2025-12-10 02:44:20 - INFO - Epoch: 20.76, Step: 82220, Train Loss: 1.2501, Learning Rate: 5.06e-05
2025-12-10 02:44:31 - INFO - Epoch: 20.76, Step: 82230, Train Loss: 1.2433, Learning Rate: 5.06e-05
2025-12-10 02:44:42 - INFO - Epoch: 20.76, Step: 82240, Train Loss: 1.2631, Learning Rate: 5.06e-05
2025-12-10 02:44:53 - INFO - Epoch: 20.76, Step: 82250, Train Loss: 1.1894, Learning Rate: 5.06e-05
2025-12-10 02:45:04 - INFO - Epoch: 20.77, Step: 82260, Train Loss: 1.2838, Learning Rate: 5.06e-05
2025-12-10 02:45:15 - INFO - Epoch: 20.77, Step: 82270, Train Loss: 1.1991, Learning Rate: 5.06e-05
2025-12-10 02:45:27 - INFO - Epoch: 20.77, Step: 82280, Train Loss: 1.2686, Learning Rate: 5.06e-05
2025-12-10 02:45:38 - INFO - Epoch: 20.78, Step: 82290, Train Loss: 1.2709, Learning Rate: 5.06e-05
2025-12-10 02:45:49 - INFO - Epoch: 20.78, Step: 82300, Train Loss: 1.2699, Learning Rate: 5.06e-05
2025-12-10 02:46:00 - INFO - Epoch: 20.78, Step: 82310, Train Loss: 1.2837, Learning Rate: 5.06e-05
2025-12-10 02:46:11 - INFO - Epoch: 20.78, Step: 82320, Train Loss: 1.2644, Learning Rate: 5.06e-05
2025-12-10 02:46:22 - INFO - Epoch: 20.79, Step: 82330, Train Loss: 1.2680, Learning Rate: 5.06e-05
2025-12-10 02:46:33 - INFO - Epoch: 20.79, Step: 82340, Train Loss: 1.3170, Learning Rate: 5.06e-05
2025-12-10 02:46:45 - INFO - Epoch: 20.79, Step: 82350, Train Loss: 1.2548, Learning Rate: 5.06e-05
2025-12-10 02:46:56 - INFO - Epoch: 20.79, Step: 82360, Train Loss: 1.2386, Learning Rate: 5.05e-05
2025-12-10 02:47:07 - INFO - Epoch: 20.80, Step: 82370, Train Loss: 1.2208, Learning Rate: 5.05e-05
2025-12-10 02:47:18 - INFO - Epoch: 20.80, Step: 82380, Train Loss: 1.2703, Learning Rate: 5.05e-05
2025-12-10 02:47:29 - INFO - Epoch: 20.80, Step: 82390, Train Loss: 1.2457, Learning Rate: 5.05e-05
2025-12-10 02:47:40 - INFO - Epoch: 20.80, Step: 82400, Train Loss: 1.3084, Learning Rate: 5.05e-05
2025-12-10 02:47:52 - INFO - Epoch: 20.81, Step: 82410, Train Loss: 1.2112, Learning Rate: 5.05e-05
2025-12-10 02:48:03 - INFO - Epoch: 20.81, Step: 82420, Train Loss: 1.2515, Learning Rate: 5.05e-05
2025-12-10 02:48:14 - INFO - Epoch: 20.81, Step: 82430, Train Loss: 1.2398, Learning Rate: 5.05e-05
2025-12-10 02:48:25 - INFO - Epoch: 20.81, Step: 82440, Train Loss: 1.2956, Learning Rate: 5.05e-05
2025-12-10 02:48:36 - INFO - Epoch: 20.82, Step: 82450, Train Loss: 1.2813, Learning Rate: 5.05e-05
2025-12-10 02:48:47 - INFO - Epoch: 20.82, Step: 82460, Train Loss: 1.2706, Learning Rate: 5.05e-05
2025-12-10 02:48:59 - INFO - Epoch: 20.82, Step: 82470, Train Loss: 1.2808, Learning Rate: 5.05e-05
2025-12-10 02:49:10 - INFO - Epoch: 20.82, Step: 82480, Train Loss: 1.1983, Learning Rate: 5.05e-05
2025-12-10 02:49:21 - INFO - Epoch: 20.83, Step: 82490, Train Loss: 1.2471, Learning Rate: 5.05e-05
2025-12-10 02:49:32 - INFO - Epoch: 20.83, Step: 82500, Train Loss: 1.2688, Learning Rate: 5.05e-05
2025-12-10 02:49:43 - INFO - Epoch: 20.83, Step: 82510, Train Loss: 1.2725, Learning Rate: 5.04e-05
2025-12-10 02:49:54 - INFO - Epoch: 20.83, Step: 82520, Train Loss: 1.2593, Learning Rate: 5.04e-05
2025-12-10 02:50:05 - INFO - Epoch: 20.84, Step: 82530, Train Loss: 1.2490, Learning Rate: 5.04e-05
2025-12-10 02:50:17 - INFO - Epoch: 20.84, Step: 82540, Train Loss: 1.2136, Learning Rate: 5.04e-05
2025-12-10 02:50:28 - INFO - Epoch: 20.84, Step: 82550, Train Loss: 1.2386, Learning Rate: 5.04e-05
2025-12-10 02:50:39 - INFO - Epoch: 20.84, Step: 82560, Train Loss: 1.2328, Learning Rate: 5.04e-05
2025-12-10 02:50:50 - INFO - Epoch: 20.85, Step: 82570, Train Loss: 1.2194, Learning Rate: 5.04e-05
2025-12-10 02:51:01 - INFO - Epoch: 20.85, Step: 82580, Train Loss: 1.2681, Learning Rate: 5.04e-05
2025-12-10 02:51:12 - INFO - Epoch: 20.85, Step: 82590, Train Loss: 1.2971, Learning Rate: 5.04e-05
2025-12-10 02:51:24 - INFO - Epoch: 20.85, Step: 82600, Train Loss: 1.2654, Learning Rate: 5.04e-05
2025-12-10 02:51:35 - INFO - Epoch: 20.86, Step: 82610, Train Loss: 1.2785, Learning Rate: 5.04e-05
2025-12-10 02:51:46 - INFO - Epoch: 20.86, Step: 82620, Train Loss: 1.2767, Learning Rate: 5.04e-05
2025-12-10 02:51:57 - INFO - Epoch: 20.86, Step: 82630, Train Loss: 1.2537, Learning Rate: 5.04e-05
2025-12-10 02:52:08 - INFO - Epoch: 20.86, Step: 82640, Train Loss: 1.2345, Learning Rate: 5.04e-05
2025-12-10 02:52:19 - INFO - Epoch: 20.87, Step: 82650, Train Loss: 1.2798, Learning Rate: 5.04e-05
2025-12-10 02:52:30 - INFO - Epoch: 20.87, Step: 82660, Train Loss: 1.2375, Learning Rate: 5.03e-05
2025-12-10 02:52:42 - INFO - Epoch: 20.87, Step: 82670, Train Loss: 1.2821, Learning Rate: 5.03e-05
2025-12-10 02:52:53 - INFO - Epoch: 20.87, Step: 82680, Train Loss: 1.2588, Learning Rate: 5.03e-05
2025-12-10 02:53:04 - INFO - Epoch: 20.88, Step: 82690, Train Loss: 1.2897, Learning Rate: 5.03e-05
2025-12-10 02:53:15 - INFO - Epoch: 20.88, Step: 82700, Train Loss: 1.2425, Learning Rate: 5.03e-05
2025-12-10 02:53:26 - INFO - Epoch: 20.88, Step: 82710, Train Loss: 1.2442, Learning Rate: 5.03e-05
2025-12-10 02:53:37 - INFO - Epoch: 20.88, Step: 82720, Train Loss: 1.2525, Learning Rate: 5.03e-05
2025-12-10 02:53:49 - INFO - Epoch: 20.89, Step: 82730, Train Loss: 1.2518, Learning Rate: 5.03e-05
2025-12-10 02:54:00 - INFO - Epoch: 20.89, Step: 82740, Train Loss: 1.2453, Learning Rate: 5.03e-05
2025-12-10 02:54:11 - INFO - Epoch: 20.89, Step: 82750, Train Loss: 1.2496, Learning Rate: 5.03e-05
2025-12-10 02:54:22 - INFO - Epoch: 20.89, Step: 82760, Train Loss: 1.2119, Learning Rate: 5.03e-05
2025-12-10 02:54:33 - INFO - Epoch: 20.90, Step: 82770, Train Loss: 1.2697, Learning Rate: 5.03e-05
2025-12-10 02:54:44 - INFO - Epoch: 20.90, Step: 82780, Train Loss: 1.2352, Learning Rate: 5.03e-05
2025-12-10 02:54:56 - INFO - Epoch: 20.90, Step: 82790, Train Loss: 1.2364, Learning Rate: 5.03e-05
2025-12-10 02:55:07 - INFO - Epoch: 20.90, Step: 82800, Train Loss: 1.2331, Learning Rate: 5.03e-05
2025-12-10 02:55:18 - INFO - Epoch: 20.91, Step: 82810, Train Loss: 1.2647, Learning Rate: 5.02e-05
2025-12-10 02:55:29 - INFO - Epoch: 20.91, Step: 82820, Train Loss: 1.2619, Learning Rate: 5.02e-05
2025-12-10 02:55:40 - INFO - Epoch: 20.91, Step: 82830, Train Loss: 1.2792, Learning Rate: 5.02e-05
2025-12-10 02:55:51 - INFO - Epoch: 20.91, Step: 82840, Train Loss: 1.2612, Learning Rate: 5.02e-05
2025-12-10 02:56:02 - INFO - Epoch: 20.92, Step: 82850, Train Loss: 1.2657, Learning Rate: 5.02e-05
2025-12-10 02:56:14 - INFO - Epoch: 20.92, Step: 82860, Train Loss: 1.2434, Learning Rate: 5.02e-05
2025-12-10 02:56:25 - INFO - Epoch: 20.92, Step: 82870, Train Loss: 1.2602, Learning Rate: 5.02e-05
2025-12-10 02:56:36 - INFO - Epoch: 20.92, Step: 82880, Train Loss: 1.2666, Learning Rate: 5.02e-05
2025-12-10 02:56:47 - INFO - Epoch: 20.93, Step: 82890, Train Loss: 1.2089, Learning Rate: 5.02e-05
2025-12-10 02:56:58 - INFO - Epoch: 20.93, Step: 82900, Train Loss: 1.2196, Learning Rate: 5.02e-05
2025-12-10 02:57:09 - INFO - Epoch: 20.93, Step: 82910, Train Loss: 1.2557, Learning Rate: 5.02e-05
2025-12-10 02:57:21 - INFO - Epoch: 20.93, Step: 82920, Train Loss: 1.3017, Learning Rate: 5.02e-05
2025-12-10 02:57:32 - INFO - Epoch: 20.94, Step: 82930, Train Loss: 1.2700, Learning Rate: 5.02e-05
2025-12-10 02:57:43 - INFO - Epoch: 20.94, Step: 82940, Train Loss: 1.2788, Learning Rate: 5.02e-05
2025-12-10 02:57:54 - INFO - Epoch: 20.94, Step: 82950, Train Loss: 1.2329, Learning Rate: 5.02e-05
2025-12-10 02:58:05 - INFO - Epoch: 20.94, Step: 82960, Train Loss: 1.2157, Learning Rate: 5.01e-05
2025-12-10 02:58:16 - INFO - Epoch: 20.95, Step: 82970, Train Loss: 1.2182, Learning Rate: 5.01e-05
2025-12-10 02:58:27 - INFO - Epoch: 20.95, Step: 82980, Train Loss: 1.2604, Learning Rate: 5.01e-05
2025-12-10 02:58:39 - INFO - Epoch: 20.95, Step: 82990, Train Loss: 1.2271, Learning Rate: 5.01e-05
2025-12-10 02:58:50 - INFO - Epoch: 20.95, Step: 83000, Train Loss: 1.2775, Learning Rate: 5.01e-05
2025-12-10 02:59:01 - INFO - Epoch: 20.96, Step: 83010, Train Loss: 1.2007, Learning Rate: 5.01e-05
2025-12-10 02:59:12 - INFO - Epoch: 20.96, Step: 83020, Train Loss: 1.2581, Learning Rate: 5.01e-05
2025-12-10 02:59:23 - INFO - Epoch: 20.96, Step: 83030, Train Loss: 1.2293, Learning Rate: 5.01e-05
2025-12-10 02:59:34 - INFO - Epoch: 20.96, Step: 83040, Train Loss: 1.2508, Learning Rate: 5.01e-05
2025-12-10 02:59:46 - INFO - Epoch: 20.97, Step: 83050, Train Loss: 1.2597, Learning Rate: 5.01e-05
2025-12-10 02:59:57 - INFO - Epoch: 20.97, Step: 83060, Train Loss: 1.2627, Learning Rate: 5.01e-05
2025-12-10 03:00:08 - INFO - Epoch: 20.97, Step: 83070, Train Loss: 1.2849, Learning Rate: 5.01e-05
2025-12-10 03:00:19 - INFO - Epoch: 20.97, Step: 83080, Train Loss: 1.2561, Learning Rate: 5.01e-05
2025-12-10 03:00:30 - INFO - Epoch: 20.98, Step: 83090, Train Loss: 1.2372, Learning Rate: 5.01e-05
2025-12-10 03:00:41 - INFO - Epoch: 20.98, Step: 83100, Train Loss: 1.2294, Learning Rate: 5.01e-05
2025-12-10 03:00:53 - INFO - Epoch: 20.98, Step: 83110, Train Loss: 1.2772, Learning Rate: 5.00e-05
2025-12-10 03:01:04 - INFO - Epoch: 20.98, Step: 83120, Train Loss: 1.2575, Learning Rate: 5.00e-05
2025-12-10 03:01:15 - INFO - Epoch: 20.99, Step: 83130, Train Loss: 1.2067, Learning Rate: 5.00e-05
2025-12-10 03:01:26 - INFO - Epoch: 20.99, Step: 83140, Train Loss: 1.2130, Learning Rate: 5.00e-05
2025-12-10 03:01:37 - INFO - Epoch: 20.99, Step: 83150, Train Loss: 1.2457, Learning Rate: 5.00e-05
2025-12-10 03:01:48 - INFO - Epoch: 20.99, Step: 83160, Train Loss: 1.2392, Learning Rate: 5.00e-05
2025-12-10 03:01:59 - INFO - Epoch: 21.00, Step: 83170, Train Loss: 1.2451, Learning Rate: 5.00e-05
2025-12-10 03:02:11 - INFO - Epoch: 21.00, Step: 83180, Train Loss: 1.2502, Learning Rate: 5.00e-05
2025-12-10 03:02:22 - INFO - Epoch: 21.00, Step: 83190, Train Loss: 1.2589, Learning Rate: 5.00e-05
2025-12-10 03:02:33 - INFO - Epoch: 21.00, Step: 83200, Train Loss: 1.2573, Learning Rate: 5.00e-05
2025-12-10 03:02:44 - INFO - Epoch: 21.01, Step: 83210, Train Loss: 1.2797, Learning Rate: 5.00e-05
2025-12-10 03:02:55 - INFO - Epoch: 21.01, Step: 83220, Train Loss: 1.2805, Learning Rate: 5.00e-05
2025-12-10 03:03:06 - INFO - Epoch: 21.01, Step: 83230, Train Loss: 1.2813, Learning Rate: 5.00e-05
2025-12-10 03:03:18 - INFO - Epoch: 21.01, Step: 83240, Train Loss: 1.2517, Learning Rate: 5.00e-05
2025-12-10 03:03:29 - INFO - Epoch: 21.02, Step: 83250, Train Loss: 1.2506, Learning Rate: 5.00e-05
2025-12-10 03:03:40 - INFO - Epoch: 21.02, Step: 83260, Train Loss: 1.2511, Learning Rate: 4.99e-05
2025-12-10 03:03:51 - INFO - Epoch: 21.02, Step: 83270, Train Loss: 1.2465, Learning Rate: 4.99e-05
2025-12-10 03:04:02 - INFO - Epoch: 21.02, Step: 83280, Train Loss: 1.2393, Learning Rate: 4.99e-05
2025-12-10 03:04:13 - INFO - Epoch: 21.03, Step: 83290, Train Loss: 1.2751, Learning Rate: 4.99e-05
2025-12-10 03:04:24 - INFO - Epoch: 21.03, Step: 83300, Train Loss: 1.2813, Learning Rate: 4.99e-05
2025-12-10 03:04:36 - INFO - Epoch: 21.03, Step: 83310, Train Loss: 1.2627, Learning Rate: 4.99e-05
2025-12-10 03:04:47 - INFO - Epoch: 21.04, Step: 83320, Train Loss: 1.2181, Learning Rate: 4.99e-05
2025-12-10 03:04:58 - INFO - Epoch: 21.04, Step: 83330, Train Loss: 1.2537, Learning Rate: 4.99e-05
2025-12-10 03:05:09 - INFO - Epoch: 21.04, Step: 83340, Train Loss: 1.2345, Learning Rate: 4.99e-05
2025-12-10 03:05:20 - INFO - Epoch: 21.04, Step: 83350, Train Loss: 1.2577, Learning Rate: 4.99e-05
2025-12-10 03:05:31 - INFO - Epoch: 21.05, Step: 83360, Train Loss: 1.2728, Learning Rate: 4.99e-05
2025-12-10 03:05:43 - INFO - Epoch: 21.05, Step: 83370, Train Loss: 1.2785, Learning Rate: 4.99e-05
2025-12-10 03:05:54 - INFO - Epoch: 21.05, Step: 83380, Train Loss: 1.2525, Learning Rate: 4.99e-05
2025-12-10 03:06:05 - INFO - Epoch: 21.05, Step: 83390, Train Loss: 1.2716, Learning Rate: 4.99e-05
2025-12-10 03:06:16 - INFO - Epoch: 21.06, Step: 83400, Train Loss: 1.2849, Learning Rate: 4.99e-05
2025-12-10 03:06:27 - INFO - Epoch: 21.06, Step: 83410, Train Loss: 1.2576, Learning Rate: 4.98e-05
2025-12-10 03:06:38 - INFO - Epoch: 21.06, Step: 83420, Train Loss: 1.2284, Learning Rate: 4.98e-05
2025-12-10 03:06:49 - INFO - Epoch: 21.06, Step: 83430, Train Loss: 1.2356, Learning Rate: 4.98e-05
2025-12-10 03:07:01 - INFO - Epoch: 21.07, Step: 83440, Train Loss: 1.2579, Learning Rate: 4.98e-05
2025-12-10 03:07:12 - INFO - Epoch: 21.07, Step: 83450, Train Loss: 1.2253, Learning Rate: 4.98e-05
2025-12-10 03:07:23 - INFO - Epoch: 21.07, Step: 83460, Train Loss: 1.2430, Learning Rate: 4.98e-05
2025-12-10 03:07:34 - INFO - Epoch: 21.07, Step: 83470, Train Loss: 1.2737, Learning Rate: 4.98e-05
2025-12-10 03:07:45 - INFO - Epoch: 21.08, Step: 83480, Train Loss: 1.2633, Learning Rate: 4.98e-05
2025-12-10 03:07:56 - INFO - Epoch: 21.08, Step: 83490, Train Loss: 1.2345, Learning Rate: 4.98e-05
2025-12-10 03:08:08 - INFO - Epoch: 21.08, Step: 83500, Train Loss: 1.2553, Learning Rate: 4.98e-05
2025-12-10 03:08:19 - INFO - Epoch: 21.08, Step: 83510, Train Loss: 1.2553, Learning Rate: 4.98e-05
2025-12-10 03:08:30 - INFO - Epoch: 21.09, Step: 83520, Train Loss: 1.2407, Learning Rate: 4.98e-05
2025-12-10 03:08:41 - INFO - Epoch: 21.09, Step: 83530, Train Loss: 1.2331, Learning Rate: 4.98e-05
2025-12-10 03:08:52 - INFO - Epoch: 21.09, Step: 83540, Train Loss: 1.2887, Learning Rate: 4.98e-05
2025-12-10 03:09:03 - INFO - Epoch: 21.09, Step: 83550, Train Loss: 1.2394, Learning Rate: 4.98e-05
2025-12-10 03:09:14 - INFO - Epoch: 21.10, Step: 83560, Train Loss: 1.2348, Learning Rate: 4.97e-05
2025-12-10 03:09:26 - INFO - Epoch: 21.10, Step: 83570, Train Loss: 1.2567, Learning Rate: 4.97e-05
2025-12-10 03:09:37 - INFO - Epoch: 21.10, Step: 83580, Train Loss: 1.2741, Learning Rate: 4.97e-05
2025-12-10 03:09:48 - INFO - Epoch: 21.10, Step: 83590, Train Loss: 1.2493, Learning Rate: 4.97e-05
2025-12-10 03:09:59 - INFO - Epoch: 21.11, Step: 83600, Train Loss: 1.2238, Learning Rate: 4.97e-05
2025-12-10 03:10:10 - INFO - Epoch: 21.11, Step: 83610, Train Loss: 1.2678, Learning Rate: 4.97e-05
2025-12-10 03:10:21 - INFO - Epoch: 21.11, Step: 83620, Train Loss: 1.2474, Learning Rate: 4.97e-05
2025-12-10 03:10:33 - INFO - Epoch: 21.11, Step: 83630, Train Loss: 1.2349, Learning Rate: 4.97e-05
2025-12-10 03:10:44 - INFO - Epoch: 21.12, Step: 83640, Train Loss: 1.2205, Learning Rate: 4.97e-05
2025-12-10 03:10:55 - INFO - Epoch: 21.12, Step: 83650, Train Loss: 1.2208, Learning Rate: 4.97e-05
2025-12-10 03:11:06 - INFO - Epoch: 21.12, Step: 83660, Train Loss: 1.2541, Learning Rate: 4.97e-05
2025-12-10 03:11:17 - INFO - Epoch: 21.12, Step: 83670, Train Loss: 1.2509, Learning Rate: 4.97e-05
2025-12-10 03:11:28 - INFO - Epoch: 21.13, Step: 83680, Train Loss: 1.2187, Learning Rate: 4.97e-05
2025-12-10 03:11:39 - INFO - Epoch: 21.13, Step: 83690, Train Loss: 1.2070, Learning Rate: 4.97e-05
2025-12-10 03:11:51 - INFO - Epoch: 21.13, Step: 83700, Train Loss: 1.2844, Learning Rate: 4.97e-05
2025-12-10 03:12:02 - INFO - Epoch: 21.13, Step: 83710, Train Loss: 1.2509, Learning Rate: 4.96e-05
2025-12-10 03:12:13 - INFO - Epoch: 21.14, Step: 83720, Train Loss: 1.2453, Learning Rate: 4.96e-05
2025-12-10 03:12:24 - INFO - Epoch: 21.14, Step: 83730, Train Loss: 1.2853, Learning Rate: 4.96e-05
2025-12-10 03:12:35 - INFO - Epoch: 21.14, Step: 83740, Train Loss: 1.2580, Learning Rate: 4.96e-05
2025-12-10 03:12:46 - INFO - Epoch: 21.14, Step: 83750, Train Loss: 1.2589, Learning Rate: 4.96e-05
2025-12-10 03:12:57 - INFO - Epoch: 21.15, Step: 83760, Train Loss: 1.2545, Learning Rate: 4.96e-05
2025-12-10 03:13:09 - INFO - Epoch: 21.15, Step: 83770, Train Loss: 1.2380, Learning Rate: 4.96e-05
2025-12-10 03:13:20 - INFO - Epoch: 21.15, Step: 83780, Train Loss: 1.2208, Learning Rate: 4.96e-05
2025-12-10 03:13:31 - INFO - Epoch: 21.15, Step: 83790, Train Loss: 1.2801, Learning Rate: 4.96e-05
2025-12-10 03:13:42 - INFO - Epoch: 21.16, Step: 83800, Train Loss: 1.2250, Learning Rate: 4.96e-05
2025-12-10 03:13:53 - INFO - Epoch: 21.16, Step: 83810, Train Loss: 1.2327, Learning Rate: 4.96e-05
2025-12-10 03:14:04 - INFO - Epoch: 21.16, Step: 83820, Train Loss: 1.2547, Learning Rate: 4.96e-05
2025-12-10 03:14:16 - INFO - Epoch: 21.16, Step: 83830, Train Loss: 1.2550, Learning Rate: 4.96e-05
2025-12-10 03:14:27 - INFO - Epoch: 21.17, Step: 83840, Train Loss: 1.2750, Learning Rate: 4.96e-05
2025-12-10 03:14:38 - INFO - Epoch: 21.17, Step: 83850, Train Loss: 1.2850, Learning Rate: 4.96e-05
2025-12-10 03:14:49 - INFO - Epoch: 21.17, Step: 83860, Train Loss: 1.2232, Learning Rate: 4.95e-05
2025-12-10 03:15:00 - INFO - Epoch: 21.17, Step: 83870, Train Loss: 1.2124, Learning Rate: 4.95e-05
2025-12-10 03:15:11 - INFO - Epoch: 21.18, Step: 83880, Train Loss: 1.2116, Learning Rate: 4.95e-05
2025-12-10 03:15:22 - INFO - Epoch: 21.18, Step: 83890, Train Loss: 1.2399, Learning Rate: 4.95e-05
2025-12-10 03:15:34 - INFO - Epoch: 21.18, Step: 83900, Train Loss: 1.2816, Learning Rate: 4.95e-05
2025-12-10 03:15:45 - INFO - Epoch: 21.18, Step: 83910, Train Loss: 1.2331, Learning Rate: 4.95e-05
2025-12-10 03:15:56 - INFO - Epoch: 21.19, Step: 83920, Train Loss: 1.2382, Learning Rate: 4.95e-05
2025-12-10 03:16:07 - INFO - Epoch: 21.19, Step: 83930, Train Loss: 1.2349, Learning Rate: 4.95e-05
2025-12-10 03:16:18 - INFO - Epoch: 21.19, Step: 83940, Train Loss: 1.2581, Learning Rate: 4.95e-05
2025-12-10 03:16:29 - INFO - Epoch: 21.19, Step: 83950, Train Loss: 1.2608, Learning Rate: 4.95e-05
2025-12-10 03:16:41 - INFO - Epoch: 21.20, Step: 83960, Train Loss: 1.2548, Learning Rate: 4.95e-05
2025-12-10 03:16:52 - INFO - Epoch: 21.20, Step: 83970, Train Loss: 1.2734, Learning Rate: 4.95e-05
2025-12-10 03:17:03 - INFO - Epoch: 21.20, Step: 83980, Train Loss: 1.2719, Learning Rate: 4.95e-05
2025-12-10 03:17:14 - INFO - Epoch: 21.20, Step: 83990, Train Loss: 1.2360, Learning Rate: 4.95e-05
2025-12-10 03:17:25 - INFO - Epoch: 21.21, Step: 84000, Train Loss: 1.2764, Learning Rate: 4.95e-05
2025-12-10 03:17:36 - INFO - Epoch: 21.21, Step: 84010, Train Loss: 1.2196, Learning Rate: 4.94e-05
2025-12-10 03:17:47 - INFO - Epoch: 21.21, Step: 84020, Train Loss: 1.2317, Learning Rate: 4.94e-05
2025-12-10 03:17:59 - INFO - Epoch: 21.21, Step: 84030, Train Loss: 1.2365, Learning Rate: 4.94e-05
2025-12-10 03:18:10 - INFO - Epoch: 21.22, Step: 84040, Train Loss: 1.2539, Learning Rate: 4.94e-05
2025-12-10 03:18:21 - INFO - Epoch: 21.22, Step: 84050, Train Loss: 1.2452, Learning Rate: 4.94e-05
2025-12-10 03:18:32 - INFO - Epoch: 21.22, Step: 84060, Train Loss: 1.2202, Learning Rate: 4.94e-05
2025-12-10 03:18:43 - INFO - Epoch: 21.22, Step: 84070, Train Loss: 1.2359, Learning Rate: 4.94e-05
2025-12-10 03:18:54 - INFO - Epoch: 21.23, Step: 84080, Train Loss: 1.2481, Learning Rate: 4.94e-05
2025-12-10 03:19:06 - INFO - Epoch: 21.23, Step: 84090, Train Loss: 1.2704, Learning Rate: 4.94e-05
2025-12-10 03:19:17 - INFO - Epoch: 21.23, Step: 84100, Train Loss: 1.2624, Learning Rate: 4.94e-05
2025-12-10 03:19:28 - INFO - Epoch: 21.23, Step: 84110, Train Loss: 1.3022, Learning Rate: 4.94e-05
2025-12-10 03:19:39 - INFO - Epoch: 21.24, Step: 84120, Train Loss: 1.2227, Learning Rate: 4.94e-05
2025-12-10 03:19:50 - INFO - Epoch: 21.24, Step: 84130, Train Loss: 1.2472, Learning Rate: 4.94e-05
2025-12-10 03:20:01 - INFO - Epoch: 21.24, Step: 84140, Train Loss: 1.2436, Learning Rate: 4.94e-05
2025-12-10 03:20:12 - INFO - Epoch: 21.24, Step: 84150, Train Loss: 1.2791, Learning Rate: 4.94e-05
2025-12-10 03:20:24 - INFO - Epoch: 21.25, Step: 84160, Train Loss: 1.2548, Learning Rate: 4.94e-05
2025-12-10 03:20:35 - INFO - Epoch: 21.25, Step: 84170, Train Loss: 1.2552, Learning Rate: 4.93e-05
2025-12-10 03:20:46 - INFO - Epoch: 21.25, Step: 84180, Train Loss: 1.2434, Learning Rate: 4.93e-05
2025-12-10 03:20:57 - INFO - Epoch: 21.25, Step: 84190, Train Loss: 1.2585, Learning Rate: 4.93e-05
2025-12-10 03:21:08 - INFO - Epoch: 21.26, Step: 84200, Train Loss: 1.2563, Learning Rate: 4.93e-05
2025-12-10 03:21:19 - INFO - Epoch: 21.26, Step: 84210, Train Loss: 1.2578, Learning Rate: 4.93e-05
2025-12-10 03:21:31 - INFO - Epoch: 21.26, Step: 84220, Train Loss: 1.2527, Learning Rate: 4.93e-05
2025-12-10 03:21:42 - INFO - Epoch: 21.26, Step: 84230, Train Loss: 1.2810, Learning Rate: 4.93e-05
2025-12-10 03:21:53 - INFO - Epoch: 21.27, Step: 84240, Train Loss: 1.2769, Learning Rate: 4.93e-05
2025-12-10 03:22:04 - INFO - Epoch: 21.27, Step: 84250, Train Loss: 1.2527, Learning Rate: 4.93e-05
2025-12-10 03:22:15 - INFO - Epoch: 21.27, Step: 84260, Train Loss: 1.2442, Learning Rate: 4.93e-05
2025-12-10 03:22:26 - INFO - Epoch: 21.27, Step: 84270, Train Loss: 1.2144, Learning Rate: 4.93e-05
2025-12-10 03:22:37 - INFO - Epoch: 21.28, Step: 84280, Train Loss: 1.2241, Learning Rate: 4.93e-05
2025-12-10 03:22:49 - INFO - Epoch: 21.28, Step: 84290, Train Loss: 1.2618, Learning Rate: 4.93e-05
2025-12-10 03:23:00 - INFO - Epoch: 21.28, Step: 84300, Train Loss: 1.2347, Learning Rate: 4.93e-05
2025-12-10 03:23:11 - INFO - Epoch: 21.29, Step: 84310, Train Loss: 1.2551, Learning Rate: 4.93e-05
2025-12-10 03:23:22 - INFO - Epoch: 21.29, Step: 84320, Train Loss: 1.2461, Learning Rate: 4.92e-05
2025-12-10 03:23:33 - INFO - Epoch: 21.29, Step: 84330, Train Loss: 1.2745, Learning Rate: 4.92e-05
2025-12-10 03:23:44 - INFO - Epoch: 21.29, Step: 84340, Train Loss: 1.2324, Learning Rate: 4.92e-05
2025-12-10 03:23:56 - INFO - Epoch: 21.30, Step: 84350, Train Loss: 1.2524, Learning Rate: 4.92e-05
2025-12-10 03:24:07 - INFO - Epoch: 21.30, Step: 84360, Train Loss: 1.2469, Learning Rate: 4.92e-05
2025-12-10 03:24:18 - INFO - Epoch: 21.30, Step: 84370, Train Loss: 1.2269, Learning Rate: 4.92e-05
2025-12-10 03:24:29 - INFO - Epoch: 21.30, Step: 84380, Train Loss: 1.2617, Learning Rate: 4.92e-05
2025-12-10 03:24:40 - INFO - Epoch: 21.31, Step: 84390, Train Loss: 1.2587, Learning Rate: 4.92e-05
2025-12-10 03:24:51 - INFO - Epoch: 21.31, Step: 84400, Train Loss: 1.2646, Learning Rate: 4.92e-05
2025-12-10 03:25:02 - INFO - Epoch: 21.31, Step: 84410, Train Loss: 1.2495, Learning Rate: 4.92e-05
2025-12-10 03:25:14 - INFO - Epoch: 21.31, Step: 84420, Train Loss: 1.2430, Learning Rate: 4.92e-05
2025-12-10 03:25:25 - INFO - Epoch: 21.32, Step: 84430, Train Loss: 1.2574, Learning Rate: 4.92e-05
2025-12-10 03:25:36 - INFO - Epoch: 21.32, Step: 84440, Train Loss: 1.2239, Learning Rate: 4.92e-05
2025-12-10 03:25:47 - INFO - Epoch: 21.32, Step: 84450, Train Loss: 1.2743, Learning Rate: 4.92e-05
2025-12-10 03:25:58 - INFO - Epoch: 21.32, Step: 84460, Train Loss: 1.2332, Learning Rate: 4.92e-05
2025-12-10 03:26:09 - INFO - Epoch: 21.33, Step: 84470, Train Loss: 1.2101, Learning Rate: 4.91e-05
2025-12-10 03:26:21 - INFO - Epoch: 21.33, Step: 84480, Train Loss: 1.2634, Learning Rate: 4.91e-05
2025-12-10 03:26:32 - INFO - Epoch: 21.33, Step: 84490, Train Loss: 1.2454, Learning Rate: 4.91e-05
2025-12-10 03:26:43 - INFO - Epoch: 21.33, Step: 84500, Train Loss: 1.2320, Learning Rate: 4.91e-05
2025-12-10 03:26:54 - INFO - Epoch: 21.34, Step: 84510, Train Loss: 1.2846, Learning Rate: 4.91e-05
2025-12-10 03:27:05 - INFO - Epoch: 21.34, Step: 84520, Train Loss: 1.2372, Learning Rate: 4.91e-05
2025-12-10 03:27:16 - INFO - Epoch: 21.34, Step: 84530, Train Loss: 1.2346, Learning Rate: 4.91e-05
2025-12-10 03:27:27 - INFO - Epoch: 21.34, Step: 84540, Train Loss: 1.2287, Learning Rate: 4.91e-05
2025-12-10 03:27:39 - INFO - Epoch: 21.35, Step: 84550, Train Loss: 1.2371, Learning Rate: 4.91e-05
2025-12-10 03:27:50 - INFO - Epoch: 21.35, Step: 84560, Train Loss: 1.2808, Learning Rate: 4.91e-05
2025-12-10 03:28:01 - INFO - Epoch: 21.35, Step: 84570, Train Loss: 1.2097, Learning Rate: 4.91e-05
2025-12-10 03:28:12 - INFO - Epoch: 21.35, Step: 84580, Train Loss: 1.2790, Learning Rate: 4.91e-05
2025-12-10 03:28:23 - INFO - Epoch: 21.36, Step: 84590, Train Loss: 1.2660, Learning Rate: 4.91e-05
2025-12-10 03:28:34 - INFO - Epoch: 21.36, Step: 84600, Train Loss: 1.2371, Learning Rate: 4.91e-05
2025-12-10 03:28:46 - INFO - Epoch: 21.36, Step: 84610, Train Loss: 1.2751, Learning Rate: 4.91e-05
2025-12-10 03:28:57 - INFO - Epoch: 21.36, Step: 84620, Train Loss: 1.2077, Learning Rate: 4.90e-05
2025-12-10 03:29:08 - INFO - Epoch: 21.37, Step: 84630, Train Loss: 1.2076, Learning Rate: 4.90e-05
2025-12-10 03:29:19 - INFO - Epoch: 21.37, Step: 84640, Train Loss: 1.2466, Learning Rate: 4.90e-05
2025-12-10 03:29:30 - INFO - Epoch: 21.37, Step: 84650, Train Loss: 1.2499, Learning Rate: 4.90e-05
2025-12-10 03:29:41 - INFO - Epoch: 21.37, Step: 84660, Train Loss: 1.2230, Learning Rate: 4.90e-05
2025-12-10 03:29:52 - INFO - Epoch: 21.38, Step: 84670, Train Loss: 1.2537, Learning Rate: 4.90e-05
2025-12-10 03:30:04 - INFO - Epoch: 21.38, Step: 84680, Train Loss: 1.2296, Learning Rate: 4.90e-05
2025-12-10 03:30:15 - INFO - Epoch: 21.38, Step: 84690, Train Loss: 1.2313, Learning Rate: 4.90e-05
2025-12-10 03:30:26 - INFO - Epoch: 21.38, Step: 84700, Train Loss: 1.2537, Learning Rate: 4.90e-05
2025-12-10 03:30:37 - INFO - Epoch: 21.39, Step: 84710, Train Loss: 1.2459, Learning Rate: 4.90e-05
2025-12-10 03:30:48 - INFO - Epoch: 21.39, Step: 84720, Train Loss: 1.2847, Learning Rate: 4.90e-05
2025-12-10 03:30:59 - INFO - Epoch: 21.39, Step: 84730, Train Loss: 1.2390, Learning Rate: 4.90e-05
2025-12-10 03:31:11 - INFO - Epoch: 21.39, Step: 84740, Train Loss: 1.2623, Learning Rate: 4.90e-05
2025-12-10 03:31:22 - INFO - Epoch: 21.40, Step: 84750, Train Loss: 1.2891, Learning Rate: 4.90e-05
2025-12-10 03:31:33 - INFO - Epoch: 21.40, Step: 84760, Train Loss: 1.2362, Learning Rate: 4.90e-05
2025-12-10 03:31:44 - INFO - Epoch: 21.40, Step: 84770, Train Loss: 1.2430, Learning Rate: 4.89e-05
2025-12-10 03:31:55 - INFO - Epoch: 21.40, Step: 84780, Train Loss: 1.2302, Learning Rate: 4.89e-05
2025-12-10 03:32:06 - INFO - Epoch: 21.41, Step: 84790, Train Loss: 1.2456, Learning Rate: 4.89e-05
2025-12-10 03:32:17 - INFO - Epoch: 21.41, Step: 84800, Train Loss: 1.2685, Learning Rate: 4.89e-05
2025-12-10 03:32:29 - INFO - Epoch: 21.41, Step: 84810, Train Loss: 1.2681, Learning Rate: 4.89e-05
2025-12-10 03:32:40 - INFO - Epoch: 21.41, Step: 84820, Train Loss: 1.2684, Learning Rate: 4.89e-05
2025-12-10 03:32:51 - INFO - Epoch: 21.42, Step: 84830, Train Loss: 1.2729, Learning Rate: 4.89e-05
2025-12-10 03:33:02 - INFO - Epoch: 21.42, Step: 84840, Train Loss: 1.1893, Learning Rate: 4.89e-05
2025-12-10 03:33:13 - INFO - Epoch: 21.42, Step: 84850, Train Loss: 1.2454, Learning Rate: 4.89e-05
2025-12-10 03:33:24 - INFO - Epoch: 21.42, Step: 84860, Train Loss: 1.2677, Learning Rate: 4.89e-05
2025-12-10 03:33:35 - INFO - Epoch: 21.43, Step: 84870, Train Loss: 1.2909, Learning Rate: 4.89e-05
2025-12-10 03:33:47 - INFO - Epoch: 21.43, Step: 84880, Train Loss: 1.2263, Learning Rate: 4.89e-05
2025-12-10 03:33:58 - INFO - Epoch: 21.43, Step: 84890, Train Loss: 1.2606, Learning Rate: 4.89e-05
2025-12-10 03:34:09 - INFO - Epoch: 21.43, Step: 84900, Train Loss: 1.2374, Learning Rate: 4.89e-05
2025-12-10 03:34:20 - INFO - Epoch: 21.44, Step: 84910, Train Loss: 1.2367, Learning Rate: 4.89e-05
2025-12-10 03:34:31 - INFO - Epoch: 21.44, Step: 84920, Train Loss: 1.2428, Learning Rate: 4.88e-05
2025-12-10 03:34:42 - INFO - Epoch: 21.44, Step: 84930, Train Loss: 1.1938, Learning Rate: 4.88e-05
2025-12-10 03:34:54 - INFO - Epoch: 21.44, Step: 84940, Train Loss: 1.2780, Learning Rate: 4.88e-05
2025-12-10 03:35:05 - INFO - Epoch: 21.45, Step: 84950, Train Loss: 1.2484, Learning Rate: 4.88e-05
2025-12-10 03:35:16 - INFO - Epoch: 21.45, Step: 84960, Train Loss: 1.2299, Learning Rate: 4.88e-05
2025-12-10 03:35:27 - INFO - Epoch: 21.45, Step: 84970, Train Loss: 1.2439, Learning Rate: 4.88e-05
2025-12-10 03:35:38 - INFO - Epoch: 21.45, Step: 84980, Train Loss: 1.2833, Learning Rate: 4.88e-05
2025-12-10 03:35:49 - INFO - Epoch: 21.46, Step: 84990, Train Loss: 1.2179, Learning Rate: 4.88e-05
2025-12-10 03:36:00 - INFO - Epoch: 21.46, Step: 85000, Train Loss: 1.2171, Learning Rate: 4.88e-05
2025-12-10 03:36:12 - INFO - Epoch: 21.46, Step: 85010, Train Loss: 1.2264, Learning Rate: 4.88e-05
2025-12-10 03:36:23 - INFO - Epoch: 21.46, Step: 85020, Train Loss: 1.2485, Learning Rate: 4.88e-05
2025-12-10 03:36:34 - INFO - Epoch: 21.47, Step: 85030, Train Loss: 1.2082, Learning Rate: 4.88e-05
2025-12-10 03:36:45 - INFO - Epoch: 21.47, Step: 85040, Train Loss: 1.2722, Learning Rate: 4.88e-05
2025-12-10 03:36:56 - INFO - Epoch: 21.47, Step: 85050, Train Loss: 1.2689, Learning Rate: 4.88e-05
2025-12-10 03:37:07 - INFO - Epoch: 21.47, Step: 85060, Train Loss: 1.2555, Learning Rate: 4.88e-05
2025-12-10 03:37:19 - INFO - Epoch: 21.48, Step: 85070, Train Loss: 1.2474, Learning Rate: 4.87e-05
2025-12-10 03:37:30 - INFO - Epoch: 21.48, Step: 85080, Train Loss: 1.2355, Learning Rate: 4.87e-05
2025-12-10 03:37:41 - INFO - Epoch: 21.48, Step: 85090, Train Loss: 1.2259, Learning Rate: 4.87e-05
2025-12-10 03:37:52 - INFO - Epoch: 21.48, Step: 85100, Train Loss: 1.2753, Learning Rate: 4.87e-05
2025-12-10 03:38:03 - INFO - Epoch: 21.49, Step: 85110, Train Loss: 1.2693, Learning Rate: 4.87e-05
2025-12-10 03:38:14 - INFO - Epoch: 21.49, Step: 85120, Train Loss: 1.2479, Learning Rate: 4.87e-05
2025-12-10 03:38:25 - INFO - Epoch: 21.49, Step: 85130, Train Loss: 1.2260, Learning Rate: 4.87e-05
2025-12-10 03:38:37 - INFO - Epoch: 21.49, Step: 85140, Train Loss: 1.1981, Learning Rate: 4.87e-05
2025-12-10 03:38:48 - INFO - Epoch: 21.50, Step: 85150, Train Loss: 1.2389, Learning Rate: 4.87e-05
2025-12-10 03:38:59 - INFO - Epoch: 21.50, Step: 85160, Train Loss: 1.2156, Learning Rate: 4.87e-05
2025-12-10 03:39:10 - INFO - Epoch: 21.50, Step: 85170, Train Loss: 1.2719, Learning Rate: 4.87e-05
2025-12-10 03:39:21 - INFO - Epoch: 21.50, Step: 85180, Train Loss: 1.2578, Learning Rate: 4.87e-05
2025-12-10 03:39:32 - INFO - Epoch: 21.51, Step: 85190, Train Loss: 1.2713, Learning Rate: 4.87e-05
2025-12-10 03:39:44 - INFO - Epoch: 21.51, Step: 85200, Train Loss: 1.2104, Learning Rate: 4.87e-05
2025-12-10 03:39:55 - INFO - Epoch: 21.51, Step: 85210, Train Loss: 1.2421, Learning Rate: 4.87e-05
2025-12-10 03:40:06 - INFO - Epoch: 21.51, Step: 85220, Train Loss: 1.2596, Learning Rate: 4.86e-05
2025-12-10 03:40:17 - INFO - Epoch: 21.52, Step: 85230, Train Loss: 1.2187, Learning Rate: 4.86e-05
2025-12-10 03:40:28 - INFO - Epoch: 21.52, Step: 85240, Train Loss: 1.2659, Learning Rate: 4.86e-05
2025-12-10 03:40:39 - INFO - Epoch: 21.52, Step: 85250, Train Loss: 1.2833, Learning Rate: 4.86e-05
2025-12-10 03:40:50 - INFO - Epoch: 21.52, Step: 85260, Train Loss: 1.2215, Learning Rate: 4.86e-05
2025-12-10 03:41:02 - INFO - Epoch: 21.53, Step: 85270, Train Loss: 1.2628, Learning Rate: 4.86e-05
2025-12-10 03:41:13 - INFO - Epoch: 21.53, Step: 85280, Train Loss: 1.2449, Learning Rate: 4.86e-05
2025-12-10 03:41:24 - INFO - Epoch: 21.53, Step: 85290, Train Loss: 1.2724, Learning Rate: 4.86e-05
2025-12-10 03:41:35 - INFO - Epoch: 21.53, Step: 85300, Train Loss: 1.2601, Learning Rate: 4.86e-05
2025-12-10 03:41:46 - INFO - Epoch: 21.54, Step: 85310, Train Loss: 1.2308, Learning Rate: 4.86e-05
2025-12-10 03:41:57 - INFO - Epoch: 21.54, Step: 85320, Train Loss: 1.2540, Learning Rate: 4.86e-05
2025-12-10 03:42:09 - INFO - Epoch: 21.54, Step: 85330, Train Loss: 1.2562, Learning Rate: 4.86e-05
2025-12-10 03:42:20 - INFO - Epoch: 21.55, Step: 85340, Train Loss: 1.2637, Learning Rate: 4.86e-05
2025-12-10 03:42:31 - INFO - Epoch: 21.55, Step: 85350, Train Loss: 1.2559, Learning Rate: 4.86e-05
2025-12-10 03:42:42 - INFO - Epoch: 21.55, Step: 85360, Train Loss: 1.2017, Learning Rate: 4.86e-05
2025-12-10 03:42:53 - INFO - Epoch: 21.55, Step: 85370, Train Loss: 1.2893, Learning Rate: 4.85e-05
2025-12-10 03:43:04 - INFO - Epoch: 21.56, Step: 85380, Train Loss: 1.2600, Learning Rate: 4.85e-05
2025-12-10 03:43:15 - INFO - Epoch: 21.56, Step: 85390, Train Loss: 1.3017, Learning Rate: 4.85e-05
2025-12-10 03:43:27 - INFO - Epoch: 21.56, Step: 85400, Train Loss: 1.1937, Learning Rate: 4.85e-05
2025-12-10 03:43:38 - INFO - Epoch: 21.56, Step: 85410, Train Loss: 1.2510, Learning Rate: 4.85e-05
2025-12-10 03:43:49 - INFO - Epoch: 21.57, Step: 85420, Train Loss: 1.2389, Learning Rate: 4.85e-05
2025-12-10 03:44:00 - INFO - Epoch: 21.57, Step: 85430, Train Loss: 1.2707, Learning Rate: 4.85e-05
2025-12-10 03:44:11 - INFO - Epoch: 21.57, Step: 85440, Train Loss: 1.2340, Learning Rate: 4.85e-05
2025-12-10 03:44:22 - INFO - Epoch: 21.57, Step: 85450, Train Loss: 1.2584, Learning Rate: 4.85e-05
2025-12-10 03:44:34 - INFO - Epoch: 21.58, Step: 85460, Train Loss: 1.2447, Learning Rate: 4.85e-05
2025-12-10 03:44:45 - INFO - Epoch: 21.58, Step: 85470, Train Loss: 1.2563, Learning Rate: 4.85e-05
2025-12-10 03:44:56 - INFO - Epoch: 21.58, Step: 85480, Train Loss: 1.2839, Learning Rate: 4.85e-05
2025-12-10 03:45:07 - INFO - Epoch: 21.58, Step: 85490, Train Loss: 1.2151, Learning Rate: 4.85e-05
2025-12-10 03:45:18 - INFO - Epoch: 21.59, Step: 85500, Train Loss: 1.2554, Learning Rate: 4.85e-05
2025-12-10 03:45:29 - INFO - Epoch: 21.59, Step: 85510, Train Loss: 1.2302, Learning Rate: 4.85e-05
2025-12-10 03:45:40 - INFO - Epoch: 21.59, Step: 85520, Train Loss: 1.2719, Learning Rate: 4.84e-05
2025-12-10 03:45:52 - INFO - Epoch: 21.59, Step: 85530, Train Loss: 1.2610, Learning Rate: 4.84e-05
2025-12-10 03:46:03 - INFO - Epoch: 21.60, Step: 85540, Train Loss: 1.2655, Learning Rate: 4.84e-05
2025-12-10 03:46:14 - INFO - Epoch: 21.60, Step: 85550, Train Loss: 1.2816, Learning Rate: 4.84e-05
2025-12-10 03:46:25 - INFO - Epoch: 21.60, Step: 85560, Train Loss: 1.2543, Learning Rate: 4.84e-05
2025-12-10 03:46:36 - INFO - Epoch: 21.60, Step: 85570, Train Loss: 1.2406, Learning Rate: 4.84e-05
2025-12-10 03:46:47 - INFO - Epoch: 21.61, Step: 85580, Train Loss: 1.2309, Learning Rate: 4.84e-05
2025-12-10 03:46:59 - INFO - Epoch: 21.61, Step: 85590, Train Loss: 1.2485, Learning Rate: 4.84e-05
2025-12-10 03:47:10 - INFO - Epoch: 21.61, Step: 85600, Train Loss: 1.2550, Learning Rate: 4.84e-05
2025-12-10 03:47:21 - INFO - Epoch: 21.61, Step: 85610, Train Loss: 1.2699, Learning Rate: 4.84e-05
2025-12-10 03:47:32 - INFO - Epoch: 21.62, Step: 85620, Train Loss: 1.2739, Learning Rate: 4.84e-05
2025-12-10 03:47:43 - INFO - Epoch: 21.62, Step: 85630, Train Loss: 1.2198, Learning Rate: 4.84e-05
2025-12-10 03:47:54 - INFO - Epoch: 21.62, Step: 85640, Train Loss: 1.2488, Learning Rate: 4.84e-05
2025-12-10 03:48:05 - INFO - Epoch: 21.62, Step: 85650, Train Loss: 1.2267, Learning Rate: 4.84e-05
2025-12-10 03:48:17 - INFO - Epoch: 21.63, Step: 85660, Train Loss: 1.2681, Learning Rate: 4.84e-05
2025-12-10 03:48:28 - INFO - Epoch: 21.63, Step: 85670, Train Loss: 1.2435, Learning Rate: 4.83e-05
2025-12-10 03:48:39 - INFO - Epoch: 21.63, Step: 85680, Train Loss: 1.2635, Learning Rate: 4.83e-05
2025-12-10 03:48:50 - INFO - Epoch: 21.63, Step: 85690, Train Loss: 1.2292, Learning Rate: 4.83e-05
2025-12-10 03:49:01 - INFO - Epoch: 21.64, Step: 85700, Train Loss: 1.2849, Learning Rate: 4.83e-05
2025-12-10 03:49:12 - INFO - Epoch: 21.64, Step: 85710, Train Loss: 1.2457, Learning Rate: 4.83e-05
2025-12-10 03:49:24 - INFO - Epoch: 21.64, Step: 85720, Train Loss: 1.2567, Learning Rate: 4.83e-05
2025-12-10 03:49:35 - INFO - Epoch: 21.64, Step: 85730, Train Loss: 1.2560, Learning Rate: 4.83e-05
2025-12-10 03:49:46 - INFO - Epoch: 21.65, Step: 85740, Train Loss: 1.2200, Learning Rate: 4.83e-05
2025-12-10 03:49:57 - INFO - Epoch: 21.65, Step: 85750, Train Loss: 1.2179, Learning Rate: 4.83e-05
2025-12-10 03:50:08 - INFO - Epoch: 21.65, Step: 85760, Train Loss: 1.2535, Learning Rate: 4.83e-05
2025-12-10 03:50:19 - INFO - Epoch: 21.65, Step: 85770, Train Loss: 1.2523, Learning Rate: 4.83e-05
2025-12-10 03:50:30 - INFO - Epoch: 21.66, Step: 85780, Train Loss: 1.2384, Learning Rate: 4.83e-05
2025-12-10 03:50:42 - INFO - Epoch: 21.66, Step: 85790, Train Loss: 1.2571, Learning Rate: 4.83e-05
2025-12-10 03:50:53 - INFO - Epoch: 21.66, Step: 85800, Train Loss: 1.2143, Learning Rate: 4.83e-05
2025-12-10 03:51:04 - INFO - Epoch: 21.66, Step: 85810, Train Loss: 1.2521, Learning Rate: 4.83e-05
2025-12-10 03:51:15 - INFO - Epoch: 21.67, Step: 85820, Train Loss: 1.2090, Learning Rate: 4.82e-05
2025-12-10 03:51:26 - INFO - Epoch: 21.67, Step: 85830, Train Loss: 1.2131, Learning Rate: 4.82e-05
2025-12-10 03:51:37 - INFO - Epoch: 21.67, Step: 85840, Train Loss: 1.3027, Learning Rate: 4.82e-05
2025-12-10 03:51:49 - INFO - Epoch: 21.67, Step: 85850, Train Loss: 1.2708, Learning Rate: 4.82e-05
2025-12-10 03:52:00 - INFO - Epoch: 21.68, Step: 85860, Train Loss: 1.2666, Learning Rate: 4.82e-05
2025-12-10 03:52:11 - INFO - Epoch: 21.68, Step: 85870, Train Loss: 1.2324, Learning Rate: 4.82e-05
2025-12-10 03:52:22 - INFO - Epoch: 21.68, Step: 85880, Train Loss: 1.2660, Learning Rate: 4.82e-05
2025-12-10 03:52:33 - INFO - Epoch: 21.68, Step: 85890, Train Loss: 1.2236, Learning Rate: 4.82e-05
2025-12-10 03:52:44 - INFO - Epoch: 21.69, Step: 85900, Train Loss: 1.2034, Learning Rate: 4.82e-05
2025-12-10 03:52:55 - INFO - Epoch: 21.69, Step: 85910, Train Loss: 1.2765, Learning Rate: 4.82e-05
2025-12-10 03:53:07 - INFO - Epoch: 21.69, Step: 85920, Train Loss: 1.2355, Learning Rate: 4.82e-05
2025-12-10 03:53:18 - INFO - Epoch: 21.69, Step: 85930, Train Loss: 1.2310, Learning Rate: 4.82e-05
2025-12-10 03:53:29 - INFO - Epoch: 21.70, Step: 85940, Train Loss: 1.2298, Learning Rate: 4.82e-05
2025-12-10 03:53:40 - INFO - Epoch: 21.70, Step: 85950, Train Loss: 1.2406, Learning Rate: 4.82e-05
2025-12-10 03:53:51 - INFO - Epoch: 21.70, Step: 85960, Train Loss: 1.2424, Learning Rate: 4.82e-05
2025-12-10 03:54:02 - INFO - Epoch: 21.70, Step: 85970, Train Loss: 1.2721, Learning Rate: 4.81e-05
2025-12-10 03:54:13 - INFO - Epoch: 21.71, Step: 85980, Train Loss: 1.2171, Learning Rate: 4.81e-05
2025-12-10 03:54:25 - INFO - Epoch: 21.71, Step: 85990, Train Loss: 1.2604, Learning Rate: 4.81e-05
2025-12-10 03:54:36 - INFO - Epoch: 21.71, Step: 86000, Train Loss: 1.2196, Learning Rate: 4.81e-05
2025-12-10 03:54:47 - INFO - Epoch: 21.71, Step: 86010, Train Loss: 1.2085, Learning Rate: 4.81e-05
2025-12-10 03:54:58 - INFO - Epoch: 21.72, Step: 86020, Train Loss: 1.2740, Learning Rate: 4.81e-05
2025-12-10 03:55:09 - INFO - Epoch: 21.72, Step: 86030, Train Loss: 1.2808, Learning Rate: 4.81e-05
2025-12-10 03:55:20 - INFO - Epoch: 21.72, Step: 86040, Train Loss: 1.2517, Learning Rate: 4.81e-05
2025-12-10 03:55:32 - INFO - Epoch: 21.72, Step: 86050, Train Loss: 1.2207, Learning Rate: 4.81e-05
2025-12-10 03:55:43 - INFO - Epoch: 21.73, Step: 86060, Train Loss: 1.2302, Learning Rate: 4.81e-05
2025-12-10 03:55:54 - INFO - Epoch: 21.73, Step: 86070, Train Loss: 1.2359, Learning Rate: 4.81e-05
2025-12-10 03:56:05 - INFO - Epoch: 21.73, Step: 86080, Train Loss: 1.2664, Learning Rate: 4.81e-05
2025-12-10 03:56:16 - INFO - Epoch: 21.73, Step: 86090, Train Loss: 1.2326, Learning Rate: 4.81e-05
2025-12-10 03:56:27 - INFO - Epoch: 21.74, Step: 86100, Train Loss: 1.2846, Learning Rate: 4.81e-05
2025-12-10 03:56:38 - INFO - Epoch: 21.74, Step: 86110, Train Loss: 1.2508, Learning Rate: 4.81e-05
2025-12-10 03:56:50 - INFO - Epoch: 21.74, Step: 86120, Train Loss: 1.2163, Learning Rate: 4.80e-05
2025-12-10 03:57:01 - INFO - Epoch: 21.74, Step: 86130, Train Loss: 1.2472, Learning Rate: 4.80e-05
2025-12-10 03:57:12 - INFO - Epoch: 21.75, Step: 86140, Train Loss: 1.2481, Learning Rate: 4.80e-05
2025-12-10 03:57:23 - INFO - Epoch: 21.75, Step: 86150, Train Loss: 1.2727, Learning Rate: 4.80e-05
2025-12-10 03:57:34 - INFO - Epoch: 21.75, Step: 86160, Train Loss: 1.2345, Learning Rate: 4.80e-05
2025-12-10 03:57:45 - INFO - Epoch: 21.75, Step: 86170, Train Loss: 1.2067, Learning Rate: 4.80e-05
2025-12-10 03:57:57 - INFO - Epoch: 21.76, Step: 86180, Train Loss: 1.2294, Learning Rate: 4.80e-05
2025-12-10 03:58:08 - INFO - Epoch: 21.76, Step: 86190, Train Loss: 1.2356, Learning Rate: 4.80e-05
2025-12-10 03:58:19 - INFO - Epoch: 21.76, Step: 86200, Train Loss: 1.2355, Learning Rate: 4.80e-05
2025-12-10 03:58:30 - INFO - Epoch: 21.76, Step: 86210, Train Loss: 1.2430, Learning Rate: 4.80e-05
2025-12-10 03:58:41 - INFO - Epoch: 21.77, Step: 86220, Train Loss: 1.2523, Learning Rate: 4.80e-05
2025-12-10 03:58:52 - INFO - Epoch: 21.77, Step: 86230, Train Loss: 1.2746, Learning Rate: 4.80e-05
2025-12-10 03:59:03 - INFO - Epoch: 21.77, Step: 86240, Train Loss: 1.2036, Learning Rate: 4.80e-05
2025-12-10 03:59:15 - INFO - Epoch: 21.77, Step: 86250, Train Loss: 1.2502, Learning Rate: 4.80e-05
2025-12-10 03:59:26 - INFO - Epoch: 21.78, Step: 86260, Train Loss: 1.2103, Learning Rate: 4.80e-05
2025-12-10 03:59:37 - INFO - Epoch: 21.78, Step: 86270, Train Loss: 1.2473, Learning Rate: 4.79e-05
2025-12-10 03:59:48 - INFO - Epoch: 21.78, Step: 86280, Train Loss: 1.2471, Learning Rate: 4.79e-05
2025-12-10 03:59:59 - INFO - Epoch: 21.78, Step: 86290, Train Loss: 1.2737, Learning Rate: 4.79e-05
2025-12-10 04:00:10 - INFO - Epoch: 21.79, Step: 86300, Train Loss: 1.2316, Learning Rate: 4.79e-05
2025-12-10 04:00:22 - INFO - Epoch: 21.79, Step: 86310, Train Loss: 1.2421, Learning Rate: 4.79e-05
2025-12-10 04:00:33 - INFO - Epoch: 21.79, Step: 86320, Train Loss: 1.2846, Learning Rate: 4.79e-05
2025-12-10 04:00:44 - INFO - Epoch: 21.80, Step: 86330, Train Loss: 1.2411, Learning Rate: 4.79e-05
2025-12-10 04:00:55 - INFO - Epoch: 21.80, Step: 86340, Train Loss: 1.3239, Learning Rate: 4.79e-05
2025-12-10 04:01:06 - INFO - Epoch: 21.80, Step: 86350, Train Loss: 1.2058, Learning Rate: 4.79e-05
2025-12-10 04:01:17 - INFO - Epoch: 21.80, Step: 86360, Train Loss: 1.2551, Learning Rate: 4.79e-05
2025-12-10 04:01:28 - INFO - Epoch: 21.81, Step: 86370, Train Loss: 1.2860, Learning Rate: 4.79e-05
2025-12-10 04:01:40 - INFO - Epoch: 21.81, Step: 86380, Train Loss: 1.2139, Learning Rate: 4.79e-05
2025-12-10 04:01:51 - INFO - Epoch: 21.81, Step: 86390, Train Loss: 1.2271, Learning Rate: 4.79e-05
2025-12-10 04:02:02 - INFO - Epoch: 21.81, Step: 86400, Train Loss: 1.2245, Learning Rate: 4.79e-05
2025-12-10 04:02:13 - INFO - Epoch: 21.82, Step: 86410, Train Loss: 1.2674, Learning Rate: 4.79e-05
2025-12-10 04:02:24 - INFO - Epoch: 21.82, Step: 86420, Train Loss: 1.2624, Learning Rate: 4.78e-05
2025-12-10 04:02:35 - INFO - Epoch: 21.82, Step: 86430, Train Loss: 1.2227, Learning Rate: 4.78e-05
2025-12-10 04:02:47 - INFO - Epoch: 21.82, Step: 86440, Train Loss: 1.2168, Learning Rate: 4.78e-05
2025-12-10 04:02:58 - INFO - Epoch: 21.83, Step: 86450, Train Loss: 1.2770, Learning Rate: 4.78e-05
2025-12-10 04:03:09 - INFO - Epoch: 21.83, Step: 86460, Train Loss: 1.2029, Learning Rate: 4.78e-05
2025-12-10 04:03:20 - INFO - Epoch: 21.83, Step: 86470, Train Loss: 1.2294, Learning Rate: 4.78e-05
2025-12-10 04:03:31 - INFO - Epoch: 21.83, Step: 86480, Train Loss: 1.2136, Learning Rate: 4.78e-05
2025-12-10 04:03:42 - INFO - Epoch: 21.84, Step: 86490, Train Loss: 1.2124, Learning Rate: 4.78e-05
2025-12-10 04:03:53 - INFO - Epoch: 21.84, Step: 86500, Train Loss: 1.2240, Learning Rate: 4.78e-05
2025-12-10 04:04:05 - INFO - Epoch: 21.84, Step: 86510, Train Loss: 1.2574, Learning Rate: 4.78e-05
2025-12-10 04:04:16 - INFO - Epoch: 21.84, Step: 86520, Train Loss: 1.2437, Learning Rate: 4.78e-05
2025-12-10 04:04:27 - INFO - Epoch: 21.85, Step: 86530, Train Loss: 1.2748, Learning Rate: 4.78e-05
2025-12-10 04:04:38 - INFO - Epoch: 21.85, Step: 86540, Train Loss: 1.2636, Learning Rate: 4.78e-05
2025-12-10 04:04:49 - INFO - Epoch: 21.85, Step: 86550, Train Loss: 1.2276, Learning Rate: 4.78e-05
2025-12-10 04:05:00 - INFO - Epoch: 21.85, Step: 86560, Train Loss: 1.2017, Learning Rate: 4.78e-05
2025-12-10 04:05:12 - INFO - Epoch: 21.86, Step: 86570, Train Loss: 1.2352, Learning Rate: 4.77e-05
2025-12-10 04:05:23 - INFO - Epoch: 21.86, Step: 86580, Train Loss: 1.2491, Learning Rate: 4.77e-05
2025-12-10 04:05:34 - INFO - Epoch: 21.86, Step: 86590, Train Loss: 1.2394, Learning Rate: 4.77e-05
2025-12-10 04:05:45 - INFO - Epoch: 21.86, Step: 86600, Train Loss: 1.2166, Learning Rate: 4.77e-05
2025-12-10 04:05:56 - INFO - Epoch: 21.87, Step: 86610, Train Loss: 1.2589, Learning Rate: 4.77e-05
2025-12-10 04:06:07 - INFO - Epoch: 21.87, Step: 86620, Train Loss: 1.2520, Learning Rate: 4.77e-05
2025-12-10 04:06:18 - INFO - Epoch: 21.87, Step: 86630, Train Loss: 1.2491, Learning Rate: 4.77e-05
2025-12-10 04:06:30 - INFO - Epoch: 21.87, Step: 86640, Train Loss: 1.2392, Learning Rate: 4.77e-05
2025-12-10 04:06:41 - INFO - Epoch: 21.88, Step: 86650, Train Loss: 1.2559, Learning Rate: 4.77e-05
2025-12-10 04:06:52 - INFO - Epoch: 21.88, Step: 86660, Train Loss: 1.2313, Learning Rate: 4.77e-05
2025-12-10 04:07:03 - INFO - Epoch: 21.88, Step: 86670, Train Loss: 1.2305, Learning Rate: 4.77e-05
2025-12-10 04:07:14 - INFO - Epoch: 21.88, Step: 86680, Train Loss: 1.2627, Learning Rate: 4.77e-05
2025-12-10 04:07:25 - INFO - Epoch: 21.89, Step: 86690, Train Loss: 1.2624, Learning Rate: 4.77e-05
2025-12-10 04:07:37 - INFO - Epoch: 21.89, Step: 86700, Train Loss: 1.2789, Learning Rate: 4.77e-05
2025-12-10 04:07:48 - INFO - Epoch: 21.89, Step: 86710, Train Loss: 1.1961, Learning Rate: 4.77e-05
2025-12-10 04:07:59 - INFO - Epoch: 21.89, Step: 86720, Train Loss: 1.2354, Learning Rate: 4.76e-05
2025-12-10 04:08:10 - INFO - Epoch: 21.90, Step: 86730, Train Loss: 1.2540, Learning Rate: 4.76e-05
2025-12-10 04:08:21 - INFO - Epoch: 21.90, Step: 86740, Train Loss: 1.2499, Learning Rate: 4.76e-05
2025-12-10 04:08:32 - INFO - Epoch: 21.90, Step: 86750, Train Loss: 1.2173, Learning Rate: 4.76e-05
2025-12-10 04:08:43 - INFO - Epoch: 21.90, Step: 86760, Train Loss: 1.2554, Learning Rate: 4.76e-05
2025-12-10 04:08:55 - INFO - Epoch: 21.91, Step: 86770, Train Loss: 1.2480, Learning Rate: 4.76e-05
2025-12-10 04:09:06 - INFO - Epoch: 21.91, Step: 86780, Train Loss: 1.2190, Learning Rate: 4.76e-05
2025-12-10 04:09:17 - INFO - Epoch: 21.91, Step: 86790, Train Loss: 1.2390, Learning Rate: 4.76e-05
2025-12-10 04:09:28 - INFO - Epoch: 21.91, Step: 86800, Train Loss: 1.2624, Learning Rate: 4.76e-05
2025-12-10 04:09:39 - INFO - Epoch: 21.92, Step: 86810, Train Loss: 1.2598, Learning Rate: 4.76e-05
2025-12-10 04:09:50 - INFO - Epoch: 21.92, Step: 86820, Train Loss: 1.2578, Learning Rate: 4.76e-05
2025-12-10 04:10:02 - INFO - Epoch: 21.92, Step: 86830, Train Loss: 1.2516, Learning Rate: 4.76e-05
2025-12-10 04:10:13 - INFO - Epoch: 21.92, Step: 86840, Train Loss: 1.2578, Learning Rate: 4.76e-05
2025-12-10 04:10:24 - INFO - Epoch: 21.93, Step: 86850, Train Loss: 1.2594, Learning Rate: 4.76e-05
2025-12-10 04:10:35 - INFO - Epoch: 21.93, Step: 86860, Train Loss: 1.2101, Learning Rate: 4.76e-05
2025-12-10 04:10:46 - INFO - Epoch: 21.93, Step: 86870, Train Loss: 1.2205, Learning Rate: 4.75e-05
2025-12-10 04:10:57 - INFO - Epoch: 21.93, Step: 86880, Train Loss: 1.2065, Learning Rate: 4.75e-05
2025-12-10 04:11:08 - INFO - Epoch: 21.94, Step: 86890, Train Loss: 1.2618, Learning Rate: 4.75e-05
2025-12-10 04:11:20 - INFO - Epoch: 21.94, Step: 86900, Train Loss: 1.2537, Learning Rate: 4.75e-05
2025-12-10 04:11:31 - INFO - Epoch: 21.94, Step: 86910, Train Loss: 1.2489, Learning Rate: 4.75e-05
2025-12-10 04:11:42 - INFO - Epoch: 21.94, Step: 86920, Train Loss: 1.2332, Learning Rate: 4.75e-05
2025-12-10 04:11:53 - INFO - Epoch: 21.95, Step: 86930, Train Loss: 1.2312, Learning Rate: 4.75e-05
2025-12-10 04:12:04 - INFO - Epoch: 21.95, Step: 86940, Train Loss: 1.2358, Learning Rate: 4.75e-05
2025-12-10 04:12:15 - INFO - Epoch: 21.95, Step: 86950, Train Loss: 1.2510, Learning Rate: 4.75e-05
2025-12-10 04:12:27 - INFO - Epoch: 21.95, Step: 86960, Train Loss: 1.2361, Learning Rate: 4.75e-05
2025-12-10 04:12:38 - INFO - Epoch: 21.96, Step: 86970, Train Loss: 1.2156, Learning Rate: 4.75e-05
2025-12-10 04:12:49 - INFO - Epoch: 21.96, Step: 86980, Train Loss: 1.2176, Learning Rate: 4.75e-05
2025-12-10 04:13:00 - INFO - Epoch: 21.96, Step: 86990, Train Loss: 1.2169, Learning Rate: 4.75e-05
2025-12-10 04:13:11 - INFO - Epoch: 21.96, Step: 87000, Train Loss: 1.2049, Learning Rate: 4.75e-05
2025-12-10 04:13:22 - INFO - Epoch: 21.97, Step: 87010, Train Loss: 1.2471, Learning Rate: 4.75e-05
2025-12-10 04:13:33 - INFO - Epoch: 21.97, Step: 87020, Train Loss: 1.2375, Learning Rate: 4.75e-05
2025-12-10 04:13:45 - INFO - Epoch: 21.97, Step: 87030, Train Loss: 1.2535, Learning Rate: 4.74e-05
2025-12-10 04:13:56 - INFO - Epoch: 21.97, Step: 87040, Train Loss: 1.2360, Learning Rate: 4.74e-05
2025-12-10 04:14:07 - INFO - Epoch: 21.98, Step: 87050, Train Loss: 1.2375, Learning Rate: 4.74e-05
2025-12-10 04:14:18 - INFO - Epoch: 21.98, Step: 87060, Train Loss: 1.2558, Learning Rate: 4.74e-05
2025-12-10 04:14:29 - INFO - Epoch: 21.98, Step: 87070, Train Loss: 1.2349, Learning Rate: 4.74e-05
2025-12-10 04:14:40 - INFO - Epoch: 21.98, Step: 87080, Train Loss: 1.2342, Learning Rate: 4.74e-05
2025-12-10 04:14:51 - INFO - Epoch: 21.99, Step: 87090, Train Loss: 1.2370, Learning Rate: 4.74e-05
2025-12-10 04:15:03 - INFO - Epoch: 21.99, Step: 87100, Train Loss: 1.2703, Learning Rate: 4.74e-05
2025-12-10 04:15:14 - INFO - Epoch: 21.99, Step: 87110, Train Loss: 1.2318, Learning Rate: 4.74e-05
2025-12-10 04:15:25 - INFO - Epoch: 21.99, Step: 87120, Train Loss: 1.2380, Learning Rate: 4.74e-05
2025-12-10 04:15:36 - INFO - Epoch: 22.00, Step: 87130, Train Loss: 1.2392, Learning Rate: 4.74e-05
2025-12-10 04:15:47 - INFO - Epoch: 22.00, Step: 87140, Train Loss: 1.2149, Learning Rate: 4.74e-05
2025-12-10 04:15:58 - INFO - Epoch: 22.00, Step: 87150, Train Loss: 1.2441, Learning Rate: 4.74e-05
2025-12-10 04:16:10 - INFO - Epoch: 22.00, Step: 87160, Train Loss: 1.2229, Learning Rate: 4.74e-05
2025-12-10 04:16:21 - INFO - Epoch: 22.01, Step: 87170, Train Loss: 1.2206, Learning Rate: 4.74e-05
2025-12-10 04:16:32 - INFO - Epoch: 22.01, Step: 87180, Train Loss: 1.2622, Learning Rate: 4.73e-05
2025-12-10 04:16:43 - INFO - Epoch: 22.01, Step: 87190, Train Loss: 1.2221, Learning Rate: 4.73e-05
2025-12-10 04:16:54 - INFO - Epoch: 22.01, Step: 87200, Train Loss: 1.2073, Learning Rate: 4.73e-05
2025-12-10 04:17:05 - INFO - Epoch: 22.02, Step: 87210, Train Loss: 1.2348, Learning Rate: 4.73e-05
2025-12-10 04:17:16 - INFO - Epoch: 22.02, Step: 87220, Train Loss: 1.2572, Learning Rate: 4.73e-05
2025-12-10 04:17:28 - INFO - Epoch: 22.02, Step: 87230, Train Loss: 1.2882, Learning Rate: 4.73e-05
2025-12-10 04:17:39 - INFO - Epoch: 22.02, Step: 87240, Train Loss: 1.2619, Learning Rate: 4.73e-05
2025-12-10 04:17:50 - INFO - Epoch: 22.03, Step: 87250, Train Loss: 1.2366, Learning Rate: 4.73e-05
2025-12-10 04:18:01 - INFO - Epoch: 22.03, Step: 87260, Train Loss: 1.2218, Learning Rate: 4.73e-05
2025-12-10 04:18:12 - INFO - Epoch: 22.03, Step: 87270, Train Loss: 1.2292, Learning Rate: 4.73e-05
2025-12-10 04:18:23 - INFO - Epoch: 22.03, Step: 87280, Train Loss: 1.2624, Learning Rate: 4.73e-05
2025-12-10 04:18:35 - INFO - Epoch: 22.04, Step: 87290, Train Loss: 1.2907, Learning Rate: 4.73e-05
2025-12-10 04:18:46 - INFO - Epoch: 22.04, Step: 87300, Train Loss: 1.2356, Learning Rate: 4.73e-05
2025-12-10 04:18:57 - INFO - Epoch: 22.04, Step: 87310, Train Loss: 1.2517, Learning Rate: 4.73e-05
2025-12-10 04:19:08 - INFO - Epoch: 22.04, Step: 87320, Train Loss: 1.2267, Learning Rate: 4.73e-05
2025-12-10 04:19:19 - INFO - Epoch: 22.05, Step: 87330, Train Loss: 1.2695, Learning Rate: 4.72e-05
2025-12-10 04:19:30 - INFO - Epoch: 22.05, Step: 87340, Train Loss: 1.2230, Learning Rate: 4.72e-05
2025-12-10 04:19:41 - INFO - Epoch: 22.05, Step: 87350, Train Loss: 1.1858, Learning Rate: 4.72e-05
2025-12-10 04:19:53 - INFO - Epoch: 22.06, Step: 87360, Train Loss: 1.2226, Learning Rate: 4.72e-05
2025-12-10 04:20:04 - INFO - Epoch: 22.06, Step: 87370, Train Loss: 1.2462, Learning Rate: 4.72e-05
2025-12-10 04:20:15 - INFO - Epoch: 22.06, Step: 87380, Train Loss: 1.2794, Learning Rate: 4.72e-05
2025-12-10 04:20:26 - INFO - Epoch: 22.06, Step: 87390, Train Loss: 1.2296, Learning Rate: 4.72e-05
2025-12-10 04:20:37 - INFO - Epoch: 22.07, Step: 87400, Train Loss: 1.2920, Learning Rate: 4.72e-05
2025-12-10 04:20:48 - INFO - Epoch: 22.07, Step: 87410, Train Loss: 1.1931, Learning Rate: 4.72e-05
2025-12-10 04:21:00 - INFO - Epoch: 22.07, Step: 87420, Train Loss: 1.1915, Learning Rate: 4.72e-05
2025-12-10 04:21:11 - INFO - Epoch: 22.07, Step: 87430, Train Loss: 1.2838, Learning Rate: 4.72e-05
2025-12-10 04:21:22 - INFO - Epoch: 22.08, Step: 87440, Train Loss: 1.2349, Learning Rate: 4.72e-05
2025-12-10 04:21:33 - INFO - Epoch: 22.08, Step: 87450, Train Loss: 1.2296, Learning Rate: 4.72e-05
2025-12-10 04:21:44 - INFO - Epoch: 22.08, Step: 87460, Train Loss: 1.2304, Learning Rate: 4.72e-05
2025-12-10 04:21:55 - INFO - Epoch: 22.08, Step: 87470, Train Loss: 1.2136, Learning Rate: 4.72e-05
2025-12-10 04:22:06 - INFO - Epoch: 22.09, Step: 87480, Train Loss: 1.1876, Learning Rate: 4.71e-05
2025-12-10 04:22:18 - INFO - Epoch: 22.09, Step: 87490, Train Loss: 1.2345, Learning Rate: 4.71e-05
2025-12-10 04:22:29 - INFO - Epoch: 22.09, Step: 87500, Train Loss: 1.2578, Learning Rate: 4.71e-05
2025-12-10 04:22:40 - INFO - Epoch: 22.09, Step: 87510, Train Loss: 1.2543, Learning Rate: 4.71e-05
2025-12-10 04:22:51 - INFO - Epoch: 22.10, Step: 87520, Train Loss: 1.2388, Learning Rate: 4.71e-05
2025-12-10 04:23:02 - INFO - Epoch: 22.10, Step: 87530, Train Loss: 1.2345, Learning Rate: 4.71e-05
2025-12-10 04:23:13 - INFO - Epoch: 22.10, Step: 87540, Train Loss: 1.1916, Learning Rate: 4.71e-05
2025-12-10 04:23:24 - INFO - Epoch: 22.10, Step: 87550, Train Loss: 1.2017, Learning Rate: 4.71e-05
2025-12-10 04:23:36 - INFO - Epoch: 22.11, Step: 87560, Train Loss: 1.2708, Learning Rate: 4.71e-05
2025-12-10 04:23:47 - INFO - Epoch: 22.11, Step: 87570, Train Loss: 1.2106, Learning Rate: 4.71e-05
2025-12-10 04:23:58 - INFO - Epoch: 22.11, Step: 87580, Train Loss: 1.2736, Learning Rate: 4.71e-05
2025-12-10 04:24:09 - INFO - Epoch: 22.11, Step: 87590, Train Loss: 1.2570, Learning Rate: 4.71e-05
2025-12-10 04:24:20 - INFO - Epoch: 22.12, Step: 87600, Train Loss: 1.2261, Learning Rate: 4.71e-05
2025-12-10 04:24:31 - INFO - Epoch: 22.12, Step: 87610, Train Loss: 1.2616, Learning Rate: 4.71e-05
2025-12-10 04:24:43 - INFO - Epoch: 22.12, Step: 87620, Train Loss: 1.2739, Learning Rate: 4.71e-05
2025-12-10 04:24:54 - INFO - Epoch: 22.12, Step: 87630, Train Loss: 1.2492, Learning Rate: 4.70e-05
2025-12-10 04:25:05 - INFO - Epoch: 22.13, Step: 87640, Train Loss: 1.2467, Learning Rate: 4.70e-05
2025-12-10 04:25:16 - INFO - Epoch: 22.13, Step: 87650, Train Loss: 1.2235, Learning Rate: 4.70e-05
2025-12-10 04:25:27 - INFO - Epoch: 22.13, Step: 87660, Train Loss: 1.2272, Learning Rate: 4.70e-05
2025-12-10 04:25:38 - INFO - Epoch: 22.13, Step: 87670, Train Loss: 1.2569, Learning Rate: 4.70e-05
2025-12-10 04:25:49 - INFO - Epoch: 22.14, Step: 87680, Train Loss: 1.2793, Learning Rate: 4.70e-05
2025-12-10 04:26:01 - INFO - Epoch: 22.14, Step: 87690, Train Loss: 1.2433, Learning Rate: 4.70e-05
2025-12-10 04:26:12 - INFO - Epoch: 22.14, Step: 87700, Train Loss: 1.2148, Learning Rate: 4.70e-05
2025-12-10 04:26:23 - INFO - Epoch: 22.14, Step: 87710, Train Loss: 1.2531, Learning Rate: 4.70e-05
2025-12-10 04:26:34 - INFO - Epoch: 22.15, Step: 87720, Train Loss: 1.2432, Learning Rate: 4.70e-05
2025-12-10 04:26:45 - INFO - Epoch: 22.15, Step: 87730, Train Loss: 1.2087, Learning Rate: 4.70e-05
2025-12-10 04:26:56 - INFO - Epoch: 22.15, Step: 87740, Train Loss: 1.2279, Learning Rate: 4.70e-05
2025-12-10 04:27:08 - INFO - Epoch: 22.15, Step: 87750, Train Loss: 1.1808, Learning Rate: 4.70e-05
2025-12-10 04:27:19 - INFO - Epoch: 22.16, Step: 87760, Train Loss: 1.2679, Learning Rate: 4.70e-05
2025-12-10 04:27:30 - INFO - Epoch: 22.16, Step: 87770, Train Loss: 1.2555, Learning Rate: 4.70e-05
2025-12-10 04:27:41 - INFO - Epoch: 22.16, Step: 87780, Train Loss: 1.2318, Learning Rate: 4.69e-05
2025-12-10 04:27:52 - INFO - Epoch: 22.16, Step: 87790, Train Loss: 1.2484, Learning Rate: 4.69e-05
2025-12-10 04:28:03 - INFO - Epoch: 22.17, Step: 87800, Train Loss: 1.2418, Learning Rate: 4.69e-05
2025-12-10 04:28:14 - INFO - Epoch: 22.17, Step: 87810, Train Loss: 1.2429, Learning Rate: 4.69e-05
2025-12-10 04:28:26 - INFO - Epoch: 22.17, Step: 87820, Train Loss: 1.2493, Learning Rate: 4.69e-05
2025-12-10 04:28:37 - INFO - Epoch: 22.17, Step: 87830, Train Loss: 1.2470, Learning Rate: 4.69e-05
2025-12-10 04:28:48 - INFO - Epoch: 22.18, Step: 87840, Train Loss: 1.2451, Learning Rate: 4.69e-05
2025-12-10 04:28:59 - INFO - Epoch: 22.18, Step: 87850, Train Loss: 1.2581, Learning Rate: 4.69e-05
2025-12-10 04:29:10 - INFO - Epoch: 22.18, Step: 87860, Train Loss: 1.2521, Learning Rate: 4.69e-05
2025-12-10 04:29:21 - INFO - Epoch: 22.18, Step: 87870, Train Loss: 1.2398, Learning Rate: 4.69e-05
2025-12-10 04:29:33 - INFO - Epoch: 22.19, Step: 87880, Train Loss: 1.2677, Learning Rate: 4.69e-05
2025-12-10 04:29:44 - INFO - Epoch: 22.19, Step: 87890, Train Loss: 1.2418, Learning Rate: 4.69e-05
2025-12-10 04:29:55 - INFO - Epoch: 22.19, Step: 87900, Train Loss: 1.2127, Learning Rate: 4.69e-05
2025-12-10 04:30:06 - INFO - Epoch: 22.19, Step: 87910, Train Loss: 1.2749, Learning Rate: 4.69e-05
2025-12-10 04:30:17 - INFO - Epoch: 22.20, Step: 87920, Train Loss: 1.2175, Learning Rate: 4.69e-05
2025-12-10 04:30:28 - INFO - Epoch: 22.20, Step: 87930, Train Loss: 1.2358, Learning Rate: 4.68e-05
2025-12-10 04:30:39 - INFO - Epoch: 22.20, Step: 87940, Train Loss: 1.2229, Learning Rate: 4.68e-05
2025-12-10 04:30:51 - INFO - Epoch: 22.20, Step: 87950, Train Loss: 1.2085, Learning Rate: 4.68e-05
2025-12-10 04:31:02 - INFO - Epoch: 22.21, Step: 87960, Train Loss: 1.2284, Learning Rate: 4.68e-05
2025-12-10 04:31:13 - INFO - Epoch: 22.21, Step: 87970, Train Loss: 1.2069, Learning Rate: 4.68e-05
2025-12-10 04:31:24 - INFO - Epoch: 22.21, Step: 87980, Train Loss: 1.2504, Learning Rate: 4.68e-05
2025-12-10 04:31:35 - INFO - Epoch: 22.21, Step: 87990, Train Loss: 1.2034, Learning Rate: 4.68e-05
2025-12-10 04:31:46 - INFO - Epoch: 22.22, Step: 88000, Train Loss: 1.2214, Learning Rate: 4.68e-05
2025-12-10 04:31:57 - INFO - Epoch: 22.22, Step: 88010, Train Loss: 1.2631, Learning Rate: 4.68e-05
2025-12-10 04:32:09 - INFO - Epoch: 22.22, Step: 88020, Train Loss: 1.1643, Learning Rate: 4.68e-05
2025-12-10 04:32:20 - INFO - Epoch: 22.22, Step: 88030, Train Loss: 1.2251, Learning Rate: 4.68e-05
2025-12-10 04:32:31 - INFO - Epoch: 22.23, Step: 88040, Train Loss: 1.2584, Learning Rate: 4.68e-05
2025-12-10 04:32:42 - INFO - Epoch: 22.23, Step: 88050, Train Loss: 1.2395, Learning Rate: 4.68e-05
2025-12-10 04:32:53 - INFO - Epoch: 22.23, Step: 88060, Train Loss: 1.2527, Learning Rate: 4.68e-05
2025-12-10 04:33:04 - INFO - Epoch: 22.23, Step: 88070, Train Loss: 1.2007, Learning Rate: 4.68e-05
2025-12-10 04:33:16 - INFO - Epoch: 22.24, Step: 88080, Train Loss: 1.2306, Learning Rate: 4.67e-05
2025-12-10 04:33:27 - INFO - Epoch: 22.24, Step: 88090, Train Loss: 1.2732, Learning Rate: 4.67e-05
2025-12-10 04:33:38 - INFO - Epoch: 22.24, Step: 88100, Train Loss: 1.2040, Learning Rate: 4.67e-05
2025-12-10 04:33:49 - INFO - Epoch: 22.24, Step: 88110, Train Loss: 1.2706, Learning Rate: 4.67e-05
2025-12-10 04:34:00 - INFO - Epoch: 22.25, Step: 88120, Train Loss: 1.2520, Learning Rate: 4.67e-05
2025-12-10 04:34:11 - INFO - Epoch: 22.25, Step: 88130, Train Loss: 1.2555, Learning Rate: 4.67e-05
2025-12-10 04:34:22 - INFO - Epoch: 22.25, Step: 88140, Train Loss: 1.2401, Learning Rate: 4.67e-05
2025-12-10 04:34:34 - INFO - Epoch: 22.25, Step: 88150, Train Loss: 1.2759, Learning Rate: 4.67e-05
2025-12-10 04:34:45 - INFO - Epoch: 22.26, Step: 88160, Train Loss: 1.2471, Learning Rate: 4.67e-05
2025-12-10 04:34:56 - INFO - Epoch: 22.26, Step: 88170, Train Loss: 1.2515, Learning Rate: 4.67e-05
2025-12-10 04:35:07 - INFO - Epoch: 22.26, Step: 88180, Train Loss: 1.2526, Learning Rate: 4.67e-05
2025-12-10 04:35:18 - INFO - Epoch: 22.26, Step: 88190, Train Loss: 1.2467, Learning Rate: 4.67e-05
2025-12-10 04:35:29 - INFO - Epoch: 22.27, Step: 88200, Train Loss: 1.2296, Learning Rate: 4.67e-05
2025-12-10 04:35:41 - INFO - Epoch: 22.27, Step: 88210, Train Loss: 1.2422, Learning Rate: 4.67e-05
2025-12-10 04:35:52 - INFO - Epoch: 22.27, Step: 88220, Train Loss: 1.2473, Learning Rate: 4.67e-05
2025-12-10 04:36:03 - INFO - Epoch: 22.27, Step: 88230, Train Loss: 1.2378, Learning Rate: 4.66e-05
2025-12-10 04:36:14 - INFO - Epoch: 22.28, Step: 88240, Train Loss: 1.2239, Learning Rate: 4.66e-05
2025-12-10 04:36:25 - INFO - Epoch: 22.28, Step: 88250, Train Loss: 1.2393, Learning Rate: 4.66e-05
2025-12-10 04:36:36 - INFO - Epoch: 22.28, Step: 88260, Train Loss: 1.2005, Learning Rate: 4.66e-05
2025-12-10 04:36:47 - INFO - Epoch: 22.28, Step: 88270, Train Loss: 1.2382, Learning Rate: 4.66e-05
2025-12-10 04:36:59 - INFO - Epoch: 22.29, Step: 88280, Train Loss: 1.2325, Learning Rate: 4.66e-05
2025-12-10 04:37:10 - INFO - Epoch: 22.29, Step: 88290, Train Loss: 1.2266, Learning Rate: 4.66e-05
2025-12-10 04:37:21 - INFO - Epoch: 22.29, Step: 88300, Train Loss: 1.2191, Learning Rate: 4.66e-05
2025-12-10 04:37:32 - INFO - Epoch: 22.29, Step: 88310, Train Loss: 1.2139, Learning Rate: 4.66e-05
2025-12-10 04:37:43 - INFO - Epoch: 22.30, Step: 88320, Train Loss: 1.2217, Learning Rate: 4.66e-05
2025-12-10 04:37:54 - INFO - Epoch: 22.30, Step: 88330, Train Loss: 1.2464, Learning Rate: 4.66e-05
2025-12-10 04:38:05 - INFO - Epoch: 22.30, Step: 88340, Train Loss: 1.2443, Learning Rate: 4.66e-05
2025-12-10 04:38:17 - INFO - Epoch: 22.30, Step: 88350, Train Loss: 1.2220, Learning Rate: 4.66e-05
2025-12-10 04:38:28 - INFO - Epoch: 22.31, Step: 88360, Train Loss: 1.2129, Learning Rate: 4.66e-05
2025-12-10 04:38:39 - INFO - Epoch: 22.31, Step: 88370, Train Loss: 1.2323, Learning Rate: 4.66e-05
2025-12-10 04:38:50 - INFO - Epoch: 22.31, Step: 88380, Train Loss: 1.2198, Learning Rate: 4.65e-05
2025-12-10 04:39:01 - INFO - Epoch: 22.32, Step: 88390, Train Loss: 1.2299, Learning Rate: 4.65e-05
2025-12-10 04:39:12 - INFO - Epoch: 22.32, Step: 88400, Train Loss: 1.2142, Learning Rate: 4.65e-05
2025-12-10 04:39:24 - INFO - Epoch: 22.32, Step: 88410, Train Loss: 1.2590, Learning Rate: 4.65e-05
2025-12-10 04:39:35 - INFO - Epoch: 22.32, Step: 88420, Train Loss: 1.2173, Learning Rate: 4.65e-05
2025-12-10 04:39:46 - INFO - Epoch: 22.33, Step: 88430, Train Loss: 1.2288, Learning Rate: 4.65e-05
2025-12-10 04:39:57 - INFO - Epoch: 22.33, Step: 88440, Train Loss: 1.2285, Learning Rate: 4.65e-05
2025-12-10 04:40:08 - INFO - Epoch: 22.33, Step: 88450, Train Loss: 1.1891, Learning Rate: 4.65e-05
2025-12-10 04:40:19 - INFO - Epoch: 22.33, Step: 88460, Train Loss: 1.2027, Learning Rate: 4.65e-05
2025-12-10 04:40:30 - INFO - Epoch: 22.34, Step: 88470, Train Loss: 1.2550, Learning Rate: 4.65e-05
2025-12-10 04:40:42 - INFO - Epoch: 22.34, Step: 88480, Train Loss: 1.1989, Learning Rate: 4.65e-05
2025-12-10 04:40:53 - INFO - Epoch: 22.34, Step: 88490, Train Loss: 1.2437, Learning Rate: 4.65e-05
2025-12-10 04:41:04 - INFO - Epoch: 22.34, Step: 88500, Train Loss: 1.2569, Learning Rate: 4.65e-05
2025-12-10 04:41:15 - INFO - Epoch: 22.35, Step: 88510, Train Loss: 1.2598, Learning Rate: 4.65e-05
2025-12-10 04:41:26 - INFO - Epoch: 22.35, Step: 88520, Train Loss: 1.2411, Learning Rate: 4.65e-05
2025-12-10 04:41:37 - INFO - Epoch: 22.35, Step: 88530, Train Loss: 1.2458, Learning Rate: 4.64e-05
2025-12-10 04:41:49 - INFO - Epoch: 22.35, Step: 88540, Train Loss: 1.2302, Learning Rate: 4.64e-05
2025-12-10 04:42:00 - INFO - Epoch: 22.36, Step: 88550, Train Loss: 1.2153, Learning Rate: 4.64e-05
2025-12-10 04:42:11 - INFO - Epoch: 22.36, Step: 88560, Train Loss: 1.1987, Learning Rate: 4.64e-05
2025-12-10 04:42:22 - INFO - Epoch: 22.36, Step: 88570, Train Loss: 1.1971, Learning Rate: 4.64e-05
2025-12-10 04:42:33 - INFO - Epoch: 22.36, Step: 88580, Train Loss: 1.2220, Learning Rate: 4.64e-05
2025-12-10 04:42:44 - INFO - Epoch: 22.37, Step: 88590, Train Loss: 1.2383, Learning Rate: 4.64e-05
2025-12-10 04:42:55 - INFO - Epoch: 22.37, Step: 88600, Train Loss: 1.2215, Learning Rate: 4.64e-05
2025-12-10 04:43:07 - INFO - Epoch: 22.37, Step: 88610, Train Loss: 1.2122, Learning Rate: 4.64e-05
2025-12-10 04:43:18 - INFO - Epoch: 22.37, Step: 88620, Train Loss: 1.1996, Learning Rate: 4.64e-05
2025-12-10 04:43:29 - INFO - Epoch: 22.38, Step: 88630, Train Loss: 1.2370, Learning Rate: 4.64e-05
2025-12-10 04:43:40 - INFO - Epoch: 22.38, Step: 88640, Train Loss: 1.2435, Learning Rate: 4.64e-05
2025-12-10 04:43:51 - INFO - Epoch: 22.38, Step: 88650, Train Loss: 1.2287, Learning Rate: 4.64e-05
2025-12-10 04:44:02 - INFO - Epoch: 22.38, Step: 88660, Train Loss: 1.2406, Learning Rate: 4.64e-05
2025-12-10 04:44:14 - INFO - Epoch: 22.39, Step: 88670, Train Loss: 1.2593, Learning Rate: 4.64e-05
2025-12-10 04:44:25 - INFO - Epoch: 22.39, Step: 88680, Train Loss: 1.2425, Learning Rate: 4.63e-05
2025-12-10 04:44:36 - INFO - Epoch: 22.39, Step: 88690, Train Loss: 1.2195, Learning Rate: 4.63e-05
2025-12-10 04:44:47 - INFO - Epoch: 22.39, Step: 88700, Train Loss: 1.2385, Learning Rate: 4.63e-05
2025-12-10 04:44:58 - INFO - Epoch: 22.40, Step: 88710, Train Loss: 1.2297, Learning Rate: 4.63e-05
2025-12-10 04:45:09 - INFO - Epoch: 22.40, Step: 88720, Train Loss: 1.2079, Learning Rate: 4.63e-05
2025-12-10 04:45:20 - INFO - Epoch: 22.40, Step: 88730, Train Loss: 1.2148, Learning Rate: 4.63e-05
2025-12-10 04:45:32 - INFO - Epoch: 22.40, Step: 88740, Train Loss: 1.2399, Learning Rate: 4.63e-05
2025-12-10 04:45:43 - INFO - Epoch: 22.41, Step: 88750, Train Loss: 1.2331, Learning Rate: 4.63e-05
2025-12-10 04:45:54 - INFO - Epoch: 22.41, Step: 88760, Train Loss: 1.2487, Learning Rate: 4.63e-05
2025-12-10 04:46:05 - INFO - Epoch: 22.41, Step: 88770, Train Loss: 1.2608, Learning Rate: 4.63e-05
2025-12-10 04:46:16 - INFO - Epoch: 22.41, Step: 88780, Train Loss: 1.2345, Learning Rate: 4.63e-05
2025-12-10 04:46:27 - INFO - Epoch: 22.42, Step: 88790, Train Loss: 1.2668, Learning Rate: 4.63e-05
2025-12-10 04:46:38 - INFO - Epoch: 22.42, Step: 88800, Train Loss: 1.2397, Learning Rate: 4.63e-05
2025-12-10 04:46:50 - INFO - Epoch: 22.42, Step: 88810, Train Loss: 1.2077, Learning Rate: 4.63e-05
2025-12-10 04:47:01 - INFO - Epoch: 22.42, Step: 88820, Train Loss: 1.2799, Learning Rate: 4.63e-05
2025-12-10 04:47:12 - INFO - Epoch: 22.43, Step: 88830, Train Loss: 1.2516, Learning Rate: 4.62e-05
2025-12-10 04:47:23 - INFO - Epoch: 22.43, Step: 88840, Train Loss: 1.2399, Learning Rate: 4.62e-05
2025-12-10 04:47:34 - INFO - Epoch: 22.43, Step: 88850, Train Loss: 1.2287, Learning Rate: 4.62e-05
2025-12-10 04:47:45 - INFO - Epoch: 22.43, Step: 88860, Train Loss: 1.2181, Learning Rate: 4.62e-05
2025-12-10 04:47:57 - INFO - Epoch: 22.44, Step: 88870, Train Loss: 1.2173, Learning Rate: 4.62e-05
2025-12-10 04:48:08 - INFO - Epoch: 22.44, Step: 88880, Train Loss: 1.1985, Learning Rate: 4.62e-05
2025-12-10 04:48:19 - INFO - Epoch: 22.44, Step: 88890, Train Loss: 1.2015, Learning Rate: 4.62e-05
2025-12-10 04:48:30 - INFO - Epoch: 22.44, Step: 88900, Train Loss: 1.2425, Learning Rate: 4.62e-05
2025-12-10 04:48:41 - INFO - Epoch: 22.45, Step: 88910, Train Loss: 1.2244, Learning Rate: 4.62e-05
2025-12-10 04:48:52 - INFO - Epoch: 22.45, Step: 88920, Train Loss: 1.2477, Learning Rate: 4.62e-05
2025-12-10 04:49:03 - INFO - Epoch: 22.45, Step: 88930, Train Loss: 1.2311, Learning Rate: 4.62e-05
2025-12-10 04:49:15 - INFO - Epoch: 22.45, Step: 88940, Train Loss: 1.2195, Learning Rate: 4.62e-05
2025-12-10 04:49:26 - INFO - Epoch: 22.46, Step: 88950, Train Loss: 1.2038, Learning Rate: 4.62e-05
2025-12-10 04:49:37 - INFO - Epoch: 22.46, Step: 88960, Train Loss: 1.2203, Learning Rate: 4.62e-05
2025-12-10 04:49:48 - INFO - Epoch: 22.46, Step: 88970, Train Loss: 1.2353, Learning Rate: 4.62e-05
2025-12-10 04:49:59 - INFO - Epoch: 22.46, Step: 88980, Train Loss: 1.2324, Learning Rate: 4.61e-05
2025-12-10 04:50:10 - INFO - Epoch: 22.47, Step: 88990, Train Loss: 1.2679, Learning Rate: 4.61e-05
2025-12-10 04:50:22 - INFO - Epoch: 22.47, Step: 89000, Train Loss: 1.2943, Learning Rate: 4.61e-05
2025-12-10 04:50:33 - INFO - Epoch: 22.47, Step: 89010, Train Loss: 1.2142, Learning Rate: 4.61e-05
2025-12-10 04:50:44 - INFO - Epoch: 22.47, Step: 89020, Train Loss: 1.2669, Learning Rate: 4.61e-05
2025-12-10 04:50:55 - INFO - Epoch: 22.48, Step: 89030, Train Loss: 1.2088, Learning Rate: 4.61e-05
2025-12-10 04:51:06 - INFO - Epoch: 22.48, Step: 89040, Train Loss: 1.2248, Learning Rate: 4.61e-05
2025-12-10 04:51:17 - INFO - Epoch: 22.48, Step: 89050, Train Loss: 1.2411, Learning Rate: 4.61e-05
2025-12-10 04:51:28 - INFO - Epoch: 22.48, Step: 89060, Train Loss: 1.2358, Learning Rate: 4.61e-05
2025-12-10 04:51:40 - INFO - Epoch: 22.49, Step: 89070, Train Loss: 1.1996, Learning Rate: 4.61e-05
2025-12-10 04:51:51 - INFO - Epoch: 22.49, Step: 89080, Train Loss: 1.2531, Learning Rate: 4.61e-05
2025-12-10 04:52:02 - INFO - Epoch: 22.49, Step: 89090, Train Loss: 1.2503, Learning Rate: 4.61e-05
2025-12-10 04:52:13 - INFO - Epoch: 22.49, Step: 89100, Train Loss: 1.1742, Learning Rate: 4.61e-05
2025-12-10 04:52:24 - INFO - Epoch: 22.50, Step: 89110, Train Loss: 1.2414, Learning Rate: 4.61e-05
2025-12-10 04:52:35 - INFO - Epoch: 22.50, Step: 89120, Train Loss: 1.2357, Learning Rate: 4.61e-05
2025-12-10 04:52:47 - INFO - Epoch: 22.50, Step: 89130, Train Loss: 1.1989, Learning Rate: 4.60e-05
2025-12-10 04:52:58 - INFO - Epoch: 22.50, Step: 89140, Train Loss: 1.2341, Learning Rate: 4.60e-05
2025-12-10 04:53:09 - INFO - Epoch: 22.51, Step: 89150, Train Loss: 1.2061, Learning Rate: 4.60e-05
2025-12-10 04:53:20 - INFO - Epoch: 22.51, Step: 89160, Train Loss: 1.2858, Learning Rate: 4.60e-05
2025-12-10 04:53:31 - INFO - Epoch: 22.51, Step: 89170, Train Loss: 1.2540, Learning Rate: 4.60e-05
2025-12-10 04:53:42 - INFO - Epoch: 22.51, Step: 89180, Train Loss: 1.2458, Learning Rate: 4.60e-05
2025-12-10 04:53:53 - INFO - Epoch: 22.52, Step: 89190, Train Loss: 1.2526, Learning Rate: 4.60e-05
2025-12-10 04:54:05 - INFO - Epoch: 22.52, Step: 89200, Train Loss: 1.2336, Learning Rate: 4.60e-05
2025-12-10 04:54:16 - INFO - Epoch: 22.52, Step: 89210, Train Loss: 1.2392, Learning Rate: 4.60e-05
2025-12-10 04:54:27 - INFO - Epoch: 22.52, Step: 89220, Train Loss: 1.2277, Learning Rate: 4.60e-05
2025-12-10 04:54:38 - INFO - Epoch: 22.53, Step: 89230, Train Loss: 1.2218, Learning Rate: 4.60e-05
2025-12-10 04:54:49 - INFO - Epoch: 22.53, Step: 89240, Train Loss: 1.2176, Learning Rate: 4.60e-05
2025-12-10 04:55:00 - INFO - Epoch: 22.53, Step: 89250, Train Loss: 1.2315, Learning Rate: 4.60e-05
2025-12-10 04:55:11 - INFO - Epoch: 22.53, Step: 89260, Train Loss: 1.2536, Learning Rate: 4.60e-05
2025-12-10 04:55:23 - INFO - Epoch: 22.54, Step: 89270, Train Loss: 1.2371, Learning Rate: 4.60e-05
2025-12-10 04:55:34 - INFO - Epoch: 22.54, Step: 89280, Train Loss: 1.1933, Learning Rate: 4.59e-05
2025-12-10 04:55:45 - INFO - Epoch: 22.54, Step: 89290, Train Loss: 1.2489, Learning Rate: 4.59e-05
2025-12-10 04:55:56 - INFO - Epoch: 22.54, Step: 89300, Train Loss: 1.2367, Learning Rate: 4.59e-05
2025-12-10 04:56:07 - INFO - Epoch: 22.55, Step: 89310, Train Loss: 1.2523, Learning Rate: 4.59e-05
2025-12-10 04:56:18 - INFO - Epoch: 22.55, Step: 89320, Train Loss: 1.2415, Learning Rate: 4.59e-05
2025-12-10 04:56:30 - INFO - Epoch: 22.55, Step: 89330, Train Loss: 1.2441, Learning Rate: 4.59e-05
2025-12-10 04:56:41 - INFO - Epoch: 22.55, Step: 89340, Train Loss: 1.2392, Learning Rate: 4.59e-05
2025-12-10 04:56:52 - INFO - Epoch: 22.56, Step: 89350, Train Loss: 1.2255, Learning Rate: 4.59e-05
2025-12-10 04:57:03 - INFO - Epoch: 22.56, Step: 89360, Train Loss: 1.2396, Learning Rate: 4.59e-05
2025-12-10 04:57:14 - INFO - Epoch: 22.56, Step: 89370, Train Loss: 1.2264, Learning Rate: 4.59e-05
2025-12-10 04:57:25 - INFO - Epoch: 22.57, Step: 89380, Train Loss: 1.2942, Learning Rate: 4.59e-05
2025-12-10 04:57:36 - INFO - Epoch: 22.57, Step: 89390, Train Loss: 1.2354, Learning Rate: 4.59e-05
2025-12-10 04:57:48 - INFO - Epoch: 22.57, Step: 89400, Train Loss: 1.2784, Learning Rate: 4.59e-05
2025-12-10 04:57:59 - INFO - Epoch: 22.57, Step: 89410, Train Loss: 1.2478, Learning Rate: 4.59e-05
2025-12-10 04:58:10 - INFO - Epoch: 22.58, Step: 89420, Train Loss: 1.2496, Learning Rate: 4.59e-05
2025-12-10 04:58:21 - INFO - Epoch: 22.58, Step: 89430, Train Loss: 1.1989, Learning Rate: 4.58e-05
2025-12-10 04:58:32 - INFO - Epoch: 22.58, Step: 89440, Train Loss: 1.2555, Learning Rate: 4.58e-05
2025-12-10 04:58:43 - INFO - Epoch: 22.58, Step: 89450, Train Loss: 1.2433, Learning Rate: 4.58e-05
2025-12-10 04:58:55 - INFO - Epoch: 22.59, Step: 89460, Train Loss: 1.2299, Learning Rate: 4.58e-05
2025-12-10 04:59:06 - INFO - Epoch: 22.59, Step: 89470, Train Loss: 1.2832, Learning Rate: 4.58e-05
2025-12-10 04:59:17 - INFO - Epoch: 22.59, Step: 89480, Train Loss: 1.2233, Learning Rate: 4.58e-05
2025-12-10 04:59:28 - INFO - Epoch: 22.59, Step: 89490, Train Loss: 1.2373, Learning Rate: 4.58e-05
2025-12-10 04:59:39 - INFO - Epoch: 22.60, Step: 89500, Train Loss: 1.2385, Learning Rate: 4.58e-05
2025-12-10 04:59:50 - INFO - Epoch: 22.60, Step: 89510, Train Loss: 1.2511, Learning Rate: 4.58e-05
2025-12-10 05:00:01 - INFO - Epoch: 22.60, Step: 89520, Train Loss: 1.2270, Learning Rate: 4.58e-05
2025-12-10 05:00:13 - INFO - Epoch: 22.60, Step: 89530, Train Loss: 1.2585, Learning Rate: 4.58e-05
2025-12-10 05:00:24 - INFO - Epoch: 22.61, Step: 89540, Train Loss: 1.2430, Learning Rate: 4.58e-05
2025-12-10 05:00:35 - INFO - Epoch: 22.61, Step: 89550, Train Loss: 1.2310, Learning Rate: 4.58e-05
2025-12-10 05:00:46 - INFO - Epoch: 22.61, Step: 89560, Train Loss: 1.2517, Learning Rate: 4.58e-05
2025-12-10 05:00:57 - INFO - Epoch: 22.61, Step: 89570, Train Loss: 1.2322, Learning Rate: 4.58e-05
2025-12-10 05:01:08 - INFO - Epoch: 22.62, Step: 89580, Train Loss: 1.2076, Learning Rate: 4.57e-05
2025-12-10 05:01:19 - INFO - Epoch: 22.62, Step: 89590, Train Loss: 1.2222, Learning Rate: 4.57e-05
2025-12-10 05:01:31 - INFO - Epoch: 22.62, Step: 89600, Train Loss: 1.2001, Learning Rate: 4.57e-05
2025-12-10 05:01:42 - INFO - Epoch: 22.62, Step: 89610, Train Loss: 1.2236, Learning Rate: 4.57e-05
2025-12-10 05:01:53 - INFO - Epoch: 22.63, Step: 89620, Train Loss: 1.2530, Learning Rate: 4.57e-05
2025-12-10 05:02:04 - INFO - Epoch: 22.63, Step: 89630, Train Loss: 1.2198, Learning Rate: 4.57e-05
2025-12-10 05:02:15 - INFO - Epoch: 22.63, Step: 89640, Train Loss: 1.1851, Learning Rate: 4.57e-05
2025-12-10 05:02:26 - INFO - Epoch: 22.63, Step: 89650, Train Loss: 1.2466, Learning Rate: 4.57e-05
2025-12-10 05:02:38 - INFO - Epoch: 22.64, Step: 89660, Train Loss: 1.2740, Learning Rate: 4.57e-05
2025-12-10 05:02:49 - INFO - Epoch: 22.64, Step: 89670, Train Loss: 1.2015, Learning Rate: 4.57e-05
2025-12-10 05:03:00 - INFO - Epoch: 22.64, Step: 89680, Train Loss: 1.2260, Learning Rate: 4.57e-05
2025-12-10 05:03:11 - INFO - Epoch: 22.64, Step: 89690, Train Loss: 1.2593, Learning Rate: 4.57e-05
2025-12-10 05:03:22 - INFO - Epoch: 22.65, Step: 89700, Train Loss: 1.2302, Learning Rate: 4.57e-05
2025-12-10 05:03:33 - INFO - Epoch: 22.65, Step: 89710, Train Loss: 1.2309, Learning Rate: 4.57e-05
2025-12-10 05:03:44 - INFO - Epoch: 22.65, Step: 89720, Train Loss: 1.2237, Learning Rate: 4.57e-05
2025-12-10 05:03:56 - INFO - Epoch: 22.65, Step: 89730, Train Loss: 1.2381, Learning Rate: 4.56e-05
2025-12-10 05:04:07 - INFO - Epoch: 22.66, Step: 89740, Train Loss: 1.2327, Learning Rate: 4.56e-05
2025-12-10 05:04:18 - INFO - Epoch: 22.66, Step: 89750, Train Loss: 1.2238, Learning Rate: 4.56e-05
2025-12-10 05:04:29 - INFO - Epoch: 22.66, Step: 89760, Train Loss: 1.2542, Learning Rate: 4.56e-05
2025-12-10 05:04:40 - INFO - Epoch: 22.66, Step: 89770, Train Loss: 1.2234, Learning Rate: 4.56e-05
2025-12-10 05:04:51 - INFO - Epoch: 22.67, Step: 89780, Train Loss: 1.2582, Learning Rate: 4.56e-05
2025-12-10 05:05:03 - INFO - Epoch: 22.67, Step: 89790, Train Loss: 1.2667, Learning Rate: 4.56e-05
2025-12-10 05:05:14 - INFO - Epoch: 22.67, Step: 89800, Train Loss: 1.2467, Learning Rate: 4.56e-05
2025-12-10 05:05:25 - INFO - Epoch: 22.67, Step: 89810, Train Loss: 1.2591, Learning Rate: 4.56e-05
2025-12-10 05:05:36 - INFO - Epoch: 22.68, Step: 89820, Train Loss: 1.2338, Learning Rate: 4.56e-05
2025-12-10 05:05:47 - INFO - Epoch: 22.68, Step: 89830, Train Loss: 1.1977, Learning Rate: 4.56e-05
2025-12-10 05:05:58 - INFO - Epoch: 22.68, Step: 89840, Train Loss: 1.2208, Learning Rate: 4.56e-05
2025-12-10 05:06:09 - INFO - Epoch: 22.68, Step: 89850, Train Loss: 1.2809, Learning Rate: 4.56e-05
2025-12-10 05:06:21 - INFO - Epoch: 22.69, Step: 89860, Train Loss: 1.2373, Learning Rate: 4.56e-05
2025-12-10 05:06:32 - INFO - Epoch: 22.69, Step: 89870, Train Loss: 1.2674, Learning Rate: 4.56e-05
2025-12-10 05:06:43 - INFO - Epoch: 22.69, Step: 89880, Train Loss: 1.2360, Learning Rate: 4.56e-05
2025-12-10 05:06:54 - INFO - Epoch: 22.69, Step: 89890, Train Loss: 1.2100, Learning Rate: 4.55e-05
2025-12-10 05:07:05 - INFO - Epoch: 22.70, Step: 89900, Train Loss: 1.2307, Learning Rate: 4.55e-05
2025-12-10 05:07:16 - INFO - Epoch: 22.70, Step: 89910, Train Loss: 1.2492, Learning Rate: 4.55e-05
2025-12-10 05:07:28 - INFO - Epoch: 22.70, Step: 89920, Train Loss: 1.2277, Learning Rate: 4.55e-05
2025-12-10 05:07:39 - INFO - Epoch: 22.70, Step: 89930, Train Loss: 1.2449, Learning Rate: 4.55e-05
2025-12-10 05:07:50 - INFO - Epoch: 22.71, Step: 89940, Train Loss: 1.2542, Learning Rate: 4.55e-05
2025-12-10 05:08:01 - INFO - Epoch: 22.71, Step: 89950, Train Loss: 1.2252, Learning Rate: 4.55e-05
2025-12-10 05:08:12 - INFO - Epoch: 22.71, Step: 89960, Train Loss: 1.2627, Learning Rate: 4.55e-05
2025-12-10 05:08:23 - INFO - Epoch: 22.71, Step: 89970, Train Loss: 1.2405, Learning Rate: 4.55e-05
2025-12-10 05:08:34 - INFO - Epoch: 22.72, Step: 89980, Train Loss: 1.2723, Learning Rate: 4.55e-05
2025-12-10 05:08:46 - INFO - Epoch: 22.72, Step: 89990, Train Loss: 1.2369, Learning Rate: 4.55e-05
2025-12-10 05:08:57 - INFO - Epoch: 22.72, Step: 90000, Train Loss: 1.2310, Learning Rate: 4.55e-05
2025-12-10 05:09:08 - INFO - Epoch: 22.72, Step: 90010, Train Loss: 1.2559, Learning Rate: 4.55e-05
2025-12-10 05:09:19 - INFO - Epoch: 22.73, Step: 90020, Train Loss: 1.2237, Learning Rate: 4.55e-05
2025-12-10 05:09:30 - INFO - Epoch: 22.73, Step: 90030, Train Loss: 1.1847, Learning Rate: 4.55e-05
2025-12-10 05:09:41 - INFO - Epoch: 22.73, Step: 90040, Train Loss: 1.2663, Learning Rate: 4.54e-05
2025-12-10 05:09:52 - INFO - Epoch: 22.73, Step: 90050, Train Loss: 1.2727, Learning Rate: 4.54e-05
2025-12-10 05:10:04 - INFO - Epoch: 22.74, Step: 90060, Train Loss: 1.2692, Learning Rate: 4.54e-05
2025-12-10 05:10:15 - INFO - Epoch: 22.74, Step: 90070, Train Loss: 1.1993, Learning Rate: 4.54e-05
2025-12-10 05:10:26 - INFO - Epoch: 22.74, Step: 90080, Train Loss: 1.2320, Learning Rate: 4.54e-05
2025-12-10 05:10:37 - INFO - Epoch: 22.74, Step: 90090, Train Loss: 1.2524, Learning Rate: 4.54e-05
2025-12-10 05:10:48 - INFO - Epoch: 22.75, Step: 90100, Train Loss: 1.2438, Learning Rate: 4.54e-05
2025-12-10 05:10:59 - INFO - Epoch: 22.75, Step: 90110, Train Loss: 1.2300, Learning Rate: 4.54e-05
2025-12-10 05:11:11 - INFO - Epoch: 22.75, Step: 90120, Train Loss: 1.2264, Learning Rate: 4.54e-05
2025-12-10 05:11:22 - INFO - Epoch: 22.75, Step: 90130, Train Loss: 1.2181, Learning Rate: 4.54e-05
2025-12-10 05:11:33 - INFO - Epoch: 22.76, Step: 90140, Train Loss: 1.2623, Learning Rate: 4.54e-05
2025-12-10 05:11:44 - INFO - Epoch: 22.76, Step: 90150, Train Loss: 1.2103, Learning Rate: 4.54e-05
2025-12-10 05:11:55 - INFO - Epoch: 22.76, Step: 90160, Train Loss: 1.2148, Learning Rate: 4.54e-05
2025-12-10 05:12:06 - INFO - Epoch: 22.76, Step: 90170, Train Loss: 1.1991, Learning Rate: 4.54e-05
2025-12-10 05:12:17 - INFO - Epoch: 22.77, Step: 90180, Train Loss: 1.2323, Learning Rate: 4.54e-05
2025-12-10 05:12:29 - INFO - Epoch: 22.77, Step: 90190, Train Loss: 1.2549, Learning Rate: 4.53e-05
2025-12-10 05:12:40 - INFO - Epoch: 22.77, Step: 90200, Train Loss: 1.2436, Learning Rate: 4.53e-05
2025-12-10 05:12:51 - INFO - Epoch: 22.77, Step: 90210, Train Loss: 1.2035, Learning Rate: 4.53e-05
2025-12-10 05:13:02 - INFO - Epoch: 22.78, Step: 90220, Train Loss: 1.2325, Learning Rate: 4.53e-05
2025-12-10 05:13:13 - INFO - Epoch: 22.78, Step: 90230, Train Loss: 1.2673, Learning Rate: 4.53e-05
2025-12-10 05:13:24 - INFO - Epoch: 22.78, Step: 90240, Train Loss: 1.2463, Learning Rate: 4.53e-05
2025-12-10 05:13:36 - INFO - Epoch: 22.78, Step: 90250, Train Loss: 1.2594, Learning Rate: 4.53e-05
2025-12-10 05:13:47 - INFO - Epoch: 22.79, Step: 90260, Train Loss: 1.2117, Learning Rate: 4.53e-05
2025-12-10 05:13:58 - INFO - Epoch: 22.79, Step: 90270, Train Loss: 1.2445, Learning Rate: 4.53e-05
2025-12-10 05:14:09 - INFO - Epoch: 22.79, Step: 90280, Train Loss: 1.2188, Learning Rate: 4.53e-05
2025-12-10 05:14:20 - INFO - Epoch: 22.79, Step: 90290, Train Loss: 1.2486, Learning Rate: 4.53e-05
2025-12-10 05:14:31 - INFO - Epoch: 22.80, Step: 90300, Train Loss: 1.2613, Learning Rate: 4.53e-05
2025-12-10 05:14:42 - INFO - Epoch: 22.80, Step: 90310, Train Loss: 1.2569, Learning Rate: 4.53e-05
2025-12-10 05:14:54 - INFO - Epoch: 22.80, Step: 90320, Train Loss: 1.2246, Learning Rate: 4.53e-05
2025-12-10 05:15:05 - INFO - Epoch: 22.80, Step: 90330, Train Loss: 1.1755, Learning Rate: 4.53e-05
2025-12-10 05:15:16 - INFO - Epoch: 22.81, Step: 90340, Train Loss: 1.2432, Learning Rate: 4.52e-05
2025-12-10 05:15:27 - INFO - Epoch: 22.81, Step: 90350, Train Loss: 1.2257, Learning Rate: 4.52e-05
2025-12-10 05:15:38 - INFO - Epoch: 22.81, Step: 90360, Train Loss: 1.2291, Learning Rate: 4.52e-05
2025-12-10 05:15:49 - INFO - Epoch: 22.81, Step: 90370, Train Loss: 1.2205, Learning Rate: 4.52e-05
2025-12-10 05:16:00 - INFO - Epoch: 22.82, Step: 90380, Train Loss: 1.1878, Learning Rate: 4.52e-05
2025-12-10 05:16:12 - INFO - Epoch: 22.82, Step: 90390, Train Loss: 1.2254, Learning Rate: 4.52e-05
2025-12-10 05:16:23 - INFO - Epoch: 22.82, Step: 90400, Train Loss: 1.2281, Learning Rate: 4.52e-05
2025-12-10 05:16:34 - INFO - Epoch: 22.83, Step: 90410, Train Loss: 1.2761, Learning Rate: 4.52e-05
2025-12-10 05:16:45 - INFO - Epoch: 22.83, Step: 90420, Train Loss: 1.2546, Learning Rate: 4.52e-05
2025-12-10 05:16:56 - INFO - Epoch: 22.83, Step: 90430, Train Loss: 1.2366, Learning Rate: 4.52e-05
2025-12-10 05:17:07 - INFO - Epoch: 22.83, Step: 90440, Train Loss: 1.2382, Learning Rate: 4.52e-05
2025-12-10 05:17:19 - INFO - Epoch: 22.84, Step: 90450, Train Loss: 1.2225, Learning Rate: 4.52e-05
2025-12-10 05:17:30 - INFO - Epoch: 22.84, Step: 90460, Train Loss: 1.2339, Learning Rate: 4.52e-05
2025-12-10 05:17:41 - INFO - Epoch: 22.84, Step: 90470, Train Loss: 1.2795, Learning Rate: 4.52e-05
2025-12-10 05:17:52 - INFO - Epoch: 22.84, Step: 90480, Train Loss: 1.2328, Learning Rate: 4.52e-05
2025-12-10 05:18:03 - INFO - Epoch: 22.85, Step: 90490, Train Loss: 1.2117, Learning Rate: 4.51e-05
2025-12-10 05:18:14 - INFO - Epoch: 22.85, Step: 90500, Train Loss: 1.2309, Learning Rate: 4.51e-05
2025-12-10 05:18:25 - INFO - Epoch: 22.85, Step: 90510, Train Loss: 1.2279, Learning Rate: 4.51e-05
2025-12-10 05:18:37 - INFO - Epoch: 22.85, Step: 90520, Train Loss: 1.2022, Learning Rate: 4.51e-05
2025-12-10 05:18:48 - INFO - Epoch: 22.86, Step: 90530, Train Loss: 1.2650, Learning Rate: 4.51e-05
2025-12-10 05:18:59 - INFO - Epoch: 22.86, Step: 90540, Train Loss: 1.2492, Learning Rate: 4.51e-05
2025-12-10 05:19:10 - INFO - Epoch: 22.86, Step: 90550, Train Loss: 1.2514, Learning Rate: 4.51e-05
2025-12-10 05:19:21 - INFO - Epoch: 22.86, Step: 90560, Train Loss: 1.2616, Learning Rate: 4.51e-05
2025-12-10 05:19:32 - INFO - Epoch: 22.87, Step: 90570, Train Loss: 1.2607, Learning Rate: 4.51e-05
2025-12-10 05:19:44 - INFO - Epoch: 22.87, Step: 90580, Train Loss: 1.2467, Learning Rate: 4.51e-05
2025-12-10 05:19:55 - INFO - Epoch: 22.87, Step: 90590, Train Loss: 1.2104, Learning Rate: 4.51e-05
2025-12-10 05:20:06 - INFO - Epoch: 22.87, Step: 90600, Train Loss: 1.2068, Learning Rate: 4.51e-05
2025-12-10 05:20:17 - INFO - Epoch: 22.88, Step: 90610, Train Loss: 1.2218, Learning Rate: 4.51e-05
2025-12-10 05:20:28 - INFO - Epoch: 22.88, Step: 90620, Train Loss: 1.2319, Learning Rate: 4.51e-05
2025-12-10 05:20:39 - INFO - Epoch: 22.88, Step: 90630, Train Loss: 1.2570, Learning Rate: 4.51e-05
2025-12-10 05:20:50 - INFO - Epoch: 22.88, Step: 90640, Train Loss: 1.2382, Learning Rate: 4.50e-05
2025-12-10 05:21:02 - INFO - Epoch: 22.89, Step: 90650, Train Loss: 1.2398, Learning Rate: 4.50e-05
2025-12-10 05:21:13 - INFO - Epoch: 22.89, Step: 90660, Train Loss: 1.2493, Learning Rate: 4.50e-05
2025-12-10 05:21:24 - INFO - Epoch: 22.89, Step: 90670, Train Loss: 1.2393, Learning Rate: 4.50e-05
2025-12-10 05:21:35 - INFO - Epoch: 22.89, Step: 90680, Train Loss: 1.2333, Learning Rate: 4.50e-05
2025-12-10 05:21:46 - INFO - Epoch: 22.90, Step: 90690, Train Loss: 1.2024, Learning Rate: 4.50e-05
2025-12-10 05:21:57 - INFO - Epoch: 22.90, Step: 90700, Train Loss: 1.2444, Learning Rate: 4.50e-05
2025-12-10 05:22:09 - INFO - Epoch: 22.90, Step: 90710, Train Loss: 1.2409, Learning Rate: 4.50e-05
2025-12-10 05:22:20 - INFO - Epoch: 22.90, Step: 90720, Train Loss: 1.2271, Learning Rate: 4.50e-05
2025-12-10 05:22:31 - INFO - Epoch: 22.91, Step: 90730, Train Loss: 1.2360, Learning Rate: 4.50e-05
2025-12-10 05:22:42 - INFO - Epoch: 22.91, Step: 90740, Train Loss: 1.2331, Learning Rate: 4.50e-05
2025-12-10 05:22:53 - INFO - Epoch: 22.91, Step: 90750, Train Loss: 1.2075, Learning Rate: 4.50e-05
2025-12-10 05:23:04 - INFO - Epoch: 22.91, Step: 90760, Train Loss: 1.2226, Learning Rate: 4.50e-05
2025-12-10 05:23:15 - INFO - Epoch: 22.92, Step: 90770, Train Loss: 1.2747, Learning Rate: 4.50e-05
2025-12-10 05:23:27 - INFO - Epoch: 22.92, Step: 90780, Train Loss: 1.2087, Learning Rate: 4.50e-05
2025-12-10 05:23:38 - INFO - Epoch: 22.92, Step: 90790, Train Loss: 1.2436, Learning Rate: 4.49e-05
2025-12-10 05:23:49 - INFO - Epoch: 22.92, Step: 90800, Train Loss: 1.2164, Learning Rate: 4.49e-05
2025-12-10 05:24:00 - INFO - Epoch: 22.93, Step: 90810, Train Loss: 1.2199, Learning Rate: 4.49e-05
2025-12-10 05:24:11 - INFO - Epoch: 22.93, Step: 90820, Train Loss: 1.2266, Learning Rate: 4.49e-05
2025-12-10 05:24:22 - INFO - Epoch: 22.93, Step: 90830, Train Loss: 1.2089, Learning Rate: 4.49e-05
2025-12-10 05:24:33 - INFO - Epoch: 22.93, Step: 90840, Train Loss: 1.2159, Learning Rate: 4.49e-05
2025-12-10 05:24:45 - INFO - Epoch: 22.94, Step: 90850, Train Loss: 1.2240, Learning Rate: 4.49e-05
2025-12-10 05:24:56 - INFO - Epoch: 22.94, Step: 90860, Train Loss: 1.2301, Learning Rate: 4.49e-05
2025-12-10 05:25:07 - INFO - Epoch: 22.94, Step: 90870, Train Loss: 1.2801, Learning Rate: 4.49e-05
2025-12-10 05:25:18 - INFO - Epoch: 22.94, Step: 90880, Train Loss: 1.2414, Learning Rate: 4.49e-05
2025-12-10 05:25:29 - INFO - Epoch: 22.95, Step: 90890, Train Loss: 1.2401, Learning Rate: 4.49e-05
2025-12-10 05:25:40 - INFO - Epoch: 22.95, Step: 90900, Train Loss: 1.2785, Learning Rate: 4.49e-05
2025-12-10 05:25:52 - INFO - Epoch: 22.95, Step: 90910, Train Loss: 1.2579, Learning Rate: 4.49e-05
2025-12-10 05:26:03 - INFO - Epoch: 22.95, Step: 90920, Train Loss: 1.2136, Learning Rate: 4.49e-05
2025-12-10 05:26:14 - INFO - Epoch: 22.96, Step: 90930, Train Loss: 1.1835, Learning Rate: 4.49e-05
2025-12-10 05:26:25 - INFO - Epoch: 22.96, Step: 90940, Train Loss: 1.2436, Learning Rate: 4.48e-05
2025-12-10 05:26:36 - INFO - Epoch: 22.96, Step: 90950, Train Loss: 1.2152, Learning Rate: 4.48e-05
2025-12-10 05:26:47 - INFO - Epoch: 22.96, Step: 90960, Train Loss: 1.2291, Learning Rate: 4.48e-05
2025-12-10 05:26:58 - INFO - Epoch: 22.97, Step: 90970, Train Loss: 1.2742, Learning Rate: 4.48e-05
2025-12-10 05:27:10 - INFO - Epoch: 22.97, Step: 90980, Train Loss: 1.2455, Learning Rate: 4.48e-05
2025-12-10 05:27:21 - INFO - Epoch: 22.97, Step: 90990, Train Loss: 1.2201, Learning Rate: 4.48e-05
2025-12-10 05:27:32 - INFO - Epoch: 22.97, Step: 91000, Train Loss: 1.2709, Learning Rate: 4.48e-05
2025-12-10 05:27:43 - INFO - Epoch: 22.98, Step: 91010, Train Loss: 1.1998, Learning Rate: 4.48e-05
2025-12-10 05:27:54 - INFO - Epoch: 22.98, Step: 91020, Train Loss: 1.2238, Learning Rate: 4.48e-05
2025-12-10 05:28:05 - INFO - Epoch: 22.98, Step: 91030, Train Loss: 1.2227, Learning Rate: 4.48e-05
2025-12-10 05:28:17 - INFO - Epoch: 22.98, Step: 91040, Train Loss: 1.2468, Learning Rate: 4.48e-05
2025-12-10 05:28:28 - INFO - Epoch: 22.99, Step: 91050, Train Loss: 1.2482, Learning Rate: 4.48e-05
2025-12-10 05:28:39 - INFO - Epoch: 22.99, Step: 91060, Train Loss: 1.2200, Learning Rate: 4.48e-05
2025-12-10 05:28:50 - INFO - Epoch: 22.99, Step: 91070, Train Loss: 1.2470, Learning Rate: 4.48e-05
2025-12-10 05:29:01 - INFO - Epoch: 22.99, Step: 91080, Train Loss: 1.2291, Learning Rate: 4.48e-05
2025-12-10 05:29:12 - INFO - Epoch: 23.00, Step: 91090, Train Loss: 1.2316, Learning Rate: 4.47e-05
2025-12-10 05:29:23 - INFO - Epoch: 23.00, Step: 91100, Train Loss: 1.1890, Learning Rate: 4.47e-05
2025-12-10 05:29:35 - INFO - Epoch: 23.00, Step: 91110, Train Loss: 1.2174, Learning Rate: 4.47e-05
2025-12-10 05:29:46 - INFO - Epoch: 23.00, Step: 91120, Train Loss: 1.2153, Learning Rate: 4.47e-05
2025-12-10 05:29:57 - INFO - Epoch: 23.01, Step: 91130, Train Loss: 1.2133, Learning Rate: 4.47e-05
2025-12-10 05:30:08 - INFO - Epoch: 23.01, Step: 91140, Train Loss: 1.2456, Learning Rate: 4.47e-05
2025-12-10 05:30:19 - INFO - Epoch: 23.01, Step: 91150, Train Loss: 1.2615, Learning Rate: 4.47e-05
2025-12-10 05:30:30 - INFO - Epoch: 23.01, Step: 91160, Train Loss: 1.2810, Learning Rate: 4.47e-05
2025-12-10 05:30:42 - INFO - Epoch: 23.02, Step: 91170, Train Loss: 1.2079, Learning Rate: 4.47e-05
2025-12-10 05:30:53 - INFO - Epoch: 23.02, Step: 91180, Train Loss: 1.2137, Learning Rate: 4.47e-05
2025-12-10 05:31:04 - INFO - Epoch: 23.02, Step: 91190, Train Loss: 1.2376, Learning Rate: 4.47e-05
2025-12-10 05:31:15 - INFO - Epoch: 23.02, Step: 91200, Train Loss: 1.2154, Learning Rate: 4.47e-05
2025-12-10 05:31:26 - INFO - Epoch: 23.03, Step: 91210, Train Loss: 1.2174, Learning Rate: 4.47e-05
2025-12-10 05:31:37 - INFO - Epoch: 23.03, Step: 91220, Train Loss: 1.2036, Learning Rate: 4.47e-05
2025-12-10 05:31:48 - INFO - Epoch: 23.03, Step: 91230, Train Loss: 1.2045, Learning Rate: 4.47e-05
2025-12-10 05:32:00 - INFO - Epoch: 23.03, Step: 91240, Train Loss: 1.2240, Learning Rate: 4.46e-05
2025-12-10 05:32:11 - INFO - Epoch: 23.04, Step: 91250, Train Loss: 1.2395, Learning Rate: 4.46e-05
2025-12-10 05:32:22 - INFO - Epoch: 23.04, Step: 91260, Train Loss: 1.2217, Learning Rate: 4.46e-05
2025-12-10 05:32:33 - INFO - Epoch: 23.04, Step: 91270, Train Loss: 1.2132, Learning Rate: 4.46e-05
2025-12-10 05:32:44 - INFO - Epoch: 23.04, Step: 91280, Train Loss: 1.2592, Learning Rate: 4.46e-05
2025-12-10 05:32:55 - INFO - Epoch: 23.05, Step: 91290, Train Loss: 1.2138, Learning Rate: 4.46e-05
2025-12-10 05:33:07 - INFO - Epoch: 23.05, Step: 91300, Train Loss: 1.2349, Learning Rate: 4.46e-05
2025-12-10 05:33:18 - INFO - Epoch: 23.05, Step: 91310, Train Loss: 1.2653, Learning Rate: 4.46e-05
2025-12-10 05:33:29 - INFO - Epoch: 23.05, Step: 91320, Train Loss: 1.1857, Learning Rate: 4.46e-05
2025-12-10 05:33:40 - INFO - Epoch: 23.06, Step: 91330, Train Loss: 1.2027, Learning Rate: 4.46e-05
2025-12-10 05:33:51 - INFO - Epoch: 23.06, Step: 91340, Train Loss: 1.2537, Learning Rate: 4.46e-05
2025-12-10 05:34:02 - INFO - Epoch: 23.06, Step: 91350, Train Loss: 1.2601, Learning Rate: 4.46e-05
2025-12-10 05:34:13 - INFO - Epoch: 23.06, Step: 91360, Train Loss: 1.2366, Learning Rate: 4.46e-05
2025-12-10 05:34:25 - INFO - Epoch: 23.07, Step: 91370, Train Loss: 1.2059, Learning Rate: 4.46e-05
2025-12-10 05:34:36 - INFO - Epoch: 23.07, Step: 91380, Train Loss: 1.1871, Learning Rate: 4.46e-05
2025-12-10 05:34:47 - INFO - Epoch: 23.07, Step: 91390, Train Loss: 1.2055, Learning Rate: 4.45e-05
2025-12-10 05:34:58 - INFO - Epoch: 23.07, Step: 91400, Train Loss: 1.2215, Learning Rate: 4.45e-05
2025-12-10 05:35:09 - INFO - Epoch: 23.08, Step: 91410, Train Loss: 1.2430, Learning Rate: 4.45e-05
2025-12-10 05:35:20 - INFO - Epoch: 23.08, Step: 91420, Train Loss: 1.2550, Learning Rate: 4.45e-05
2025-12-10 05:35:32 - INFO - Epoch: 23.08, Step: 91430, Train Loss: 1.2355, Learning Rate: 4.45e-05
2025-12-10 05:35:43 - INFO - Epoch: 23.09, Step: 91440, Train Loss: 1.2541, Learning Rate: 4.45e-05
2025-12-10 05:35:54 - INFO - Epoch: 23.09, Step: 91450, Train Loss: 1.2074, Learning Rate: 4.45e-05
2025-12-10 05:36:05 - INFO - Epoch: 23.09, Step: 91460, Train Loss: 1.2282, Learning Rate: 4.45e-05
2025-12-10 05:36:16 - INFO - Epoch: 23.09, Step: 91470, Train Loss: 1.2476, Learning Rate: 4.45e-05
2025-12-10 05:36:27 - INFO - Epoch: 23.10, Step: 91480, Train Loss: 1.2166, Learning Rate: 4.45e-05
2025-12-10 05:36:38 - INFO - Epoch: 23.10, Step: 91490, Train Loss: 1.2350, Learning Rate: 4.45e-05
2025-12-10 05:36:50 - INFO - Epoch: 23.10, Step: 91500, Train Loss: 1.2277, Learning Rate: 4.45e-05
2025-12-10 05:37:01 - INFO - Epoch: 23.10, Step: 91510, Train Loss: 1.2412, Learning Rate: 4.45e-05
2025-12-10 05:37:12 - INFO - Epoch: 23.11, Step: 91520, Train Loss: 1.2202, Learning Rate: 4.45e-05
2025-12-10 05:37:23 - INFO - Epoch: 23.11, Step: 91530, Train Loss: 1.2385, Learning Rate: 4.45e-05
2025-12-10 05:37:34 - INFO - Epoch: 23.11, Step: 91540, Train Loss: 1.2303, Learning Rate: 4.44e-05
2025-12-10 05:37:45 - INFO - Epoch: 23.11, Step: 91550, Train Loss: 1.2347, Learning Rate: 4.44e-05
2025-12-10 05:37:57 - INFO - Epoch: 23.12, Step: 91560, Train Loss: 1.2141, Learning Rate: 4.44e-05
2025-12-10 05:38:08 - INFO - Epoch: 23.12, Step: 91570, Train Loss: 1.1989, Learning Rate: 4.44e-05
2025-12-10 05:38:19 - INFO - Epoch: 23.12, Step: 91580, Train Loss: 1.2332, Learning Rate: 4.44e-05
2025-12-10 05:38:30 - INFO - Epoch: 23.12, Step: 91590, Train Loss: 1.2252, Learning Rate: 4.44e-05
2025-12-10 05:38:41 - INFO - Epoch: 23.13, Step: 91600, Train Loss: 1.2252, Learning Rate: 4.44e-05
2025-12-10 05:38:52 - INFO - Epoch: 23.13, Step: 91610, Train Loss: 1.2669, Learning Rate: 4.44e-05
2025-12-10 05:39:04 - INFO - Epoch: 23.13, Step: 91620, Train Loss: 1.2568, Learning Rate: 4.44e-05
2025-12-10 05:39:15 - INFO - Epoch: 23.13, Step: 91630, Train Loss: 1.2253, Learning Rate: 4.44e-05
2025-12-10 05:39:26 - INFO - Epoch: 23.14, Step: 91640, Train Loss: 1.2137, Learning Rate: 4.44e-05
2025-12-10 05:39:37 - INFO - Epoch: 23.14, Step: 91650, Train Loss: 1.2347, Learning Rate: 4.44e-05
2025-12-10 05:39:48 - INFO - Epoch: 23.14, Step: 91660, Train Loss: 1.2105, Learning Rate: 4.44e-05
2025-12-10 05:39:59 - INFO - Epoch: 23.14, Step: 91670, Train Loss: 1.2433, Learning Rate: 4.44e-05
2025-12-10 05:40:10 - INFO - Epoch: 23.15, Step: 91680, Train Loss: 1.2336, Learning Rate: 4.44e-05
2025-12-10 05:40:22 - INFO - Epoch: 23.15, Step: 91690, Train Loss: 1.2771, Learning Rate: 4.43e-05
2025-12-10 05:40:33 - INFO - Epoch: 23.15, Step: 91700, Train Loss: 1.1976, Learning Rate: 4.43e-05
2025-12-10 05:40:44 - INFO - Epoch: 23.15, Step: 91710, Train Loss: 1.2232, Learning Rate: 4.43e-05
2025-12-10 05:40:55 - INFO - Epoch: 23.16, Step: 91720, Train Loss: 1.2293, Learning Rate: 4.43e-05
2025-12-10 05:41:06 - INFO - Epoch: 23.16, Step: 91730, Train Loss: 1.2157, Learning Rate: 4.43e-05
2025-12-10 05:41:17 - INFO - Epoch: 23.16, Step: 91740, Train Loss: 1.2276, Learning Rate: 4.43e-05
2025-12-10 05:41:29 - INFO - Epoch: 23.16, Step: 91750, Train Loss: 1.2295, Learning Rate: 4.43e-05
2025-12-10 05:41:40 - INFO - Epoch: 23.17, Step: 91760, Train Loss: 1.2303, Learning Rate: 4.43e-05
2025-12-10 05:41:51 - INFO - Epoch: 23.17, Step: 91770, Train Loss: 1.2746, Learning Rate: 4.43e-05
2025-12-10 05:42:02 - INFO - Epoch: 23.17, Step: 91780, Train Loss: 1.2247, Learning Rate: 4.43e-05
2025-12-10 05:42:13 - INFO - Epoch: 23.17, Step: 91790, Train Loss: 1.2393, Learning Rate: 4.43e-05
2025-12-10 05:42:24 - INFO - Epoch: 23.18, Step: 91800, Train Loss: 1.2370, Learning Rate: 4.43e-05
2025-12-10 05:42:35 - INFO - Epoch: 23.18, Step: 91810, Train Loss: 1.2296, Learning Rate: 4.43e-05
2025-12-10 05:42:47 - INFO - Epoch: 23.18, Step: 91820, Train Loss: 1.2320, Learning Rate: 4.43e-05
2025-12-10 05:42:58 - INFO - Epoch: 23.18, Step: 91830, Train Loss: 1.2073, Learning Rate: 4.43e-05
2025-12-10 05:43:09 - INFO - Epoch: 23.19, Step: 91840, Train Loss: 1.2417, Learning Rate: 4.42e-05
2025-12-10 05:43:20 - INFO - Epoch: 23.19, Step: 91850, Train Loss: 1.2416, Learning Rate: 4.42e-05
2025-12-10 05:43:31 - INFO - Epoch: 23.19, Step: 91860, Train Loss: 1.2191, Learning Rate: 4.42e-05
2025-12-10 05:43:42 - INFO - Epoch: 23.19, Step: 91870, Train Loss: 1.2102, Learning Rate: 4.42e-05
2025-12-10 05:43:54 - INFO - Epoch: 23.20, Step: 91880, Train Loss: 1.2718, Learning Rate: 4.42e-05
2025-12-10 05:44:05 - INFO - Epoch: 23.20, Step: 91890, Train Loss: 1.2177, Learning Rate: 4.42e-05
2025-12-10 05:44:16 - INFO - Epoch: 23.20, Step: 91900, Train Loss: 1.1939, Learning Rate: 4.42e-05
2025-12-10 05:44:27 - INFO - Epoch: 23.20, Step: 91910, Train Loss: 1.2227, Learning Rate: 4.42e-05
2025-12-10 05:44:38 - INFO - Epoch: 23.21, Step: 91920, Train Loss: 1.2589, Learning Rate: 4.42e-05
2025-12-10 05:44:49 - INFO - Epoch: 23.21, Step: 91930, Train Loss: 1.2219, Learning Rate: 4.42e-05
2025-12-10 05:45:00 - INFO - Epoch: 23.21, Step: 91940, Train Loss: 1.2296, Learning Rate: 4.42e-05
2025-12-10 05:45:12 - INFO - Epoch: 23.21, Step: 91950, Train Loss: 1.1929, Learning Rate: 4.42e-05
2025-12-10 05:45:23 - INFO - Epoch: 23.22, Step: 91960, Train Loss: 1.2759, Learning Rate: 4.42e-05
2025-12-10 05:45:34 - INFO - Epoch: 23.22, Step: 91970, Train Loss: 1.2106, Learning Rate: 4.42e-05
2025-12-10 05:45:45 - INFO - Epoch: 23.22, Step: 91980, Train Loss: 1.1948, Learning Rate: 4.42e-05
2025-12-10 05:45:56 - INFO - Epoch: 23.22, Step: 91990, Train Loss: 1.2246, Learning Rate: 4.41e-05
2025-12-10 05:46:07 - INFO - Epoch: 23.23, Step: 92000, Train Loss: 1.1947, Learning Rate: 4.41e-05
2025-12-10 05:46:19 - INFO - Epoch: 23.23, Step: 92010, Train Loss: 1.2545, Learning Rate: 4.41e-05
2025-12-10 05:46:30 - INFO - Epoch: 23.23, Step: 92020, Train Loss: 1.2311, Learning Rate: 4.41e-05
2025-12-10 05:46:41 - INFO - Epoch: 23.23, Step: 92030, Train Loss: 1.2509, Learning Rate: 4.41e-05
2025-12-10 05:46:52 - INFO - Epoch: 23.24, Step: 92040, Train Loss: 1.2567, Learning Rate: 4.41e-05
2025-12-10 05:47:03 - INFO - Epoch: 23.24, Step: 92050, Train Loss: 1.2039, Learning Rate: 4.41e-05
2025-12-10 05:47:14 - INFO - Epoch: 23.24, Step: 92060, Train Loss: 1.1920, Learning Rate: 4.41e-05
2025-12-10 05:47:26 - INFO - Epoch: 23.24, Step: 92070, Train Loss: 1.2066, Learning Rate: 4.41e-05
2025-12-10 05:47:37 - INFO - Epoch: 23.25, Step: 92080, Train Loss: 1.2091, Learning Rate: 4.41e-05
2025-12-10 05:47:48 - INFO - Epoch: 23.25, Step: 92090, Train Loss: 1.2369, Learning Rate: 4.41e-05
2025-12-10 05:47:59 - INFO - Epoch: 23.25, Step: 92100, Train Loss: 1.2238, Learning Rate: 4.41e-05
2025-12-10 05:48:10 - INFO - Epoch: 23.25, Step: 92110, Train Loss: 1.2779, Learning Rate: 4.41e-05
2025-12-10 05:48:21 - INFO - Epoch: 23.26, Step: 92120, Train Loss: 1.2028, Learning Rate: 4.41e-05
2025-12-10 05:48:32 - INFO - Epoch: 23.26, Step: 92130, Train Loss: 1.2021, Learning Rate: 4.41e-05
2025-12-10 05:48:44 - INFO - Epoch: 23.26, Step: 92140, Train Loss: 1.2237, Learning Rate: 4.40e-05
2025-12-10 05:48:55 - INFO - Epoch: 23.26, Step: 92150, Train Loss: 1.1823, Learning Rate: 4.40e-05
2025-12-10 05:49:06 - INFO - Epoch: 23.27, Step: 92160, Train Loss: 1.2238, Learning Rate: 4.40e-05
2025-12-10 05:49:17 - INFO - Epoch: 23.27, Step: 92170, Train Loss: 1.2360, Learning Rate: 4.40e-05
2025-12-10 05:49:28 - INFO - Epoch: 23.27, Step: 92180, Train Loss: 1.2388, Learning Rate: 4.40e-05
2025-12-10 05:49:39 - INFO - Epoch: 23.27, Step: 92190, Train Loss: 1.2071, Learning Rate: 4.40e-05
2025-12-10 05:49:51 - INFO - Epoch: 23.28, Step: 92200, Train Loss: 1.2473, Learning Rate: 4.40e-05
2025-12-10 05:50:02 - INFO - Epoch: 23.28, Step: 92210, Train Loss: 1.2128, Learning Rate: 4.40e-05
2025-12-10 05:50:13 - INFO - Epoch: 23.28, Step: 92220, Train Loss: 1.2637, Learning Rate: 4.40e-05
2025-12-10 05:50:24 - INFO - Epoch: 23.28, Step: 92230, Train Loss: 1.2215, Learning Rate: 4.40e-05
2025-12-10 05:50:35 - INFO - Epoch: 23.29, Step: 92240, Train Loss: 1.2426, Learning Rate: 4.40e-05
2025-12-10 05:50:46 - INFO - Epoch: 23.29, Step: 92250, Train Loss: 1.2101, Learning Rate: 4.40e-05
2025-12-10 05:50:57 - INFO - Epoch: 23.29, Step: 92260, Train Loss: 1.2584, Learning Rate: 4.40e-05
2025-12-10 05:51:09 - INFO - Epoch: 23.29, Step: 92270, Train Loss: 1.1931, Learning Rate: 4.40e-05
2025-12-10 05:51:20 - INFO - Epoch: 23.30, Step: 92280, Train Loss: 1.2187, Learning Rate: 4.40e-05
2025-12-10 05:51:31 - INFO - Epoch: 23.30, Step: 92290, Train Loss: 1.1922, Learning Rate: 4.39e-05
2025-12-10 05:51:42 - INFO - Epoch: 23.30, Step: 92300, Train Loss: 1.2241, Learning Rate: 4.39e-05
2025-12-10 05:51:53 - INFO - Epoch: 23.30, Step: 92310, Train Loss: 1.2714, Learning Rate: 4.39e-05
2025-12-10 05:52:04 - INFO - Epoch: 23.31, Step: 92320, Train Loss: 1.2159, Learning Rate: 4.39e-05
2025-12-10 05:52:16 - INFO - Epoch: 23.31, Step: 92330, Train Loss: 1.2232, Learning Rate: 4.39e-05
2025-12-10 05:52:27 - INFO - Epoch: 23.31, Step: 92340, Train Loss: 1.2376, Learning Rate: 4.39e-05
2025-12-10 05:52:38 - INFO - Epoch: 23.31, Step: 92350, Train Loss: 1.2540, Learning Rate: 4.39e-05
2025-12-10 05:52:49 - INFO - Epoch: 23.32, Step: 92360, Train Loss: 1.2299, Learning Rate: 4.39e-05
2025-12-10 05:53:00 - INFO - Epoch: 23.32, Step: 92370, Train Loss: 1.2220, Learning Rate: 4.39e-05
2025-12-10 05:53:11 - INFO - Epoch: 23.32, Step: 92380, Train Loss: 1.1809, Learning Rate: 4.39e-05
2025-12-10 05:53:22 - INFO - Epoch: 23.32, Step: 92390, Train Loss: 1.2230, Learning Rate: 4.39e-05
2025-12-10 05:53:34 - INFO - Epoch: 23.33, Step: 92400, Train Loss: 1.2191, Learning Rate: 4.39e-05
2025-12-10 05:53:45 - INFO - Epoch: 23.33, Step: 92410, Train Loss: 1.2589, Learning Rate: 4.39e-05
2025-12-10 05:53:56 - INFO - Epoch: 23.33, Step: 92420, Train Loss: 1.2402, Learning Rate: 4.39e-05
2025-12-10 05:54:07 - INFO - Epoch: 23.34, Step: 92430, Train Loss: 1.2205, Learning Rate: 4.39e-05
2025-12-10 05:54:18 - INFO - Epoch: 23.34, Step: 92440, Train Loss: 1.2189, Learning Rate: 4.38e-05
2025-12-10 05:54:29 - INFO - Epoch: 23.34, Step: 92450, Train Loss: 1.1848, Learning Rate: 4.38e-05
2025-12-10 05:54:41 - INFO - Epoch: 23.34, Step: 92460, Train Loss: 1.2177, Learning Rate: 4.38e-05
2025-12-10 05:54:52 - INFO - Epoch: 23.35, Step: 92470, Train Loss: 1.2314, Learning Rate: 4.38e-05
2025-12-10 05:55:03 - INFO - Epoch: 23.35, Step: 92480, Train Loss: 1.2190, Learning Rate: 4.38e-05
2025-12-10 05:55:14 - INFO - Epoch: 23.35, Step: 92490, Train Loss: 1.2170, Learning Rate: 4.38e-05
2025-12-10 05:55:25 - INFO - Epoch: 23.35, Step: 92500, Train Loss: 1.2294, Learning Rate: 4.38e-05
2025-12-10 05:55:36 - INFO - Epoch: 23.36, Step: 92510, Train Loss: 1.2369, Learning Rate: 4.38e-05
2025-12-10 05:55:48 - INFO - Epoch: 23.36, Step: 92520, Train Loss: 1.2153, Learning Rate: 4.38e-05
2025-12-10 05:55:59 - INFO - Epoch: 23.36, Step: 92530, Train Loss: 1.2277, Learning Rate: 4.38e-05
2025-12-10 05:56:10 - INFO - Epoch: 23.36, Step: 92540, Train Loss: 1.2041, Learning Rate: 4.38e-05
2025-12-10 05:56:21 - INFO - Epoch: 23.37, Step: 92550, Train Loss: 1.2198, Learning Rate: 4.38e-05
2025-12-10 05:56:32 - INFO - Epoch: 23.37, Step: 92560, Train Loss: 1.2281, Learning Rate: 4.38e-05
2025-12-10 05:56:43 - INFO - Epoch: 23.37, Step: 92570, Train Loss: 1.2328, Learning Rate: 4.38e-05
2025-12-10 05:56:54 - INFO - Epoch: 23.37, Step: 92580, Train Loss: 1.2283, Learning Rate: 4.38e-05
2025-12-10 05:57:06 - INFO - Epoch: 23.38, Step: 92590, Train Loss: 1.2291, Learning Rate: 4.37e-05
2025-12-10 05:57:17 - INFO - Epoch: 23.38, Step: 92600, Train Loss: 1.2631, Learning Rate: 4.37e-05
2025-12-10 05:57:28 - INFO - Epoch: 23.38, Step: 92610, Train Loss: 1.2252, Learning Rate: 4.37e-05
2025-12-10 05:57:39 - INFO - Epoch: 23.38, Step: 92620, Train Loss: 1.1935, Learning Rate: 4.37e-05
2025-12-10 05:57:50 - INFO - Epoch: 23.39, Step: 92630, Train Loss: 1.2455, Learning Rate: 4.37e-05
2025-12-10 05:58:01 - INFO - Epoch: 23.39, Step: 92640, Train Loss: 1.2279, Learning Rate: 4.37e-05
2025-12-10 05:58:13 - INFO - Epoch: 23.39, Step: 92650, Train Loss: 1.1982, Learning Rate: 4.37e-05
2025-12-10 05:58:24 - INFO - Epoch: 23.39, Step: 92660, Train Loss: 1.2091, Learning Rate: 4.37e-05
2025-12-10 05:58:35 - INFO - Epoch: 23.40, Step: 92670, Train Loss: 1.2039, Learning Rate: 4.37e-05
2025-12-10 05:58:46 - INFO - Epoch: 23.40, Step: 92680, Train Loss: 1.2174, Learning Rate: 4.37e-05
2025-12-10 05:58:57 - INFO - Epoch: 23.40, Step: 92690, Train Loss: 1.2266, Learning Rate: 4.37e-05
2025-12-10 05:59:08 - INFO - Epoch: 23.40, Step: 92700, Train Loss: 1.2269, Learning Rate: 4.37e-05
2025-12-10 05:59:19 - INFO - Epoch: 23.41, Step: 92710, Train Loss: 1.2272, Learning Rate: 4.37e-05
2025-12-10 05:59:31 - INFO - Epoch: 23.41, Step: 92720, Train Loss: 1.2218, Learning Rate: 4.37e-05
2025-12-10 05:59:42 - INFO - Epoch: 23.41, Step: 92730, Train Loss: 1.2105, Learning Rate: 4.37e-05
2025-12-10 05:59:53 - INFO - Epoch: 23.41, Step: 92740, Train Loss: 1.2616, Learning Rate: 4.36e-05
2025-12-10 06:00:04 - INFO - Epoch: 23.42, Step: 92750, Train Loss: 1.1995, Learning Rate: 4.36e-05
2025-12-10 06:00:15 - INFO - Epoch: 23.42, Step: 92760, Train Loss: 1.2490, Learning Rate: 4.36e-05
2025-12-10 06:00:26 - INFO - Epoch: 23.42, Step: 92770, Train Loss: 1.2505, Learning Rate: 4.36e-05
2025-12-10 06:00:38 - INFO - Epoch: 23.42, Step: 92780, Train Loss: 1.2026, Learning Rate: 4.36e-05
2025-12-10 06:00:49 - INFO - Epoch: 23.43, Step: 92790, Train Loss: 1.2351, Learning Rate: 4.36e-05
2025-12-10 06:01:00 - INFO - Epoch: 23.43, Step: 92800, Train Loss: 1.2200, Learning Rate: 4.36e-05
2025-12-10 06:01:11 - INFO - Epoch: 23.43, Step: 92810, Train Loss: 1.2498, Learning Rate: 4.36e-05
2025-12-10 06:01:22 - INFO - Epoch: 23.43, Step: 92820, Train Loss: 1.2270, Learning Rate: 4.36e-05
2025-12-10 06:01:33 - INFO - Epoch: 23.44, Step: 92830, Train Loss: 1.1901, Learning Rate: 4.36e-05
2025-12-10 06:01:44 - INFO - Epoch: 23.44, Step: 92840, Train Loss: 1.2473, Learning Rate: 4.36e-05
2025-12-10 06:01:56 - INFO - Epoch: 23.44, Step: 92850, Train Loss: 1.2091, Learning Rate: 4.36e-05
2025-12-10 06:02:07 - INFO - Epoch: 23.44, Step: 92860, Train Loss: 1.2273, Learning Rate: 4.36e-05
2025-12-10 06:02:18 - INFO - Epoch: 23.45, Step: 92870, Train Loss: 1.2407, Learning Rate: 4.36e-05
2025-12-10 06:02:29 - INFO - Epoch: 23.45, Step: 92880, Train Loss: 1.2066, Learning Rate: 4.36e-05
2025-12-10 06:02:40 - INFO - Epoch: 23.45, Step: 92890, Train Loss: 1.2165, Learning Rate: 4.36e-05
2025-12-10 06:02:51 - INFO - Epoch: 23.45, Step: 92900, Train Loss: 1.2452, Learning Rate: 4.35e-05
2025-12-10 06:03:03 - INFO - Epoch: 23.46, Step: 92910, Train Loss: 1.1990, Learning Rate: 4.35e-05
2025-12-10 06:03:14 - INFO - Epoch: 23.46, Step: 92920, Train Loss: 1.1816, Learning Rate: 4.35e-05
2025-12-10 06:03:25 - INFO - Epoch: 23.46, Step: 92930, Train Loss: 1.1799, Learning Rate: 4.35e-05
2025-12-10 06:03:36 - INFO - Epoch: 23.46, Step: 92940, Train Loss: 1.2220, Learning Rate: 4.35e-05
2025-12-10 06:03:47 - INFO - Epoch: 23.47, Step: 92950, Train Loss: 1.2128, Learning Rate: 4.35e-05
2025-12-10 06:03:58 - INFO - Epoch: 23.47, Step: 92960, Train Loss: 1.2456, Learning Rate: 4.35e-05
2025-12-10 06:04:10 - INFO - Epoch: 23.47, Step: 92970, Train Loss: 1.2425, Learning Rate: 4.35e-05
2025-12-10 06:04:21 - INFO - Epoch: 23.47, Step: 92980, Train Loss: 1.1914, Learning Rate: 4.35e-05
2025-12-10 06:04:32 - INFO - Epoch: 23.48, Step: 92990, Train Loss: 1.2355, Learning Rate: 4.35e-05
2025-12-10 06:04:43 - INFO - Epoch: 23.48, Step: 93000, Train Loss: 1.2094, Learning Rate: 4.35e-05
2025-12-10 06:04:54 - INFO - Epoch: 23.48, Step: 93010, Train Loss: 1.2386, Learning Rate: 4.35e-05
2025-12-10 06:05:05 - INFO - Epoch: 23.48, Step: 93020, Train Loss: 1.1818, Learning Rate: 4.35e-05
2025-12-10 06:05:16 - INFO - Epoch: 23.49, Step: 93030, Train Loss: 1.1894, Learning Rate: 4.35e-05
2025-12-10 06:05:28 - INFO - Epoch: 23.49, Step: 93040, Train Loss: 1.2498, Learning Rate: 4.35e-05
2025-12-10 06:05:39 - INFO - Epoch: 23.49, Step: 93050, Train Loss: 1.2333, Learning Rate: 4.34e-05
2025-12-10 06:05:50 - INFO - Epoch: 23.49, Step: 93060, Train Loss: 1.1636, Learning Rate: 4.34e-05
2025-12-10 06:06:01 - INFO - Epoch: 23.50, Step: 93070, Train Loss: 1.2387, Learning Rate: 4.34e-05
2025-12-10 06:06:12 - INFO - Epoch: 23.50, Step: 93080, Train Loss: 1.2215, Learning Rate: 4.34e-05
2025-12-10 06:06:23 - INFO - Epoch: 23.50, Step: 93090, Train Loss: 1.2553, Learning Rate: 4.34e-05
2025-12-10 06:06:35 - INFO - Epoch: 23.50, Step: 93100, Train Loss: 1.2279, Learning Rate: 4.34e-05
2025-12-10 06:06:46 - INFO - Epoch: 23.51, Step: 93110, Train Loss: 1.2439, Learning Rate: 4.34e-05
2025-12-10 06:06:57 - INFO - Epoch: 23.51, Step: 93120, Train Loss: 1.1809, Learning Rate: 4.34e-05
2025-12-10 06:07:08 - INFO - Epoch: 23.51, Step: 93130, Train Loss: 1.2159, Learning Rate: 4.34e-05
2025-12-10 06:07:19 - INFO - Epoch: 23.51, Step: 93140, Train Loss: 1.2217, Learning Rate: 4.34e-05
2025-12-10 06:07:30 - INFO - Epoch: 23.52, Step: 93150, Train Loss: 1.2811, Learning Rate: 4.34e-05
2025-12-10 06:07:41 - INFO - Epoch: 23.52, Step: 93160, Train Loss: 1.2114, Learning Rate: 4.34e-05
2025-12-10 06:07:53 - INFO - Epoch: 23.52, Step: 93170, Train Loss: 1.2086, Learning Rate: 4.34e-05
2025-12-10 06:08:04 - INFO - Epoch: 23.52, Step: 93180, Train Loss: 1.2154, Learning Rate: 4.34e-05
2025-12-10 06:08:15 - INFO - Epoch: 23.53, Step: 93190, Train Loss: 1.2053, Learning Rate: 4.34e-05
2025-12-10 06:08:26 - INFO - Epoch: 23.53, Step: 93200, Train Loss: 1.2438, Learning Rate: 4.33e-05
2025-12-10 06:08:37 - INFO - Epoch: 23.53, Step: 93210, Train Loss: 1.2448, Learning Rate: 4.33e-05
2025-12-10 06:08:48 - INFO - Epoch: 23.53, Step: 93220, Train Loss: 1.2012, Learning Rate: 4.33e-05
2025-12-10 06:09:00 - INFO - Epoch: 23.54, Step: 93230, Train Loss: 1.2611, Learning Rate: 4.33e-05
2025-12-10 06:09:11 - INFO - Epoch: 23.54, Step: 93240, Train Loss: 1.2313, Learning Rate: 4.33e-05
2025-12-10 06:09:22 - INFO - Epoch: 23.54, Step: 93250, Train Loss: 1.2227, Learning Rate: 4.33e-05
2025-12-10 06:09:33 - INFO - Epoch: 23.54, Step: 93260, Train Loss: 1.2145, Learning Rate: 4.33e-05
2025-12-10 06:09:44 - INFO - Epoch: 23.55, Step: 93270, Train Loss: 1.2352, Learning Rate: 4.33e-05
2025-12-10 06:09:55 - INFO - Epoch: 23.55, Step: 93280, Train Loss: 1.2253, Learning Rate: 4.33e-05
2025-12-10 06:10:06 - INFO - Epoch: 23.55, Step: 93290, Train Loss: 1.2658, Learning Rate: 4.33e-05
2025-12-10 06:10:18 - INFO - Epoch: 23.55, Step: 93300, Train Loss: 1.2390, Learning Rate: 4.33e-05
2025-12-10 06:10:29 - INFO - Epoch: 23.56, Step: 93310, Train Loss: 1.2106, Learning Rate: 4.33e-05
2025-12-10 06:10:40 - INFO - Epoch: 23.56, Step: 93320, Train Loss: 1.2239, Learning Rate: 4.33e-05
2025-12-10 06:10:51 - INFO - Epoch: 23.56, Step: 93330, Train Loss: 1.2306, Learning Rate: 4.33e-05
2025-12-10 06:11:02 - INFO - Epoch: 23.56, Step: 93340, Train Loss: 1.2522, Learning Rate: 4.33e-05
2025-12-10 06:11:13 - INFO - Epoch: 23.57, Step: 93350, Train Loss: 1.2231, Learning Rate: 4.32e-05
2025-12-10 06:11:25 - INFO - Epoch: 23.57, Step: 93360, Train Loss: 1.2034, Learning Rate: 4.32e-05
2025-12-10 06:11:36 - INFO - Epoch: 23.57, Step: 93370, Train Loss: 1.1946, Learning Rate: 4.32e-05
2025-12-10 06:11:47 - INFO - Epoch: 23.57, Step: 93380, Train Loss: 1.2158, Learning Rate: 4.32e-05
2025-12-10 06:11:58 - INFO - Epoch: 23.58, Step: 93390, Train Loss: 1.2503, Learning Rate: 4.32e-05
2025-12-10 06:12:09 - INFO - Epoch: 23.58, Step: 93400, Train Loss: 1.2632, Learning Rate: 4.32e-05
2025-12-10 06:12:20 - INFO - Epoch: 23.58, Step: 93410, Train Loss: 1.2021, Learning Rate: 4.32e-05
2025-12-10 06:12:32 - INFO - Epoch: 23.58, Step: 93420, Train Loss: 1.2298, Learning Rate: 4.32e-05
2025-12-10 06:12:43 - INFO - Epoch: 23.59, Step: 93430, Train Loss: 1.2340, Learning Rate: 4.32e-05
2025-12-10 06:12:54 - INFO - Epoch: 23.59, Step: 93440, Train Loss: 1.2135, Learning Rate: 4.32e-05
2025-12-10 06:13:05 - INFO - Epoch: 23.59, Step: 93450, Train Loss: 1.2324, Learning Rate: 4.32e-05
2025-12-10 06:13:16 - INFO - Epoch: 23.60, Step: 93460, Train Loss: 1.2354, Learning Rate: 4.32e-05
2025-12-10 06:13:27 - INFO - Epoch: 23.60, Step: 93470, Train Loss: 1.1879, Learning Rate: 4.32e-05
2025-12-10 06:13:38 - INFO - Epoch: 23.60, Step: 93480, Train Loss: 1.1982, Learning Rate: 4.32e-05
2025-12-10 06:13:50 - INFO - Epoch: 23.60, Step: 93490, Train Loss: 1.2594, Learning Rate: 4.32e-05
2025-12-10 06:14:01 - INFO - Epoch: 23.61, Step: 93500, Train Loss: 1.2554, Learning Rate: 4.31e-05
2025-12-10 06:14:12 - INFO - Epoch: 23.61, Step: 93510, Train Loss: 1.2008, Learning Rate: 4.31e-05
2025-12-10 06:14:23 - INFO - Epoch: 23.61, Step: 93520, Train Loss: 1.2252, Learning Rate: 4.31e-05
2025-12-10 06:14:34 - INFO - Epoch: 23.61, Step: 93530, Train Loss: 1.2061, Learning Rate: 4.31e-05
2025-12-10 06:14:45 - INFO - Epoch: 23.62, Step: 93540, Train Loss: 1.1929, Learning Rate: 4.31e-05
2025-12-10 06:14:57 - INFO - Epoch: 23.62, Step: 93550, Train Loss: 1.1995, Learning Rate: 4.31e-05
2025-12-10 06:15:08 - INFO - Epoch: 23.62, Step: 93560, Train Loss: 1.2298, Learning Rate: 4.31e-05
2025-12-10 06:15:19 - INFO - Epoch: 23.62, Step: 93570, Train Loss: 1.2369, Learning Rate: 4.31e-05
2025-12-10 06:15:30 - INFO - Epoch: 23.63, Step: 93580, Train Loss: 1.2025, Learning Rate: 4.31e-05
2025-12-10 06:15:41 - INFO - Epoch: 23.63, Step: 93590, Train Loss: 1.2492, Learning Rate: 4.31e-05
2025-12-10 06:15:52 - INFO - Epoch: 23.63, Step: 93600, Train Loss: 1.2003, Learning Rate: 4.31e-05
2025-12-10 06:16:03 - INFO - Epoch: 23.63, Step: 93610, Train Loss: 1.2253, Learning Rate: 4.31e-05
2025-12-10 06:16:15 - INFO - Epoch: 23.64, Step: 93620, Train Loss: 1.2522, Learning Rate: 4.31e-05
2025-12-10 06:16:26 - INFO - Epoch: 23.64, Step: 93630, Train Loss: 1.2278, Learning Rate: 4.31e-05
2025-12-10 06:16:37 - INFO - Epoch: 23.64, Step: 93640, Train Loss: 1.2187, Learning Rate: 4.31e-05
2025-12-10 06:16:48 - INFO - Epoch: 23.64, Step: 93650, Train Loss: 1.2643, Learning Rate: 4.30e-05
2025-12-10 06:16:59 - INFO - Epoch: 23.65, Step: 93660, Train Loss: 1.2888, Learning Rate: 4.30e-05
2025-12-10 06:17:10 - INFO - Epoch: 23.65, Step: 93670, Train Loss: 1.2004, Learning Rate: 4.30e-05
2025-12-10 06:17:22 - INFO - Epoch: 23.65, Step: 93680, Train Loss: 1.2200, Learning Rate: 4.30e-05
2025-12-10 06:17:33 - INFO - Epoch: 23.65, Step: 93690, Train Loss: 1.2212, Learning Rate: 4.30e-05
2025-12-10 06:17:44 - INFO - Epoch: 23.66, Step: 93700, Train Loss: 1.2078, Learning Rate: 4.30e-05
2025-12-10 06:17:55 - INFO - Epoch: 23.66, Step: 93710, Train Loss: 1.2530, Learning Rate: 4.30e-05
2025-12-10 06:18:06 - INFO - Epoch: 23.66, Step: 93720, Train Loss: 1.2489, Learning Rate: 4.30e-05
2025-12-10 06:18:17 - INFO - Epoch: 23.66, Step: 93730, Train Loss: 1.2356, Learning Rate: 4.30e-05
2025-12-10 06:18:28 - INFO - Epoch: 23.67, Step: 93740, Train Loss: 1.1860, Learning Rate: 4.30e-05
2025-12-10 06:18:40 - INFO - Epoch: 23.67, Step: 93750, Train Loss: 1.2509, Learning Rate: 4.30e-05
2025-12-10 06:18:51 - INFO - Epoch: 23.67, Step: 93760, Train Loss: 1.2306, Learning Rate: 4.30e-05
2025-12-10 06:19:02 - INFO - Epoch: 23.67, Step: 93770, Train Loss: 1.2176, Learning Rate: 4.30e-05
2025-12-10 06:19:13 - INFO - Epoch: 23.68, Step: 93780, Train Loss: 1.2559, Learning Rate: 4.30e-05
2025-12-10 06:19:24 - INFO - Epoch: 23.68, Step: 93790, Train Loss: 1.2473, Learning Rate: 4.30e-05
2025-12-10 06:19:35 - INFO - Epoch: 23.68, Step: 93800, Train Loss: 1.2400, Learning Rate: 4.29e-05
2025-12-10 06:19:47 - INFO - Epoch: 23.68, Step: 93810, Train Loss: 1.2262, Learning Rate: 4.29e-05
2025-12-10 06:19:58 - INFO - Epoch: 23.69, Step: 93820, Train Loss: 1.2138, Learning Rate: 4.29e-05
2025-12-10 06:20:09 - INFO - Epoch: 23.69, Step: 93830, Train Loss: 1.2435, Learning Rate: 4.29e-05
2025-12-10 06:20:20 - INFO - Epoch: 23.69, Step: 93840, Train Loss: 1.1897, Learning Rate: 4.29e-05
2025-12-10 06:20:31 - INFO - Epoch: 23.69, Step: 93850, Train Loss: 1.2126, Learning Rate: 4.29e-05
2025-12-10 06:20:42 - INFO - Epoch: 23.70, Step: 93860, Train Loss: 1.2223, Learning Rate: 4.29e-05
2025-12-10 06:20:54 - INFO - Epoch: 23.70, Step: 93870, Train Loss: 1.2047, Learning Rate: 4.29e-05
2025-12-10 06:21:05 - INFO - Epoch: 23.70, Step: 93880, Train Loss: 1.2514, Learning Rate: 4.29e-05
2025-12-10 06:21:16 - INFO - Epoch: 23.70, Step: 93890, Train Loss: 1.1982, Learning Rate: 4.29e-05
2025-12-10 06:21:27 - INFO - Epoch: 23.71, Step: 93900, Train Loss: 1.1904, Learning Rate: 4.29e-05
2025-12-10 06:21:38 - INFO - Epoch: 23.71, Step: 93910, Train Loss: 1.2421, Learning Rate: 4.29e-05
2025-12-10 06:21:49 - INFO - Epoch: 23.71, Step: 93920, Train Loss: 1.2306, Learning Rate: 4.29e-05
2025-12-10 06:22:00 - INFO - Epoch: 23.71, Step: 93930, Train Loss: 1.2193, Learning Rate: 4.29e-05
2025-12-10 06:22:12 - INFO - Epoch: 23.72, Step: 93940, Train Loss: 1.2245, Learning Rate: 4.29e-05
2025-12-10 06:22:23 - INFO - Epoch: 23.72, Step: 93950, Train Loss: 1.2589, Learning Rate: 4.28e-05
2025-12-10 06:22:34 - INFO - Epoch: 23.72, Step: 93960, Train Loss: 1.2009, Learning Rate: 4.28e-05
2025-12-10 06:22:45 - INFO - Epoch: 23.72, Step: 93970, Train Loss: 1.2508, Learning Rate: 4.28e-05
2025-12-10 06:22:56 - INFO - Epoch: 23.73, Step: 93980, Train Loss: 1.1815, Learning Rate: 4.28e-05
2025-12-10 06:23:07 - INFO - Epoch: 23.73, Step: 93990, Train Loss: 1.2190, Learning Rate: 4.28e-05
2025-12-10 06:23:19 - INFO - Epoch: 23.73, Step: 94000, Train Loss: 1.2109, Learning Rate: 4.28e-05
2025-12-10 06:23:30 - INFO - Epoch: 23.73, Step: 94010, Train Loss: 1.2387, Learning Rate: 4.28e-05
2025-12-10 06:23:41 - INFO - Epoch: 23.74, Step: 94020, Train Loss: 1.2275, Learning Rate: 4.28e-05
2025-12-10 06:23:52 - INFO - Epoch: 23.74, Step: 94030, Train Loss: 1.2224, Learning Rate: 4.28e-05
2025-12-10 06:24:03 - INFO - Epoch: 23.74, Step: 94040, Train Loss: 1.1679, Learning Rate: 4.28e-05
2025-12-10 06:24:14 - INFO - Epoch: 23.74, Step: 94050, Train Loss: 1.2151, Learning Rate: 4.28e-05
2025-12-10 06:24:25 - INFO - Epoch: 23.75, Step: 94060, Train Loss: 1.2749, Learning Rate: 4.28e-05
2025-12-10 06:24:37 - INFO - Epoch: 23.75, Step: 94070, Train Loss: 1.2414, Learning Rate: 4.28e-05
2025-12-10 06:24:48 - INFO - Epoch: 23.75, Step: 94080, Train Loss: 1.2195, Learning Rate: 4.28e-05
2025-12-10 06:24:59 - INFO - Epoch: 23.75, Step: 94090, Train Loss: 1.2242, Learning Rate: 4.28e-05
2025-12-10 06:25:10 - INFO - Epoch: 23.76, Step: 94100, Train Loss: 1.2252, Learning Rate: 4.27e-05
2025-12-10 06:25:21 - INFO - Epoch: 23.76, Step: 94110, Train Loss: 1.2019, Learning Rate: 4.27e-05
2025-12-10 06:25:32 - INFO - Epoch: 23.76, Step: 94120, Train Loss: 1.2595, Learning Rate: 4.27e-05
2025-12-10 06:25:44 - INFO - Epoch: 23.76, Step: 94130, Train Loss: 1.2192, Learning Rate: 4.27e-05
2025-12-10 06:25:55 - INFO - Epoch: 23.77, Step: 94140, Train Loss: 1.2096, Learning Rate: 4.27e-05
2025-12-10 06:26:06 - INFO - Epoch: 23.77, Step: 94150, Train Loss: 1.2734, Learning Rate: 4.27e-05
2025-12-10 06:26:17 - INFO - Epoch: 23.77, Step: 94160, Train Loss: 1.2360, Learning Rate: 4.27e-05
2025-12-10 06:26:28 - INFO - Epoch: 23.77, Step: 94170, Train Loss: 1.2294, Learning Rate: 4.27e-05
2025-12-10 06:26:39 - INFO - Epoch: 23.78, Step: 94180, Train Loss: 1.1916, Learning Rate: 4.27e-05
2025-12-10 06:26:50 - INFO - Epoch: 23.78, Step: 94190, Train Loss: 1.2369, Learning Rate: 4.27e-05
2025-12-10 06:27:02 - INFO - Epoch: 23.78, Step: 94200, Train Loss: 1.2061, Learning Rate: 4.27e-05
2025-12-10 06:27:13 - INFO - Epoch: 23.78, Step: 94210, Train Loss: 1.2354, Learning Rate: 4.27e-05
2025-12-10 06:27:24 - INFO - Epoch: 23.79, Step: 94220, Train Loss: 1.2567, Learning Rate: 4.27e-05
2025-12-10 06:27:35 - INFO - Epoch: 23.79, Step: 94230, Train Loss: 1.1962, Learning Rate: 4.27e-05
2025-12-10 06:27:46 - INFO - Epoch: 23.79, Step: 94240, Train Loss: 1.1946, Learning Rate: 4.27e-05
2025-12-10 06:27:57 - INFO - Epoch: 23.79, Step: 94250, Train Loss: 1.2579, Learning Rate: 4.26e-05
2025-12-10 06:28:09 - INFO - Epoch: 23.80, Step: 94260, Train Loss: 1.2324, Learning Rate: 4.26e-05
2025-12-10 06:28:20 - INFO - Epoch: 23.80, Step: 94270, Train Loss: 1.2420, Learning Rate: 4.26e-05
2025-12-10 06:28:31 - INFO - Epoch: 23.80, Step: 94280, Train Loss: 1.2076, Learning Rate: 4.26e-05
2025-12-10 06:28:42 - INFO - Epoch: 23.80, Step: 94290, Train Loss: 1.2428, Learning Rate: 4.26e-05
2025-12-10 06:28:53 - INFO - Epoch: 23.81, Step: 94300, Train Loss: 1.2165, Learning Rate: 4.26e-05
2025-12-10 06:29:04 - INFO - Epoch: 23.81, Step: 94310, Train Loss: 1.2210, Learning Rate: 4.26e-05
2025-12-10 06:29:16 - INFO - Epoch: 23.81, Step: 94320, Train Loss: 1.2137, Learning Rate: 4.26e-05
2025-12-10 06:29:27 - INFO - Epoch: 23.81, Step: 94330, Train Loss: 1.2144, Learning Rate: 4.26e-05
2025-12-10 06:29:38 - INFO - Epoch: 23.82, Step: 94340, Train Loss: 1.2369, Learning Rate: 4.26e-05
2025-12-10 06:29:49 - INFO - Epoch: 23.82, Step: 94350, Train Loss: 1.1786, Learning Rate: 4.26e-05
2025-12-10 06:30:00 - INFO - Epoch: 23.82, Step: 94360, Train Loss: 1.2218, Learning Rate: 4.26e-05
2025-12-10 06:30:11 - INFO - Epoch: 23.82, Step: 94370, Train Loss: 1.1808, Learning Rate: 4.26e-05
2025-12-10 06:30:22 - INFO - Epoch: 23.83, Step: 94380, Train Loss: 1.1734, Learning Rate: 4.26e-05
2025-12-10 06:30:34 - INFO - Epoch: 23.83, Step: 94390, Train Loss: 1.2152, Learning Rate: 4.26e-05
2025-12-10 06:30:45 - INFO - Epoch: 23.83, Step: 94400, Train Loss: 1.2262, Learning Rate: 4.25e-05
2025-12-10 06:30:56 - INFO - Epoch: 23.83, Step: 94410, Train Loss: 1.2123, Learning Rate: 4.25e-05
2025-12-10 06:31:07 - INFO - Epoch: 23.84, Step: 94420, Train Loss: 1.1891, Learning Rate: 4.25e-05
2025-12-10 06:31:18 - INFO - Epoch: 23.84, Step: 94430, Train Loss: 1.1879, Learning Rate: 4.25e-05
2025-12-10 06:31:29 - INFO - Epoch: 23.84, Step: 94440, Train Loss: 1.2178, Learning Rate: 4.25e-05
2025-12-10 06:31:41 - INFO - Epoch: 23.84, Step: 94450, Train Loss: 1.2503, Learning Rate: 4.25e-05
2025-12-10 06:31:52 - INFO - Epoch: 23.85, Step: 94460, Train Loss: 1.2049, Learning Rate: 4.25e-05
2025-12-10 06:32:03 - INFO - Epoch: 23.85, Step: 94470, Train Loss: 1.2126, Learning Rate: 4.25e-05
2025-12-10 06:32:14 - INFO - Epoch: 23.85, Step: 94480, Train Loss: 1.2477, Learning Rate: 4.25e-05
2025-12-10 06:32:25 - INFO - Epoch: 23.86, Step: 94490, Train Loss: 1.1932, Learning Rate: 4.25e-05
2025-12-10 06:32:36 - INFO - Epoch: 23.86, Step: 94500, Train Loss: 1.2036, Learning Rate: 4.25e-05
2025-12-10 06:32:47 - INFO - Epoch: 23.86, Step: 94510, Train Loss: 1.2412, Learning Rate: 4.25e-05
2025-12-10 06:32:59 - INFO - Epoch: 23.86, Step: 94520, Train Loss: 1.2308, Learning Rate: 4.25e-05
2025-12-10 06:33:10 - INFO - Epoch: 23.87, Step: 94530, Train Loss: 1.2737, Learning Rate: 4.25e-05
2025-12-10 06:33:21 - INFO - Epoch: 23.87, Step: 94540, Train Loss: 1.2458, Learning Rate: 4.25e-05
2025-12-10 06:33:32 - INFO - Epoch: 23.87, Step: 94550, Train Loss: 1.2104, Learning Rate: 4.24e-05
2025-12-10 06:33:43 - INFO - Epoch: 23.87, Step: 94560, Train Loss: 1.2137, Learning Rate: 4.24e-05
2025-12-10 06:33:54 - INFO - Epoch: 23.88, Step: 94570, Train Loss: 1.2276, Learning Rate: 4.24e-05
2025-12-10 06:34:06 - INFO - Epoch: 23.88, Step: 94580, Train Loss: 1.2270, Learning Rate: 4.24e-05
2025-12-10 06:34:17 - INFO - Epoch: 23.88, Step: 94590, Train Loss: 1.2111, Learning Rate: 4.24e-05
2025-12-10 06:34:28 - INFO - Epoch: 23.88, Step: 94600, Train Loss: 1.2440, Learning Rate: 4.24e-05
2025-12-10 06:34:39 - INFO - Epoch: 23.89, Step: 94610, Train Loss: 1.2206, Learning Rate: 4.24e-05
2025-12-10 06:34:50 - INFO - Epoch: 23.89, Step: 94620, Train Loss: 1.1774, Learning Rate: 4.24e-05
2025-12-10 06:35:01 - INFO - Epoch: 23.89, Step: 94630, Train Loss: 1.2344, Learning Rate: 4.24e-05
2025-12-10 06:35:12 - INFO - Epoch: 23.89, Step: 94640, Train Loss: 1.2197, Learning Rate: 4.24e-05
2025-12-10 06:35:24 - INFO - Epoch: 23.90, Step: 94650, Train Loss: 1.2649, Learning Rate: 4.24e-05
2025-12-10 06:35:35 - INFO - Epoch: 23.90, Step: 94660, Train Loss: 1.2193, Learning Rate: 4.24e-05
2025-12-10 06:35:46 - INFO - Epoch: 23.90, Step: 94670, Train Loss: 1.2468, Learning Rate: 4.24e-05
2025-12-10 06:35:57 - INFO - Epoch: 23.90, Step: 94680, Train Loss: 1.2468, Learning Rate: 4.24e-05
2025-12-10 06:36:08 - INFO - Epoch: 23.91, Step: 94690, Train Loss: 1.1812, Learning Rate: 4.24e-05
2025-12-10 06:36:19 - INFO - Epoch: 23.91, Step: 94700, Train Loss: 1.2100, Learning Rate: 4.23e-05
2025-12-10 06:36:31 - INFO - Epoch: 23.91, Step: 94710, Train Loss: 1.2016, Learning Rate: 4.23e-05
2025-12-10 06:36:42 - INFO - Epoch: 23.91, Step: 94720, Train Loss: 1.2135, Learning Rate: 4.23e-05
2025-12-10 06:36:53 - INFO - Epoch: 23.92, Step: 94730, Train Loss: 1.1884, Learning Rate: 4.23e-05
2025-12-10 06:37:04 - INFO - Epoch: 23.92, Step: 94740, Train Loss: 1.2327, Learning Rate: 4.23e-05
2025-12-10 06:37:15 - INFO - Epoch: 23.92, Step: 94750, Train Loss: 1.2108, Learning Rate: 4.23e-05
2025-12-10 06:37:26 - INFO - Epoch: 23.92, Step: 94760, Train Loss: 1.2205, Learning Rate: 4.23e-05
2025-12-10 06:37:38 - INFO - Epoch: 23.93, Step: 94770, Train Loss: 1.2452, Learning Rate: 4.23e-05
2025-12-10 06:37:49 - INFO - Epoch: 23.93, Step: 94780, Train Loss: 1.2209, Learning Rate: 4.23e-05
2025-12-10 06:38:00 - INFO - Epoch: 23.93, Step: 94790, Train Loss: 1.2135, Learning Rate: 4.23e-05
2025-12-10 06:38:11 - INFO - Epoch: 23.93, Step: 94800, Train Loss: 1.2200, Learning Rate: 4.23e-05
2025-12-10 06:38:22 - INFO - Epoch: 23.94, Step: 94810, Train Loss: 1.2173, Learning Rate: 4.23e-05
2025-12-10 06:38:33 - INFO - Epoch: 23.94, Step: 94820, Train Loss: 1.2233, Learning Rate: 4.23e-05
2025-12-10 06:38:44 - INFO - Epoch: 23.94, Step: 94830, Train Loss: 1.2532, Learning Rate: 4.23e-05
2025-12-10 06:38:56 - INFO - Epoch: 23.94, Step: 94840, Train Loss: 1.2470, Learning Rate: 4.23e-05
2025-12-10 06:39:07 - INFO - Epoch: 23.95, Step: 94850, Train Loss: 1.1847, Learning Rate: 4.22e-05
2025-12-10 06:39:18 - INFO - Epoch: 23.95, Step: 94860, Train Loss: 1.2514, Learning Rate: 4.22e-05
2025-12-10 06:39:29 - INFO - Epoch: 23.95, Step: 94870, Train Loss: 1.2460, Learning Rate: 4.22e-05
2025-12-10 06:39:40 - INFO - Epoch: 23.95, Step: 94880, Train Loss: 1.2479, Learning Rate: 4.22e-05
2025-12-10 06:39:51 - INFO - Epoch: 23.96, Step: 94890, Train Loss: 1.2466, Learning Rate: 4.22e-05
2025-12-10 06:40:03 - INFO - Epoch: 23.96, Step: 94900, Train Loss: 1.2301, Learning Rate: 4.22e-05
2025-12-10 06:40:14 - INFO - Epoch: 23.96, Step: 94910, Train Loss: 1.2575, Learning Rate: 4.22e-05
2025-12-10 06:40:25 - INFO - Epoch: 23.96, Step: 94920, Train Loss: 1.2043, Learning Rate: 4.22e-05
2025-12-10 06:40:36 - INFO - Epoch: 23.97, Step: 94930, Train Loss: 1.1830, Learning Rate: 4.22e-05
2025-12-10 06:40:47 - INFO - Epoch: 23.97, Step: 94940, Train Loss: 1.2726, Learning Rate: 4.22e-05
2025-12-10 06:40:58 - INFO - Epoch: 23.97, Step: 94950, Train Loss: 1.2509, Learning Rate: 4.22e-05
2025-12-10 06:41:09 - INFO - Epoch: 23.97, Step: 94960, Train Loss: 1.2240, Learning Rate: 4.22e-05
2025-12-10 06:41:21 - INFO - Epoch: 23.98, Step: 94970, Train Loss: 1.2371, Learning Rate: 4.22e-05
2025-12-10 06:41:32 - INFO - Epoch: 23.98, Step: 94980, Train Loss: 1.2336, Learning Rate: 4.22e-05
2025-12-10 06:41:43 - INFO - Epoch: 23.98, Step: 94990, Train Loss: 1.1832, Learning Rate: 4.22e-05
2025-12-10 06:41:54 - INFO - Epoch: 23.98, Step: 95000, Train Loss: 1.2217, Learning Rate: 4.21e-05
2025-12-10 06:42:05 - INFO - Epoch: 23.99, Step: 95010, Train Loss: 1.2273, Learning Rate: 4.21e-05
2025-12-10 06:42:16 - INFO - Epoch: 23.99, Step: 95020, Train Loss: 1.2128, Learning Rate: 4.21e-05
2025-12-10 06:42:28 - INFO - Epoch: 23.99, Step: 95030, Train Loss: 1.2119, Learning Rate: 4.21e-05
2025-12-10 06:42:39 - INFO - Epoch: 23.99, Step: 95040, Train Loss: 1.2134, Learning Rate: 4.21e-05
2025-12-10 06:42:50 - INFO - Epoch: 24.00, Step: 95050, Train Loss: 1.2458, Learning Rate: 4.21e-05
2025-12-10 06:43:01 - INFO - Epoch: 24.00, Step: 95060, Train Loss: 1.2193, Learning Rate: 4.21e-05
2025-12-10 06:43:12 - INFO - Epoch: 24.00, Step: 95070, Train Loss: 1.2056, Learning Rate: 4.21e-05
2025-12-10 06:43:23 - INFO - Epoch: 24.00, Step: 95080, Train Loss: 1.2151, Learning Rate: 4.21e-05
2025-12-10 06:43:34 - INFO - Epoch: 24.01, Step: 95090, Train Loss: 1.2416, Learning Rate: 4.21e-05
2025-12-10 06:43:46 - INFO - Epoch: 24.01, Step: 95100, Train Loss: 1.2068, Learning Rate: 4.21e-05
2025-12-10 06:43:57 - INFO - Epoch: 24.01, Step: 95110, Train Loss: 1.2365, Learning Rate: 4.21e-05
2025-12-10 06:44:08 - INFO - Epoch: 24.01, Step: 95120, Train Loss: 1.1964, Learning Rate: 4.21e-05
2025-12-10 06:44:19 - INFO - Epoch: 24.02, Step: 95130, Train Loss: 1.2081, Learning Rate: 4.21e-05
2025-12-10 06:44:30 - INFO - Epoch: 24.02, Step: 95140, Train Loss: 1.2246, Learning Rate: 4.21e-05
2025-12-10 06:44:41 - INFO - Epoch: 24.02, Step: 95150, Train Loss: 1.2128, Learning Rate: 4.20e-05
2025-12-10 06:44:53 - INFO - Epoch: 24.02, Step: 95160, Train Loss: 1.2194, Learning Rate: 4.20e-05
2025-12-10 06:45:04 - INFO - Epoch: 24.03, Step: 95170, Train Loss: 1.1980, Learning Rate: 4.20e-05
2025-12-10 06:45:15 - INFO - Epoch: 24.03, Step: 95180, Train Loss: 1.2711, Learning Rate: 4.20e-05
2025-12-10 06:45:26 - INFO - Epoch: 24.03, Step: 95190, Train Loss: 1.2351, Learning Rate: 4.20e-05
2025-12-10 06:45:37 - INFO - Epoch: 24.03, Step: 95200, Train Loss: 1.1959, Learning Rate: 4.20e-05
2025-12-10 06:45:48 - INFO - Epoch: 24.04, Step: 95210, Train Loss: 1.2422, Learning Rate: 4.20e-05
2025-12-10 06:45:59 - INFO - Epoch: 24.04, Step: 95220, Train Loss: 1.2067, Learning Rate: 4.20e-05
2025-12-10 06:46:11 - INFO - Epoch: 24.04, Step: 95230, Train Loss: 1.2040, Learning Rate: 4.20e-05
2025-12-10 06:46:22 - INFO - Epoch: 24.04, Step: 95240, Train Loss: 1.2025, Learning Rate: 4.20e-05
2025-12-10 06:46:33 - INFO - Epoch: 24.05, Step: 95250, Train Loss: 1.2489, Learning Rate: 4.20e-05
2025-12-10 06:46:44 - INFO - Epoch: 24.05, Step: 95260, Train Loss: 1.2260, Learning Rate: 4.20e-05
2025-12-10 06:46:55 - INFO - Epoch: 24.05, Step: 95270, Train Loss: 1.2258, Learning Rate: 4.20e-05
2025-12-10 06:47:06 - INFO - Epoch: 24.05, Step: 95280, Train Loss: 1.2210, Learning Rate: 4.20e-05
2025-12-10 06:47:18 - INFO - Epoch: 24.06, Step: 95290, Train Loss: 1.2015, Learning Rate: 4.20e-05
2025-12-10 06:47:29 - INFO - Epoch: 24.06, Step: 95300, Train Loss: 1.2219, Learning Rate: 4.19e-05
2025-12-10 06:47:40 - INFO - Epoch: 24.06, Step: 95310, Train Loss: 1.2268, Learning Rate: 4.19e-05
2025-12-10 06:47:51 - INFO - Epoch: 24.06, Step: 95320, Train Loss: 1.2113, Learning Rate: 4.19e-05
2025-12-10 06:48:02 - INFO - Epoch: 24.07, Step: 95330, Train Loss: 1.2226, Learning Rate: 4.19e-05
2025-12-10 06:48:13 - INFO - Epoch: 24.07, Step: 95340, Train Loss: 1.2042, Learning Rate: 4.19e-05
2025-12-10 06:48:24 - INFO - Epoch: 24.07, Step: 95350, Train Loss: 1.1936, Learning Rate: 4.19e-05
2025-12-10 06:48:36 - INFO - Epoch: 24.07, Step: 95360, Train Loss: 1.1871, Learning Rate: 4.19e-05
2025-12-10 06:48:47 - INFO - Epoch: 24.08, Step: 95370, Train Loss: 1.2209, Learning Rate: 4.19e-05
2025-12-10 06:48:58 - INFO - Epoch: 24.08, Step: 95380, Train Loss: 1.1937, Learning Rate: 4.19e-05
2025-12-10 06:49:09 - INFO - Epoch: 24.08, Step: 95390, Train Loss: 1.2614, Learning Rate: 4.19e-05
2025-12-10 06:49:20 - INFO - Epoch: 24.08, Step: 95400, Train Loss: 1.1948, Learning Rate: 4.19e-05
2025-12-10 06:49:31 - INFO - Epoch: 24.09, Step: 95410, Train Loss: 1.2078, Learning Rate: 4.19e-05
2025-12-10 06:49:43 - INFO - Epoch: 24.09, Step: 95420, Train Loss: 1.2132, Learning Rate: 4.19e-05
2025-12-10 06:49:54 - INFO - Epoch: 24.09, Step: 95430, Train Loss: 1.2367, Learning Rate: 4.19e-05
2025-12-10 06:50:05 - INFO - Epoch: 24.09, Step: 95440, Train Loss: 1.2037, Learning Rate: 4.19e-05
2025-12-10 06:50:16 - INFO - Epoch: 24.10, Step: 95450, Train Loss: 1.2304, Learning Rate: 4.18e-05
2025-12-10 06:50:27 - INFO - Epoch: 24.10, Step: 95460, Train Loss: 1.2076, Learning Rate: 4.18e-05
2025-12-10 06:50:38 - INFO - Epoch: 24.10, Step: 95470, Train Loss: 1.2502, Learning Rate: 4.18e-05
2025-12-10 06:50:49 - INFO - Epoch: 24.11, Step: 95480, Train Loss: 1.2129, Learning Rate: 4.18e-05
2025-12-10 06:51:01 - INFO - Epoch: 24.11, Step: 95490, Train Loss: 1.2323, Learning Rate: 4.18e-05
2025-12-10 06:51:12 - INFO - Epoch: 24.11, Step: 95500, Train Loss: 1.1946, Learning Rate: 4.18e-05
2025-12-10 06:51:23 - INFO - Epoch: 24.11, Step: 95510, Train Loss: 1.2263, Learning Rate: 4.18e-05
2025-12-10 06:51:34 - INFO - Epoch: 24.12, Step: 95520, Train Loss: 1.1775, Learning Rate: 4.18e-05
2025-12-10 06:51:45 - INFO - Epoch: 24.12, Step: 95530, Train Loss: 1.1771, Learning Rate: 4.18e-05
2025-12-10 06:51:56 - INFO - Epoch: 24.12, Step: 95540, Train Loss: 1.2238, Learning Rate: 4.18e-05
2025-12-10 06:52:07 - INFO - Epoch: 24.12, Step: 95550, Train Loss: 1.2167, Learning Rate: 4.18e-05
2025-12-10 06:52:19 - INFO - Epoch: 24.13, Step: 95560, Train Loss: 1.2617, Learning Rate: 4.18e-05
2025-12-10 06:52:30 - INFO - Epoch: 24.13, Step: 95570, Train Loss: 1.2272, Learning Rate: 4.18e-05
2025-12-10 06:52:41 - INFO - Epoch: 24.13, Step: 95580, Train Loss: 1.2181, Learning Rate: 4.18e-05
2025-12-10 06:52:52 - INFO - Epoch: 24.13, Step: 95590, Train Loss: 1.2268, Learning Rate: 4.18e-05
2025-12-10 06:53:03 - INFO - Epoch: 24.14, Step: 95600, Train Loss: 1.1896, Learning Rate: 4.17e-05
2025-12-10 06:53:14 - INFO - Epoch: 24.14, Step: 95610, Train Loss: 1.1779, Learning Rate: 4.17e-05
2025-12-10 06:53:26 - INFO - Epoch: 24.14, Step: 95620, Train Loss: 1.2631, Learning Rate: 4.17e-05
2025-12-10 06:53:37 - INFO - Epoch: 24.14, Step: 95630, Train Loss: 1.2339, Learning Rate: 4.17e-05
2025-12-10 06:53:48 - INFO - Epoch: 24.15, Step: 95640, Train Loss: 1.2494, Learning Rate: 4.17e-05
2025-12-10 06:53:59 - INFO - Epoch: 24.15, Step: 95650, Train Loss: 1.2315, Learning Rate: 4.17e-05
2025-12-10 06:54:10 - INFO - Epoch: 24.15, Step: 95660, Train Loss: 1.2079, Learning Rate: 4.17e-05
2025-12-10 06:54:21 - INFO - Epoch: 24.15, Step: 95670, Train Loss: 1.2061, Learning Rate: 4.17e-05
2025-12-10 06:54:32 - INFO - Epoch: 24.16, Step: 95680, Train Loss: 1.2142, Learning Rate: 4.17e-05
2025-12-10 06:54:44 - INFO - Epoch: 24.16, Step: 95690, Train Loss: 1.1895, Learning Rate: 4.17e-05
2025-12-10 06:54:55 - INFO - Epoch: 24.16, Step: 95700, Train Loss: 1.2222, Learning Rate: 4.17e-05
2025-12-10 06:55:06 - INFO - Epoch: 24.16, Step: 95710, Train Loss: 1.2166, Learning Rate: 4.17e-05
2025-12-10 06:55:17 - INFO - Epoch: 24.17, Step: 95720, Train Loss: 1.1992, Learning Rate: 4.17e-05
2025-12-10 06:55:28 - INFO - Epoch: 24.17, Step: 95730, Train Loss: 1.2293, Learning Rate: 4.17e-05
2025-12-10 06:55:39 - INFO - Epoch: 24.17, Step: 95740, Train Loss: 1.2243, Learning Rate: 4.17e-05
2025-12-10 06:55:51 - INFO - Epoch: 24.17, Step: 95750, Train Loss: 1.2393, Learning Rate: 4.17e-05
2025-12-10 06:56:02 - INFO - Epoch: 24.18, Step: 95760, Train Loss: 1.2279, Learning Rate: 4.16e-05
2025-12-10 06:56:13 - INFO - Epoch: 24.18, Step: 95770, Train Loss: 1.2021, Learning Rate: 4.16e-05
2025-12-10 06:56:24 - INFO - Epoch: 24.18, Step: 95780, Train Loss: 1.2146, Learning Rate: 4.16e-05
2025-12-10 06:56:35 - INFO - Epoch: 24.18, Step: 95790, Train Loss: 1.2580, Learning Rate: 4.16e-05
2025-12-10 06:56:46 - INFO - Epoch: 24.19, Step: 95800, Train Loss: 1.2524, Learning Rate: 4.16e-05
2025-12-10 06:56:57 - INFO - Epoch: 24.19, Step: 95810, Train Loss: 1.2162, Learning Rate: 4.16e-05
2025-12-10 06:57:09 - INFO - Epoch: 24.19, Step: 95820, Train Loss: 1.2567, Learning Rate: 4.16e-05
2025-12-10 06:57:20 - INFO - Epoch: 24.19, Step: 95830, Train Loss: 1.2267, Learning Rate: 4.16e-05
2025-12-10 06:57:31 - INFO - Epoch: 24.20, Step: 95840, Train Loss: 1.2304, Learning Rate: 4.16e-05
2025-12-10 06:57:42 - INFO - Epoch: 24.20, Step: 95850, Train Loss: 1.2050, Learning Rate: 4.16e-05
2025-12-10 06:57:53 - INFO - Epoch: 24.20, Step: 95860, Train Loss: 1.1650, Learning Rate: 4.16e-05
2025-12-10 06:58:04 - INFO - Epoch: 24.20, Step: 95870, Train Loss: 1.1798, Learning Rate: 4.16e-05
2025-12-10 06:58:16 - INFO - Epoch: 24.21, Step: 95880, Train Loss: 1.2189, Learning Rate: 4.16e-05
2025-12-10 06:58:27 - INFO - Epoch: 24.21, Step: 95890, Train Loss: 1.1849, Learning Rate: 4.16e-05
2025-12-10 06:58:38 - INFO - Epoch: 24.21, Step: 95900, Train Loss: 1.2280, Learning Rate: 4.16e-05
2025-12-10 06:58:49 - INFO - Epoch: 24.21, Step: 95910, Train Loss: 1.1940, Learning Rate: 4.15e-05
2025-12-10 06:59:00 - INFO - Epoch: 24.22, Step: 95920, Train Loss: 1.1934, Learning Rate: 4.15e-05
2025-12-10 06:59:11 - INFO - Epoch: 24.22, Step: 95930, Train Loss: 1.2228, Learning Rate: 4.15e-05
2025-12-10 06:59:22 - INFO - Epoch: 24.22, Step: 95940, Train Loss: 1.1905, Learning Rate: 4.15e-05
2025-12-10 06:59:34 - INFO - Epoch: 24.22, Step: 95950, Train Loss: 1.1732, Learning Rate: 4.15e-05
2025-12-10 06:59:45 - INFO - Epoch: 24.23, Step: 95960, Train Loss: 1.2492, Learning Rate: 4.15e-05
2025-12-10 06:59:56 - INFO - Epoch: 24.23, Step: 95970, Train Loss: 1.2217, Learning Rate: 4.15e-05
2025-12-10 07:00:07 - INFO - Epoch: 24.23, Step: 95980, Train Loss: 1.1908, Learning Rate: 4.15e-05
2025-12-10 07:00:18 - INFO - Epoch: 24.23, Step: 95990, Train Loss: 1.2183, Learning Rate: 4.15e-05
2025-12-10 07:00:29 - INFO - Epoch: 24.24, Step: 96000, Train Loss: 1.1658, Learning Rate: 4.15e-05
2025-12-10 07:00:41 - INFO - Epoch: 24.24, Step: 96010, Train Loss: 1.2131, Learning Rate: 4.15e-05
2025-12-10 07:00:52 - INFO - Epoch: 24.24, Step: 96020, Train Loss: 1.2454, Learning Rate: 4.15e-05
2025-12-10 07:01:03 - INFO - Epoch: 24.24, Step: 96030, Train Loss: 1.1906, Learning Rate: 4.15e-05
2025-12-10 07:01:14 - INFO - Epoch: 24.25, Step: 96040, Train Loss: 1.2453, Learning Rate: 4.15e-05
2025-12-10 07:01:25 - INFO - Epoch: 24.25, Step: 96050, Train Loss: 1.1916, Learning Rate: 4.15e-05
2025-12-10 07:01:36 - INFO - Epoch: 24.25, Step: 96060, Train Loss: 1.2545, Learning Rate: 4.14e-05
2025-12-10 07:01:47 - INFO - Epoch: 24.25, Step: 96070, Train Loss: 1.2140, Learning Rate: 4.14e-05
2025-12-10 07:01:59 - INFO - Epoch: 24.26, Step: 96080, Train Loss: 1.2352, Learning Rate: 4.14e-05
2025-12-10 07:02:10 - INFO - Epoch: 24.26, Step: 96090, Train Loss: 1.2425, Learning Rate: 4.14e-05
2025-12-10 07:02:21 - INFO - Epoch: 24.26, Step: 96100, Train Loss: 1.2036, Learning Rate: 4.14e-05
2025-12-10 07:02:32 - INFO - Epoch: 24.26, Step: 96110, Train Loss: 1.1915, Learning Rate: 4.14e-05
2025-12-10 07:02:43 - INFO - Epoch: 24.27, Step: 96120, Train Loss: 1.2467, Learning Rate: 4.14e-05
2025-12-10 07:02:54 - INFO - Epoch: 24.27, Step: 96130, Train Loss: 1.1907, Learning Rate: 4.14e-05
2025-12-10 07:03:05 - INFO - Epoch: 24.27, Step: 96140, Train Loss: 1.1850, Learning Rate: 4.14e-05
2025-12-10 07:03:17 - INFO - Epoch: 24.27, Step: 96150, Train Loss: 1.2146, Learning Rate: 4.14e-05
2025-12-10 07:03:28 - INFO - Epoch: 24.28, Step: 96160, Train Loss: 1.1969, Learning Rate: 4.14e-05
2025-12-10 07:03:39 - INFO - Epoch: 24.28, Step: 96170, Train Loss: 1.2426, Learning Rate: 4.14e-05
2025-12-10 07:03:50 - INFO - Epoch: 24.28, Step: 96180, Train Loss: 1.1855, Learning Rate: 4.14e-05
2025-12-10 07:04:01 - INFO - Epoch: 24.28, Step: 96190, Train Loss: 1.2165, Learning Rate: 4.14e-05
2025-12-10 07:04:12 - INFO - Epoch: 24.29, Step: 96200, Train Loss: 1.1761, Learning Rate: 4.14e-05
2025-12-10 07:04:24 - INFO - Epoch: 24.29, Step: 96210, Train Loss: 1.2035, Learning Rate: 4.13e-05
2025-12-10 07:04:35 - INFO - Epoch: 24.29, Step: 96220, Train Loss: 1.2304, Learning Rate: 4.13e-05
2025-12-10 07:04:46 - INFO - Epoch: 24.29, Step: 96230, Train Loss: 1.2091, Learning Rate: 4.13e-05
2025-12-10 07:04:57 - INFO - Epoch: 24.30, Step: 96240, Train Loss: 1.2193, Learning Rate: 4.13e-05
2025-12-10 07:05:08 - INFO - Epoch: 24.30, Step: 96250, Train Loss: 1.1913, Learning Rate: 4.13e-05
2025-12-10 07:05:19 - INFO - Epoch: 24.30, Step: 96260, Train Loss: 1.2109, Learning Rate: 4.13e-05
2025-12-10 07:05:30 - INFO - Epoch: 24.30, Step: 96270, Train Loss: 1.2385, Learning Rate: 4.13e-05
2025-12-10 07:05:42 - INFO - Epoch: 24.31, Step: 96280, Train Loss: 1.2047, Learning Rate: 4.13e-05
2025-12-10 07:05:53 - INFO - Epoch: 24.31, Step: 96290, Train Loss: 1.2401, Learning Rate: 4.13e-05
2025-12-10 07:06:04 - INFO - Epoch: 24.31, Step: 96300, Train Loss: 1.2159, Learning Rate: 4.13e-05
2025-12-10 07:06:15 - INFO - Epoch: 24.31, Step: 96310, Train Loss: 1.1810, Learning Rate: 4.13e-05
2025-12-10 07:06:26 - INFO - Epoch: 24.32, Step: 96320, Train Loss: 1.2129, Learning Rate: 4.13e-05
2025-12-10 07:06:37 - INFO - Epoch: 24.32, Step: 96330, Train Loss: 1.2250, Learning Rate: 4.13e-05
2025-12-10 07:06:49 - INFO - Epoch: 24.32, Step: 96340, Train Loss: 1.2234, Learning Rate: 4.13e-05
2025-12-10 07:07:00 - INFO - Epoch: 24.32, Step: 96350, Train Loss: 1.2396, Learning Rate: 4.13e-05
2025-12-10 07:07:11 - INFO - Epoch: 24.33, Step: 96360, Train Loss: 1.2213, Learning Rate: 4.12e-05
2025-12-10 07:07:22 - INFO - Epoch: 24.33, Step: 96370, Train Loss: 1.2361, Learning Rate: 4.12e-05
2025-12-10 07:07:33 - INFO - Epoch: 24.33, Step: 96380, Train Loss: 1.2215, Learning Rate: 4.12e-05
2025-12-10 07:07:44 - INFO - Epoch: 24.33, Step: 96390, Train Loss: 1.1815, Learning Rate: 4.12e-05
2025-12-10 07:07:55 - INFO - Epoch: 24.34, Step: 96400, Train Loss: 1.1907, Learning Rate: 4.12e-05
2025-12-10 07:08:07 - INFO - Epoch: 24.34, Step: 96410, Train Loss: 1.2189, Learning Rate: 4.12e-05
2025-12-10 07:08:18 - INFO - Epoch: 24.34, Step: 96420, Train Loss: 1.2237, Learning Rate: 4.12e-05
2025-12-10 07:08:29 - INFO - Epoch: 24.34, Step: 96430, Train Loss: 1.2180, Learning Rate: 4.12e-05
2025-12-10 07:08:40 - INFO - Epoch: 24.35, Step: 96440, Train Loss: 1.2262, Learning Rate: 4.12e-05
2025-12-10 07:08:51 - INFO - Epoch: 24.35, Step: 96450, Train Loss: 1.1935, Learning Rate: 4.12e-05
2025-12-10 07:09:02 - INFO - Epoch: 24.35, Step: 96460, Train Loss: 1.2220, Learning Rate: 4.12e-05
2025-12-10 07:09:14 - INFO - Epoch: 24.35, Step: 96470, Train Loss: 1.2317, Learning Rate: 4.12e-05
2025-12-10 07:09:25 - INFO - Epoch: 24.36, Step: 96480, Train Loss: 1.1727, Learning Rate: 4.12e-05
2025-12-10 07:09:36 - INFO - Epoch: 24.36, Step: 96490, Train Loss: 1.1769, Learning Rate: 4.12e-05
2025-12-10 07:09:47 - INFO - Epoch: 24.36, Step: 96500, Train Loss: 1.1839, Learning Rate: 4.12e-05
2025-12-10 07:09:58 - INFO - Epoch: 24.37, Step: 96510, Train Loss: 1.2521, Learning Rate: 4.11e-05
2025-12-10 07:10:09 - INFO - Epoch: 24.37, Step: 96520, Train Loss: 1.2067, Learning Rate: 4.11e-05
2025-12-10 07:10:20 - INFO - Epoch: 24.37, Step: 96530, Train Loss: 1.2077, Learning Rate: 4.11e-05
2025-12-10 07:10:32 - INFO - Epoch: 24.37, Step: 96540, Train Loss: 1.2103, Learning Rate: 4.11e-05
2025-12-10 07:10:43 - INFO - Epoch: 24.38, Step: 96550, Train Loss: 1.2084, Learning Rate: 4.11e-05
2025-12-10 07:10:54 - INFO - Epoch: 24.38, Step: 96560, Train Loss: 1.2297, Learning Rate: 4.11e-05
2025-12-10 07:11:05 - INFO - Epoch: 24.38, Step: 96570, Train Loss: 1.2095, Learning Rate: 4.11e-05
2025-12-10 07:11:16 - INFO - Epoch: 24.38, Step: 96580, Train Loss: 1.2357, Learning Rate: 4.11e-05
2025-12-10 07:11:27 - INFO - Epoch: 24.39, Step: 96590, Train Loss: 1.2077, Learning Rate: 4.11e-05
2025-12-10 07:11:38 - INFO - Epoch: 24.39, Step: 96600, Train Loss: 1.2080, Learning Rate: 4.11e-05
2025-12-10 07:11:50 - INFO - Epoch: 24.39, Step: 96610, Train Loss: 1.1935, Learning Rate: 4.11e-05
2025-12-10 07:12:01 - INFO - Epoch: 24.39, Step: 96620, Train Loss: 1.1911, Learning Rate: 4.11e-05
2025-12-10 07:12:12 - INFO - Epoch: 24.40, Step: 96630, Train Loss: 1.2220, Learning Rate: 4.11e-05
2025-12-10 07:12:23 - INFO - Epoch: 24.40, Step: 96640, Train Loss: 1.1840, Learning Rate: 4.11e-05
2025-12-10 07:12:34 - INFO - Epoch: 24.40, Step: 96650, Train Loss: 1.2361, Learning Rate: 4.11e-05
2025-12-10 07:12:45 - INFO - Epoch: 24.40, Step: 96660, Train Loss: 1.2371, Learning Rate: 4.10e-05
2025-12-10 07:12:57 - INFO - Epoch: 24.41, Step: 96670, Train Loss: 1.2105, Learning Rate: 4.10e-05
2025-12-10 07:13:08 - INFO - Epoch: 24.41, Step: 96680, Train Loss: 1.2434, Learning Rate: 4.10e-05
2025-12-10 07:13:19 - INFO - Epoch: 24.41, Step: 96690, Train Loss: 1.2220, Learning Rate: 4.10e-05
2025-12-10 07:13:30 - INFO - Epoch: 24.41, Step: 96700, Train Loss: 1.2624, Learning Rate: 4.10e-05
2025-12-10 07:13:41 - INFO - Epoch: 24.42, Step: 96710, Train Loss: 1.2299, Learning Rate: 4.10e-05
2025-12-10 07:13:52 - INFO - Epoch: 24.42, Step: 96720, Train Loss: 1.2107, Learning Rate: 4.10e-05
2025-12-10 07:14:03 - INFO - Epoch: 24.42, Step: 96730, Train Loss: 1.2020, Learning Rate: 4.10e-05
2025-12-10 07:14:15 - INFO - Epoch: 24.42, Step: 96740, Train Loss: 1.2237, Learning Rate: 4.10e-05
2025-12-10 07:14:26 - INFO - Epoch: 24.43, Step: 96750, Train Loss: 1.1824, Learning Rate: 4.10e-05
2025-12-10 07:14:37 - INFO - Epoch: 24.43, Step: 96760, Train Loss: 1.2071, Learning Rate: 4.10e-05
2025-12-10 07:14:48 - INFO - Epoch: 24.43, Step: 96770, Train Loss: 1.1913, Learning Rate: 4.10e-05
2025-12-10 07:14:59 - INFO - Epoch: 24.43, Step: 96780, Train Loss: 1.1910, Learning Rate: 4.10e-05
2025-12-10 07:15:10 - INFO - Epoch: 24.44, Step: 96790, Train Loss: 1.2366, Learning Rate: 4.10e-05
2025-12-10 07:15:22 - INFO - Epoch: 24.44, Step: 96800, Train Loss: 1.1982, Learning Rate: 4.10e-05
2025-12-10 07:15:33 - INFO - Epoch: 24.44, Step: 96810, Train Loss: 1.2396, Learning Rate: 4.09e-05
2025-12-10 07:15:44 - INFO - Epoch: 24.44, Step: 96820, Train Loss: 1.2491, Learning Rate: 4.09e-05
2025-12-10 07:15:55 - INFO - Epoch: 24.45, Step: 96830, Train Loss: 1.1955, Learning Rate: 4.09e-05
2025-12-10 07:16:06 - INFO - Epoch: 24.45, Step: 96840, Train Loss: 1.2120, Learning Rate: 4.09e-05
2025-12-10 07:16:17 - INFO - Epoch: 24.45, Step: 96850, Train Loss: 1.2072, Learning Rate: 4.09e-05
2025-12-10 07:16:28 - INFO - Epoch: 24.45, Step: 96860, Train Loss: 1.1937, Learning Rate: 4.09e-05
2025-12-10 07:16:40 - INFO - Epoch: 24.46, Step: 96870, Train Loss: 1.2243, Learning Rate: 4.09e-05
2025-12-10 07:16:51 - INFO - Epoch: 24.46, Step: 96880, Train Loss: 1.2065, Learning Rate: 4.09e-05
2025-12-10 07:17:02 - INFO - Epoch: 24.46, Step: 96890, Train Loss: 1.1939, Learning Rate: 4.09e-05
2025-12-10 07:17:13 - INFO - Epoch: 24.46, Step: 96900, Train Loss: 1.1922, Learning Rate: 4.09e-05
2025-12-10 07:17:24 - INFO - Epoch: 24.47, Step: 96910, Train Loss: 1.2071, Learning Rate: 4.09e-05
2025-12-10 07:17:35 - INFO - Epoch: 24.47, Step: 96920, Train Loss: 1.2181, Learning Rate: 4.09e-05
2025-12-10 07:17:47 - INFO - Epoch: 24.47, Step: 96930, Train Loss: 1.2551, Learning Rate: 4.09e-05
2025-12-10 07:17:58 - INFO - Epoch: 24.47, Step: 96940, Train Loss: 1.2297, Learning Rate: 4.09e-05
2025-12-10 07:18:09 - INFO - Epoch: 24.48, Step: 96950, Train Loss: 1.2029, Learning Rate: 4.09e-05
2025-12-10 07:18:20 - INFO - Epoch: 24.48, Step: 96960, Train Loss: 1.2053, Learning Rate: 4.08e-05
2025-12-10 07:18:31 - INFO - Epoch: 24.48, Step: 96970, Train Loss: 1.2049, Learning Rate: 4.08e-05
2025-12-10 07:18:42 - INFO - Epoch: 24.48, Step: 96980, Train Loss: 1.2152, Learning Rate: 4.08e-05
2025-12-10 07:18:53 - INFO - Epoch: 24.49, Step: 96990, Train Loss: 1.2193, Learning Rate: 4.08e-05
2025-12-10 07:19:05 - INFO - Epoch: 24.49, Step: 97000, Train Loss: 1.2335, Learning Rate: 4.08e-05
2025-12-10 07:19:16 - INFO - Epoch: 24.49, Step: 97010, Train Loss: 1.1878, Learning Rate: 4.08e-05
2025-12-10 07:19:27 - INFO - Epoch: 24.49, Step: 97020, Train Loss: 1.2005, Learning Rate: 4.08e-05
2025-12-10 07:19:38 - INFO - Epoch: 24.50, Step: 97030, Train Loss: 1.2217, Learning Rate: 4.08e-05
2025-12-10 07:19:49 - INFO - Epoch: 24.50, Step: 97040, Train Loss: 1.2485, Learning Rate: 4.08e-05
2025-12-10 07:20:00 - INFO - Epoch: 24.50, Step: 97050, Train Loss: 1.2128, Learning Rate: 4.08e-05
2025-12-10 07:20:12 - INFO - Epoch: 24.50, Step: 97060, Train Loss: 1.2108, Learning Rate: 4.08e-05
2025-12-10 07:20:23 - INFO - Epoch: 24.51, Step: 97070, Train Loss: 1.2250, Learning Rate: 4.08e-05
2025-12-10 07:20:34 - INFO - Epoch: 24.51, Step: 97080, Train Loss: 1.1555, Learning Rate: 4.08e-05
2025-12-10 07:20:45 - INFO - Epoch: 24.51, Step: 97090, Train Loss: 1.2304, Learning Rate: 4.08e-05
2025-12-10 07:20:56 - INFO - Epoch: 24.51, Step: 97100, Train Loss: 1.2256, Learning Rate: 4.08e-05
2025-12-10 07:21:07 - INFO - Epoch: 24.52, Step: 97110, Train Loss: 1.2303, Learning Rate: 4.07e-05
2025-12-10 07:21:18 - INFO - Epoch: 24.52, Step: 97120, Train Loss: 1.2020, Learning Rate: 4.07e-05
2025-12-10 07:21:30 - INFO - Epoch: 24.52, Step: 97130, Train Loss: 1.1968, Learning Rate: 4.07e-05
2025-12-10 07:21:41 - INFO - Epoch: 24.52, Step: 97140, Train Loss: 1.2162, Learning Rate: 4.07e-05
2025-12-10 07:21:52 - INFO - Epoch: 24.53, Step: 97150, Train Loss: 1.1947, Learning Rate: 4.07e-05
2025-12-10 07:22:03 - INFO - Epoch: 24.53, Step: 97160, Train Loss: 1.2281, Learning Rate: 4.07e-05
2025-12-10 07:22:14 - INFO - Epoch: 24.53, Step: 97170, Train Loss: 1.2504, Learning Rate: 4.07e-05
2025-12-10 07:22:25 - INFO - Epoch: 24.53, Step: 97180, Train Loss: 1.2023, Learning Rate: 4.07e-05
2025-12-10 07:22:36 - INFO - Epoch: 24.54, Step: 97190, Train Loss: 1.2179, Learning Rate: 4.07e-05
2025-12-10 07:22:48 - INFO - Epoch: 24.54, Step: 97200, Train Loss: 1.2166, Learning Rate: 4.07e-05
2025-12-10 07:22:59 - INFO - Epoch: 24.54, Step: 97210, Train Loss: 1.2091, Learning Rate: 4.07e-05
2025-12-10 07:23:10 - INFO - Epoch: 24.54, Step: 97220, Train Loss: 1.2016, Learning Rate: 4.07e-05
2025-12-10 07:23:21 - INFO - Epoch: 24.55, Step: 97230, Train Loss: 1.2075, Learning Rate: 4.07e-05
2025-12-10 07:23:32 - INFO - Epoch: 24.55, Step: 97240, Train Loss: 1.2017, Learning Rate: 4.07e-05
2025-12-10 07:23:43 - INFO - Epoch: 24.55, Step: 97250, Train Loss: 1.2266, Learning Rate: 4.07e-05
2025-12-10 07:23:55 - INFO - Epoch: 24.55, Step: 97260, Train Loss: 1.2091, Learning Rate: 4.06e-05
2025-12-10 07:24:06 - INFO - Epoch: 24.56, Step: 97270, Train Loss: 1.2375, Learning Rate: 4.06e-05
2025-12-10 07:24:17 - INFO - Epoch: 24.56, Step: 97280, Train Loss: 1.1710, Learning Rate: 4.06e-05
2025-12-10 07:24:28 - INFO - Epoch: 24.56, Step: 97290, Train Loss: 1.2014, Learning Rate: 4.06e-05
2025-12-10 07:24:39 - INFO - Epoch: 24.56, Step: 97300, Train Loss: 1.2035, Learning Rate: 4.06e-05
2025-12-10 07:24:50 - INFO - Epoch: 24.57, Step: 97310, Train Loss: 1.2313, Learning Rate: 4.06e-05
2025-12-10 07:25:01 - INFO - Epoch: 24.57, Step: 97320, Train Loss: 1.2234, Learning Rate: 4.06e-05
2025-12-10 07:25:13 - INFO - Epoch: 24.57, Step: 97330, Train Loss: 1.1878, Learning Rate: 4.06e-05
2025-12-10 07:25:24 - INFO - Epoch: 24.57, Step: 97340, Train Loss: 1.1899, Learning Rate: 4.06e-05
2025-12-10 07:25:35 - INFO - Epoch: 24.58, Step: 97350, Train Loss: 1.2278, Learning Rate: 4.06e-05
2025-12-10 07:25:46 - INFO - Epoch: 24.58, Step: 97360, Train Loss: 1.2257, Learning Rate: 4.06e-05
2025-12-10 07:25:57 - INFO - Epoch: 24.58, Step: 97370, Train Loss: 1.2462, Learning Rate: 4.06e-05
2025-12-10 07:26:08 - INFO - Epoch: 24.58, Step: 97380, Train Loss: 1.2351, Learning Rate: 4.06e-05
2025-12-10 07:26:20 - INFO - Epoch: 24.59, Step: 97390, Train Loss: 1.2452, Learning Rate: 4.06e-05
2025-12-10 07:26:31 - INFO - Epoch: 24.59, Step: 97400, Train Loss: 1.2193, Learning Rate: 4.06e-05
2025-12-10 07:26:42 - INFO - Epoch: 24.59, Step: 97410, Train Loss: 1.2358, Learning Rate: 4.05e-05
2025-12-10 07:26:53 - INFO - Epoch: 24.59, Step: 97420, Train Loss: 1.1902, Learning Rate: 4.05e-05
2025-12-10 07:27:04 - INFO - Epoch: 24.60, Step: 97430, Train Loss: 1.2390, Learning Rate: 4.05e-05
2025-12-10 07:27:15 - INFO - Epoch: 24.60, Step: 97440, Train Loss: 1.2440, Learning Rate: 4.05e-05
2025-12-10 07:27:26 - INFO - Epoch: 24.60, Step: 97450, Train Loss: 1.2224, Learning Rate: 4.05e-05
2025-12-10 07:27:38 - INFO - Epoch: 24.60, Step: 97460, Train Loss: 1.1953, Learning Rate: 4.05e-05
2025-12-10 07:27:49 - INFO - Epoch: 24.61, Step: 97470, Train Loss: 1.2120, Learning Rate: 4.05e-05
2025-12-10 07:28:00 - INFO - Epoch: 24.61, Step: 97480, Train Loss: 1.2292, Learning Rate: 4.05e-05
2025-12-10 07:28:11 - INFO - Epoch: 24.61, Step: 97490, Train Loss: 1.2189, Learning Rate: 4.05e-05
2025-12-10 07:28:22 - INFO - Epoch: 24.61, Step: 97500, Train Loss: 1.2170, Learning Rate: 4.05e-05
2025-12-10 07:28:33 - INFO - Epoch: 24.62, Step: 97510, Train Loss: 1.1952, Learning Rate: 4.05e-05
2025-12-10 07:28:45 - INFO - Epoch: 24.62, Step: 97520, Train Loss: 1.2763, Learning Rate: 4.05e-05
2025-12-10 07:28:56 - INFO - Epoch: 24.62, Step: 97530, Train Loss: 1.2308, Learning Rate: 4.05e-05
2025-12-10 07:29:07 - INFO - Epoch: 24.63, Step: 97540, Train Loss: 1.2145, Learning Rate: 4.05e-05
2025-12-10 07:29:18 - INFO - Epoch: 24.63, Step: 97550, Train Loss: 1.1908, Learning Rate: 4.05e-05
2025-12-10 07:29:29 - INFO - Epoch: 24.63, Step: 97560, Train Loss: 1.2268, Learning Rate: 4.04e-05
2025-12-10 07:29:40 - INFO - Epoch: 24.63, Step: 97570, Train Loss: 1.1828, Learning Rate: 4.04e-05
2025-12-10 07:29:51 - INFO - Epoch: 24.64, Step: 97580, Train Loss: 1.1836, Learning Rate: 4.04e-05
2025-12-10 07:30:03 - INFO - Epoch: 24.64, Step: 97590, Train Loss: 1.2341, Learning Rate: 4.04e-05
2025-12-10 07:30:14 - INFO - Epoch: 24.64, Step: 97600, Train Loss: 1.2289, Learning Rate: 4.04e-05
2025-12-10 07:30:25 - INFO - Epoch: 24.64, Step: 97610, Train Loss: 1.2555, Learning Rate: 4.04e-05
2025-12-10 07:30:36 - INFO - Epoch: 24.65, Step: 97620, Train Loss: 1.2427, Learning Rate: 4.04e-05
2025-12-10 07:30:47 - INFO - Epoch: 24.65, Step: 97630, Train Loss: 1.2092, Learning Rate: 4.04e-05
2025-12-10 07:30:58 - INFO - Epoch: 24.65, Step: 97640, Train Loss: 1.2077, Learning Rate: 4.04e-05
2025-12-10 07:31:10 - INFO - Epoch: 24.65, Step: 97650, Train Loss: 1.2498, Learning Rate: 4.04e-05
2025-12-10 07:31:21 - INFO - Epoch: 24.66, Step: 97660, Train Loss: 1.2344, Learning Rate: 4.04e-05
2025-12-10 07:31:32 - INFO - Epoch: 24.66, Step: 97670, Train Loss: 1.2398, Learning Rate: 4.04e-05
2025-12-10 07:31:43 - INFO - Epoch: 24.66, Step: 97680, Train Loss: 1.2101, Learning Rate: 4.04e-05
2025-12-10 07:31:54 - INFO - Epoch: 24.66, Step: 97690, Train Loss: 1.1853, Learning Rate: 4.04e-05
2025-12-10 07:32:05 - INFO - Epoch: 24.67, Step: 97700, Train Loss: 1.2182, Learning Rate: 4.04e-05
2025-12-10 07:32:16 - INFO - Epoch: 24.67, Step: 97710, Train Loss: 1.2124, Learning Rate: 4.03e-05
2025-12-10 07:32:28 - INFO - Epoch: 24.67, Step: 97720, Train Loss: 1.2177, Learning Rate: 4.03e-05
2025-12-10 07:32:39 - INFO - Epoch: 24.67, Step: 97730, Train Loss: 1.2009, Learning Rate: 4.03e-05
2025-12-10 07:32:50 - INFO - Epoch: 24.68, Step: 97740, Train Loss: 1.1566, Learning Rate: 4.03e-05
2025-12-10 07:33:01 - INFO - Epoch: 24.68, Step: 97750, Train Loss: 1.2149, Learning Rate: 4.03e-05
2025-12-10 07:33:12 - INFO - Epoch: 24.68, Step: 97760, Train Loss: 1.2207, Learning Rate: 4.03e-05
2025-12-10 07:33:23 - INFO - Epoch: 24.68, Step: 97770, Train Loss: 1.2338, Learning Rate: 4.03e-05
2025-12-10 07:33:34 - INFO - Epoch: 24.69, Step: 97780, Train Loss: 1.2546, Learning Rate: 4.03e-05
2025-12-10 07:33:46 - INFO - Epoch: 24.69, Step: 97790, Train Loss: 1.2416, Learning Rate: 4.03e-05
2025-12-10 07:33:57 - INFO - Epoch: 24.69, Step: 97800, Train Loss: 1.2325, Learning Rate: 4.03e-05
2025-12-10 07:34:08 - INFO - Epoch: 24.69, Step: 97810, Train Loss: 1.2414, Learning Rate: 4.03e-05
2025-12-10 07:34:19 - INFO - Epoch: 24.70, Step: 97820, Train Loss: 1.2042, Learning Rate: 4.03e-05
2025-12-10 07:34:30 - INFO - Epoch: 24.70, Step: 97830, Train Loss: 1.2035, Learning Rate: 4.03e-05
2025-12-10 07:34:41 - INFO - Epoch: 24.70, Step: 97840, Train Loss: 1.2353, Learning Rate: 4.03e-05
2025-12-10 07:34:53 - INFO - Epoch: 24.70, Step: 97850, Train Loss: 1.1844, Learning Rate: 4.03e-05
2025-12-10 07:35:04 - INFO - Epoch: 24.71, Step: 97860, Train Loss: 1.2251, Learning Rate: 4.02e-05
2025-12-10 07:35:15 - INFO - Epoch: 24.71, Step: 97870, Train Loss: 1.1722, Learning Rate: 4.02e-05
2025-12-10 07:35:26 - INFO - Epoch: 24.71, Step: 97880, Train Loss: 1.2526, Learning Rate: 4.02e-05
2025-12-10 07:35:37 - INFO - Epoch: 24.71, Step: 97890, Train Loss: 1.2271, Learning Rate: 4.02e-05
2025-12-10 07:35:48 - INFO - Epoch: 24.72, Step: 97900, Train Loss: 1.2530, Learning Rate: 4.02e-05
2025-12-10 07:35:59 - INFO - Epoch: 24.72, Step: 97910, Train Loss: 1.1938, Learning Rate: 4.02e-05
2025-12-10 07:36:11 - INFO - Epoch: 24.72, Step: 97920, Train Loss: 1.2430, Learning Rate: 4.02e-05
2025-12-10 07:36:22 - INFO - Epoch: 24.72, Step: 97930, Train Loss: 1.2376, Learning Rate: 4.02e-05
2025-12-10 07:36:33 - INFO - Epoch: 24.73, Step: 97940, Train Loss: 1.2268, Learning Rate: 4.02e-05
2025-12-10 07:36:44 - INFO - Epoch: 24.73, Step: 97950, Train Loss: 1.2059, Learning Rate: 4.02e-05
2025-12-10 07:36:55 - INFO - Epoch: 24.73, Step: 97960, Train Loss: 1.2070, Learning Rate: 4.02e-05
2025-12-10 07:37:06 - INFO - Epoch: 24.73, Step: 97970, Train Loss: 1.2016, Learning Rate: 4.02e-05
2025-12-10 07:37:18 - INFO - Epoch: 24.74, Step: 97980, Train Loss: 1.2394, Learning Rate: 4.02e-05
2025-12-10 07:37:29 - INFO - Epoch: 24.74, Step: 97990, Train Loss: 1.2375, Learning Rate: 4.02e-05
2025-12-10 07:37:40 - INFO - Epoch: 24.74, Step: 98000, Train Loss: 1.2092, Learning Rate: 4.02e-05
2025-12-10 07:37:51 - INFO - Epoch: 24.74, Step: 98010, Train Loss: 1.1975, Learning Rate: 4.01e-05
2025-12-10 07:38:02 - INFO - Epoch: 24.75, Step: 98020, Train Loss: 1.2053, Learning Rate: 4.01e-05
2025-12-10 07:38:13 - INFO - Epoch: 24.75, Step: 98030, Train Loss: 1.2117, Learning Rate: 4.01e-05
2025-12-10 07:38:24 - INFO - Epoch: 24.75, Step: 98040, Train Loss: 1.2301, Learning Rate: 4.01e-05
2025-12-10 07:38:36 - INFO - Epoch: 24.75, Step: 98050, Train Loss: 1.2596, Learning Rate: 4.01e-05
2025-12-10 07:38:47 - INFO - Epoch: 24.76, Step: 98060, Train Loss: 1.2236, Learning Rate: 4.01e-05
2025-12-10 07:38:58 - INFO - Epoch: 24.76, Step: 98070, Train Loss: 1.1840, Learning Rate: 4.01e-05
2025-12-10 07:39:09 - INFO - Epoch: 24.76, Step: 98080, Train Loss: 1.2244, Learning Rate: 4.01e-05
2025-12-10 07:39:20 - INFO - Epoch: 24.76, Step: 98090, Train Loss: 1.2089, Learning Rate: 4.01e-05
2025-12-10 07:39:31 - INFO - Epoch: 24.77, Step: 98100, Train Loss: 1.2179, Learning Rate: 4.01e-05
2025-12-10 07:39:43 - INFO - Epoch: 24.77, Step: 98110, Train Loss: 1.2151, Learning Rate: 4.01e-05
2025-12-10 07:39:54 - INFO - Epoch: 24.77, Step: 98120, Train Loss: 1.2042, Learning Rate: 4.01e-05
2025-12-10 07:40:05 - INFO - Epoch: 24.77, Step: 98130, Train Loss: 1.2526, Learning Rate: 4.01e-05
2025-12-10 07:40:16 - INFO - Epoch: 24.78, Step: 98140, Train Loss: 1.2185, Learning Rate: 4.01e-05
2025-12-10 07:40:27 - INFO - Epoch: 24.78, Step: 98150, Train Loss: 1.2065, Learning Rate: 4.01e-05
2025-12-10 07:40:38 - INFO - Epoch: 24.78, Step: 98160, Train Loss: 1.2606, Learning Rate: 4.00e-05
2025-12-10 07:40:49 - INFO - Epoch: 24.78, Step: 98170, Train Loss: 1.1620, Learning Rate: 4.00e-05
2025-12-10 07:41:01 - INFO - Epoch: 24.79, Step: 98180, Train Loss: 1.1892, Learning Rate: 4.00e-05
2025-12-10 07:41:12 - INFO - Epoch: 24.79, Step: 98190, Train Loss: 1.1964, Learning Rate: 4.00e-05
2025-12-10 07:41:23 - INFO - Epoch: 24.79, Step: 98200, Train Loss: 1.2114, Learning Rate: 4.00e-05
2025-12-10 07:41:34 - INFO - Epoch: 24.79, Step: 98210, Train Loss: 1.2091, Learning Rate: 4.00e-05
2025-12-10 07:41:45 - INFO - Epoch: 24.80, Step: 98220, Train Loss: 1.2264, Learning Rate: 4.00e-05
2025-12-10 07:41:56 - INFO - Epoch: 24.80, Step: 98230, Train Loss: 1.1953, Learning Rate: 4.00e-05
2025-12-10 07:42:08 - INFO - Epoch: 24.80, Step: 98240, Train Loss: 1.1806, Learning Rate: 4.00e-05
2025-12-10 07:42:19 - INFO - Epoch: 24.80, Step: 98250, Train Loss: 1.2092, Learning Rate: 4.00e-05
2025-12-10 07:42:30 - INFO - Epoch: 24.81, Step: 98260, Train Loss: 1.2166, Learning Rate: 4.00e-05
2025-12-10 07:42:41 - INFO - Epoch: 24.81, Step: 98270, Train Loss: 1.2451, Learning Rate: 4.00e-05
2025-12-10 07:42:52 - INFO - Epoch: 24.81, Step: 98280, Train Loss: 1.1960, Learning Rate: 4.00e-05
2025-12-10 07:43:03 - INFO - Epoch: 24.81, Step: 98290, Train Loss: 1.2516, Learning Rate: 4.00e-05
2025-12-10 07:43:14 - INFO - Epoch: 24.82, Step: 98300, Train Loss: 1.2085, Learning Rate: 4.00e-05
2025-12-10 07:43:26 - INFO - Epoch: 24.82, Step: 98310, Train Loss: 1.2036, Learning Rate: 3.99e-05
2025-12-10 07:43:37 - INFO - Epoch: 24.82, Step: 98320, Train Loss: 1.2124, Learning Rate: 3.99e-05
2025-12-10 07:43:48 - INFO - Epoch: 24.82, Step: 98330, Train Loss: 1.2184, Learning Rate: 3.99e-05
2025-12-10 07:43:59 - INFO - Epoch: 24.83, Step: 98340, Train Loss: 1.2017, Learning Rate: 3.99e-05
2025-12-10 07:44:10 - INFO - Epoch: 24.83, Step: 98350, Train Loss: 1.2220, Learning Rate: 3.99e-05
2025-12-10 07:44:21 - INFO - Epoch: 24.83, Step: 98360, Train Loss: 1.1813, Learning Rate: 3.99e-05
2025-12-10 07:44:32 - INFO - Epoch: 24.83, Step: 98370, Train Loss: 1.2217, Learning Rate: 3.99e-05
2025-12-10 07:44:44 - INFO - Epoch: 24.84, Step: 98380, Train Loss: 1.2924, Learning Rate: 3.99e-05
2025-12-10 07:44:55 - INFO - Epoch: 24.84, Step: 98390, Train Loss: 1.2294, Learning Rate: 3.99e-05
2025-12-10 07:45:06 - INFO - Epoch: 24.84, Step: 98400, Train Loss: 1.2178, Learning Rate: 3.99e-05
2025-12-10 07:45:17 - INFO - Epoch: 24.84, Step: 98410, Train Loss: 1.2413, Learning Rate: 3.99e-05
2025-12-10 07:45:28 - INFO - Epoch: 24.85, Step: 98420, Train Loss: 1.2069, Learning Rate: 3.99e-05
2025-12-10 07:45:39 - INFO - Epoch: 24.85, Step: 98430, Train Loss: 1.2489, Learning Rate: 3.99e-05
2025-12-10 07:45:51 - INFO - Epoch: 24.85, Step: 98440, Train Loss: 1.1947, Learning Rate: 3.99e-05
2025-12-10 07:46:02 - INFO - Epoch: 24.85, Step: 98450, Train Loss: 1.2399, Learning Rate: 3.99e-05
2025-12-10 07:46:13 - INFO - Epoch: 24.86, Step: 98460, Train Loss: 1.2146, Learning Rate: 3.98e-05
2025-12-10 07:46:24 - INFO - Epoch: 24.86, Step: 98470, Train Loss: 1.2108, Learning Rate: 3.98e-05
2025-12-10 07:46:35 - INFO - Epoch: 24.86, Step: 98480, Train Loss: 1.2201, Learning Rate: 3.98e-05
2025-12-10 07:46:46 - INFO - Epoch: 24.86, Step: 98490, Train Loss: 1.2034, Learning Rate: 3.98e-05
2025-12-10 07:46:57 - INFO - Epoch: 24.87, Step: 98500, Train Loss: 1.2010, Learning Rate: 3.98e-05
2025-12-10 07:47:09 - INFO - Epoch: 24.87, Step: 98510, Train Loss: 1.2254, Learning Rate: 3.98e-05
2025-12-10 07:47:20 - INFO - Epoch: 24.87, Step: 98520, Train Loss: 1.2241, Learning Rate: 3.98e-05
2025-12-10 07:47:31 - INFO - Epoch: 24.88, Step: 98530, Train Loss: 1.1759, Learning Rate: 3.98e-05
2025-12-10 07:47:42 - INFO - Epoch: 24.88, Step: 98540, Train Loss: 1.2238, Learning Rate: 3.98e-05
2025-12-10 07:47:53 - INFO - Epoch: 24.88, Step: 98550, Train Loss: 1.2126, Learning Rate: 3.98e-05
2025-12-10 07:48:04 - INFO - Epoch: 24.88, Step: 98560, Train Loss: 1.1823, Learning Rate: 3.98e-05
2025-12-10 07:48:16 - INFO - Epoch: 24.89, Step: 98570, Train Loss: 1.2564, Learning Rate: 3.98e-05
2025-12-10 07:48:27 - INFO - Epoch: 24.89, Step: 98580, Train Loss: 1.1852, Learning Rate: 3.98e-05
2025-12-10 07:48:38 - INFO - Epoch: 24.89, Step: 98590, Train Loss: 1.1944, Learning Rate: 3.98e-05
2025-12-10 07:48:49 - INFO - Epoch: 24.89, Step: 98600, Train Loss: 1.2147, Learning Rate: 3.98e-05
2025-12-10 07:49:00 - INFO - Epoch: 24.90, Step: 98610, Train Loss: 1.2167, Learning Rate: 3.98e-05
2025-12-10 07:49:11 - INFO - Epoch: 24.90, Step: 98620, Train Loss: 1.2150, Learning Rate: 3.97e-05
2025-12-10 07:49:22 - INFO - Epoch: 24.90, Step: 98630, Train Loss: 1.2373, Learning Rate: 3.97e-05
2025-12-10 07:49:34 - INFO - Epoch: 24.90, Step: 98640, Train Loss: 1.1883, Learning Rate: 3.97e-05
2025-12-10 07:49:45 - INFO - Epoch: 24.91, Step: 98650, Train Loss: 1.2567, Learning Rate: 3.97e-05
2025-12-10 07:49:56 - INFO - Epoch: 24.91, Step: 98660, Train Loss: 1.2241, Learning Rate: 3.97e-05
2025-12-10 07:50:07 - INFO - Epoch: 24.91, Step: 98670, Train Loss: 1.2450, Learning Rate: 3.97e-05
2025-12-10 07:50:18 - INFO - Epoch: 24.91, Step: 98680, Train Loss: 1.1838, Learning Rate: 3.97e-05
2025-12-10 07:50:29 - INFO - Epoch: 24.92, Step: 98690, Train Loss: 1.2041, Learning Rate: 3.97e-05
2025-12-10 07:50:41 - INFO - Epoch: 24.92, Step: 98700, Train Loss: 1.2167, Learning Rate: 3.97e-05
2025-12-10 07:50:52 - INFO - Epoch: 24.92, Step: 98710, Train Loss: 1.1967, Learning Rate: 3.97e-05
2025-12-10 07:51:03 - INFO - Epoch: 24.92, Step: 98720, Train Loss: 1.2185, Learning Rate: 3.97e-05
2025-12-10 07:51:14 - INFO - Epoch: 24.93, Step: 98730, Train Loss: 1.2294, Learning Rate: 3.97e-05
2025-12-10 07:51:25 - INFO - Epoch: 24.93, Step: 98740, Train Loss: 1.2149, Learning Rate: 3.97e-05
2025-12-10 07:51:36 - INFO - Epoch: 24.93, Step: 98750, Train Loss: 1.2314, Learning Rate: 3.97e-05
2025-12-10 07:51:47 - INFO - Epoch: 24.93, Step: 98760, Train Loss: 1.2202, Learning Rate: 3.97e-05
2025-12-10 07:51:59 - INFO - Epoch: 24.94, Step: 98770, Train Loss: 1.1926, Learning Rate: 3.96e-05
2025-12-10 07:52:10 - INFO - Epoch: 24.94, Step: 98780, Train Loss: 1.1877, Learning Rate: 3.96e-05
2025-12-10 07:52:21 - INFO - Epoch: 24.94, Step: 98790, Train Loss: 1.2025, Learning Rate: 3.96e-05
2025-12-10 07:52:32 - INFO - Epoch: 24.94, Step: 98800, Train Loss: 1.1766, Learning Rate: 3.96e-05
2025-12-10 07:52:43 - INFO - Epoch: 24.95, Step: 98810, Train Loss: 1.2048, Learning Rate: 3.96e-05
2025-12-10 07:52:54 - INFO - Epoch: 24.95, Step: 98820, Train Loss: 1.1878, Learning Rate: 3.96e-05
2025-12-10 07:53:05 - INFO - Epoch: 24.95, Step: 98830, Train Loss: 1.2309, Learning Rate: 3.96e-05
2025-12-10 07:53:17 - INFO - Epoch: 24.95, Step: 98840, Train Loss: 1.1853, Learning Rate: 3.96e-05
2025-12-10 07:53:28 - INFO - Epoch: 24.96, Step: 98850, Train Loss: 1.2087, Learning Rate: 3.96e-05
2025-12-10 07:53:39 - INFO - Epoch: 24.96, Step: 98860, Train Loss: 1.1748, Learning Rate: 3.96e-05
2025-12-10 07:53:50 - INFO - Epoch: 24.96, Step: 98870, Train Loss: 1.2378, Learning Rate: 3.96e-05
2025-12-10 07:54:01 - INFO - Epoch: 24.96, Step: 98880, Train Loss: 1.1894, Learning Rate: 3.96e-05
2025-12-10 07:54:12 - INFO - Epoch: 24.97, Step: 98890, Train Loss: 1.1873, Learning Rate: 3.96e-05
2025-12-10 07:54:24 - INFO - Epoch: 24.97, Step: 98900, Train Loss: 1.2381, Learning Rate: 3.96e-05
2025-12-10 07:54:35 - INFO - Epoch: 24.97, Step: 98910, Train Loss: 1.2097, Learning Rate: 3.96e-05
2025-12-10 07:54:46 - INFO - Epoch: 24.97, Step: 98920, Train Loss: 1.1684, Learning Rate: 3.95e-05
2025-12-10 07:54:57 - INFO - Epoch: 24.98, Step: 98930, Train Loss: 1.1825, Learning Rate: 3.95e-05
2025-12-10 07:55:08 - INFO - Epoch: 24.98, Step: 98940, Train Loss: 1.2308, Learning Rate: 3.95e-05
2025-12-10 07:55:19 - INFO - Epoch: 24.98, Step: 98950, Train Loss: 1.2154, Learning Rate: 3.95e-05
2025-12-10 07:55:30 - INFO - Epoch: 24.98, Step: 98960, Train Loss: 1.2194, Learning Rate: 3.95e-05
2025-12-10 07:55:42 - INFO - Epoch: 24.99, Step: 98970, Train Loss: 1.2141, Learning Rate: 3.95e-05
2025-12-10 07:55:53 - INFO - Epoch: 24.99, Step: 98980, Train Loss: 1.2711, Learning Rate: 3.95e-05
2025-12-10 07:56:04 - INFO - Epoch: 24.99, Step: 98990, Train Loss: 1.2187, Learning Rate: 3.95e-05
2025-12-10 07:56:15 - INFO - Epoch: 24.99, Step: 99000, Train Loss: 1.2446, Learning Rate: 3.95e-05
2025-12-10 07:56:26 - INFO - Epoch: 25.00, Step: 99010, Train Loss: 1.2525, Learning Rate: 3.95e-05
2025-12-10 07:56:37 - INFO - Epoch: 25.00, Step: 99020, Train Loss: 1.2516, Learning Rate: 3.95e-05
2025-12-10 07:56:49 - INFO - Epoch: 25.00, Step: 99030, Train Loss: 1.1970, Learning Rate: 3.95e-05
2025-12-10 07:57:00 - INFO - Epoch: 25.00, Step: 99040, Train Loss: 1.2372, Learning Rate: 3.95e-05
2025-12-10 07:57:11 - INFO - Epoch: 25.01, Step: 99050, Train Loss: 1.1909, Learning Rate: 3.95e-05
2025-12-10 07:57:22 - INFO - Epoch: 25.01, Step: 99060, Train Loss: 1.1892, Learning Rate: 3.95e-05
2025-12-10 07:57:33 - INFO - Epoch: 25.01, Step: 99070, Train Loss: 1.2235, Learning Rate: 3.94e-05
2025-12-10 07:57:44 - INFO - Epoch: 25.01, Step: 99080, Train Loss: 1.2128, Learning Rate: 3.94e-05
2025-12-10 07:57:55 - INFO - Epoch: 25.02, Step: 99090, Train Loss: 1.2021, Learning Rate: 3.94e-05
2025-12-10 07:58:07 - INFO - Epoch: 25.02, Step: 99100, Train Loss: 1.1658, Learning Rate: 3.94e-05
2025-12-10 07:58:18 - INFO - Epoch: 25.02, Step: 99110, Train Loss: 1.1955, Learning Rate: 3.94e-05
2025-12-10 07:58:29 - INFO - Epoch: 25.02, Step: 99120, Train Loss: 1.1955, Learning Rate: 3.94e-05
2025-12-10 07:58:40 - INFO - Epoch: 25.03, Step: 99130, Train Loss: 1.2164, Learning Rate: 3.94e-05
2025-12-10 07:58:51 - INFO - Epoch: 25.03, Step: 99140, Train Loss: 1.1775, Learning Rate: 3.94e-05
2025-12-10 07:59:02 - INFO - Epoch: 25.03, Step: 99150, Train Loss: 1.2066, Learning Rate: 3.94e-05
2025-12-10 07:59:14 - INFO - Epoch: 25.03, Step: 99160, Train Loss: 1.1964, Learning Rate: 3.94e-05
2025-12-10 07:59:25 - INFO - Epoch: 25.04, Step: 99170, Train Loss: 1.2228, Learning Rate: 3.94e-05
2025-12-10 07:59:36 - INFO - Epoch: 25.04, Step: 99180, Train Loss: 1.1993, Learning Rate: 3.94e-05
2025-12-10 07:59:47 - INFO - Epoch: 25.04, Step: 99190, Train Loss: 1.2122, Learning Rate: 3.94e-05
2025-12-10 07:59:58 - INFO - Epoch: 25.04, Step: 99200, Train Loss: 1.2010, Learning Rate: 3.94e-05
2025-12-10 08:00:09 - INFO - Epoch: 25.05, Step: 99210, Train Loss: 1.2248, Learning Rate: 3.94e-05
2025-12-10 08:00:21 - INFO - Epoch: 25.05, Step: 99220, Train Loss: 1.2119, Learning Rate: 3.93e-05
2025-12-10 08:00:32 - INFO - Epoch: 25.05, Step: 99230, Train Loss: 1.1860, Learning Rate: 3.93e-05
2025-12-10 08:00:43 - INFO - Epoch: 25.05, Step: 99240, Train Loss: 1.1654, Learning Rate: 3.93e-05
2025-12-10 08:00:54 - INFO - Epoch: 25.06, Step: 99250, Train Loss: 1.1615, Learning Rate: 3.93e-05
2025-12-10 08:01:05 - INFO - Epoch: 25.06, Step: 99260, Train Loss: 1.1898, Learning Rate: 3.93e-05
2025-12-10 08:01:16 - INFO - Epoch: 25.06, Step: 99270, Train Loss: 1.2363, Learning Rate: 3.93e-05
2025-12-10 08:01:27 - INFO - Epoch: 25.06, Step: 99280, Train Loss: 1.2064, Learning Rate: 3.93e-05
2025-12-10 08:01:39 - INFO - Epoch: 25.07, Step: 99290, Train Loss: 1.2046, Learning Rate: 3.93e-05
2025-12-10 08:01:50 - INFO - Epoch: 25.07, Step: 99300, Train Loss: 1.2546, Learning Rate: 3.93e-05
2025-12-10 08:02:01 - INFO - Epoch: 25.07, Step: 99310, Train Loss: 1.2455, Learning Rate: 3.93e-05
2025-12-10 08:02:12 - INFO - Epoch: 25.07, Step: 99320, Train Loss: 1.2217, Learning Rate: 3.93e-05
2025-12-10 08:02:23 - INFO - Epoch: 25.08, Step: 99330, Train Loss: 1.2225, Learning Rate: 3.93e-05
2025-12-10 08:02:34 - INFO - Epoch: 25.08, Step: 99340, Train Loss: 1.2241, Learning Rate: 3.93e-05
2025-12-10 08:02:46 - INFO - Epoch: 25.08, Step: 99350, Train Loss: 1.2053, Learning Rate: 3.93e-05
2025-12-10 08:02:57 - INFO - Epoch: 25.08, Step: 99360, Train Loss: 1.2181, Learning Rate: 3.93e-05
2025-12-10 08:03:08 - INFO - Epoch: 25.09, Step: 99370, Train Loss: 1.1897, Learning Rate: 3.92e-05
2025-12-10 08:03:19 - INFO - Epoch: 25.09, Step: 99380, Train Loss: 1.1905, Learning Rate: 3.92e-05
2025-12-10 08:03:30 - INFO - Epoch: 25.09, Step: 99390, Train Loss: 1.1976, Learning Rate: 3.92e-05
2025-12-10 08:03:41 - INFO - Epoch: 25.09, Step: 99400, Train Loss: 1.2218, Learning Rate: 3.92e-05
2025-12-10 08:03:52 - INFO - Epoch: 25.10, Step: 99410, Train Loss: 1.1883, Learning Rate: 3.92e-05
2025-12-10 08:04:04 - INFO - Epoch: 25.10, Step: 99420, Train Loss: 1.2126, Learning Rate: 3.92e-05
2025-12-10 08:04:15 - INFO - Epoch: 25.10, Step: 99430, Train Loss: 1.1840, Learning Rate: 3.92e-05
2025-12-10 08:04:26 - INFO - Epoch: 25.10, Step: 99440, Train Loss: 1.2122, Learning Rate: 3.92e-05
2025-12-10 08:04:37 - INFO - Epoch: 25.11, Step: 99450, Train Loss: 1.1898, Learning Rate: 3.92e-05
2025-12-10 08:04:48 - INFO - Epoch: 25.11, Step: 99460, Train Loss: 1.1833, Learning Rate: 3.92e-05
2025-12-10 08:04:59 - INFO - Epoch: 25.11, Step: 99470, Train Loss: 1.1664, Learning Rate: 3.92e-05
2025-12-10 08:05:11 - INFO - Epoch: 25.11, Step: 99480, Train Loss: 1.1873, Learning Rate: 3.92e-05
2025-12-10 08:05:22 - INFO - Epoch: 25.12, Step: 99490, Train Loss: 1.2566, Learning Rate: 3.92e-05
2025-12-10 08:05:33 - INFO - Epoch: 25.12, Step: 99500, Train Loss: 1.2242, Learning Rate: 3.92e-05
2025-12-10 08:05:44 - INFO - Epoch: 25.12, Step: 99510, Train Loss: 1.1434, Learning Rate: 3.92e-05
2025-12-10 08:05:55 - INFO - Epoch: 25.12, Step: 99520, Train Loss: 1.2038, Learning Rate: 3.91e-05
2025-12-10 08:06:06 - INFO - Epoch: 25.13, Step: 99530, Train Loss: 1.1934, Learning Rate: 3.91e-05
2025-12-10 08:06:17 - INFO - Epoch: 25.13, Step: 99540, Train Loss: 1.2301, Learning Rate: 3.91e-05
2025-12-10 08:06:29 - INFO - Epoch: 25.13, Step: 99550, Train Loss: 1.2210, Learning Rate: 3.91e-05
2025-12-10 08:06:40 - INFO - Epoch: 25.14, Step: 99560, Train Loss: 1.1878, Learning Rate: 3.91e-05
2025-12-10 08:06:51 - INFO - Epoch: 25.14, Step: 99570, Train Loss: 1.2434, Learning Rate: 3.91e-05
2025-12-10 08:07:02 - INFO - Epoch: 25.14, Step: 99580, Train Loss: 1.2355, Learning Rate: 3.91e-05
2025-12-10 08:07:13 - INFO - Epoch: 25.14, Step: 99590, Train Loss: 1.2069, Learning Rate: 3.91e-05
2025-12-10 08:07:24 - INFO - Epoch: 25.15, Step: 99600, Train Loss: 1.2156, Learning Rate: 3.91e-05
2025-12-10 08:07:36 - INFO - Epoch: 25.15, Step: 99610, Train Loss: 1.1817, Learning Rate: 3.91e-05
2025-12-10 08:07:47 - INFO - Epoch: 25.15, Step: 99620, Train Loss: 1.1890, Learning Rate: 3.91e-05
2025-12-10 08:07:58 - INFO - Epoch: 25.15, Step: 99630, Train Loss: 1.1795, Learning Rate: 3.91e-05
2025-12-10 08:08:09 - INFO - Epoch: 25.16, Step: 99640, Train Loss: 1.2103, Learning Rate: 3.91e-05
2025-12-10 08:08:20 - INFO - Epoch: 25.16, Step: 99650, Train Loss: 1.1962, Learning Rate: 3.91e-05
2025-12-10 08:08:31 - INFO - Epoch: 25.16, Step: 99660, Train Loss: 1.2240, Learning Rate: 3.91e-05
2025-12-10 08:08:43 - INFO - Epoch: 25.16, Step: 99670, Train Loss: 1.2118, Learning Rate: 3.90e-05
2025-12-10 08:08:54 - INFO - Epoch: 25.17, Step: 99680, Train Loss: 1.2119, Learning Rate: 3.90e-05
2025-12-10 08:09:05 - INFO - Epoch: 25.17, Step: 99690, Train Loss: 1.1992, Learning Rate: 3.90e-05
2025-12-10 08:09:16 - INFO - Epoch: 25.17, Step: 99700, Train Loss: 1.2059, Learning Rate: 3.90e-05
2025-12-10 08:09:27 - INFO - Epoch: 25.17, Step: 99710, Train Loss: 1.2183, Learning Rate: 3.90e-05
2025-12-10 08:09:38 - INFO - Epoch: 25.18, Step: 99720, Train Loss: 1.2187, Learning Rate: 3.90e-05
2025-12-10 08:09:49 - INFO - Epoch: 25.18, Step: 99730, Train Loss: 1.2051, Learning Rate: 3.90e-05
2025-12-10 08:10:01 - INFO - Epoch: 25.18, Step: 99740, Train Loss: 1.2538, Learning Rate: 3.90e-05
2025-12-10 08:10:12 - INFO - Epoch: 25.18, Step: 99750, Train Loss: 1.2306, Learning Rate: 3.90e-05
2025-12-10 08:10:23 - INFO - Epoch: 25.19, Step: 99760, Train Loss: 1.2482, Learning Rate: 3.90e-05
2025-12-10 08:10:34 - INFO - Epoch: 25.19, Step: 99770, Train Loss: 1.2135, Learning Rate: 3.90e-05
2025-12-10 08:10:45 - INFO - Epoch: 25.19, Step: 99780, Train Loss: 1.2056, Learning Rate: 3.90e-05
2025-12-10 08:10:56 - INFO - Epoch: 25.19, Step: 99790, Train Loss: 1.2280, Learning Rate: 3.90e-05
2025-12-10 08:11:08 - INFO - Epoch: 25.20, Step: 99800, Train Loss: 1.2072, Learning Rate: 3.90e-05
2025-12-10 08:11:19 - INFO - Epoch: 25.20, Step: 99810, Train Loss: 1.1812, Learning Rate: 3.90e-05
2025-12-10 08:11:30 - INFO - Epoch: 25.20, Step: 99820, Train Loss: 1.1921, Learning Rate: 3.89e-05
2025-12-10 08:11:41 - INFO - Epoch: 25.20, Step: 99830, Train Loss: 1.2440, Learning Rate: 3.89e-05
2025-12-10 08:11:52 - INFO - Epoch: 25.21, Step: 99840, Train Loss: 1.1921, Learning Rate: 3.89e-05
2025-12-10 08:12:03 - INFO - Epoch: 25.21, Step: 99850, Train Loss: 1.1918, Learning Rate: 3.89e-05
2025-12-10 08:12:14 - INFO - Epoch: 25.21, Step: 99860, Train Loss: 1.1949, Learning Rate: 3.89e-05
2025-12-10 08:12:26 - INFO - Epoch: 25.21, Step: 99870, Train Loss: 1.2395, Learning Rate: 3.89e-05
2025-12-10 08:12:37 - INFO - Epoch: 25.22, Step: 99880, Train Loss: 1.1539, Learning Rate: 3.89e-05
2025-12-10 08:12:48 - INFO - Epoch: 25.22, Step: 99890, Train Loss: 1.2247, Learning Rate: 3.89e-05
2025-12-10 08:12:59 - INFO - Epoch: 25.22, Step: 99900, Train Loss: 1.2350, Learning Rate: 3.89e-05
2025-12-10 08:13:10 - INFO - Epoch: 25.22, Step: 99910, Train Loss: 1.1902, Learning Rate: 3.89e-05
2025-12-10 08:13:21 - INFO - Epoch: 25.23, Step: 99920, Train Loss: 1.2164, Learning Rate: 3.89e-05
2025-12-10 08:13:33 - INFO - Epoch: 25.23, Step: 99930, Train Loss: 1.1776, Learning Rate: 3.89e-05
2025-12-10 08:13:44 - INFO - Epoch: 25.23, Step: 99940, Train Loss: 1.2120, Learning Rate: 3.89e-05
2025-12-10 08:13:55 - INFO - Epoch: 25.23, Step: 99950, Train Loss: 1.2096, Learning Rate: 3.89e-05
2025-12-10 08:14:06 - INFO - Epoch: 25.24, Step: 99960, Train Loss: 1.2121, Learning Rate: 3.89e-05
2025-12-10 08:14:17 - INFO - Epoch: 25.24, Step: 99970, Train Loss: 1.2057, Learning Rate: 3.88e-05
2025-12-10 08:14:28 - INFO - Epoch: 25.24, Step: 99980, Train Loss: 1.2225, Learning Rate: 3.88e-05
2025-12-10 08:14:39 - INFO - Epoch: 25.24, Step: 99990, Train Loss: 1.2144, Learning Rate: 3.88e-05
2025-12-10 08:14:51 - INFO - Epoch: 25.25, Step: 100000, Train Loss: 1.1788, Learning Rate: 3.88e-05
2025-12-10 08:15:02 - INFO - Epoch: 25.25, Step: 100010, Train Loss: 1.1925, Learning Rate: 3.88e-05
2025-12-10 08:15:13 - INFO - Epoch: 25.25, Step: 100020, Train Loss: 1.2415, Learning Rate: 3.88e-05
2025-12-10 08:15:24 - INFO - Epoch: 25.25, Step: 100030, Train Loss: 1.2243, Learning Rate: 3.88e-05
2025-12-10 08:15:35 - INFO - Epoch: 25.26, Step: 100040, Train Loss: 1.2141, Learning Rate: 3.88e-05
2025-12-10 08:15:46 - INFO - Epoch: 25.26, Step: 100050, Train Loss: 1.2375, Learning Rate: 3.88e-05
2025-12-10 08:15:58 - INFO - Epoch: 25.26, Step: 100060, Train Loss: 1.2157, Learning Rate: 3.88e-05
2025-12-10 08:16:09 - INFO - Epoch: 25.26, Step: 100070, Train Loss: 1.2201, Learning Rate: 3.88e-05
2025-12-10 08:16:20 - INFO - Epoch: 25.27, Step: 100080, Train Loss: 1.2136, Learning Rate: 3.88e-05
2025-12-10 08:16:31 - INFO - Epoch: 25.27, Step: 100090, Train Loss: 1.1772, Learning Rate: 3.88e-05
2025-12-10 08:16:42 - INFO - Epoch: 25.27, Step: 100100, Train Loss: 1.1954, Learning Rate: 3.88e-05
2025-12-10 08:16:53 - INFO - Epoch: 25.27, Step: 100110, Train Loss: 1.2376, Learning Rate: 3.88e-05
2025-12-10 08:17:05 - INFO - Epoch: 25.28, Step: 100120, Train Loss: 1.2316, Learning Rate: 3.87e-05
2025-12-10 08:17:16 - INFO - Epoch: 25.28, Step: 100130, Train Loss: 1.1797, Learning Rate: 3.87e-05
2025-12-10 08:17:27 - INFO - Epoch: 25.28, Step: 100140, Train Loss: 1.1902, Learning Rate: 3.87e-05
2025-12-10 08:17:38 - INFO - Epoch: 25.28, Step: 100150, Train Loss: 1.1762, Learning Rate: 3.87e-05
2025-12-10 08:17:49 - INFO - Epoch: 25.29, Step: 100160, Train Loss: 1.2221, Learning Rate: 3.87e-05
2025-12-10 08:18:00 - INFO - Epoch: 25.29, Step: 100170, Train Loss: 1.1728, Learning Rate: 3.87e-05
2025-12-10 08:18:11 - INFO - Epoch: 25.29, Step: 100180, Train Loss: 1.1923, Learning Rate: 3.87e-05
2025-12-10 08:18:23 - INFO - Epoch: 25.29, Step: 100190, Train Loss: 1.2085, Learning Rate: 3.87e-05
2025-12-10 08:18:34 - INFO - Epoch: 25.30, Step: 100200, Train Loss: 1.1883, Learning Rate: 3.87e-05
2025-12-10 08:18:45 - INFO - Epoch: 25.30, Step: 100210, Train Loss: 1.2242, Learning Rate: 3.87e-05
2025-12-10 08:18:56 - INFO - Epoch: 25.30, Step: 100220, Train Loss: 1.1598, Learning Rate: 3.87e-05
2025-12-10 08:19:07 - INFO - Epoch: 25.30, Step: 100230, Train Loss: 1.2314, Learning Rate: 3.87e-05
2025-12-10 08:19:18 - INFO - Epoch: 25.31, Step: 100240, Train Loss: 1.2694, Learning Rate: 3.87e-05
2025-12-10 08:19:30 - INFO - Epoch: 25.31, Step: 100250, Train Loss: 1.2023, Learning Rate: 3.87e-05
2025-12-10 08:19:41 - INFO - Epoch: 25.31, Step: 100260, Train Loss: 1.1874, Learning Rate: 3.87e-05
2025-12-10 08:19:52 - INFO - Epoch: 25.31, Step: 100270, Train Loss: 1.1876, Learning Rate: 3.86e-05
2025-12-10 08:20:03 - INFO - Epoch: 25.32, Step: 100280, Train Loss: 1.2027, Learning Rate: 3.86e-05
2025-12-10 08:20:14 - INFO - Epoch: 25.32, Step: 100290, Train Loss: 1.1884, Learning Rate: 3.86e-05
2025-12-10 08:20:25 - INFO - Epoch: 25.32, Step: 100300, Train Loss: 1.2058, Learning Rate: 3.86e-05
2025-12-10 08:20:36 - INFO - Epoch: 25.32, Step: 100310, Train Loss: 1.2252, Learning Rate: 3.86e-05
2025-12-10 08:20:48 - INFO - Epoch: 25.33, Step: 100320, Train Loss: 1.1783, Learning Rate: 3.86e-05
2025-12-10 08:20:59 - INFO - Epoch: 25.33, Step: 100330, Train Loss: 1.1750, Learning Rate: 3.86e-05
2025-12-10 08:21:10 - INFO - Epoch: 25.33, Step: 100340, Train Loss: 1.2021, Learning Rate: 3.86e-05
2025-12-10 08:21:21 - INFO - Epoch: 25.33, Step: 100350, Train Loss: 1.2004, Learning Rate: 3.86e-05
2025-12-10 08:21:32 - INFO - Epoch: 25.34, Step: 100360, Train Loss: 1.2270, Learning Rate: 3.86e-05
2025-12-10 08:21:43 - INFO - Epoch: 25.34, Step: 100370, Train Loss: 1.1763, Learning Rate: 3.86e-05
2025-12-10 08:21:55 - INFO - Epoch: 25.34, Step: 100380, Train Loss: 1.2091, Learning Rate: 3.86e-05
2025-12-10 08:22:06 - INFO - Epoch: 25.34, Step: 100390, Train Loss: 1.1656, Learning Rate: 3.86e-05
2025-12-10 08:22:17 - INFO - Epoch: 25.35, Step: 100400, Train Loss: 1.2489, Learning Rate: 3.86e-05
2025-12-10 08:22:28 - INFO - Epoch: 25.35, Step: 100410, Train Loss: 1.2208, Learning Rate: 3.86e-05
2025-12-10 08:22:39 - INFO - Epoch: 25.35, Step: 100420, Train Loss: 1.2122, Learning Rate: 3.85e-05
2025-12-10 08:22:50 - INFO - Epoch: 25.35, Step: 100430, Train Loss: 1.1858, Learning Rate: 3.85e-05
2025-12-10 08:23:02 - INFO - Epoch: 25.36, Step: 100440, Train Loss: 1.2437, Learning Rate: 3.85e-05
2025-12-10 08:23:13 - INFO - Epoch: 25.36, Step: 100450, Train Loss: 1.2323, Learning Rate: 3.85e-05
2025-12-10 08:23:24 - INFO - Epoch: 25.36, Step: 100460, Train Loss: 1.1890, Learning Rate: 3.85e-05
2025-12-10 08:23:35 - INFO - Epoch: 25.36, Step: 100470, Train Loss: 1.2419, Learning Rate: 3.85e-05
2025-12-10 08:23:46 - INFO - Epoch: 25.37, Step: 100480, Train Loss: 1.2161, Learning Rate: 3.85e-05
2025-12-10 08:23:57 - INFO - Epoch: 25.37, Step: 100490, Train Loss: 1.1776, Learning Rate: 3.85e-05
2025-12-10 08:24:08 - INFO - Epoch: 25.37, Step: 100500, Train Loss: 1.2545, Learning Rate: 3.85e-05
2025-12-10 08:24:20 - INFO - Epoch: 25.37, Step: 100510, Train Loss: 1.1827, Learning Rate: 3.85e-05
2025-12-10 08:24:31 - INFO - Epoch: 25.38, Step: 100520, Train Loss: 1.2087, Learning Rate: 3.85e-05
2025-12-10 08:24:42 - INFO - Epoch: 25.38, Step: 100530, Train Loss: 1.1944, Learning Rate: 3.85e-05
2025-12-10 08:24:53 - INFO - Epoch: 25.38, Step: 100540, Train Loss: 1.1704, Learning Rate: 3.85e-05
2025-12-10 08:25:04 - INFO - Epoch: 25.39, Step: 100550, Train Loss: 1.1777, Learning Rate: 3.85e-05
2025-12-10 08:25:15 - INFO - Epoch: 25.39, Step: 100560, Train Loss: 1.1944, Learning Rate: 3.85e-05
2025-12-10 08:25:27 - INFO - Epoch: 25.39, Step: 100570, Train Loss: 1.2253, Learning Rate: 3.84e-05
2025-12-10 08:25:38 - INFO - Epoch: 25.39, Step: 100580, Train Loss: 1.2023, Learning Rate: 3.84e-05
2025-12-10 08:25:49 - INFO - Epoch: 25.40, Step: 100590, Train Loss: 1.2178, Learning Rate: 3.84e-05
2025-12-10 08:26:00 - INFO - Epoch: 25.40, Step: 100600, Train Loss: 1.2058, Learning Rate: 3.84e-05
2025-12-10 08:26:11 - INFO - Epoch: 25.40, Step: 100610, Train Loss: 1.2053, Learning Rate: 3.84e-05
2025-12-10 08:26:22 - INFO - Epoch: 25.40, Step: 100620, Train Loss: 1.2079, Learning Rate: 3.84e-05
2025-12-10 08:26:33 - INFO - Epoch: 25.41, Step: 100630, Train Loss: 1.1784, Learning Rate: 3.84e-05
2025-12-10 08:26:45 - INFO - Epoch: 25.41, Step: 100640, Train Loss: 1.2171, Learning Rate: 3.84e-05
2025-12-10 08:26:56 - INFO - Epoch: 25.41, Step: 100650, Train Loss: 1.2078, Learning Rate: 3.84e-05
2025-12-10 08:27:07 - INFO - Epoch: 25.41, Step: 100660, Train Loss: 1.2371, Learning Rate: 3.84e-05
2025-12-10 08:27:18 - INFO - Epoch: 25.42, Step: 100670, Train Loss: 1.2028, Learning Rate: 3.84e-05
2025-12-10 08:27:29 - INFO - Epoch: 25.42, Step: 100680, Train Loss: 1.1656, Learning Rate: 3.84e-05
2025-12-10 08:27:40 - INFO - Epoch: 25.42, Step: 100690, Train Loss: 1.2536, Learning Rate: 3.84e-05
2025-12-10 08:27:52 - INFO - Epoch: 25.42, Step: 100700, Train Loss: 1.1822, Learning Rate: 3.84e-05
2025-12-10 08:28:03 - INFO - Epoch: 25.43, Step: 100710, Train Loss: 1.2138, Learning Rate: 3.84e-05
2025-12-10 08:28:14 - INFO - Epoch: 25.43, Step: 100720, Train Loss: 1.1969, Learning Rate: 3.83e-05
2025-12-10 08:28:25 - INFO - Epoch: 25.43, Step: 100730, Train Loss: 1.2445, Learning Rate: 3.83e-05
2025-12-10 08:28:36 - INFO - Epoch: 25.43, Step: 100740, Train Loss: 1.2201, Learning Rate: 3.83e-05
2025-12-10 08:28:47 - INFO - Epoch: 25.44, Step: 100750, Train Loss: 1.1876, Learning Rate: 3.83e-05
2025-12-10 08:28:58 - INFO - Epoch: 25.44, Step: 100760, Train Loss: 1.2242, Learning Rate: 3.83e-05
2025-12-10 08:29:10 - INFO - Epoch: 25.44, Step: 100770, Train Loss: 1.2294, Learning Rate: 3.83e-05
2025-12-10 08:29:21 - INFO - Epoch: 25.44, Step: 100780, Train Loss: 1.1966, Learning Rate: 3.83e-05
2025-12-10 08:29:32 - INFO - Epoch: 25.45, Step: 100790, Train Loss: 1.2172, Learning Rate: 3.83e-05
2025-12-10 08:29:43 - INFO - Epoch: 25.45, Step: 100800, Train Loss: 1.1987, Learning Rate: 3.83e-05
2025-12-10 08:29:54 - INFO - Epoch: 25.45, Step: 100810, Train Loss: 1.2331, Learning Rate: 3.83e-05
2025-12-10 08:30:05 - INFO - Epoch: 25.45, Step: 100820, Train Loss: 1.1938, Learning Rate: 3.83e-05
2025-12-10 08:30:17 - INFO - Epoch: 25.46, Step: 100830, Train Loss: 1.2013, Learning Rate: 3.83e-05
2025-12-10 08:30:28 - INFO - Epoch: 25.46, Step: 100840, Train Loss: 1.2403, Learning Rate: 3.83e-05
2025-12-10 08:30:39 - INFO - Epoch: 25.46, Step: 100850, Train Loss: 1.2421, Learning Rate: 3.83e-05
2025-12-10 08:30:50 - INFO - Epoch: 25.46, Step: 100860, Train Loss: 1.2180, Learning Rate: 3.83e-05
2025-12-10 08:31:01 - INFO - Epoch: 25.47, Step: 100870, Train Loss: 1.2036, Learning Rate: 3.82e-05
2025-12-10 08:31:12 - INFO - Epoch: 25.47, Step: 100880, Train Loss: 1.2016, Learning Rate: 3.82e-05
2025-12-10 08:31:24 - INFO - Epoch: 25.47, Step: 100890, Train Loss: 1.2497, Learning Rate: 3.82e-05
2025-12-10 08:31:35 - INFO - Epoch: 25.47, Step: 100900, Train Loss: 1.1579, Learning Rate: 3.82e-05
2025-12-10 08:31:46 - INFO - Epoch: 25.48, Step: 100910, Train Loss: 1.2064, Learning Rate: 3.82e-05
2025-12-10 08:31:57 - INFO - Epoch: 25.48, Step: 100920, Train Loss: 1.2053, Learning Rate: 3.82e-05
2025-12-10 08:32:08 - INFO - Epoch: 25.48, Step: 100930, Train Loss: 1.2080, Learning Rate: 3.82e-05
2025-12-10 08:32:19 - INFO - Epoch: 25.48, Step: 100940, Train Loss: 1.1951, Learning Rate: 3.82e-05
2025-12-10 08:32:30 - INFO - Epoch: 25.49, Step: 100950, Train Loss: 1.2103, Learning Rate: 3.82e-05
2025-12-10 08:32:42 - INFO - Epoch: 25.49, Step: 100960, Train Loss: 1.2141, Learning Rate: 3.82e-05
2025-12-10 08:32:53 - INFO - Epoch: 25.49, Step: 100970, Train Loss: 1.1805, Learning Rate: 3.82e-05
2025-12-10 08:33:04 - INFO - Epoch: 25.49, Step: 100980, Train Loss: 1.2237, Learning Rate: 3.82e-05
2025-12-10 08:33:15 - INFO - Epoch: 25.50, Step: 100990, Train Loss: 1.1904, Learning Rate: 3.82e-05
2025-12-10 08:33:26 - INFO - Epoch: 25.50, Step: 101000, Train Loss: 1.1969, Learning Rate: 3.82e-05
2025-12-10 08:33:37 - INFO - Epoch: 25.50, Step: 101010, Train Loss: 1.1961, Learning Rate: 3.82e-05
2025-12-10 08:33:49 - INFO - Epoch: 25.50, Step: 101020, Train Loss: 1.2193, Learning Rate: 3.81e-05
2025-12-10 08:34:00 - INFO - Epoch: 25.51, Step: 101030, Train Loss: 1.2180, Learning Rate: 3.81e-05
2025-12-10 08:34:11 - INFO - Epoch: 25.51, Step: 101040, Train Loss: 1.2121, Learning Rate: 3.81e-05
2025-12-10 08:34:22 - INFO - Epoch: 25.51, Step: 101050, Train Loss: 1.2577, Learning Rate: 3.81e-05
2025-12-10 08:34:33 - INFO - Epoch: 25.51, Step: 101060, Train Loss: 1.2066, Learning Rate: 3.81e-05
2025-12-10 08:34:44 - INFO - Epoch: 25.52, Step: 101070, Train Loss: 1.1664, Learning Rate: 3.81e-05
2025-12-10 08:34:55 - INFO - Epoch: 25.52, Step: 101080, Train Loss: 1.1916, Learning Rate: 3.81e-05
2025-12-10 08:35:07 - INFO - Epoch: 25.52, Step: 101090, Train Loss: 1.2294, Learning Rate: 3.81e-05
2025-12-10 08:35:18 - INFO - Epoch: 25.52, Step: 101100, Train Loss: 1.2120, Learning Rate: 3.81e-05
2025-12-10 08:35:29 - INFO - Epoch: 25.53, Step: 101110, Train Loss: 1.1699, Learning Rate: 3.81e-05
2025-12-10 08:35:40 - INFO - Epoch: 25.53, Step: 101120, Train Loss: 1.2156, Learning Rate: 3.81e-05
2025-12-10 08:35:51 - INFO - Epoch: 25.53, Step: 101130, Train Loss: 1.2358, Learning Rate: 3.81e-05
2025-12-10 08:36:02 - INFO - Epoch: 25.53, Step: 101140, Train Loss: 1.2338, Learning Rate: 3.81e-05
2025-12-10 08:36:14 - INFO - Epoch: 25.54, Step: 101150, Train Loss: 1.2095, Learning Rate: 3.81e-05
2025-12-10 08:36:25 - INFO - Epoch: 25.54, Step: 101160, Train Loss: 1.2689, Learning Rate: 3.81e-05
2025-12-10 08:36:36 - INFO - Epoch: 25.54, Step: 101170, Train Loss: 1.2147, Learning Rate: 3.80e-05
2025-12-10 08:36:47 - INFO - Epoch: 25.54, Step: 101180, Train Loss: 1.2327, Learning Rate: 3.80e-05
2025-12-10 08:36:58 - INFO - Epoch: 25.55, Step: 101190, Train Loss: 1.1995, Learning Rate: 3.80e-05
2025-12-10 08:37:09 - INFO - Epoch: 25.55, Step: 101200, Train Loss: 1.1987, Learning Rate: 3.80e-05
2025-12-10 08:37:20 - INFO - Epoch: 25.55, Step: 101210, Train Loss: 1.2314, Learning Rate: 3.80e-05
2025-12-10 08:37:32 - INFO - Epoch: 25.55, Step: 101220, Train Loss: 1.1940, Learning Rate: 3.80e-05
2025-12-10 08:37:43 - INFO - Epoch: 25.56, Step: 101230, Train Loss: 1.2399, Learning Rate: 3.80e-05
2025-12-10 08:37:54 - INFO - Epoch: 25.56, Step: 101240, Train Loss: 1.2084, Learning Rate: 3.80e-05
2025-12-10 08:38:05 - INFO - Epoch: 25.56, Step: 101250, Train Loss: 1.2125, Learning Rate: 3.80e-05
2025-12-10 08:38:16 - INFO - Epoch: 25.56, Step: 101260, Train Loss: 1.1836, Learning Rate: 3.80e-05
2025-12-10 08:38:27 - INFO - Epoch: 25.57, Step: 101270, Train Loss: 1.2253, Learning Rate: 3.80e-05
2025-12-10 08:38:39 - INFO - Epoch: 25.57, Step: 101280, Train Loss: 1.2101, Learning Rate: 3.80e-05
2025-12-10 08:38:50 - INFO - Epoch: 25.57, Step: 101290, Train Loss: 1.2055, Learning Rate: 3.80e-05
2025-12-10 08:39:01 - INFO - Epoch: 25.57, Step: 101300, Train Loss: 1.2128, Learning Rate: 3.80e-05
2025-12-10 08:39:12 - INFO - Epoch: 25.58, Step: 101310, Train Loss: 1.2179, Learning Rate: 3.80e-05
2025-12-10 08:39:23 - INFO - Epoch: 25.58, Step: 101320, Train Loss: 1.1875, Learning Rate: 3.79e-05
2025-12-10 08:39:34 - INFO - Epoch: 25.58, Step: 101330, Train Loss: 1.1834, Learning Rate: 3.79e-05
2025-12-10 08:39:46 - INFO - Epoch: 25.58, Step: 101340, Train Loss: 1.2010, Learning Rate: 3.79e-05
2025-12-10 08:39:57 - INFO - Epoch: 25.59, Step: 101350, Train Loss: 1.1903, Learning Rate: 3.79e-05
2025-12-10 08:40:08 - INFO - Epoch: 25.59, Step: 101360, Train Loss: 1.1938, Learning Rate: 3.79e-05
2025-12-10 08:40:19 - INFO - Epoch: 25.59, Step: 101370, Train Loss: 1.1707, Learning Rate: 3.79e-05
2025-12-10 08:40:30 - INFO - Epoch: 25.59, Step: 101380, Train Loss: 1.1752, Learning Rate: 3.79e-05
2025-12-10 08:40:41 - INFO - Epoch: 25.60, Step: 101390, Train Loss: 1.1906, Learning Rate: 3.79e-05
2025-12-10 08:40:52 - INFO - Epoch: 25.60, Step: 101400, Train Loss: 1.2578, Learning Rate: 3.79e-05
2025-12-10 08:41:04 - INFO - Epoch: 25.60, Step: 101410, Train Loss: 1.1992, Learning Rate: 3.79e-05
2025-12-10 08:41:15 - INFO - Epoch: 25.60, Step: 101420, Train Loss: 1.2112, Learning Rate: 3.79e-05
2025-12-10 08:41:26 - INFO - Epoch: 25.61, Step: 101430, Train Loss: 1.1832, Learning Rate: 3.79e-05
2025-12-10 08:41:37 - INFO - Epoch: 25.61, Step: 101440, Train Loss: 1.1934, Learning Rate: 3.79e-05
2025-12-10 08:41:48 - INFO - Epoch: 25.61, Step: 101450, Train Loss: 1.2060, Learning Rate: 3.79e-05
2025-12-10 08:41:59 - INFO - Epoch: 25.61, Step: 101460, Train Loss: 1.1960, Learning Rate: 3.79e-05
2025-12-10 08:42:11 - INFO - Epoch: 25.62, Step: 101470, Train Loss: 1.2315, Learning Rate: 3.78e-05
2025-12-10 08:42:22 - INFO - Epoch: 25.62, Step: 101480, Train Loss: 1.2139, Learning Rate: 3.78e-05
2025-12-10 08:42:33 - INFO - Epoch: 25.62, Step: 101490, Train Loss: 1.2358, Learning Rate: 3.78e-05
2025-12-10 08:42:44 - INFO - Epoch: 25.62, Step: 101500, Train Loss: 1.1920, Learning Rate: 3.78e-05
2025-12-10 08:42:55 - INFO - Epoch: 25.63, Step: 101510, Train Loss: 1.1550, Learning Rate: 3.78e-05
2025-12-10 08:43:06 - INFO - Epoch: 25.63, Step: 101520, Train Loss: 1.2295, Learning Rate: 3.78e-05
2025-12-10 08:43:17 - INFO - Epoch: 25.63, Step: 101530, Train Loss: 1.2245, Learning Rate: 3.78e-05
2025-12-10 08:43:29 - INFO - Epoch: 25.63, Step: 101540, Train Loss: 1.2022, Learning Rate: 3.78e-05
2025-12-10 08:43:40 - INFO - Epoch: 25.64, Step: 101550, Train Loss: 1.2111, Learning Rate: 3.78e-05
2025-12-10 08:43:51 - INFO - Epoch: 25.64, Step: 101560, Train Loss: 1.1685, Learning Rate: 3.78e-05
2025-12-10 08:44:02 - INFO - Epoch: 25.64, Step: 101570, Train Loss: 1.2596, Learning Rate: 3.78e-05
2025-12-10 08:44:13 - INFO - Epoch: 25.65, Step: 101580, Train Loss: 1.1734, Learning Rate: 3.78e-05
2025-12-10 08:44:24 - INFO - Epoch: 25.65, Step: 101590, Train Loss: 1.1994, Learning Rate: 3.78e-05
2025-12-10 08:44:36 - INFO - Epoch: 25.65, Step: 101600, Train Loss: 1.1617, Learning Rate: 3.78e-05
2025-12-10 08:44:47 - INFO - Epoch: 25.65, Step: 101610, Train Loss: 1.2043, Learning Rate: 3.78e-05
2025-12-10 08:44:58 - INFO - Epoch: 25.66, Step: 101620, Train Loss: 1.2139, Learning Rate: 3.78e-05
2025-12-10 08:45:09 - INFO - Epoch: 25.66, Step: 101630, Train Loss: 1.1971, Learning Rate: 3.77e-05
2025-12-10 08:45:20 - INFO - Epoch: 25.66, Step: 101640, Train Loss: 1.2389, Learning Rate: 3.77e-05
2025-12-10 08:45:31 - INFO - Epoch: 25.66, Step: 101650, Train Loss: 1.2277, Learning Rate: 3.77e-05
2025-12-10 08:45:42 - INFO - Epoch: 25.67, Step: 101660, Train Loss: 1.1916, Learning Rate: 3.77e-05
2025-12-10 08:45:54 - INFO - Epoch: 25.67, Step: 101670, Train Loss: 1.2200, Learning Rate: 3.77e-05
2025-12-10 08:46:05 - INFO - Epoch: 25.67, Step: 101680, Train Loss: 1.2293, Learning Rate: 3.77e-05
2025-12-10 08:46:16 - INFO - Epoch: 25.67, Step: 101690, Train Loss: 1.1918, Learning Rate: 3.77e-05
2025-12-10 08:46:27 - INFO - Epoch: 25.68, Step: 101700, Train Loss: 1.1876, Learning Rate: 3.77e-05
2025-12-10 08:46:38 - INFO - Epoch: 25.68, Step: 101710, Train Loss: 1.1847, Learning Rate: 3.77e-05
2025-12-10 08:46:49 - INFO - Epoch: 25.68, Step: 101720, Train Loss: 1.1949, Learning Rate: 3.77e-05
2025-12-10 08:47:01 - INFO - Epoch: 25.68, Step: 101730, Train Loss: 1.1748, Learning Rate: 3.77e-05
2025-12-10 08:47:12 - INFO - Epoch: 25.69, Step: 101740, Train Loss: 1.2132, Learning Rate: 3.77e-05
2025-12-10 08:47:23 - INFO - Epoch: 25.69, Step: 101750, Train Loss: 1.2178, Learning Rate: 3.77e-05
2025-12-10 08:47:34 - INFO - Epoch: 25.69, Step: 101760, Train Loss: 1.2251, Learning Rate: 3.77e-05
2025-12-10 08:47:45 - INFO - Epoch: 25.69, Step: 101770, Train Loss: 1.1791, Learning Rate: 3.77e-05
2025-12-10 08:47:56 - INFO - Epoch: 25.70, Step: 101780, Train Loss: 1.1746, Learning Rate: 3.76e-05
2025-12-10 08:48:08 - INFO - Epoch: 25.70, Step: 101790, Train Loss: 1.2014, Learning Rate: 3.76e-05
2025-12-10 08:48:19 - INFO - Epoch: 25.70, Step: 101800, Train Loss: 1.2027, Learning Rate: 3.76e-05
2025-12-10 08:48:30 - INFO - Epoch: 25.70, Step: 101810, Train Loss: 1.1742, Learning Rate: 3.76e-05
2025-12-10 08:48:41 - INFO - Epoch: 25.71, Step: 101820, Train Loss: 1.2160, Learning Rate: 3.76e-05
2025-12-10 08:48:52 - INFO - Epoch: 25.71, Step: 101830, Train Loss: 1.2108, Learning Rate: 3.76e-05
2025-12-10 08:49:03 - INFO - Epoch: 25.71, Step: 101840, Train Loss: 1.2203, Learning Rate: 3.76e-05
2025-12-10 08:49:14 - INFO - Epoch: 25.71, Step: 101850, Train Loss: 1.2126, Learning Rate: 3.76e-05
2025-12-10 08:49:26 - INFO - Epoch: 25.72, Step: 101860, Train Loss: 1.2127, Learning Rate: 3.76e-05
2025-12-10 08:49:37 - INFO - Epoch: 25.72, Step: 101870, Train Loss: 1.2073, Learning Rate: 3.76e-05
2025-12-10 08:49:48 - INFO - Epoch: 25.72, Step: 101880, Train Loss: 1.1880, Learning Rate: 3.76e-05
2025-12-10 08:49:59 - INFO - Epoch: 25.72, Step: 101890, Train Loss: 1.2047, Learning Rate: 3.76e-05
2025-12-10 08:50:10 - INFO - Epoch: 25.73, Step: 101900, Train Loss: 1.1702, Learning Rate: 3.76e-05
2025-12-10 08:50:21 - INFO - Epoch: 25.73, Step: 101910, Train Loss: 1.2222, Learning Rate: 3.76e-05
2025-12-10 08:50:33 - INFO - Epoch: 25.73, Step: 101920, Train Loss: 1.2211, Learning Rate: 3.76e-05
2025-12-10 08:50:44 - INFO - Epoch: 25.73, Step: 101930, Train Loss: 1.1750, Learning Rate: 3.75e-05
2025-12-10 08:50:55 - INFO - Epoch: 25.74, Step: 101940, Train Loss: 1.2084, Learning Rate: 3.75e-05
2025-12-10 08:51:06 - INFO - Epoch: 25.74, Step: 101950, Train Loss: 1.2133, Learning Rate: 3.75e-05
2025-12-10 08:51:17 - INFO - Epoch: 25.74, Step: 101960, Train Loss: 1.2252, Learning Rate: 3.75e-05
2025-12-10 08:51:28 - INFO - Epoch: 25.74, Step: 101970, Train Loss: 1.2302, Learning Rate: 3.75e-05
2025-12-10 08:51:39 - INFO - Epoch: 25.75, Step: 101980, Train Loss: 1.2274, Learning Rate: 3.75e-05
2025-12-10 08:51:51 - INFO - Epoch: 25.75, Step: 101990, Train Loss: 1.2175, Learning Rate: 3.75e-05
2025-12-10 08:52:02 - INFO - Epoch: 25.75, Step: 102000, Train Loss: 1.2146, Learning Rate: 3.75e-05
2025-12-10 08:52:13 - INFO - Epoch: 25.75, Step: 102010, Train Loss: 1.1842, Learning Rate: 3.75e-05
2025-12-10 08:52:24 - INFO - Epoch: 25.76, Step: 102020, Train Loss: 1.1732, Learning Rate: 3.75e-05
2025-12-10 08:52:35 - INFO - Epoch: 25.76, Step: 102030, Train Loss: 1.2328, Learning Rate: 3.75e-05
2025-12-10 08:52:46 - INFO - Epoch: 25.76, Step: 102040, Train Loss: 1.2257, Learning Rate: 3.75e-05
2025-12-10 08:52:58 - INFO - Epoch: 25.76, Step: 102050, Train Loss: 1.2514, Learning Rate: 3.75e-05
2025-12-10 08:53:09 - INFO - Epoch: 25.77, Step: 102060, Train Loss: 1.1882, Learning Rate: 3.75e-05
2025-12-10 08:53:20 - INFO - Epoch: 25.77, Step: 102070, Train Loss: 1.2128, Learning Rate: 3.75e-05
2025-12-10 08:53:31 - INFO - Epoch: 25.77, Step: 102080, Train Loss: 1.2219, Learning Rate: 3.74e-05
2025-12-10 08:53:42 - INFO - Epoch: 25.77, Step: 102090, Train Loss: 1.2323, Learning Rate: 3.74e-05
2025-12-10 08:53:53 - INFO - Epoch: 25.78, Step: 102100, Train Loss: 1.1915, Learning Rate: 3.74e-05
2025-12-10 08:54:05 - INFO - Epoch: 25.78, Step: 102110, Train Loss: 1.2001, Learning Rate: 3.74e-05
2025-12-10 08:54:16 - INFO - Epoch: 25.78, Step: 102120, Train Loss: 1.2053, Learning Rate: 3.74e-05
2025-12-10 08:54:27 - INFO - Epoch: 25.78, Step: 102130, Train Loss: 1.2211, Learning Rate: 3.74e-05
2025-12-10 08:54:38 - INFO - Epoch: 25.79, Step: 102140, Train Loss: 1.2042, Learning Rate: 3.74e-05
2025-12-10 08:54:49 - INFO - Epoch: 25.79, Step: 102150, Train Loss: 1.2076, Learning Rate: 3.74e-05
2025-12-10 08:55:00 - INFO - Epoch: 25.79, Step: 102160, Train Loss: 1.2549, Learning Rate: 3.74e-05
2025-12-10 08:55:11 - INFO - Epoch: 25.79, Step: 102170, Train Loss: 1.2139, Learning Rate: 3.74e-05
2025-12-10 08:55:23 - INFO - Epoch: 25.80, Step: 102180, Train Loss: 1.2240, Learning Rate: 3.74e-05
2025-12-10 08:55:34 - INFO - Epoch: 25.80, Step: 102190, Train Loss: 1.1787, Learning Rate: 3.74e-05
2025-12-10 08:55:45 - INFO - Epoch: 25.80, Step: 102200, Train Loss: 1.2329, Learning Rate: 3.74e-05
2025-12-10 08:55:56 - INFO - Epoch: 25.80, Step: 102210, Train Loss: 1.2280, Learning Rate: 3.74e-05
2025-12-10 08:56:07 - INFO - Epoch: 25.81, Step: 102220, Train Loss: 1.2081, Learning Rate: 3.74e-05
2025-12-10 08:56:18 - INFO - Epoch: 25.81, Step: 102230, Train Loss: 1.2389, Learning Rate: 3.73e-05
2025-12-10 08:56:30 - INFO - Epoch: 25.81, Step: 102240, Train Loss: 1.1880, Learning Rate: 3.73e-05
2025-12-10 08:56:41 - INFO - Epoch: 25.81, Step: 102250, Train Loss: 1.2170, Learning Rate: 3.73e-05
2025-12-10 08:56:52 - INFO - Epoch: 25.82, Step: 102260, Train Loss: 1.2032, Learning Rate: 3.73e-05
2025-12-10 08:57:03 - INFO - Epoch: 25.82, Step: 102270, Train Loss: 1.1937, Learning Rate: 3.73e-05
2025-12-10 08:57:14 - INFO - Epoch: 25.82, Step: 102280, Train Loss: 1.1922, Learning Rate: 3.73e-05
2025-12-10 08:57:25 - INFO - Epoch: 25.82, Step: 102290, Train Loss: 1.2350, Learning Rate: 3.73e-05
2025-12-10 08:57:36 - INFO - Epoch: 25.83, Step: 102300, Train Loss: 1.2199, Learning Rate: 3.73e-05
2025-12-10 08:57:48 - INFO - Epoch: 25.83, Step: 102310, Train Loss: 1.2122, Learning Rate: 3.73e-05
2025-12-10 08:57:59 - INFO - Epoch: 25.83, Step: 102320, Train Loss: 1.1672, Learning Rate: 3.73e-05
2025-12-10 08:58:10 - INFO - Epoch: 25.83, Step: 102330, Train Loss: 1.2140, Learning Rate: 3.73e-05
2025-12-10 08:58:21 - INFO - Epoch: 25.84, Step: 102340, Train Loss: 1.1566, Learning Rate: 3.73e-05
2025-12-10 08:58:32 - INFO - Epoch: 25.84, Step: 102350, Train Loss: 1.2475, Learning Rate: 3.73e-05
2025-12-10 08:58:43 - INFO - Epoch: 25.84, Step: 102360, Train Loss: 1.2220, Learning Rate: 3.73e-05
2025-12-10 08:58:55 - INFO - Epoch: 25.84, Step: 102370, Train Loss: 1.1647, Learning Rate: 3.73e-05
2025-12-10 08:59:06 - INFO - Epoch: 25.85, Step: 102380, Train Loss: 1.2043, Learning Rate: 3.72e-05
2025-12-10 08:59:17 - INFO - Epoch: 25.85, Step: 102390, Train Loss: 1.2317, Learning Rate: 3.72e-05
2025-12-10 08:59:28 - INFO - Epoch: 25.85, Step: 102400, Train Loss: 1.1915, Learning Rate: 3.72e-05
2025-12-10 08:59:39 - INFO - Epoch: 25.85, Step: 102410, Train Loss: 1.1573, Learning Rate: 3.72e-05
2025-12-10 08:59:50 - INFO - Epoch: 25.86, Step: 102420, Train Loss: 1.2058, Learning Rate: 3.72e-05
2025-12-10 09:00:01 - INFO - Epoch: 25.86, Step: 102430, Train Loss: 1.1646, Learning Rate: 3.72e-05
2025-12-10 09:00:13 - INFO - Epoch: 25.86, Step: 102440, Train Loss: 1.2300, Learning Rate: 3.72e-05
2025-12-10 09:00:24 - INFO - Epoch: 25.86, Step: 102450, Train Loss: 1.2079, Learning Rate: 3.72e-05
2025-12-10 09:00:35 - INFO - Epoch: 25.87, Step: 102460, Train Loss: 1.2054, Learning Rate: 3.72e-05
2025-12-10 09:00:46 - INFO - Epoch: 25.87, Step: 102470, Train Loss: 1.2147, Learning Rate: 3.72e-05
2025-12-10 09:00:57 - INFO - Epoch: 25.87, Step: 102480, Train Loss: 1.2127, Learning Rate: 3.72e-05
2025-12-10 09:01:08 - INFO - Epoch: 25.87, Step: 102490, Train Loss: 1.1790, Learning Rate: 3.72e-05
2025-12-10 09:01:20 - INFO - Epoch: 25.88, Step: 102500, Train Loss: 1.1236, Learning Rate: 3.72e-05
2025-12-10 09:01:31 - INFO - Epoch: 25.88, Step: 102510, Train Loss: 1.2301, Learning Rate: 3.72e-05
2025-12-10 09:01:42 - INFO - Epoch: 25.88, Step: 102520, Train Loss: 1.2066, Learning Rate: 3.72e-05
2025-12-10 09:01:53 - INFO - Epoch: 25.88, Step: 102530, Train Loss: 1.2384, Learning Rate: 3.71e-05
2025-12-10 09:02:04 - INFO - Epoch: 25.89, Step: 102540, Train Loss: 1.1992, Learning Rate: 3.71e-05
2025-12-10 09:02:15 - INFO - Epoch: 25.89, Step: 102550, Train Loss: 1.2179, Learning Rate: 3.71e-05
2025-12-10 09:02:27 - INFO - Epoch: 25.89, Step: 102560, Train Loss: 1.2130, Learning Rate: 3.71e-05
2025-12-10 09:02:38 - INFO - Epoch: 25.89, Step: 102570, Train Loss: 1.2139, Learning Rate: 3.71e-05
2025-12-10 09:02:49 - INFO - Epoch: 25.90, Step: 102580, Train Loss: 1.2215, Learning Rate: 3.71e-05
2025-12-10 09:03:00 - INFO - Epoch: 25.90, Step: 102590, Train Loss: 1.1810, Learning Rate: 3.71e-05
2025-12-10 09:03:11 - INFO - Epoch: 25.90, Step: 102600, Train Loss: 1.2030, Learning Rate: 3.71e-05
2025-12-10 09:03:22 - INFO - Epoch: 25.91, Step: 102610, Train Loss: 1.1892, Learning Rate: 3.71e-05
2025-12-10 09:03:33 - INFO - Epoch: 25.91, Step: 102620, Train Loss: 1.1864, Learning Rate: 3.71e-05
2025-12-10 09:03:45 - INFO - Epoch: 25.91, Step: 102630, Train Loss: 1.1843, Learning Rate: 3.71e-05
2025-12-10 09:03:56 - INFO - Epoch: 25.91, Step: 102640, Train Loss: 1.1878, Learning Rate: 3.71e-05
2025-12-10 09:04:07 - INFO - Epoch: 25.92, Step: 102650, Train Loss: 1.1841, Learning Rate: 3.71e-05
2025-12-10 09:04:18 - INFO - Epoch: 25.92, Step: 102660, Train Loss: 1.2301, Learning Rate: 3.71e-05
2025-12-10 09:04:29 - INFO - Epoch: 25.92, Step: 102670, Train Loss: 1.2030, Learning Rate: 3.71e-05
2025-12-10 09:04:40 - INFO - Epoch: 25.92, Step: 102680, Train Loss: 1.2123, Learning Rate: 3.70e-05
2025-12-10 09:04:52 - INFO - Epoch: 25.93, Step: 102690, Train Loss: 1.1875, Learning Rate: 3.70e-05
2025-12-10 09:05:03 - INFO - Epoch: 25.93, Step: 102700, Train Loss: 1.2232, Learning Rate: 3.70e-05
2025-12-10 09:05:14 - INFO - Epoch: 25.93, Step: 102710, Train Loss: 1.2097, Learning Rate: 3.70e-05
2025-12-10 09:05:25 - INFO - Epoch: 25.93, Step: 102720, Train Loss: 1.2302, Learning Rate: 3.70e-05
2025-12-10 09:05:36 - INFO - Epoch: 25.94, Step: 102730, Train Loss: 1.2156, Learning Rate: 3.70e-05
2025-12-10 09:05:47 - INFO - Epoch: 25.94, Step: 102740, Train Loss: 1.1835, Learning Rate: 3.70e-05
2025-12-10 09:05:58 - INFO - Epoch: 25.94, Step: 102750, Train Loss: 1.2097, Learning Rate: 3.70e-05
2025-12-10 09:06:10 - INFO - Epoch: 25.94, Step: 102760, Train Loss: 1.2380, Learning Rate: 3.70e-05
2025-12-10 09:06:21 - INFO - Epoch: 25.95, Step: 102770, Train Loss: 1.1887, Learning Rate: 3.70e-05
2025-12-10 09:06:32 - INFO - Epoch: 25.95, Step: 102780, Train Loss: 1.2169, Learning Rate: 3.70e-05
2025-12-10 09:06:43 - INFO - Epoch: 25.95, Step: 102790, Train Loss: 1.2017, Learning Rate: 3.70e-05
2025-12-10 09:06:54 - INFO - Epoch: 25.95, Step: 102800, Train Loss: 1.1966, Learning Rate: 3.70e-05
2025-12-10 09:07:05 - INFO - Epoch: 25.96, Step: 102810, Train Loss: 1.1994, Learning Rate: 3.70e-05
2025-12-10 09:07:17 - INFO - Epoch: 25.96, Step: 102820, Train Loss: 1.2060, Learning Rate: 3.70e-05
2025-12-10 09:07:28 - INFO - Epoch: 25.96, Step: 102830, Train Loss: 1.2063, Learning Rate: 3.69e-05
2025-12-10 09:07:39 - INFO - Epoch: 25.96, Step: 102840, Train Loss: 1.1986, Learning Rate: 3.69e-05
2025-12-10 09:07:50 - INFO - Epoch: 25.97, Step: 102850, Train Loss: 1.2112, Learning Rate: 3.69e-05
2025-12-10 09:08:01 - INFO - Epoch: 25.97, Step: 102860, Train Loss: 1.1876, Learning Rate: 3.69e-05
2025-12-10 09:08:12 - INFO - Epoch: 25.97, Step: 102870, Train Loss: 1.2090, Learning Rate: 3.69e-05
2025-12-10 09:08:23 - INFO - Epoch: 25.97, Step: 102880, Train Loss: 1.2229, Learning Rate: 3.69e-05
2025-12-10 09:08:35 - INFO - Epoch: 25.98, Step: 102890, Train Loss: 1.2498, Learning Rate: 3.69e-05
2025-12-10 09:08:46 - INFO - Epoch: 25.98, Step: 102900, Train Loss: 1.2358, Learning Rate: 3.69e-05
2025-12-10 09:08:57 - INFO - Epoch: 25.98, Step: 102910, Train Loss: 1.2065, Learning Rate: 3.69e-05
2025-12-10 09:09:08 - INFO - Epoch: 25.98, Step: 102920, Train Loss: 1.2429, Learning Rate: 3.69e-05
2025-12-10 09:09:19 - INFO - Epoch: 25.99, Step: 102930, Train Loss: 1.1936, Learning Rate: 3.69e-05
2025-12-10 09:09:30 - INFO - Epoch: 25.99, Step: 102940, Train Loss: 1.2163, Learning Rate: 3.69e-05
2025-12-10 09:09:42 - INFO - Epoch: 25.99, Step: 102950, Train Loss: 1.2299, Learning Rate: 3.69e-05
2025-12-10 09:09:53 - INFO - Epoch: 25.99, Step: 102960, Train Loss: 1.2403, Learning Rate: 3.69e-05
2025-12-10 09:10:04 - INFO - Epoch: 26.00, Step: 102970, Train Loss: 1.2157, Learning Rate: 3.69e-05
2025-12-10 09:10:15 - INFO - Epoch: 26.00, Step: 102980, Train Loss: 1.1667, Learning Rate: 3.68e-05
2025-12-10 09:10:26 - INFO - Epoch: 26.00, Step: 102990, Train Loss: 1.1928, Learning Rate: 3.68e-05
2025-12-10 09:10:37 - INFO - Epoch: 26.00, Step: 103000, Train Loss: 1.1775, Learning Rate: 3.68e-05
2025-12-10 09:10:49 - INFO - Epoch: 26.01, Step: 103010, Train Loss: 1.1829, Learning Rate: 3.68e-05
2025-12-10 09:11:00 - INFO - Epoch: 26.01, Step: 103020, Train Loss: 1.2221, Learning Rate: 3.68e-05
2025-12-10 09:11:11 - INFO - Epoch: 26.01, Step: 103030, Train Loss: 1.1755, Learning Rate: 3.68e-05
2025-12-10 09:11:22 - INFO - Epoch: 26.01, Step: 103040, Train Loss: 1.1909, Learning Rate: 3.68e-05
2025-12-10 09:11:33 - INFO - Epoch: 26.02, Step: 103050, Train Loss: 1.1801, Learning Rate: 3.68e-05
2025-12-10 09:11:44 - INFO - Epoch: 26.02, Step: 103060, Train Loss: 1.2192, Learning Rate: 3.68e-05
2025-12-10 09:11:55 - INFO - Epoch: 26.02, Step: 103070, Train Loss: 1.1886, Learning Rate: 3.68e-05
2025-12-10 09:12:07 - INFO - Epoch: 26.02, Step: 103080, Train Loss: 1.1799, Learning Rate: 3.68e-05
2025-12-10 09:12:18 - INFO - Epoch: 26.03, Step: 103090, Train Loss: 1.2050, Learning Rate: 3.68e-05
2025-12-10 09:12:29 - INFO - Epoch: 26.03, Step: 103100, Train Loss: 1.1918, Learning Rate: 3.68e-05
2025-12-10 09:12:40 - INFO - Epoch: 26.03, Step: 103110, Train Loss: 1.1981, Learning Rate: 3.68e-05
2025-12-10 09:12:51 - INFO - Epoch: 26.03, Step: 103120, Train Loss: 1.2259, Learning Rate: 3.68e-05
2025-12-10 09:13:02 - INFO - Epoch: 26.04, Step: 103130, Train Loss: 1.1818, Learning Rate: 3.67e-05
2025-12-10 09:13:14 - INFO - Epoch: 26.04, Step: 103140, Train Loss: 1.1782, Learning Rate: 3.67e-05
2025-12-10 09:13:25 - INFO - Epoch: 26.04, Step: 103150, Train Loss: 1.1934, Learning Rate: 3.67e-05
2025-12-10 09:13:36 - INFO - Epoch: 26.04, Step: 103160, Train Loss: 1.1984, Learning Rate: 3.67e-05
2025-12-10 09:13:47 - INFO - Epoch: 26.05, Step: 103170, Train Loss: 1.2047, Learning Rate: 3.67e-05
2025-12-10 09:13:58 - INFO - Epoch: 26.05, Step: 103180, Train Loss: 1.1970, Learning Rate: 3.67e-05
2025-12-10 09:14:09 - INFO - Epoch: 26.05, Step: 103190, Train Loss: 1.2110, Learning Rate: 3.67e-05
2025-12-10 09:14:20 - INFO - Epoch: 26.05, Step: 103200, Train Loss: 1.2418, Learning Rate: 3.67e-05
2025-12-10 09:14:32 - INFO - Epoch: 26.06, Step: 103210, Train Loss: 1.1658, Learning Rate: 3.67e-05
2025-12-10 09:14:43 - INFO - Epoch: 26.06, Step: 103220, Train Loss: 1.2187, Learning Rate: 3.67e-05
2025-12-10 09:14:54 - INFO - Epoch: 26.06, Step: 103230, Train Loss: 1.1991, Learning Rate: 3.67e-05
2025-12-10 09:15:05 - INFO - Epoch: 26.06, Step: 103240, Train Loss: 1.1934, Learning Rate: 3.67e-05
2025-12-10 09:15:16 - INFO - Epoch: 26.07, Step: 103250, Train Loss: 1.1720, Learning Rate: 3.67e-05
2025-12-10 09:15:27 - INFO - Epoch: 26.07, Step: 103260, Train Loss: 1.2044, Learning Rate: 3.67e-05
2025-12-10 09:15:38 - INFO - Epoch: 26.07, Step: 103270, Train Loss: 1.1718, Learning Rate: 3.67e-05
2025-12-10 09:15:50 - INFO - Epoch: 26.07, Step: 103280, Train Loss: 1.2138, Learning Rate: 3.66e-05
2025-12-10 09:16:01 - INFO - Epoch: 26.08, Step: 103290, Train Loss: 1.1705, Learning Rate: 3.66e-05
2025-12-10 09:16:12 - INFO - Epoch: 26.08, Step: 103300, Train Loss: 1.1951, Learning Rate: 3.66e-05
2025-12-10 09:16:23 - INFO - Epoch: 26.08, Step: 103310, Train Loss: 1.2283, Learning Rate: 3.66e-05
2025-12-10 09:16:34 - INFO - Epoch: 26.08, Step: 103320, Train Loss: 1.2181, Learning Rate: 3.66e-05
2025-12-10 09:16:45 - INFO - Epoch: 26.09, Step: 103330, Train Loss: 1.2177, Learning Rate: 3.66e-05
2025-12-10 09:16:57 - INFO - Epoch: 26.09, Step: 103340, Train Loss: 1.2140, Learning Rate: 3.66e-05
2025-12-10 09:17:08 - INFO - Epoch: 26.09, Step: 103350, Train Loss: 1.2188, Learning Rate: 3.66e-05
2025-12-10 09:17:19 - INFO - Epoch: 26.09, Step: 103360, Train Loss: 1.1630, Learning Rate: 3.66e-05
2025-12-10 09:17:30 - INFO - Epoch: 26.10, Step: 103370, Train Loss: 1.2061, Learning Rate: 3.66e-05
2025-12-10 09:17:41 - INFO - Epoch: 26.10, Step: 103380, Train Loss: 1.2150, Learning Rate: 3.66e-05
2025-12-10 09:17:52 - INFO - Epoch: 26.10, Step: 103390, Train Loss: 1.2030, Learning Rate: 3.66e-05
2025-12-10 09:18:03 - INFO - Epoch: 26.10, Step: 103400, Train Loss: 1.1595, Learning Rate: 3.66e-05
2025-12-10 09:18:15 - INFO - Epoch: 26.11, Step: 103410, Train Loss: 1.2285, Learning Rate: 3.66e-05
2025-12-10 09:18:26 - INFO - Epoch: 26.11, Step: 103420, Train Loss: 1.2203, Learning Rate: 3.66e-05
2025-12-10 09:18:37 - INFO - Epoch: 26.11, Step: 103430, Train Loss: 1.2258, Learning Rate: 3.65e-05
2025-12-10 09:18:48 - INFO - Epoch: 26.11, Step: 103440, Train Loss: 1.1937, Learning Rate: 3.65e-05
2025-12-10 09:18:59 - INFO - Epoch: 26.12, Step: 103450, Train Loss: 1.1964, Learning Rate: 3.65e-05
2025-12-10 09:19:10 - INFO - Epoch: 26.12, Step: 103460, Train Loss: 1.2284, Learning Rate: 3.65e-05
2025-12-10 09:19:22 - INFO - Epoch: 26.12, Step: 103470, Train Loss: 1.2011, Learning Rate: 3.65e-05
2025-12-10 09:19:33 - INFO - Epoch: 26.12, Step: 103480, Train Loss: 1.1979, Learning Rate: 3.65e-05
2025-12-10 09:19:44 - INFO - Epoch: 26.13, Step: 103490, Train Loss: 1.2116, Learning Rate: 3.65e-05
2025-12-10 09:19:55 - INFO - Epoch: 26.13, Step: 103500, Train Loss: 1.2179, Learning Rate: 3.65e-05
2025-12-10 09:20:06 - INFO - Epoch: 26.13, Step: 103510, Train Loss: 1.1897, Learning Rate: 3.65e-05
2025-12-10 09:20:17 - INFO - Epoch: 26.13, Step: 103520, Train Loss: 1.1898, Learning Rate: 3.65e-05
2025-12-10 09:20:28 - INFO - Epoch: 26.14, Step: 103530, Train Loss: 1.1741, Learning Rate: 3.65e-05
2025-12-10 09:20:40 - INFO - Epoch: 26.14, Step: 103540, Train Loss: 1.2288, Learning Rate: 3.65e-05
2025-12-10 09:20:51 - INFO - Epoch: 26.14, Step: 103550, Train Loss: 1.1929, Learning Rate: 3.65e-05
2025-12-10 09:21:02 - INFO - Epoch: 26.14, Step: 103560, Train Loss: 1.2029, Learning Rate: 3.65e-05
2025-12-10 09:21:13 - INFO - Epoch: 26.15, Step: 103570, Train Loss: 1.2004, Learning Rate: 3.65e-05
2025-12-10 09:21:24 - INFO - Epoch: 26.15, Step: 103580, Train Loss: 1.2006, Learning Rate: 3.64e-05
2025-12-10 09:21:35 - INFO - Epoch: 26.15, Step: 103590, Train Loss: 1.1487, Learning Rate: 3.64e-05
2025-12-10 09:21:47 - INFO - Epoch: 26.16, Step: 103600, Train Loss: 1.1637, Learning Rate: 3.64e-05
2025-12-10 09:21:58 - INFO - Epoch: 26.16, Step: 103610, Train Loss: 1.1803, Learning Rate: 3.64e-05
2025-12-10 09:22:09 - INFO - Epoch: 26.16, Step: 103620, Train Loss: 1.1587, Learning Rate: 3.64e-05
2025-12-10 09:22:20 - INFO - Epoch: 26.16, Step: 103630, Train Loss: 1.2132, Learning Rate: 3.64e-05
2025-12-10 09:22:31 - INFO - Epoch: 26.17, Step: 103640, Train Loss: 1.1710, Learning Rate: 3.64e-05
2025-12-10 09:22:42 - INFO - Epoch: 26.17, Step: 103650, Train Loss: 1.1996, Learning Rate: 3.64e-05
2025-12-10 09:22:53 - INFO - Epoch: 26.17, Step: 103660, Train Loss: 1.1908, Learning Rate: 3.64e-05
2025-12-10 09:23:05 - INFO - Epoch: 26.17, Step: 103670, Train Loss: 1.2300, Learning Rate: 3.64e-05
2025-12-10 09:23:16 - INFO - Epoch: 26.18, Step: 103680, Train Loss: 1.1704, Learning Rate: 3.64e-05
2025-12-10 09:23:27 - INFO - Epoch: 26.18, Step: 103690, Train Loss: 1.2057, Learning Rate: 3.64e-05
2025-12-10 09:23:38 - INFO - Epoch: 26.18, Step: 103700, Train Loss: 1.1855, Learning Rate: 3.64e-05
2025-12-10 09:23:49 - INFO - Epoch: 26.18, Step: 103710, Train Loss: 1.1851, Learning Rate: 3.64e-05
2025-12-10 09:24:00 - INFO - Epoch: 26.19, Step: 103720, Train Loss: 1.2049, Learning Rate: 3.64e-05
2025-12-10 09:24:12 - INFO - Epoch: 26.19, Step: 103730, Train Loss: 1.2311, Learning Rate: 3.63e-05
2025-12-10 09:24:23 - INFO - Epoch: 26.19, Step: 103740, Train Loss: 1.1862, Learning Rate: 3.63e-05
2025-12-10 09:24:34 - INFO - Epoch: 26.19, Step: 103750, Train Loss: 1.1942, Learning Rate: 3.63e-05
2025-12-10 09:24:45 - INFO - Epoch: 26.20, Step: 103760, Train Loss: 1.2469, Learning Rate: 3.63e-05
2025-12-10 09:24:56 - INFO - Epoch: 26.20, Step: 103770, Train Loss: 1.1601, Learning Rate: 3.63e-05
2025-12-10 09:25:07 - INFO - Epoch: 26.20, Step: 103780, Train Loss: 1.2302, Learning Rate: 3.63e-05
2025-12-10 09:25:18 - INFO - Epoch: 26.20, Step: 103790, Train Loss: 1.1895, Learning Rate: 3.63e-05
2025-12-10 09:25:30 - INFO - Epoch: 26.21, Step: 103800, Train Loss: 1.1878, Learning Rate: 3.63e-05
2025-12-10 09:25:41 - INFO - Epoch: 26.21, Step: 103810, Train Loss: 1.2107, Learning Rate: 3.63e-05
2025-12-10 09:25:52 - INFO - Epoch: 26.21, Step: 103820, Train Loss: 1.2073, Learning Rate: 3.63e-05
2025-12-10 09:26:03 - INFO - Epoch: 26.21, Step: 103830, Train Loss: 1.2231, Learning Rate: 3.63e-05
2025-12-10 09:26:14 - INFO - Epoch: 26.22, Step: 103840, Train Loss: 1.1928, Learning Rate: 3.63e-05
2025-12-10 09:26:25 - INFO - Epoch: 26.22, Step: 103850, Train Loss: 1.1665, Learning Rate: 3.63e-05
2025-12-10 09:26:37 - INFO - Epoch: 26.22, Step: 103860, Train Loss: 1.2043, Learning Rate: 3.63e-05
2025-12-10 09:26:48 - INFO - Epoch: 26.22, Step: 103870, Train Loss: 1.1854, Learning Rate: 3.63e-05
2025-12-10 09:26:59 - INFO - Epoch: 26.23, Step: 103880, Train Loss: 1.2133, Learning Rate: 3.62e-05
2025-12-10 09:27:10 - INFO - Epoch: 26.23, Step: 103890, Train Loss: 1.2213, Learning Rate: 3.62e-05
2025-12-10 09:27:21 - INFO - Epoch: 26.23, Step: 103900, Train Loss: 1.2154, Learning Rate: 3.62e-05
2025-12-10 09:27:32 - INFO - Epoch: 26.23, Step: 103910, Train Loss: 1.1952, Learning Rate: 3.62e-05
2025-12-10 09:27:43 - INFO - Epoch: 26.24, Step: 103920, Train Loss: 1.2026, Learning Rate: 3.62e-05
2025-12-10 09:27:55 - INFO - Epoch: 26.24, Step: 103930, Train Loss: 1.1968, Learning Rate: 3.62e-05
2025-12-10 09:28:06 - INFO - Epoch: 26.24, Step: 103940, Train Loss: 1.2126, Learning Rate: 3.62e-05
2025-12-10 09:28:17 - INFO - Epoch: 26.24, Step: 103950, Train Loss: 1.1882, Learning Rate: 3.62e-05
2025-12-10 09:28:28 - INFO - Epoch: 26.25, Step: 103960, Train Loss: 1.2358, Learning Rate: 3.62e-05
2025-12-10 09:28:39 - INFO - Epoch: 26.25, Step: 103970, Train Loss: 1.1554, Learning Rate: 3.62e-05
2025-12-10 09:28:50 - INFO - Epoch: 26.25, Step: 103980, Train Loss: 1.2316, Learning Rate: 3.62e-05
2025-12-10 09:29:02 - INFO - Epoch: 26.25, Step: 103990, Train Loss: 1.2093, Learning Rate: 3.62e-05
2025-12-10 09:29:13 - INFO - Epoch: 26.26, Step: 104000, Train Loss: 1.2182, Learning Rate: 3.62e-05
2025-12-10 09:29:24 - INFO - Epoch: 26.26, Step: 104010, Train Loss: 1.1974, Learning Rate: 3.62e-05
2025-12-10 09:29:35 - INFO - Epoch: 26.26, Step: 104020, Train Loss: 1.2362, Learning Rate: 3.62e-05
2025-12-10 09:29:46 - INFO - Epoch: 26.26, Step: 104030, Train Loss: 1.2233, Learning Rate: 3.61e-05
2025-12-10 09:29:57 - INFO - Epoch: 26.27, Step: 104040, Train Loss: 1.1873, Learning Rate: 3.61e-05
2025-12-10 09:30:08 - INFO - Epoch: 26.27, Step: 104050, Train Loss: 1.2138, Learning Rate: 3.61e-05
2025-12-10 09:30:20 - INFO - Epoch: 26.27, Step: 104060, Train Loss: 1.2031, Learning Rate: 3.61e-05
2025-12-10 09:30:31 - INFO - Epoch: 26.27, Step: 104070, Train Loss: 1.1997, Learning Rate: 3.61e-05
2025-12-10 09:30:42 - INFO - Epoch: 26.28, Step: 104080, Train Loss: 1.1545, Learning Rate: 3.61e-05
2025-12-10 09:30:53 - INFO - Epoch: 26.28, Step: 104090, Train Loss: 1.2087, Learning Rate: 3.61e-05
2025-12-10 09:31:04 - INFO - Epoch: 26.28, Step: 104100, Train Loss: 1.2345, Learning Rate: 3.61e-05
2025-12-10 09:31:15 - INFO - Epoch: 26.28, Step: 104110, Train Loss: 1.1716, Learning Rate: 3.61e-05
2025-12-10 09:31:27 - INFO - Epoch: 26.29, Step: 104120, Train Loss: 1.1903, Learning Rate: 3.61e-05
2025-12-10 09:31:38 - INFO - Epoch: 26.29, Step: 104130, Train Loss: 1.2025, Learning Rate: 3.61e-05
2025-12-10 09:31:49 - INFO - Epoch: 26.29, Step: 104140, Train Loss: 1.1891, Learning Rate: 3.61e-05
2025-12-10 09:32:00 - INFO - Epoch: 26.29, Step: 104150, Train Loss: 1.1686, Learning Rate: 3.61e-05
2025-12-10 09:32:11 - INFO - Epoch: 26.30, Step: 104160, Train Loss: 1.1925, Learning Rate: 3.61e-05
2025-12-10 09:32:22 - INFO - Epoch: 26.30, Step: 104170, Train Loss: 1.1931, Learning Rate: 3.61e-05
2025-12-10 09:32:33 - INFO - Epoch: 26.30, Step: 104180, Train Loss: 1.2204, Learning Rate: 3.60e-05
2025-12-10 09:32:45 - INFO - Epoch: 26.30, Step: 104190, Train Loss: 1.2048, Learning Rate: 3.60e-05
2025-12-10 09:32:56 - INFO - Epoch: 26.31, Step: 104200, Train Loss: 1.1863, Learning Rate: 3.60e-05
2025-12-10 09:33:07 - INFO - Epoch: 26.31, Step: 104210, Train Loss: 1.2005, Learning Rate: 3.60e-05
2025-12-10 09:33:18 - INFO - Epoch: 26.31, Step: 104220, Train Loss: 1.2194, Learning Rate: 3.60e-05
2025-12-10 09:33:29 - INFO - Epoch: 26.31, Step: 104230, Train Loss: 1.2170, Learning Rate: 3.60e-05
2025-12-10 09:33:40 - INFO - Epoch: 26.32, Step: 104240, Train Loss: 1.1677, Learning Rate: 3.60e-05
2025-12-10 09:33:52 - INFO - Epoch: 26.32, Step: 104250, Train Loss: 1.2278, Learning Rate: 3.60e-05
2025-12-10 09:34:03 - INFO - Epoch: 26.32, Step: 104260, Train Loss: 1.1935, Learning Rate: 3.60e-05
2025-12-10 09:34:14 - INFO - Epoch: 26.32, Step: 104270, Train Loss: 1.1946, Learning Rate: 3.60e-05
2025-12-10 09:34:25 - INFO - Epoch: 26.33, Step: 104280, Train Loss: 1.2119, Learning Rate: 3.60e-05
2025-12-10 09:34:36 - INFO - Epoch: 26.33, Step: 104290, Train Loss: 1.1606, Learning Rate: 3.60e-05
2025-12-10 09:34:47 - INFO - Epoch: 26.33, Step: 104300, Train Loss: 1.1789, Learning Rate: 3.60e-05
2025-12-10 09:34:58 - INFO - Epoch: 26.33, Step: 104310, Train Loss: 1.1843, Learning Rate: 3.60e-05
2025-12-10 09:35:10 - INFO - Epoch: 26.34, Step: 104320, Train Loss: 1.1814, Learning Rate: 3.60e-05
2025-12-10 09:35:21 - INFO - Epoch: 26.34, Step: 104330, Train Loss: 1.2222, Learning Rate: 3.59e-05
2025-12-10 09:35:32 - INFO - Epoch: 26.34, Step: 104340, Train Loss: 1.2002, Learning Rate: 3.59e-05
2025-12-10 09:35:43 - INFO - Epoch: 26.34, Step: 104350, Train Loss: 1.1549, Learning Rate: 3.59e-05
2025-12-10 09:35:54 - INFO - Epoch: 26.35, Step: 104360, Train Loss: 1.2398, Learning Rate: 3.59e-05
2025-12-10 09:36:05 - INFO - Epoch: 26.35, Step: 104370, Train Loss: 1.2046, Learning Rate: 3.59e-05
2025-12-10 09:36:17 - INFO - Epoch: 26.35, Step: 104380, Train Loss: 1.1874, Learning Rate: 3.59e-05
2025-12-10 09:36:28 - INFO - Epoch: 26.35, Step: 104390, Train Loss: 1.1852, Learning Rate: 3.59e-05
2025-12-10 09:36:39 - INFO - Epoch: 26.36, Step: 104400, Train Loss: 1.1988, Learning Rate: 3.59e-05
2025-12-10 09:36:50 - INFO - Epoch: 26.36, Step: 104410, Train Loss: 1.1942, Learning Rate: 3.59e-05
2025-12-10 09:37:01 - INFO - Epoch: 26.36, Step: 104420, Train Loss: 1.1946, Learning Rate: 3.59e-05
2025-12-10 09:37:12 - INFO - Epoch: 26.36, Step: 104430, Train Loss: 1.2071, Learning Rate: 3.59e-05
2025-12-10 09:37:23 - INFO - Epoch: 26.37, Step: 104440, Train Loss: 1.1823, Learning Rate: 3.59e-05
2025-12-10 09:37:35 - INFO - Epoch: 26.37, Step: 104450, Train Loss: 1.1962, Learning Rate: 3.59e-05
2025-12-10 09:37:46 - INFO - Epoch: 26.37, Step: 104460, Train Loss: 1.2124, Learning Rate: 3.59e-05
2025-12-10 09:37:57 - INFO - Epoch: 26.37, Step: 104470, Train Loss: 1.1972, Learning Rate: 3.59e-05
2025-12-10 09:38:08 - INFO - Epoch: 26.38, Step: 104480, Train Loss: 1.2200, Learning Rate: 3.59e-05
2025-12-10 09:38:19 - INFO - Epoch: 26.38, Step: 104490, Train Loss: 1.2219, Learning Rate: 3.58e-05
2025-12-10 09:38:30 - INFO - Epoch: 26.38, Step: 104500, Train Loss: 1.2029, Learning Rate: 3.58e-05
2025-12-10 09:38:42 - INFO - Epoch: 26.38, Step: 104510, Train Loss: 1.2180, Learning Rate: 3.58e-05
2025-12-10 09:38:53 - INFO - Epoch: 26.39, Step: 104520, Train Loss: 1.2084, Learning Rate: 3.58e-05
2025-12-10 09:39:04 - INFO - Epoch: 26.39, Step: 104530, Train Loss: 1.1549, Learning Rate: 3.58e-05
2025-12-10 09:39:15 - INFO - Epoch: 26.39, Step: 104540, Train Loss: 1.2163, Learning Rate: 3.58e-05
2025-12-10 09:39:26 - INFO - Epoch: 26.39, Step: 104550, Train Loss: 1.2227, Learning Rate: 3.58e-05
2025-12-10 09:39:37 - INFO - Epoch: 26.40, Step: 104560, Train Loss: 1.2026, Learning Rate: 3.58e-05
2025-12-10 09:39:48 - INFO - Epoch: 26.40, Step: 104570, Train Loss: 1.2143, Learning Rate: 3.58e-05
2025-12-10 09:40:00 - INFO - Epoch: 26.40, Step: 104580, Train Loss: 1.1867, Learning Rate: 3.58e-05
2025-12-10 09:40:11 - INFO - Epoch: 26.40, Step: 104590, Train Loss: 1.1792, Learning Rate: 3.58e-05
2025-12-10 09:40:22 - INFO - Epoch: 26.41, Step: 104600, Train Loss: 1.2507, Learning Rate: 3.58e-05
2025-12-10 09:40:33 - INFO - Epoch: 26.41, Step: 104610, Train Loss: 1.1938, Learning Rate: 3.58e-05
2025-12-10 09:40:44 - INFO - Epoch: 26.41, Step: 104620, Train Loss: 1.1909, Learning Rate: 3.58e-05
2025-12-10 09:40:55 - INFO - Epoch: 26.42, Step: 104630, Train Loss: 1.2194, Learning Rate: 3.58e-05
2025-12-10 09:41:07 - INFO - Epoch: 26.42, Step: 104640, Train Loss: 1.1519, Learning Rate: 3.57e-05
2025-12-10 09:41:18 - INFO - Epoch: 26.42, Step: 104650, Train Loss: 1.2059, Learning Rate: 3.57e-05
2025-12-10 09:41:29 - INFO - Epoch: 26.42, Step: 104660, Train Loss: 1.1828, Learning Rate: 3.57e-05
2025-12-10 09:41:40 - INFO - Epoch: 26.43, Step: 104670, Train Loss: 1.1824, Learning Rate: 3.57e-05
2025-12-10 09:41:51 - INFO - Epoch: 26.43, Step: 104680, Train Loss: 1.2130, Learning Rate: 3.57e-05
2025-12-10 09:42:02 - INFO - Epoch: 26.43, Step: 104690, Train Loss: 1.2368, Learning Rate: 3.57e-05
2025-12-10 09:42:13 - INFO - Epoch: 26.43, Step: 104700, Train Loss: 1.1867, Learning Rate: 3.57e-05
2025-12-10 09:42:25 - INFO - Epoch: 26.44, Step: 104710, Train Loss: 1.1788, Learning Rate: 3.57e-05
2025-12-10 09:42:36 - INFO - Epoch: 26.44, Step: 104720, Train Loss: 1.1523, Learning Rate: 3.57e-05
2025-12-10 09:42:47 - INFO - Epoch: 26.44, Step: 104730, Train Loss: 1.1942, Learning Rate: 3.57e-05
2025-12-10 09:42:58 - INFO - Epoch: 26.44, Step: 104740, Train Loss: 1.1980, Learning Rate: 3.57e-05
2025-12-10 09:43:09 - INFO - Epoch: 26.45, Step: 104750, Train Loss: 1.2439, Learning Rate: 3.57e-05
2025-12-10 09:43:20 - INFO - Epoch: 26.45, Step: 104760, Train Loss: 1.1885, Learning Rate: 3.57e-05
2025-12-10 09:43:32 - INFO - Epoch: 26.45, Step: 104770, Train Loss: 1.1171, Learning Rate: 3.57e-05
2025-12-10 09:43:43 - INFO - Epoch: 26.45, Step: 104780, Train Loss: 1.2398, Learning Rate: 3.57e-05
2025-12-10 09:43:54 - INFO - Epoch: 26.46, Step: 104790, Train Loss: 1.2028, Learning Rate: 3.56e-05
2025-12-10 09:44:05 - INFO - Epoch: 26.46, Step: 104800, Train Loss: 1.2024, Learning Rate: 3.56e-05
2025-12-10 09:44:16 - INFO - Epoch: 26.46, Step: 104810, Train Loss: 1.2003, Learning Rate: 3.56e-05
2025-12-10 09:44:27 - INFO - Epoch: 26.46, Step: 104820, Train Loss: 1.1757, Learning Rate: 3.56e-05
2025-12-10 09:44:38 - INFO - Epoch: 26.47, Step: 104830, Train Loss: 1.1762, Learning Rate: 3.56e-05
2025-12-10 09:44:50 - INFO - Epoch: 26.47, Step: 104840, Train Loss: 1.2314, Learning Rate: 3.56e-05
2025-12-10 09:45:01 - INFO - Epoch: 26.47, Step: 104850, Train Loss: 1.2009, Learning Rate: 3.56e-05
2025-12-10 09:45:12 - INFO - Epoch: 26.47, Step: 104860, Train Loss: 1.2133, Learning Rate: 3.56e-05
2025-12-10 09:45:23 - INFO - Epoch: 26.48, Step: 104870, Train Loss: 1.2140, Learning Rate: 3.56e-05
2025-12-10 09:45:34 - INFO - Epoch: 26.48, Step: 104880, Train Loss: 1.1938, Learning Rate: 3.56e-05
2025-12-10 09:45:45 - INFO - Epoch: 26.48, Step: 104890, Train Loss: 1.1822, Learning Rate: 3.56e-05
2025-12-10 09:45:57 - INFO - Epoch: 26.48, Step: 104900, Train Loss: 1.2393, Learning Rate: 3.56e-05
2025-12-10 09:46:08 - INFO - Epoch: 26.49, Step: 104910, Train Loss: 1.2058, Learning Rate: 3.56e-05
2025-12-10 09:46:19 - INFO - Epoch: 26.49, Step: 104920, Train Loss: 1.2386, Learning Rate: 3.56e-05
2025-12-10 09:46:30 - INFO - Epoch: 26.49, Step: 104930, Train Loss: 1.1990, Learning Rate: 3.56e-05
2025-12-10 09:46:41 - INFO - Epoch: 26.49, Step: 104940, Train Loss: 1.1799, Learning Rate: 3.55e-05
2025-12-10 09:46:52 - INFO - Epoch: 26.50, Step: 104950, Train Loss: 1.1917, Learning Rate: 3.55e-05
2025-12-10 09:47:03 - INFO - Epoch: 26.50, Step: 104960, Train Loss: 1.1859, Learning Rate: 3.55e-05
2025-12-10 09:47:15 - INFO - Epoch: 26.50, Step: 104970, Train Loss: 1.1751, Learning Rate: 3.55e-05
2025-12-10 09:47:26 - INFO - Epoch: 26.50, Step: 104980, Train Loss: 1.1861, Learning Rate: 3.55e-05
2025-12-10 09:47:37 - INFO - Epoch: 26.51, Step: 104990, Train Loss: 1.2274, Learning Rate: 3.55e-05
2025-12-10 09:47:48 - INFO - Epoch: 26.51, Step: 105000, Train Loss: 1.2181, Learning Rate: 3.55e-05
2025-12-10 09:47:59 - INFO - Epoch: 26.51, Step: 105010, Train Loss: 1.1651, Learning Rate: 3.55e-05
2025-12-10 09:48:10 - INFO - Epoch: 26.51, Step: 105020, Train Loss: 1.1761, Learning Rate: 3.55e-05
2025-12-10 09:48:22 - INFO - Epoch: 26.52, Step: 105030, Train Loss: 1.1587, Learning Rate: 3.55e-05
2025-12-10 09:48:33 - INFO - Epoch: 26.52, Step: 105040, Train Loss: 1.2150, Learning Rate: 3.55e-05
2025-12-10 09:48:44 - INFO - Epoch: 26.52, Step: 105050, Train Loss: 1.1850, Learning Rate: 3.55e-05
2025-12-10 09:48:55 - INFO - Epoch: 26.52, Step: 105060, Train Loss: 1.1978, Learning Rate: 3.55e-05
2025-12-10 09:49:06 - INFO - Epoch: 26.53, Step: 105070, Train Loss: 1.2116, Learning Rate: 3.55e-05
2025-12-10 09:49:17 - INFO - Epoch: 26.53, Step: 105080, Train Loss: 1.2212, Learning Rate: 3.55e-05
2025-12-10 09:49:28 - INFO - Epoch: 26.53, Step: 105090, Train Loss: 1.2276, Learning Rate: 3.54e-05
2025-12-10 09:49:40 - INFO - Epoch: 26.53, Step: 105100, Train Loss: 1.2097, Learning Rate: 3.54e-05
2025-12-10 09:49:51 - INFO - Epoch: 26.54, Step: 105110, Train Loss: 1.2169, Learning Rate: 3.54e-05
2025-12-10 09:50:02 - INFO - Epoch: 26.54, Step: 105120, Train Loss: 1.2207, Learning Rate: 3.54e-05
2025-12-10 09:50:13 - INFO - Epoch: 26.54, Step: 105130, Train Loss: 1.1833, Learning Rate: 3.54e-05
2025-12-10 09:50:24 - INFO - Epoch: 26.54, Step: 105140, Train Loss: 1.2306, Learning Rate: 3.54e-05
2025-12-10 09:50:35 - INFO - Epoch: 26.55, Step: 105150, Train Loss: 1.2068, Learning Rate: 3.54e-05
2025-12-10 09:50:47 - INFO - Epoch: 26.55, Step: 105160, Train Loss: 1.1835, Learning Rate: 3.54e-05
2025-12-10 09:50:58 - INFO - Epoch: 26.55, Step: 105170, Train Loss: 1.1583, Learning Rate: 3.54e-05
2025-12-10 09:51:09 - INFO - Epoch: 26.55, Step: 105180, Train Loss: 1.2104, Learning Rate: 3.54e-05
2025-12-10 09:51:20 - INFO - Epoch: 26.56, Step: 105190, Train Loss: 1.2176, Learning Rate: 3.54e-05
2025-12-10 09:51:31 - INFO - Epoch: 26.56, Step: 105200, Train Loss: 1.1772, Learning Rate: 3.54e-05
2025-12-10 09:51:42 - INFO - Epoch: 26.56, Step: 105210, Train Loss: 1.2018, Learning Rate: 3.54e-05
2025-12-10 09:51:53 - INFO - Epoch: 26.56, Step: 105220, Train Loss: 1.1749, Learning Rate: 3.54e-05
2025-12-10 09:52:05 - INFO - Epoch: 26.57, Step: 105230, Train Loss: 1.2104, Learning Rate: 3.54e-05
2025-12-10 09:52:16 - INFO - Epoch: 26.57, Step: 105240, Train Loss: 1.2013, Learning Rate: 3.53e-05
2025-12-10 09:52:27 - INFO - Epoch: 26.57, Step: 105250, Train Loss: 1.1895, Learning Rate: 3.53e-05
2025-12-10 09:52:38 - INFO - Epoch: 26.57, Step: 105260, Train Loss: 1.2240, Learning Rate: 3.53e-05
2025-12-10 09:52:49 - INFO - Epoch: 26.58, Step: 105270, Train Loss: 1.2264, Learning Rate: 3.53e-05
2025-12-10 09:53:00 - INFO - Epoch: 26.58, Step: 105280, Train Loss: 1.1649, Learning Rate: 3.53e-05
2025-12-10 09:53:12 - INFO - Epoch: 26.58, Step: 105290, Train Loss: 1.1495, Learning Rate: 3.53e-05
2025-12-10 09:53:23 - INFO - Epoch: 26.58, Step: 105300, Train Loss: 1.1940, Learning Rate: 3.53e-05
2025-12-10 09:53:34 - INFO - Epoch: 26.59, Step: 105310, Train Loss: 1.2358, Learning Rate: 3.53e-05
2025-12-10 09:53:45 - INFO - Epoch: 26.59, Step: 105320, Train Loss: 1.2072, Learning Rate: 3.53e-05
2025-12-10 09:53:56 - INFO - Epoch: 26.59, Step: 105330, Train Loss: 1.2100, Learning Rate: 3.53e-05
2025-12-10 09:54:07 - INFO - Epoch: 26.59, Step: 105340, Train Loss: 1.2256, Learning Rate: 3.53e-05
2025-12-10 09:54:18 - INFO - Epoch: 26.60, Step: 105350, Train Loss: 1.2029, Learning Rate: 3.53e-05
2025-12-10 09:54:30 - INFO - Epoch: 26.60, Step: 105360, Train Loss: 1.1854, Learning Rate: 3.53e-05
2025-12-10 09:54:41 - INFO - Epoch: 26.60, Step: 105370, Train Loss: 1.2077, Learning Rate: 3.53e-05
2025-12-10 09:54:52 - INFO - Epoch: 26.60, Step: 105380, Train Loss: 1.1984, Learning Rate: 3.53e-05
2025-12-10 09:55:03 - INFO - Epoch: 26.61, Step: 105390, Train Loss: 1.2069, Learning Rate: 3.52e-05
2025-12-10 09:55:14 - INFO - Epoch: 26.61, Step: 105400, Train Loss: 1.1913, Learning Rate: 3.52e-05
2025-12-10 09:55:25 - INFO - Epoch: 26.61, Step: 105410, Train Loss: 1.2322, Learning Rate: 3.52e-05
2025-12-10 09:55:37 - INFO - Epoch: 26.61, Step: 105420, Train Loss: 1.2092, Learning Rate: 3.52e-05
2025-12-10 09:55:48 - INFO - Epoch: 26.62, Step: 105430, Train Loss: 1.1812, Learning Rate: 3.52e-05
2025-12-10 09:55:59 - INFO - Epoch: 26.62, Step: 105440, Train Loss: 1.1874, Learning Rate: 3.52e-05
2025-12-10 09:56:10 - INFO - Epoch: 26.62, Step: 105450, Train Loss: 1.1587, Learning Rate: 3.52e-05
2025-12-10 09:56:21 - INFO - Epoch: 26.62, Step: 105460, Train Loss: 1.2023, Learning Rate: 3.52e-05
2025-12-10 09:56:32 - INFO - Epoch: 26.63, Step: 105470, Train Loss: 1.1694, Learning Rate: 3.52e-05
2025-12-10 09:56:43 - INFO - Epoch: 26.63, Step: 105480, Train Loss: 1.2122, Learning Rate: 3.52e-05
2025-12-10 09:56:55 - INFO - Epoch: 26.63, Step: 105490, Train Loss: 1.1828, Learning Rate: 3.52e-05
2025-12-10 09:57:06 - INFO - Epoch: 26.63, Step: 105500, Train Loss: 1.1928, Learning Rate: 3.52e-05
2025-12-10 09:57:17 - INFO - Epoch: 26.64, Step: 105510, Train Loss: 1.2010, Learning Rate: 3.52e-05
2025-12-10 09:57:28 - INFO - Epoch: 26.64, Step: 105520, Train Loss: 1.2145, Learning Rate: 3.52e-05
2025-12-10 09:57:39 - INFO - Epoch: 26.64, Step: 105530, Train Loss: 1.1965, Learning Rate: 3.52e-05
2025-12-10 09:57:50 - INFO - Epoch: 26.64, Step: 105540, Train Loss: 1.1887, Learning Rate: 3.51e-05
2025-12-10 09:58:02 - INFO - Epoch: 26.65, Step: 105550, Train Loss: 1.2050, Learning Rate: 3.51e-05
2025-12-10 09:58:13 - INFO - Epoch: 26.65, Step: 105560, Train Loss: 1.1910, Learning Rate: 3.51e-05
2025-12-10 09:58:24 - INFO - Epoch: 26.65, Step: 105570, Train Loss: 1.1855, Learning Rate: 3.51e-05
2025-12-10 09:58:35 - INFO - Epoch: 26.65, Step: 105580, Train Loss: 1.2032, Learning Rate: 3.51e-05
2025-12-10 09:58:46 - INFO - Epoch: 26.66, Step: 105590, Train Loss: 1.2066, Learning Rate: 3.51e-05
2025-12-10 09:58:57 - INFO - Epoch: 26.66, Step: 105600, Train Loss: 1.2097, Learning Rate: 3.51e-05
2025-12-10 09:59:08 - INFO - Epoch: 26.66, Step: 105610, Train Loss: 1.1846, Learning Rate: 3.51e-05
2025-12-10 09:59:20 - INFO - Epoch: 26.66, Step: 105620, Train Loss: 1.1318, Learning Rate: 3.51e-05
2025-12-10 09:59:31 - INFO - Epoch: 26.67, Step: 105630, Train Loss: 1.2081, Learning Rate: 3.51e-05
2025-12-10 09:59:42 - INFO - Epoch: 26.67, Step: 105640, Train Loss: 1.1992, Learning Rate: 3.51e-05
2025-12-10 09:59:53 - INFO - Epoch: 26.67, Step: 105650, Train Loss: 1.2003, Learning Rate: 3.51e-05
2025-12-10 10:00:04 - INFO - Epoch: 26.68, Step: 105660, Train Loss: 1.2235, Learning Rate: 3.51e-05
2025-12-10 10:00:15 - INFO - Epoch: 26.68, Step: 105670, Train Loss: 1.2181, Learning Rate: 3.51e-05
2025-12-10 10:00:27 - INFO - Epoch: 26.68, Step: 105680, Train Loss: 1.2151, Learning Rate: 3.51e-05
2025-12-10 10:00:38 - INFO - Epoch: 26.68, Step: 105690, Train Loss: 1.2237, Learning Rate: 3.50e-05
2025-12-10 10:00:49 - INFO - Epoch: 26.69, Step: 105700, Train Loss: 1.2047, Learning Rate: 3.50e-05
2025-12-10 10:01:00 - INFO - Epoch: 26.69, Step: 105710, Train Loss: 1.1744, Learning Rate: 3.50e-05
2025-12-10 10:01:11 - INFO - Epoch: 26.69, Step: 105720, Train Loss: 1.1756, Learning Rate: 3.50e-05
2025-12-10 10:01:22 - INFO - Epoch: 26.69, Step: 105730, Train Loss: 1.2150, Learning Rate: 3.50e-05
2025-12-10 10:01:33 - INFO - Epoch: 26.70, Step: 105740, Train Loss: 1.1957, Learning Rate: 3.50e-05
2025-12-10 10:01:45 - INFO - Epoch: 26.70, Step: 105750, Train Loss: 1.1867, Learning Rate: 3.50e-05
2025-12-10 10:01:56 - INFO - Epoch: 26.70, Step: 105760, Train Loss: 1.1515, Learning Rate: 3.50e-05
2025-12-10 10:02:07 - INFO - Epoch: 26.70, Step: 105770, Train Loss: 1.1768, Learning Rate: 3.50e-05
2025-12-10 10:02:18 - INFO - Epoch: 26.71, Step: 105780, Train Loss: 1.2042, Learning Rate: 3.50e-05
2025-12-10 10:02:29 - INFO - Epoch: 26.71, Step: 105790, Train Loss: 1.1859, Learning Rate: 3.50e-05
2025-12-10 10:02:40 - INFO - Epoch: 26.71, Step: 105800, Train Loss: 1.2209, Learning Rate: 3.50e-05
2025-12-10 10:02:52 - INFO - Epoch: 26.71, Step: 105810, Train Loss: 1.1943, Learning Rate: 3.50e-05
2025-12-10 10:03:03 - INFO - Epoch: 26.72, Step: 105820, Train Loss: 1.1669, Learning Rate: 3.50e-05
2025-12-10 10:03:14 - INFO - Epoch: 26.72, Step: 105830, Train Loss: 1.2163, Learning Rate: 3.50e-05
2025-12-10 10:03:25 - INFO - Epoch: 26.72, Step: 105840, Train Loss: 1.1741, Learning Rate: 3.49e-05
2025-12-10 10:03:36 - INFO - Epoch: 26.72, Step: 105850, Train Loss: 1.1959, Learning Rate: 3.49e-05
2025-12-10 10:03:47 - INFO - Epoch: 26.73, Step: 105860, Train Loss: 1.1991, Learning Rate: 3.49e-05
2025-12-10 10:03:58 - INFO - Epoch: 26.73, Step: 105870, Train Loss: 1.1897, Learning Rate: 3.49e-05
2025-12-10 10:04:10 - INFO - Epoch: 26.73, Step: 105880, Train Loss: 1.1973, Learning Rate: 3.49e-05
2025-12-10 10:04:21 - INFO - Epoch: 26.73, Step: 105890, Train Loss: 1.2097, Learning Rate: 3.49e-05
2025-12-10 10:04:32 - INFO - Epoch: 26.74, Step: 105900, Train Loss: 1.1687, Learning Rate: 3.49e-05
2025-12-10 10:04:43 - INFO - Epoch: 26.74, Step: 105910, Train Loss: 1.1590, Learning Rate: 3.49e-05
2025-12-10 10:04:54 - INFO - Epoch: 26.74, Step: 105920, Train Loss: 1.2065, Learning Rate: 3.49e-05
2025-12-10 10:05:05 - INFO - Epoch: 26.74, Step: 105930, Train Loss: 1.2106, Learning Rate: 3.49e-05
2025-12-10 10:05:16 - INFO - Epoch: 26.75, Step: 105940, Train Loss: 1.2315, Learning Rate: 3.49e-05
2025-12-10 10:05:28 - INFO - Epoch: 26.75, Step: 105950, Train Loss: 1.1871, Learning Rate: 3.49e-05
2025-12-10 10:05:39 - INFO - Epoch: 26.75, Step: 105960, Train Loss: 1.1608, Learning Rate: 3.49e-05
2025-12-10 10:05:50 - INFO - Epoch: 26.75, Step: 105970, Train Loss: 1.1814, Learning Rate: 3.49e-05
2025-12-10 10:06:01 - INFO - Epoch: 26.76, Step: 105980, Train Loss: 1.1882, Learning Rate: 3.49e-05
2025-12-10 10:06:12 - INFO - Epoch: 26.76, Step: 105990, Train Loss: 1.2068, Learning Rate: 3.48e-05
2025-12-10 10:06:23 - INFO - Epoch: 26.76, Step: 106000, Train Loss: 1.2094, Learning Rate: 3.48e-05
2025-12-10 10:06:35 - INFO - Epoch: 26.76, Step: 106010, Train Loss: 1.1893, Learning Rate: 3.48e-05
2025-12-10 10:06:46 - INFO - Epoch: 26.77, Step: 106020, Train Loss: 1.2012, Learning Rate: 3.48e-05
2025-12-10 10:06:57 - INFO - Epoch: 26.77, Step: 106030, Train Loss: 1.1839, Learning Rate: 3.48e-05
2025-12-10 10:07:08 - INFO - Epoch: 26.77, Step: 106040, Train Loss: 1.2178, Learning Rate: 3.48e-05
2025-12-10 10:07:19 - INFO - Epoch: 26.77, Step: 106050, Train Loss: 1.2053, Learning Rate: 3.48e-05
2025-12-10 10:07:30 - INFO - Epoch: 26.78, Step: 106060, Train Loss: 1.1739, Learning Rate: 3.48e-05
2025-12-10 10:07:41 - INFO - Epoch: 26.78, Step: 106070, Train Loss: 1.2200, Learning Rate: 3.48e-05
2025-12-10 10:07:53 - INFO - Epoch: 26.78, Step: 106080, Train Loss: 1.2184, Learning Rate: 3.48e-05
2025-12-10 10:08:04 - INFO - Epoch: 26.78, Step: 106090, Train Loss: 1.1831, Learning Rate: 3.48e-05
2025-12-10 10:08:15 - INFO - Epoch: 26.79, Step: 106100, Train Loss: 1.1953, Learning Rate: 3.48e-05
2025-12-10 10:08:26 - INFO - Epoch: 26.79, Step: 106110, Train Loss: 1.1690, Learning Rate: 3.48e-05
2025-12-10 10:08:37 - INFO - Epoch: 26.79, Step: 106120, Train Loss: 1.2114, Learning Rate: 3.48e-05
2025-12-10 10:08:48 - INFO - Epoch: 26.79, Step: 106130, Train Loss: 1.2037, Learning Rate: 3.48e-05
2025-12-10 10:09:00 - INFO - Epoch: 26.80, Step: 106140, Train Loss: 1.1643, Learning Rate: 3.47e-05
2025-12-10 10:09:11 - INFO - Epoch: 26.80, Step: 106150, Train Loss: 1.1879, Learning Rate: 3.47e-05
2025-12-10 10:09:22 - INFO - Epoch: 26.80, Step: 106160, Train Loss: 1.1667, Learning Rate: 3.47e-05
2025-12-10 10:09:33 - INFO - Epoch: 26.80, Step: 106170, Train Loss: 1.1699, Learning Rate: 3.47e-05
2025-12-10 10:09:44 - INFO - Epoch: 26.81, Step: 106180, Train Loss: 1.2168, Learning Rate: 3.47e-05
2025-12-10 10:09:55 - INFO - Epoch: 26.81, Step: 106190, Train Loss: 1.1809, Learning Rate: 3.47e-05
2025-12-10 10:10:06 - INFO - Epoch: 26.81, Step: 106200, Train Loss: 1.2055, Learning Rate: 3.47e-05
2025-12-10 10:10:18 - INFO - Epoch: 26.81, Step: 106210, Train Loss: 1.2185, Learning Rate: 3.47e-05
2025-12-10 10:10:29 - INFO - Epoch: 26.82, Step: 106220, Train Loss: 1.1967, Learning Rate: 3.47e-05
2025-12-10 10:10:40 - INFO - Epoch: 26.82, Step: 106230, Train Loss: 1.1694, Learning Rate: 3.47e-05
2025-12-10 10:10:51 - INFO - Epoch: 26.82, Step: 106240, Train Loss: 1.2196, Learning Rate: 3.47e-05
2025-12-10 10:11:02 - INFO - Epoch: 26.82, Step: 106250, Train Loss: 1.2158, Learning Rate: 3.47e-05
2025-12-10 10:11:13 - INFO - Epoch: 26.83, Step: 106260, Train Loss: 1.1627, Learning Rate: 3.47e-05
2025-12-10 10:11:25 - INFO - Epoch: 26.83, Step: 106270, Train Loss: 1.1978, Learning Rate: 3.47e-05
2025-12-10 10:11:36 - INFO - Epoch: 26.83, Step: 106280, Train Loss: 1.1992, Learning Rate: 3.47e-05
2025-12-10 10:11:47 - INFO - Epoch: 26.83, Step: 106290, Train Loss: 1.1955, Learning Rate: 3.46e-05
2025-12-10 10:11:58 - INFO - Epoch: 26.84, Step: 106300, Train Loss: 1.1573, Learning Rate: 3.46e-05
2025-12-10 10:12:09 - INFO - Epoch: 26.84, Step: 106310, Train Loss: 1.1903, Learning Rate: 3.46e-05
2025-12-10 10:12:20 - INFO - Epoch: 26.84, Step: 106320, Train Loss: 1.1843, Learning Rate: 3.46e-05
2025-12-10 10:12:31 - INFO - Epoch: 26.84, Step: 106330, Train Loss: 1.1878, Learning Rate: 3.46e-05
2025-12-10 10:12:43 - INFO - Epoch: 26.85, Step: 106340, Train Loss: 1.2000, Learning Rate: 3.46e-05
2025-12-10 10:12:54 - INFO - Epoch: 26.85, Step: 106350, Train Loss: 1.1795, Learning Rate: 3.46e-05
2025-12-10 10:13:05 - INFO - Epoch: 26.85, Step: 106360, Train Loss: 1.1981, Learning Rate: 3.46e-05
2025-12-10 10:13:16 - INFO - Epoch: 26.85, Step: 106370, Train Loss: 1.1580, Learning Rate: 3.46e-05
2025-12-10 10:13:27 - INFO - Epoch: 26.86, Step: 106380, Train Loss: 1.2028, Learning Rate: 3.46e-05
2025-12-10 10:13:38 - INFO - Epoch: 26.86, Step: 106390, Train Loss: 1.1746, Learning Rate: 3.46e-05
2025-12-10 10:13:50 - INFO - Epoch: 26.86, Step: 106400, Train Loss: 1.1947, Learning Rate: 3.46e-05
2025-12-10 10:14:01 - INFO - Epoch: 26.86, Step: 106410, Train Loss: 1.2145, Learning Rate: 3.46e-05
2025-12-10 10:14:12 - INFO - Epoch: 26.87, Step: 106420, Train Loss: 1.1695, Learning Rate: 3.46e-05
2025-12-10 10:14:23 - INFO - Epoch: 26.87, Step: 106430, Train Loss: 1.1852, Learning Rate: 3.46e-05
2025-12-10 10:14:34 - INFO - Epoch: 26.87, Step: 106440, Train Loss: 1.1729, Learning Rate: 3.45e-05
2025-12-10 10:14:45 - INFO - Epoch: 26.87, Step: 106450, Train Loss: 1.1822, Learning Rate: 3.45e-05
2025-12-10 10:14:56 - INFO - Epoch: 26.88, Step: 106460, Train Loss: 1.2072, Learning Rate: 3.45e-05
2025-12-10 10:15:08 - INFO - Epoch: 26.88, Step: 106470, Train Loss: 1.1925, Learning Rate: 3.45e-05
2025-12-10 10:15:19 - INFO - Epoch: 26.88, Step: 106480, Train Loss: 1.2179, Learning Rate: 3.45e-05
2025-12-10 10:15:30 - INFO - Epoch: 26.88, Step: 106490, Train Loss: 1.1885, Learning Rate: 3.45e-05
2025-12-10 10:15:41 - INFO - Epoch: 26.89, Step: 106500, Train Loss: 1.1888, Learning Rate: 3.45e-05
2025-12-10 10:15:52 - INFO - Epoch: 26.89, Step: 106510, Train Loss: 1.1902, Learning Rate: 3.45e-05
2025-12-10 10:16:03 - INFO - Epoch: 26.89, Step: 106520, Train Loss: 1.1961, Learning Rate: 3.45e-05
2025-12-10 10:16:15 - INFO - Epoch: 26.89, Step: 106530, Train Loss: 1.2091, Learning Rate: 3.45e-05
2025-12-10 10:16:26 - INFO - Epoch: 26.90, Step: 106540, Train Loss: 1.1814, Learning Rate: 3.45e-05
2025-12-10 10:16:37 - INFO - Epoch: 26.90, Step: 106550, Train Loss: 1.1977, Learning Rate: 3.45e-05
2025-12-10 10:16:48 - INFO - Epoch: 26.90, Step: 106560, Train Loss: 1.2086, Learning Rate: 3.45e-05
2025-12-10 10:16:59 - INFO - Epoch: 26.90, Step: 106570, Train Loss: 1.1692, Learning Rate: 3.45e-05
2025-12-10 10:17:10 - INFO - Epoch: 26.91, Step: 106580, Train Loss: 1.1817, Learning Rate: 3.45e-05
2025-12-10 10:17:21 - INFO - Epoch: 26.91, Step: 106590, Train Loss: 1.1997, Learning Rate: 3.44e-05
2025-12-10 10:17:33 - INFO - Epoch: 26.91, Step: 106600, Train Loss: 1.2066, Learning Rate: 3.44e-05
2025-12-10 10:17:44 - INFO - Epoch: 26.91, Step: 106610, Train Loss: 1.2112, Learning Rate: 3.44e-05
2025-12-10 10:17:55 - INFO - Epoch: 26.92, Step: 106620, Train Loss: 1.1959, Learning Rate: 3.44e-05
2025-12-10 10:18:06 - INFO - Epoch: 26.92, Step: 106630, Train Loss: 1.1997, Learning Rate: 3.44e-05
2025-12-10 10:18:17 - INFO - Epoch: 26.92, Step: 106640, Train Loss: 1.2123, Learning Rate: 3.44e-05
2025-12-10 10:18:28 - INFO - Epoch: 26.93, Step: 106650, Train Loss: 1.1649, Learning Rate: 3.44e-05
2025-12-10 10:18:40 - INFO - Epoch: 26.93, Step: 106660, Train Loss: 1.2185, Learning Rate: 3.44e-05
2025-12-10 10:18:51 - INFO - Epoch: 26.93, Step: 106670, Train Loss: 1.1836, Learning Rate: 3.44e-05
2025-12-10 10:19:02 - INFO - Epoch: 26.93, Step: 106680, Train Loss: 1.1973, Learning Rate: 3.44e-05
2025-12-10 10:19:13 - INFO - Epoch: 26.94, Step: 106690, Train Loss: 1.1901, Learning Rate: 3.44e-05
2025-12-10 10:19:24 - INFO - Epoch: 26.94, Step: 106700, Train Loss: 1.2166, Learning Rate: 3.44e-05
2025-12-10 10:19:35 - INFO - Epoch: 26.94, Step: 106710, Train Loss: 1.1597, Learning Rate: 3.44e-05
2025-12-10 10:19:46 - INFO - Epoch: 26.94, Step: 106720, Train Loss: 1.1929, Learning Rate: 3.44e-05
2025-12-10 10:19:58 - INFO - Epoch: 26.95, Step: 106730, Train Loss: 1.1970, Learning Rate: 3.44e-05
2025-12-10 10:20:09 - INFO - Epoch: 26.95, Step: 106740, Train Loss: 1.1824, Learning Rate: 3.43e-05
2025-12-10 10:20:20 - INFO - Epoch: 26.95, Step: 106750, Train Loss: 1.2169, Learning Rate: 3.43e-05
2025-12-10 10:20:31 - INFO - Epoch: 26.95, Step: 106760, Train Loss: 1.2058, Learning Rate: 3.43e-05
2025-12-10 10:20:42 - INFO - Epoch: 26.96, Step: 106770, Train Loss: 1.1893, Learning Rate: 3.43e-05
2025-12-10 10:20:53 - INFO - Epoch: 26.96, Step: 106780, Train Loss: 1.2430, Learning Rate: 3.43e-05
2025-12-10 10:21:05 - INFO - Epoch: 26.96, Step: 106790, Train Loss: 1.1845, Learning Rate: 3.43e-05
2025-12-10 10:21:16 - INFO - Epoch: 26.96, Step: 106800, Train Loss: 1.1971, Learning Rate: 3.43e-05
2025-12-10 10:21:27 - INFO - Epoch: 26.97, Step: 106810, Train Loss: 1.1951, Learning Rate: 3.43e-05
2025-12-10 10:21:38 - INFO - Epoch: 26.97, Step: 106820, Train Loss: 1.1947, Learning Rate: 3.43e-05
2025-12-10 10:21:49 - INFO - Epoch: 26.97, Step: 106830, Train Loss: 1.1827, Learning Rate: 3.43e-05
2025-12-10 10:22:00 - INFO - Epoch: 26.97, Step: 106840, Train Loss: 1.1993, Learning Rate: 3.43e-05
2025-12-10 10:22:11 - INFO - Epoch: 26.98, Step: 106850, Train Loss: 1.1808, Learning Rate: 3.43e-05
2025-12-10 10:22:23 - INFO - Epoch: 26.98, Step: 106860, Train Loss: 1.1817, Learning Rate: 3.43e-05
2025-12-10 10:22:34 - INFO - Epoch: 26.98, Step: 106870, Train Loss: 1.1867, Learning Rate: 3.43e-05
2025-12-10 10:22:45 - INFO - Epoch: 26.98, Step: 106880, Train Loss: 1.1928, Learning Rate: 3.43e-05
2025-12-10 10:22:56 - INFO - Epoch: 26.99, Step: 106890, Train Loss: 1.2165, Learning Rate: 3.42e-05
2025-12-10 10:23:07 - INFO - Epoch: 26.99, Step: 106900, Train Loss: 1.1840, Learning Rate: 3.42e-05
2025-12-10 10:23:18 - INFO - Epoch: 26.99, Step: 106910, Train Loss: 1.1742, Learning Rate: 3.42e-05
2025-12-10 10:23:30 - INFO - Epoch: 26.99, Step: 106920, Train Loss: 1.1771, Learning Rate: 3.42e-05
2025-12-10 10:23:41 - INFO - Epoch: 27.00, Step: 106930, Train Loss: 1.1784, Learning Rate: 3.42e-05
2025-12-10 10:23:52 - INFO - Epoch: 27.00, Step: 106940, Train Loss: 1.1963, Learning Rate: 3.42e-05
2025-12-10 10:24:03 - INFO - Epoch: 27.00, Step: 106950, Train Loss: 1.1883, Learning Rate: 3.42e-05
2025-12-10 10:24:14 - INFO - Epoch: 27.00, Step: 106960, Train Loss: 1.1756, Learning Rate: 3.42e-05
2025-12-10 10:24:25 - INFO - Epoch: 27.01, Step: 106970, Train Loss: 1.1850, Learning Rate: 3.42e-05
2025-12-10 10:24:36 - INFO - Epoch: 27.01, Step: 106980, Train Loss: 1.1690, Learning Rate: 3.42e-05
2025-12-10 10:24:48 - INFO - Epoch: 27.01, Step: 106990, Train Loss: 1.2140, Learning Rate: 3.42e-05
2025-12-10 10:24:59 - INFO - Epoch: 27.01, Step: 107000, Train Loss: 1.1640, Learning Rate: 3.42e-05
2025-12-10 10:25:10 - INFO - Epoch: 27.02, Step: 107010, Train Loss: 1.2080, Learning Rate: 3.42e-05
2025-12-10 10:25:21 - INFO - Epoch: 27.02, Step: 107020, Train Loss: 1.1861, Learning Rate: 3.42e-05
2025-12-10 10:25:32 - INFO - Epoch: 27.02, Step: 107030, Train Loss: 1.1679, Learning Rate: 3.42e-05
2025-12-10 10:25:43 - INFO - Epoch: 27.02, Step: 107040, Train Loss: 1.1434, Learning Rate: 3.41e-05
2025-12-10 10:25:55 - INFO - Epoch: 27.03, Step: 107050, Train Loss: 1.1806, Learning Rate: 3.41e-05
2025-12-10 10:26:06 - INFO - Epoch: 27.03, Step: 107060, Train Loss: 1.1943, Learning Rate: 3.41e-05
2025-12-10 10:26:17 - INFO - Epoch: 27.03, Step: 107070, Train Loss: 1.1887, Learning Rate: 3.41e-05
2025-12-10 10:26:28 - INFO - Epoch: 27.03, Step: 107080, Train Loss: 1.1926, Learning Rate: 3.41e-05
2025-12-10 10:26:39 - INFO - Epoch: 27.04, Step: 107090, Train Loss: 1.1922, Learning Rate: 3.41e-05
2025-12-10 10:26:50 - INFO - Epoch: 27.04, Step: 107100, Train Loss: 1.1379, Learning Rate: 3.41e-05
2025-12-10 10:27:01 - INFO - Epoch: 27.04, Step: 107110, Train Loss: 1.1678, Learning Rate: 3.41e-05
2025-12-10 10:27:13 - INFO - Epoch: 27.04, Step: 107120, Train Loss: 1.1624, Learning Rate: 3.41e-05
2025-12-10 10:27:24 - INFO - Epoch: 27.05, Step: 107130, Train Loss: 1.1698, Learning Rate: 3.41e-05
2025-12-10 10:27:35 - INFO - Epoch: 27.05, Step: 107140, Train Loss: 1.1537, Learning Rate: 3.41e-05
2025-12-10 10:27:46 - INFO - Epoch: 27.05, Step: 107150, Train Loss: 1.2522, Learning Rate: 3.41e-05
2025-12-10 10:27:57 - INFO - Epoch: 27.05, Step: 107160, Train Loss: 1.1917, Learning Rate: 3.41e-05
2025-12-10 10:28:08 - INFO - Epoch: 27.06, Step: 107170, Train Loss: 1.1991, Learning Rate: 3.41e-05
2025-12-10 10:28:20 - INFO - Epoch: 27.06, Step: 107180, Train Loss: 1.2000, Learning Rate: 3.41e-05
2025-12-10 10:28:31 - INFO - Epoch: 27.06, Step: 107190, Train Loss: 1.1937, Learning Rate: 3.40e-05
2025-12-10 10:28:42 - INFO - Epoch: 27.06, Step: 107200, Train Loss: 1.2116, Learning Rate: 3.40e-05
2025-12-10 10:28:53 - INFO - Epoch: 27.07, Step: 107210, Train Loss: 1.1779, Learning Rate: 3.40e-05
2025-12-10 10:29:04 - INFO - Epoch: 27.07, Step: 107220, Train Loss: 1.1732, Learning Rate: 3.40e-05
2025-12-10 10:29:15 - INFO - Epoch: 27.07, Step: 107230, Train Loss: 1.2485, Learning Rate: 3.40e-05
2025-12-10 10:29:26 - INFO - Epoch: 27.07, Step: 107240, Train Loss: 1.2347, Learning Rate: 3.40e-05
2025-12-10 10:29:38 - INFO - Epoch: 27.08, Step: 107250, Train Loss: 1.2066, Learning Rate: 3.40e-05
2025-12-10 10:29:49 - INFO - Epoch: 27.08, Step: 107260, Train Loss: 1.2185, Learning Rate: 3.40e-05
2025-12-10 10:30:00 - INFO - Epoch: 27.08, Step: 107270, Train Loss: 1.1725, Learning Rate: 3.40e-05
2025-12-10 10:30:11 - INFO - Epoch: 27.08, Step: 107280, Train Loss: 1.2277, Learning Rate: 3.40e-05
2025-12-10 10:30:22 - INFO - Epoch: 27.09, Step: 107290, Train Loss: 1.1890, Learning Rate: 3.40e-05
2025-12-10 10:30:33 - INFO - Epoch: 27.09, Step: 107300, Train Loss: 1.2137, Learning Rate: 3.40e-05
2025-12-10 10:30:45 - INFO - Epoch: 27.09, Step: 107310, Train Loss: 1.1937, Learning Rate: 3.40e-05
2025-12-10 10:30:56 - INFO - Epoch: 27.09, Step: 107320, Train Loss: 1.2107, Learning Rate: 3.40e-05
2025-12-10 10:31:07 - INFO - Epoch: 27.10, Step: 107330, Train Loss: 1.1753, Learning Rate: 3.40e-05
2025-12-10 10:31:18 - INFO - Epoch: 27.10, Step: 107340, Train Loss: 1.2040, Learning Rate: 3.40e-05
2025-12-10 10:31:29 - INFO - Epoch: 27.10, Step: 107350, Train Loss: 1.2044, Learning Rate: 3.39e-05
2025-12-10 10:31:40 - INFO - Epoch: 27.10, Step: 107360, Train Loss: 1.2017, Learning Rate: 3.39e-05
2025-12-10 10:31:51 - INFO - Epoch: 27.11, Step: 107370, Train Loss: 1.2290, Learning Rate: 3.39e-05
2025-12-10 10:32:03 - INFO - Epoch: 27.11, Step: 107380, Train Loss: 1.2130, Learning Rate: 3.39e-05
2025-12-10 10:32:14 - INFO - Epoch: 27.11, Step: 107390, Train Loss: 1.1926, Learning Rate: 3.39e-05
2025-12-10 10:32:25 - INFO - Epoch: 27.11, Step: 107400, Train Loss: 1.2063, Learning Rate: 3.39e-05
2025-12-10 10:32:36 - INFO - Epoch: 27.12, Step: 107410, Train Loss: 1.1853, Learning Rate: 3.39e-05
2025-12-10 10:32:47 - INFO - Epoch: 27.12, Step: 107420, Train Loss: 1.2521, Learning Rate: 3.39e-05
2025-12-10 10:32:58 - INFO - Epoch: 27.12, Step: 107430, Train Loss: 1.1900, Learning Rate: 3.39e-05
2025-12-10 10:33:10 - INFO - Epoch: 27.12, Step: 107440, Train Loss: 1.1665, Learning Rate: 3.39e-05
2025-12-10 10:33:21 - INFO - Epoch: 27.13, Step: 107450, Train Loss: 1.2024, Learning Rate: 3.39e-05
2025-12-10 10:33:32 - INFO - Epoch: 27.13, Step: 107460, Train Loss: 1.1619, Learning Rate: 3.39e-05
2025-12-10 10:33:43 - INFO - Epoch: 27.13, Step: 107470, Train Loss: 1.2225, Learning Rate: 3.39e-05
2025-12-10 10:33:54 - INFO - Epoch: 27.13, Step: 107480, Train Loss: 1.1362, Learning Rate: 3.39e-05
2025-12-10 10:34:05 - INFO - Epoch: 27.14, Step: 107490, Train Loss: 1.1823, Learning Rate: 3.39e-05
2025-12-10 10:34:16 - INFO - Epoch: 27.14, Step: 107500, Train Loss: 1.1980, Learning Rate: 3.38e-05
2025-12-10 10:34:28 - INFO - Epoch: 27.14, Step: 107510, Train Loss: 1.1817, Learning Rate: 3.38e-05
2025-12-10 10:34:39 - INFO - Epoch: 27.14, Step: 107520, Train Loss: 1.1995, Learning Rate: 3.38e-05
2025-12-10 10:34:50 - INFO - Epoch: 27.15, Step: 107530, Train Loss: 1.2219, Learning Rate: 3.38e-05
2025-12-10 10:35:01 - INFO - Epoch: 27.15, Step: 107540, Train Loss: 1.2005, Learning Rate: 3.38e-05
2025-12-10 10:35:12 - INFO - Epoch: 27.15, Step: 107550, Train Loss: 1.2206, Learning Rate: 3.38e-05
2025-12-10 10:35:23 - INFO - Epoch: 27.15, Step: 107560, Train Loss: 1.2463, Learning Rate: 3.38e-05
2025-12-10 10:35:35 - INFO - Epoch: 27.16, Step: 107570, Train Loss: 1.1462, Learning Rate: 3.38e-05
2025-12-10 10:35:46 - INFO - Epoch: 27.16, Step: 107580, Train Loss: 1.1827, Learning Rate: 3.38e-05
2025-12-10 10:35:57 - INFO - Epoch: 27.16, Step: 107590, Train Loss: 1.1952, Learning Rate: 3.38e-05
2025-12-10 10:36:08 - INFO - Epoch: 27.16, Step: 107600, Train Loss: 1.1930, Learning Rate: 3.38e-05
2025-12-10 10:36:19 - INFO - Epoch: 27.17, Step: 107610, Train Loss: 1.1947, Learning Rate: 3.38e-05
2025-12-10 10:36:30 - INFO - Epoch: 27.17, Step: 107620, Train Loss: 1.2001, Learning Rate: 3.38e-05
2025-12-10 10:36:41 - INFO - Epoch: 27.17, Step: 107630, Train Loss: 1.1995, Learning Rate: 3.38e-05
2025-12-10 10:36:53 - INFO - Epoch: 27.17, Step: 107640, Train Loss: 1.2005, Learning Rate: 3.38e-05
2025-12-10 10:37:04 - INFO - Epoch: 27.18, Step: 107650, Train Loss: 1.2141, Learning Rate: 3.37e-05
2025-12-10 10:37:15 - INFO - Epoch: 27.18, Step: 107660, Train Loss: 1.1781, Learning Rate: 3.37e-05
2025-12-10 10:37:26 - INFO - Epoch: 27.18, Step: 107670, Train Loss: 1.1916, Learning Rate: 3.37e-05
2025-12-10 10:37:37 - INFO - Epoch: 27.19, Step: 107680, Train Loss: 1.2070, Learning Rate: 3.37e-05
2025-12-10 10:37:48 - INFO - Epoch: 27.19, Step: 107690, Train Loss: 1.1825, Learning Rate: 3.37e-05
2025-12-10 10:38:00 - INFO - Epoch: 27.19, Step: 107700, Train Loss: 1.1975, Learning Rate: 3.37e-05
2025-12-10 10:38:11 - INFO - Epoch: 27.19, Step: 107710, Train Loss: 1.2099, Learning Rate: 3.37e-05
2025-12-10 10:38:22 - INFO - Epoch: 27.20, Step: 107720, Train Loss: 1.1505, Learning Rate: 3.37e-05
2025-12-10 10:38:33 - INFO - Epoch: 27.20, Step: 107730, Train Loss: 1.1853, Learning Rate: 3.37e-05
2025-12-10 10:38:44 - INFO - Epoch: 27.20, Step: 107740, Train Loss: 1.1733, Learning Rate: 3.37e-05
2025-12-10 10:38:55 - INFO - Epoch: 27.20, Step: 107750, Train Loss: 1.2011, Learning Rate: 3.37e-05
2025-12-10 10:39:06 - INFO - Epoch: 27.21, Step: 107760, Train Loss: 1.1752, Learning Rate: 3.37e-05
2025-12-10 10:39:18 - INFO - Epoch: 27.21, Step: 107770, Train Loss: 1.2073, Learning Rate: 3.37e-05
2025-12-10 10:39:29 - INFO - Epoch: 27.21, Step: 107780, Train Loss: 1.2269, Learning Rate: 3.37e-05
2025-12-10 10:39:40 - INFO - Epoch: 27.21, Step: 107790, Train Loss: 1.2091, Learning Rate: 3.37e-05
2025-12-10 10:39:51 - INFO - Epoch: 27.22, Step: 107800, Train Loss: 1.1837, Learning Rate: 3.36e-05
2025-12-10 10:40:02 - INFO - Epoch: 27.22, Step: 107810, Train Loss: 1.2116, Learning Rate: 3.36e-05
2025-12-10 10:40:13 - INFO - Epoch: 27.22, Step: 107820, Train Loss: 1.1727, Learning Rate: 3.36e-05
2025-12-10 10:40:24 - INFO - Epoch: 27.22, Step: 107830, Train Loss: 1.1590, Learning Rate: 3.36e-05
2025-12-10 10:40:36 - INFO - Epoch: 27.23, Step: 107840, Train Loss: 1.1604, Learning Rate: 3.36e-05
2025-12-10 10:40:47 - INFO - Epoch: 27.23, Step: 107850, Train Loss: 1.1699, Learning Rate: 3.36e-05
2025-12-10 10:40:58 - INFO - Epoch: 27.23, Step: 107860, Train Loss: 1.1494, Learning Rate: 3.36e-05
2025-12-10 10:41:09 - INFO - Epoch: 27.23, Step: 107870, Train Loss: 1.1896, Learning Rate: 3.36e-05
2025-12-10 10:41:20 - INFO - Epoch: 27.24, Step: 107880, Train Loss: 1.1966, Learning Rate: 3.36e-05
2025-12-10 10:41:31 - INFO - Epoch: 27.24, Step: 107890, Train Loss: 1.2143, Learning Rate: 3.36e-05
2025-12-10 10:41:43 - INFO - Epoch: 27.24, Step: 107900, Train Loss: 1.2107, Learning Rate: 3.36e-05
2025-12-10 10:41:54 - INFO - Epoch: 27.24, Step: 107910, Train Loss: 1.1947, Learning Rate: 3.36e-05
2025-12-10 10:42:05 - INFO - Epoch: 27.25, Step: 107920, Train Loss: 1.1952, Learning Rate: 3.36e-05
2025-12-10 10:42:16 - INFO - Epoch: 27.25, Step: 107930, Train Loss: 1.1972, Learning Rate: 3.36e-05
2025-12-10 10:42:27 - INFO - Epoch: 27.25, Step: 107940, Train Loss: 1.2047, Learning Rate: 3.36e-05
2025-12-10 10:42:38 - INFO - Epoch: 27.25, Step: 107950, Train Loss: 1.1803, Learning Rate: 3.35e-05
2025-12-10 10:42:49 - INFO - Epoch: 27.26, Step: 107960, Train Loss: 1.1620, Learning Rate: 3.35e-05
2025-12-10 10:43:01 - INFO - Epoch: 27.26, Step: 107970, Train Loss: 1.2451, Learning Rate: 3.35e-05
2025-12-10 10:43:12 - INFO - Epoch: 27.26, Step: 107980, Train Loss: 1.1704, Learning Rate: 3.35e-05
2025-12-10 10:43:23 - INFO - Epoch: 27.26, Step: 107990, Train Loss: 1.2124, Learning Rate: 3.35e-05
2025-12-10 10:43:34 - INFO - Epoch: 27.27, Step: 108000, Train Loss: 1.1743, Learning Rate: 3.35e-05
2025-12-10 10:43:45 - INFO - Epoch: 27.27, Step: 108010, Train Loss: 1.1627, Learning Rate: 3.35e-05
2025-12-10 10:43:56 - INFO - Epoch: 27.27, Step: 108020, Train Loss: 1.1976, Learning Rate: 3.35e-05
2025-12-10 10:44:08 - INFO - Epoch: 27.27, Step: 108030, Train Loss: 1.1916, Learning Rate: 3.35e-05
2025-12-10 10:44:19 - INFO - Epoch: 27.28, Step: 108040, Train Loss: 1.1963, Learning Rate: 3.35e-05
2025-12-10 10:44:30 - INFO - Epoch: 27.28, Step: 108050, Train Loss: 1.2014, Learning Rate: 3.35e-05
2025-12-10 10:44:41 - INFO - Epoch: 27.28, Step: 108060, Train Loss: 1.1794, Learning Rate: 3.35e-05
2025-12-10 10:44:52 - INFO - Epoch: 27.28, Step: 108070, Train Loss: 1.1743, Learning Rate: 3.35e-05
2025-12-10 10:45:03 - INFO - Epoch: 27.29, Step: 108080, Train Loss: 1.1899, Learning Rate: 3.35e-05
2025-12-10 10:45:14 - INFO - Epoch: 27.29, Step: 108090, Train Loss: 1.1798, Learning Rate: 3.35e-05
2025-12-10 10:45:26 - INFO - Epoch: 27.29, Step: 108100, Train Loss: 1.2339, Learning Rate: 3.34e-05
2025-12-10 10:45:37 - INFO - Epoch: 27.29, Step: 108110, Train Loss: 1.1971, Learning Rate: 3.34e-05
2025-12-10 10:45:48 - INFO - Epoch: 27.30, Step: 108120, Train Loss: 1.1833, Learning Rate: 3.34e-05
2025-12-10 10:45:59 - INFO - Epoch: 27.30, Step: 108130, Train Loss: 1.1551, Learning Rate: 3.34e-05
2025-12-10 10:46:10 - INFO - Epoch: 27.30, Step: 108140, Train Loss: 1.1923, Learning Rate: 3.34e-05
2025-12-10 10:46:21 - INFO - Epoch: 27.30, Step: 108150, Train Loss: 1.1963, Learning Rate: 3.34e-05
2025-12-10 10:46:33 - INFO - Epoch: 27.31, Step: 108160, Train Loss: 1.1931, Learning Rate: 3.34e-05
2025-12-10 10:46:44 - INFO - Epoch: 27.31, Step: 108170, Train Loss: 1.2023, Learning Rate: 3.34e-05
2025-12-10 10:46:55 - INFO - Epoch: 27.31, Step: 108180, Train Loss: 1.2351, Learning Rate: 3.34e-05
2025-12-10 10:47:06 - INFO - Epoch: 27.31, Step: 108190, Train Loss: 1.2037, Learning Rate: 3.34e-05
2025-12-10 10:47:17 - INFO - Epoch: 27.32, Step: 108200, Train Loss: 1.1967, Learning Rate: 3.34e-05
2025-12-10 10:47:28 - INFO - Epoch: 27.32, Step: 108210, Train Loss: 1.2227, Learning Rate: 3.34e-05
2025-12-10 10:47:39 - INFO - Epoch: 27.32, Step: 108220, Train Loss: 1.1975, Learning Rate: 3.34e-05
2025-12-10 10:47:51 - INFO - Epoch: 27.32, Step: 108230, Train Loss: 1.2004, Learning Rate: 3.34e-05
2025-12-10 10:48:02 - INFO - Epoch: 27.33, Step: 108240, Train Loss: 1.1718, Learning Rate: 3.34e-05
2025-12-10 10:48:13 - INFO - Epoch: 27.33, Step: 108250, Train Loss: 1.2000, Learning Rate: 3.33e-05
2025-12-10 10:48:24 - INFO - Epoch: 27.33, Step: 108260, Train Loss: 1.2232, Learning Rate: 3.33e-05
2025-12-10 10:48:35 - INFO - Epoch: 27.33, Step: 108270, Train Loss: 1.1816, Learning Rate: 3.33e-05
2025-12-10 10:48:46 - INFO - Epoch: 27.34, Step: 108280, Train Loss: 1.1902, Learning Rate: 3.33e-05
2025-12-10 10:48:58 - INFO - Epoch: 27.34, Step: 108290, Train Loss: 1.1509, Learning Rate: 3.33e-05
2025-12-10 10:49:09 - INFO - Epoch: 27.34, Step: 108300, Train Loss: 1.1977, Learning Rate: 3.33e-05
2025-12-10 10:49:20 - INFO - Epoch: 27.34, Step: 108310, Train Loss: 1.2197, Learning Rate: 3.33e-05
2025-12-10 10:49:31 - INFO - Epoch: 27.35, Step: 108320, Train Loss: 1.1846, Learning Rate: 3.33e-05
2025-12-10 10:49:42 - INFO - Epoch: 27.35, Step: 108330, Train Loss: 1.1982, Learning Rate: 3.33e-05
2025-12-10 10:49:53 - INFO - Epoch: 27.35, Step: 108340, Train Loss: 1.2209, Learning Rate: 3.33e-05
2025-12-10 10:50:04 - INFO - Epoch: 27.35, Step: 108350, Train Loss: 1.1890, Learning Rate: 3.33e-05
2025-12-10 10:50:16 - INFO - Epoch: 27.36, Step: 108360, Train Loss: 1.2217, Learning Rate: 3.33e-05
2025-12-10 10:50:27 - INFO - Epoch: 27.36, Step: 108370, Train Loss: 1.1742, Learning Rate: 3.33e-05
2025-12-10 10:50:38 - INFO - Epoch: 27.36, Step: 108380, Train Loss: 1.1990, Learning Rate: 3.33e-05
2025-12-10 10:50:49 - INFO - Epoch: 27.36, Step: 108390, Train Loss: 1.1371, Learning Rate: 3.33e-05
2025-12-10 10:51:00 - INFO - Epoch: 27.37, Step: 108400, Train Loss: 1.2098, Learning Rate: 3.32e-05
2025-12-10 10:51:11 - INFO - Epoch: 27.37, Step: 108410, Train Loss: 1.1612, Learning Rate: 3.32e-05
2025-12-10 10:51:23 - INFO - Epoch: 27.37, Step: 108420, Train Loss: 1.2167, Learning Rate: 3.32e-05
2025-12-10 10:51:34 - INFO - Epoch: 27.37, Step: 108430, Train Loss: 1.2261, Learning Rate: 3.32e-05
2025-12-10 10:51:45 - INFO - Epoch: 27.38, Step: 108440, Train Loss: 1.1745, Learning Rate: 3.32e-05
2025-12-10 10:51:56 - INFO - Epoch: 27.38, Step: 108450, Train Loss: 1.1926, Learning Rate: 3.32e-05
2025-12-10 10:52:07 - INFO - Epoch: 27.38, Step: 108460, Train Loss: 1.1996, Learning Rate: 3.32e-05
2025-12-10 10:52:18 - INFO - Epoch: 27.38, Step: 108470, Train Loss: 1.1877, Learning Rate: 3.32e-05
2025-12-10 10:52:29 - INFO - Epoch: 27.39, Step: 108480, Train Loss: 1.1942, Learning Rate: 3.32e-05
2025-12-10 10:52:41 - INFO - Epoch: 27.39, Step: 108490, Train Loss: 1.2471, Learning Rate: 3.32e-05
2025-12-10 10:52:52 - INFO - Epoch: 27.39, Step: 108500, Train Loss: 1.2337, Learning Rate: 3.32e-05
2025-12-10 10:53:03 - INFO - Epoch: 27.39, Step: 108510, Train Loss: 1.2004, Learning Rate: 3.32e-05
2025-12-10 10:53:14 - INFO - Epoch: 27.40, Step: 108520, Train Loss: 1.1992, Learning Rate: 3.32e-05
2025-12-10 10:53:25 - INFO - Epoch: 27.40, Step: 108530, Train Loss: 1.1990, Learning Rate: 3.32e-05
2025-12-10 10:53:36 - INFO - Epoch: 27.40, Step: 108540, Train Loss: 1.2127, Learning Rate: 3.32e-05
2025-12-10 10:53:48 - INFO - Epoch: 27.40, Step: 108550, Train Loss: 1.2191, Learning Rate: 3.31e-05
2025-12-10 10:53:59 - INFO - Epoch: 27.41, Step: 108560, Train Loss: 1.1787, Learning Rate: 3.31e-05
2025-12-10 10:54:10 - INFO - Epoch: 27.41, Step: 108570, Train Loss: 1.1878, Learning Rate: 3.31e-05
2025-12-10 10:54:21 - INFO - Epoch: 27.41, Step: 108580, Train Loss: 1.1840, Learning Rate: 3.31e-05
2025-12-10 10:54:32 - INFO - Epoch: 27.41, Step: 108590, Train Loss: 1.1830, Learning Rate: 3.31e-05
2025-12-10 10:54:43 - INFO - Epoch: 27.42, Step: 108600, Train Loss: 1.1793, Learning Rate: 3.31e-05
2025-12-10 10:54:54 - INFO - Epoch: 27.42, Step: 108610, Train Loss: 1.1746, Learning Rate: 3.31e-05
2025-12-10 10:55:06 - INFO - Epoch: 27.42, Step: 108620, Train Loss: 1.1934, Learning Rate: 3.31e-05
2025-12-10 10:55:17 - INFO - Epoch: 27.42, Step: 108630, Train Loss: 1.1586, Learning Rate: 3.31e-05
2025-12-10 10:55:28 - INFO - Epoch: 27.43, Step: 108640, Train Loss: 1.1869, Learning Rate: 3.31e-05
2025-12-10 10:55:39 - INFO - Epoch: 27.43, Step: 108650, Train Loss: 1.1787, Learning Rate: 3.31e-05
2025-12-10 10:55:50 - INFO - Epoch: 27.43, Step: 108660, Train Loss: 1.1791, Learning Rate: 3.31e-05
2025-12-10 10:56:01 - INFO - Epoch: 27.43, Step: 108670, Train Loss: 1.2284, Learning Rate: 3.31e-05
2025-12-10 10:56:13 - INFO - Epoch: 27.44, Step: 108680, Train Loss: 1.1760, Learning Rate: 3.31e-05
2025-12-10 10:56:24 - INFO - Epoch: 27.44, Step: 108690, Train Loss: 1.1939, Learning Rate: 3.31e-05
2025-12-10 10:56:35 - INFO - Epoch: 27.44, Step: 108700, Train Loss: 1.1980, Learning Rate: 3.30e-05
2025-12-10 10:56:46 - INFO - Epoch: 27.45, Step: 108710, Train Loss: 1.1581, Learning Rate: 3.30e-05
2025-12-10 10:56:57 - INFO - Epoch: 27.45, Step: 108720, Train Loss: 1.1970, Learning Rate: 3.30e-05
2025-12-10 10:57:08 - INFO - Epoch: 27.45, Step: 108730, Train Loss: 1.1764, Learning Rate: 3.30e-05
2025-12-10 10:57:19 - INFO - Epoch: 27.45, Step: 108740, Train Loss: 1.1709, Learning Rate: 3.30e-05
2025-12-10 10:57:31 - INFO - Epoch: 27.46, Step: 108750, Train Loss: 1.2031, Learning Rate: 3.30e-05
2025-12-10 10:57:42 - INFO - Epoch: 27.46, Step: 108760, Train Loss: 1.1961, Learning Rate: 3.30e-05
2025-12-10 10:57:53 - INFO - Epoch: 27.46, Step: 108770, Train Loss: 1.1914, Learning Rate: 3.30e-05
2025-12-10 10:58:04 - INFO - Epoch: 27.46, Step: 108780, Train Loss: 1.1765, Learning Rate: 3.30e-05
2025-12-10 10:58:15 - INFO - Epoch: 27.47, Step: 108790, Train Loss: 1.2041, Learning Rate: 3.30e-05
2025-12-10 10:58:26 - INFO - Epoch: 27.47, Step: 108800, Train Loss: 1.2179, Learning Rate: 3.30e-05
2025-12-10 10:58:38 - INFO - Epoch: 27.47, Step: 108810, Train Loss: 1.1658, Learning Rate: 3.30e-05
2025-12-10 10:58:49 - INFO - Epoch: 27.47, Step: 108820, Train Loss: 1.1701, Learning Rate: 3.30e-05
2025-12-10 10:59:00 - INFO - Epoch: 27.48, Step: 108830, Train Loss: 1.1835, Learning Rate: 3.30e-05
2025-12-10 10:59:11 - INFO - Epoch: 27.48, Step: 108840, Train Loss: 1.1901, Learning Rate: 3.30e-05
2025-12-10 10:59:22 - INFO - Epoch: 27.48, Step: 108850, Train Loss: 1.1855, Learning Rate: 3.29e-05
2025-12-10 10:59:33 - INFO - Epoch: 27.48, Step: 108860, Train Loss: 1.2017, Learning Rate: 3.29e-05
2025-12-10 10:59:44 - INFO - Epoch: 27.49, Step: 108870, Train Loss: 1.2027, Learning Rate: 3.29e-05
2025-12-10 10:59:56 - INFO - Epoch: 27.49, Step: 108880, Train Loss: 1.1935, Learning Rate: 3.29e-05
2025-12-10 11:00:07 - INFO - Epoch: 27.49, Step: 108890, Train Loss: 1.1816, Learning Rate: 3.29e-05
2025-12-10 11:00:18 - INFO - Epoch: 27.49, Step: 108900, Train Loss: 1.2339, Learning Rate: 3.29e-05
2025-12-10 11:00:29 - INFO - Epoch: 27.50, Step: 108910, Train Loss: 1.1738, Learning Rate: 3.29e-05
2025-12-10 11:00:40 - INFO - Epoch: 27.50, Step: 108920, Train Loss: 1.1738, Learning Rate: 3.29e-05
2025-12-10 11:00:51 - INFO - Epoch: 27.50, Step: 108930, Train Loss: 1.1967, Learning Rate: 3.29e-05
2025-12-10 11:01:03 - INFO - Epoch: 27.50, Step: 108940, Train Loss: 1.2101, Learning Rate: 3.29e-05
2025-12-10 11:01:14 - INFO - Epoch: 27.51, Step: 108950, Train Loss: 1.2118, Learning Rate: 3.29e-05
2025-12-10 11:01:25 - INFO - Epoch: 27.51, Step: 108960, Train Loss: 1.1682, Learning Rate: 3.29e-05
2025-12-10 11:01:36 - INFO - Epoch: 27.51, Step: 108970, Train Loss: 1.1858, Learning Rate: 3.29e-05
2025-12-10 11:01:47 - INFO - Epoch: 27.51, Step: 108980, Train Loss: 1.1865, Learning Rate: 3.29e-05
2025-12-10 11:01:58 - INFO - Epoch: 27.52, Step: 108990, Train Loss: 1.1715, Learning Rate: 3.29e-05
2025-12-10 11:02:09 - INFO - Epoch: 27.52, Step: 109000, Train Loss: 1.1945, Learning Rate: 3.28e-05
2025-12-10 11:02:21 - INFO - Epoch: 27.52, Step: 109010, Train Loss: 1.2195, Learning Rate: 3.28e-05
2025-12-10 11:02:32 - INFO - Epoch: 27.52, Step: 109020, Train Loss: 1.1872, Learning Rate: 3.28e-05
2025-12-10 11:02:43 - INFO - Epoch: 27.53, Step: 109030, Train Loss: 1.2151, Learning Rate: 3.28e-05
2025-12-10 11:02:54 - INFO - Epoch: 27.53, Step: 109040, Train Loss: 1.1690, Learning Rate: 3.28e-05
2025-12-10 11:03:05 - INFO - Epoch: 27.53, Step: 109050, Train Loss: 1.1767, Learning Rate: 3.28e-05
2025-12-10 11:03:16 - INFO - Epoch: 27.53, Step: 109060, Train Loss: 1.1976, Learning Rate: 3.28e-05
2025-12-10 11:03:28 - INFO - Epoch: 27.54, Step: 109070, Train Loss: 1.1860, Learning Rate: 3.28e-05
2025-12-10 11:03:39 - INFO - Epoch: 27.54, Step: 109080, Train Loss: 1.1850, Learning Rate: 3.28e-05
2025-12-10 11:03:50 - INFO - Epoch: 27.54, Step: 109090, Train Loss: 1.1867, Learning Rate: 3.28e-05
2025-12-10 11:04:01 - INFO - Epoch: 27.54, Step: 109100, Train Loss: 1.2499, Learning Rate: 3.28e-05
2025-12-10 11:04:12 - INFO - Epoch: 27.55, Step: 109110, Train Loss: 1.2025, Learning Rate: 3.28e-05
2025-12-10 11:04:23 - INFO - Epoch: 27.55, Step: 109120, Train Loss: 1.1546, Learning Rate: 3.28e-05
2025-12-10 11:04:34 - INFO - Epoch: 27.55, Step: 109130, Train Loss: 1.1975, Learning Rate: 3.28e-05
2025-12-10 11:04:46 - INFO - Epoch: 27.55, Step: 109140, Train Loss: 1.1971, Learning Rate: 3.28e-05
2025-12-10 11:04:57 - INFO - Epoch: 27.56, Step: 109150, Train Loss: 1.1811, Learning Rate: 3.27e-05
2025-12-10 11:05:08 - INFO - Epoch: 27.56, Step: 109160, Train Loss: 1.2240, Learning Rate: 3.27e-05
2025-12-10 11:05:19 - INFO - Epoch: 27.56, Step: 109170, Train Loss: 1.1594, Learning Rate: 3.27e-05
2025-12-10 11:05:30 - INFO - Epoch: 27.56, Step: 109180, Train Loss: 1.1931, Learning Rate: 3.27e-05
2025-12-10 11:05:41 - INFO - Epoch: 27.57, Step: 109190, Train Loss: 1.1785, Learning Rate: 3.27e-05
2025-12-10 11:05:53 - INFO - Epoch: 27.57, Step: 109200, Train Loss: 1.1466, Learning Rate: 3.27e-05
2025-12-10 11:06:04 - INFO - Epoch: 27.57, Step: 109210, Train Loss: 1.1696, Learning Rate: 3.27e-05
2025-12-10 11:06:15 - INFO - Epoch: 27.57, Step: 109220, Train Loss: 1.1721, Learning Rate: 3.27e-05
2025-12-10 11:06:26 - INFO - Epoch: 27.58, Step: 109230, Train Loss: 1.1953, Learning Rate: 3.27e-05
2025-12-10 11:06:37 - INFO - Epoch: 27.58, Step: 109240, Train Loss: 1.1510, Learning Rate: 3.27e-05
2025-12-10 11:06:48 - INFO - Epoch: 27.58, Step: 109250, Train Loss: 1.1982, Learning Rate: 3.27e-05
2025-12-10 11:06:59 - INFO - Epoch: 27.58, Step: 109260, Train Loss: 1.1731, Learning Rate: 3.27e-05
2025-12-10 11:07:11 - INFO - Epoch: 27.59, Step: 109270, Train Loss: 1.2124, Learning Rate: 3.27e-05
2025-12-10 11:07:22 - INFO - Epoch: 27.59, Step: 109280, Train Loss: 1.1649, Learning Rate: 3.27e-05
2025-12-10 11:07:33 - INFO - Epoch: 27.59, Step: 109290, Train Loss: 1.1917, Learning Rate: 3.27e-05
2025-12-10 11:07:44 - INFO - Epoch: 27.59, Step: 109300, Train Loss: 1.2100, Learning Rate: 3.26e-05
2025-12-10 11:07:55 - INFO - Epoch: 27.60, Step: 109310, Train Loss: 1.2134, Learning Rate: 3.26e-05
2025-12-10 11:08:06 - INFO - Epoch: 27.60, Step: 109320, Train Loss: 1.1879, Learning Rate: 3.26e-05
2025-12-10 11:08:17 - INFO - Epoch: 27.60, Step: 109330, Train Loss: 1.2183, Learning Rate: 3.26e-05
2025-12-10 11:08:29 - INFO - Epoch: 27.60, Step: 109340, Train Loss: 1.1823, Learning Rate: 3.26e-05
2025-12-10 11:08:40 - INFO - Epoch: 27.61, Step: 109350, Train Loss: 1.2005, Learning Rate: 3.26e-05
2025-12-10 11:08:51 - INFO - Epoch: 27.61, Step: 109360, Train Loss: 1.1794, Learning Rate: 3.26e-05
2025-12-10 11:09:02 - INFO - Epoch: 27.61, Step: 109370, Train Loss: 1.1536, Learning Rate: 3.26e-05
2025-12-10 11:09:13 - INFO - Epoch: 27.61, Step: 109380, Train Loss: 1.1796, Learning Rate: 3.26e-05
2025-12-10 11:09:24 - INFO - Epoch: 27.62, Step: 109390, Train Loss: 1.1871, Learning Rate: 3.26e-05
2025-12-10 11:09:36 - INFO - Epoch: 27.62, Step: 109400, Train Loss: 1.1858, Learning Rate: 3.26e-05
2025-12-10 11:09:47 - INFO - Epoch: 27.62, Step: 109410, Train Loss: 1.1877, Learning Rate: 3.26e-05
2025-12-10 11:09:58 - INFO - Epoch: 27.62, Step: 109420, Train Loss: 1.1907, Learning Rate: 3.26e-05
2025-12-10 11:10:09 - INFO - Epoch: 27.63, Step: 109430, Train Loss: 1.1517, Learning Rate: 3.26e-05
2025-12-10 11:10:20 - INFO - Epoch: 27.63, Step: 109440, Train Loss: 1.2003, Learning Rate: 3.26e-05
2025-12-10 11:10:31 - INFO - Epoch: 27.63, Step: 109450, Train Loss: 1.1828, Learning Rate: 3.25e-05
2025-12-10 11:10:42 - INFO - Epoch: 27.63, Step: 109460, Train Loss: 1.1940, Learning Rate: 3.25e-05
2025-12-10 11:10:54 - INFO - Epoch: 27.64, Step: 109470, Train Loss: 1.1889, Learning Rate: 3.25e-05
2025-12-10 11:11:05 - INFO - Epoch: 27.64, Step: 109480, Train Loss: 1.2439, Learning Rate: 3.25e-05
2025-12-10 11:11:16 - INFO - Epoch: 27.64, Step: 109490, Train Loss: 1.2062, Learning Rate: 3.25e-05
2025-12-10 11:11:27 - INFO - Epoch: 27.64, Step: 109500, Train Loss: 1.1766, Learning Rate: 3.25e-05
2025-12-10 11:11:38 - INFO - Epoch: 27.65, Step: 109510, Train Loss: 1.1722, Learning Rate: 3.25e-05
2025-12-10 11:11:49 - INFO - Epoch: 27.65, Step: 109520, Train Loss: 1.1952, Learning Rate: 3.25e-05
2025-12-10 11:12:01 - INFO - Epoch: 27.65, Step: 109530, Train Loss: 1.1489, Learning Rate: 3.25e-05
2025-12-10 11:12:12 - INFO - Epoch: 27.65, Step: 109540, Train Loss: 1.1797, Learning Rate: 3.25e-05
2025-12-10 11:12:23 - INFO - Epoch: 27.66, Step: 109550, Train Loss: 1.1780, Learning Rate: 3.25e-05
2025-12-10 11:12:34 - INFO - Epoch: 27.66, Step: 109560, Train Loss: 1.1873, Learning Rate: 3.25e-05
2025-12-10 11:12:45 - INFO - Epoch: 27.66, Step: 109570, Train Loss: 1.2092, Learning Rate: 3.25e-05
2025-12-10 11:12:56 - INFO - Epoch: 27.66, Step: 109580, Train Loss: 1.1793, Learning Rate: 3.25e-05
2025-12-10 11:13:07 - INFO - Epoch: 27.67, Step: 109590, Train Loss: 1.1893, Learning Rate: 3.25e-05
2025-12-10 11:13:19 - INFO - Epoch: 27.67, Step: 109600, Train Loss: 1.1564, Learning Rate: 3.24e-05
2025-12-10 11:13:30 - INFO - Epoch: 27.67, Step: 109610, Train Loss: 1.2473, Learning Rate: 3.24e-05
2025-12-10 11:13:41 - INFO - Epoch: 27.67, Step: 109620, Train Loss: 1.2244, Learning Rate: 3.24e-05
2025-12-10 11:13:52 - INFO - Epoch: 27.68, Step: 109630, Train Loss: 1.1980, Learning Rate: 3.24e-05
2025-12-10 11:14:03 - INFO - Epoch: 27.68, Step: 109640, Train Loss: 1.1494, Learning Rate: 3.24e-05
2025-12-10 11:14:14 - INFO - Epoch: 27.68, Step: 109650, Train Loss: 1.1892, Learning Rate: 3.24e-05
2025-12-10 11:14:26 - INFO - Epoch: 27.68, Step: 109660, Train Loss: 1.1902, Learning Rate: 3.24e-05
2025-12-10 11:14:37 - INFO - Epoch: 27.69, Step: 109670, Train Loss: 1.2012, Learning Rate: 3.24e-05
2025-12-10 11:14:48 - INFO - Epoch: 27.69, Step: 109680, Train Loss: 1.2028, Learning Rate: 3.24e-05
2025-12-10 11:14:59 - INFO - Epoch: 27.69, Step: 109690, Train Loss: 1.1767, Learning Rate: 3.24e-05
2025-12-10 11:15:10 - INFO - Epoch: 27.70, Step: 109700, Train Loss: 1.1724, Learning Rate: 3.24e-05
2025-12-10 11:15:21 - INFO - Epoch: 27.70, Step: 109710, Train Loss: 1.2033, Learning Rate: 3.24e-05
2025-12-10 11:15:32 - INFO - Epoch: 27.70, Step: 109720, Train Loss: 1.1593, Learning Rate: 3.24e-05
2025-12-10 11:15:44 - INFO - Epoch: 27.70, Step: 109730, Train Loss: 1.1599, Learning Rate: 3.24e-05
2025-12-10 11:15:55 - INFO - Epoch: 27.71, Step: 109740, Train Loss: 1.2175, Learning Rate: 3.24e-05
2025-12-10 11:16:06 - INFO - Epoch: 27.71, Step: 109750, Train Loss: 1.2114, Learning Rate: 3.23e-05
2025-12-10 11:16:17 - INFO - Epoch: 27.71, Step: 109760, Train Loss: 1.1445, Learning Rate: 3.23e-05
2025-12-10 11:16:28 - INFO - Epoch: 27.71, Step: 109770, Train Loss: 1.1793, Learning Rate: 3.23e-05
2025-12-10 11:16:39 - INFO - Epoch: 27.72, Step: 109780, Train Loss: 1.1934, Learning Rate: 3.23e-05
2025-12-10 11:16:51 - INFO - Epoch: 27.72, Step: 109790, Train Loss: 1.1810, Learning Rate: 3.23e-05
2025-12-10 11:17:02 - INFO - Epoch: 27.72, Step: 109800, Train Loss: 1.1903, Learning Rate: 3.23e-05
2025-12-10 11:17:13 - INFO - Epoch: 27.72, Step: 109810, Train Loss: 1.1797, Learning Rate: 3.23e-05
2025-12-10 11:17:24 - INFO - Epoch: 27.73, Step: 109820, Train Loss: 1.1821, Learning Rate: 3.23e-05
2025-12-10 11:17:35 - INFO - Epoch: 27.73, Step: 109830, Train Loss: 1.1867, Learning Rate: 3.23e-05
2025-12-10 11:17:46 - INFO - Epoch: 27.73, Step: 109840, Train Loss: 1.1801, Learning Rate: 3.23e-05
2025-12-10 11:17:57 - INFO - Epoch: 27.73, Step: 109850, Train Loss: 1.1721, Learning Rate: 3.23e-05
2025-12-10 11:18:09 - INFO - Epoch: 27.74, Step: 109860, Train Loss: 1.2048, Learning Rate: 3.23e-05
2025-12-10 11:18:20 - INFO - Epoch: 27.74, Step: 109870, Train Loss: 1.1195, Learning Rate: 3.23e-05
2025-12-10 11:18:31 - INFO - Epoch: 27.74, Step: 109880, Train Loss: 1.2219, Learning Rate: 3.23e-05
2025-12-10 11:18:42 - INFO - Epoch: 27.74, Step: 109890, Train Loss: 1.2110, Learning Rate: 3.23e-05
2025-12-10 11:18:53 - INFO - Epoch: 27.75, Step: 109900, Train Loss: 1.1909, Learning Rate: 3.22e-05
2025-12-10 11:19:04 - INFO - Epoch: 27.75, Step: 109910, Train Loss: 1.1830, Learning Rate: 3.22e-05
2025-12-10 11:19:16 - INFO - Epoch: 27.75, Step: 109920, Train Loss: 1.1705, Learning Rate: 3.22e-05
2025-12-10 11:19:27 - INFO - Epoch: 27.75, Step: 109930, Train Loss: 1.1825, Learning Rate: 3.22e-05
2025-12-10 11:19:38 - INFO - Epoch: 27.76, Step: 109940, Train Loss: 1.1573, Learning Rate: 3.22e-05
2025-12-10 11:19:49 - INFO - Epoch: 27.76, Step: 109950, Train Loss: 1.2194, Learning Rate: 3.22e-05
2025-12-10 11:20:00 - INFO - Epoch: 27.76, Step: 109960, Train Loss: 1.1953, Learning Rate: 3.22e-05
2025-12-10 11:20:11 - INFO - Epoch: 27.76, Step: 109970, Train Loss: 1.1659, Learning Rate: 3.22e-05
2025-12-10 11:20:22 - INFO - Epoch: 27.77, Step: 109980, Train Loss: 1.1870, Learning Rate: 3.22e-05
2025-12-10 11:20:34 - INFO - Epoch: 27.77, Step: 109990, Train Loss: 1.1953, Learning Rate: 3.22e-05
2025-12-10 11:20:45 - INFO - Epoch: 27.77, Step: 110000, Train Loss: 1.1884, Learning Rate: 3.22e-05
2025-12-10 11:20:56 - INFO - Epoch: 27.77, Step: 110010, Train Loss: 1.1985, Learning Rate: 3.22e-05
2025-12-10 11:21:07 - INFO - Epoch: 27.78, Step: 110020, Train Loss: 1.1745, Learning Rate: 3.22e-05
2025-12-10 11:21:18 - INFO - Epoch: 27.78, Step: 110030, Train Loss: 1.2176, Learning Rate: 3.22e-05
2025-12-10 11:21:29 - INFO - Epoch: 27.78, Step: 110040, Train Loss: 1.1671, Learning Rate: 3.22e-05
2025-12-10 11:21:41 - INFO - Epoch: 27.78, Step: 110050, Train Loss: 1.1714, Learning Rate: 3.21e-05
2025-12-10 11:21:52 - INFO - Epoch: 27.79, Step: 110060, Train Loss: 1.1421, Learning Rate: 3.21e-05
2025-12-10 11:22:03 - INFO - Epoch: 27.79, Step: 110070, Train Loss: 1.2061, Learning Rate: 3.21e-05
2025-12-10 11:22:14 - INFO - Epoch: 27.79, Step: 110080, Train Loss: 1.1799, Learning Rate: 3.21e-05
2025-12-10 11:22:25 - INFO - Epoch: 27.79, Step: 110090, Train Loss: 1.1809, Learning Rate: 3.21e-05
2025-12-10 11:22:36 - INFO - Epoch: 27.80, Step: 110100, Train Loss: 1.1792, Learning Rate: 3.21e-05
2025-12-10 11:22:47 - INFO - Epoch: 27.80, Step: 110110, Train Loss: 1.2014, Learning Rate: 3.21e-05
2025-12-10 11:22:59 - INFO - Epoch: 27.80, Step: 110120, Train Loss: 1.1793, Learning Rate: 3.21e-05
2025-12-10 11:23:10 - INFO - Epoch: 27.80, Step: 110130, Train Loss: 1.1955, Learning Rate: 3.21e-05
2025-12-10 11:23:21 - INFO - Epoch: 27.81, Step: 110140, Train Loss: 1.1756, Learning Rate: 3.21e-05
2025-12-10 11:23:32 - INFO - Epoch: 27.81, Step: 110150, Train Loss: 1.2033, Learning Rate: 3.21e-05
2025-12-10 11:23:43 - INFO - Epoch: 27.81, Step: 110160, Train Loss: 1.1833, Learning Rate: 3.21e-05
2025-12-10 11:23:54 - INFO - Epoch: 27.81, Step: 110170, Train Loss: 1.2055, Learning Rate: 3.21e-05
2025-12-10 11:24:06 - INFO - Epoch: 27.82, Step: 110180, Train Loss: 1.2159, Learning Rate: 3.21e-05
2025-12-10 11:24:17 - INFO - Epoch: 27.82, Step: 110190, Train Loss: 1.1675, Learning Rate: 3.21e-05
2025-12-10 11:24:28 - INFO - Epoch: 27.82, Step: 110200, Train Loss: 1.1950, Learning Rate: 3.20e-05
2025-12-10 11:24:39 - INFO - Epoch: 27.82, Step: 110210, Train Loss: 1.2014, Learning Rate: 3.20e-05
2025-12-10 11:24:50 - INFO - Epoch: 27.83, Step: 110220, Train Loss: 1.1769, Learning Rate: 3.20e-05
2025-12-10 11:25:01 - INFO - Epoch: 27.83, Step: 110230, Train Loss: 1.1792, Learning Rate: 3.20e-05
2025-12-10 11:25:12 - INFO - Epoch: 27.83, Step: 110240, Train Loss: 1.1884, Learning Rate: 3.20e-05
2025-12-10 11:25:24 - INFO - Epoch: 27.83, Step: 110250, Train Loss: 1.2110, Learning Rate: 3.20e-05
2025-12-10 11:25:35 - INFO - Epoch: 27.84, Step: 110260, Train Loss: 1.2063, Learning Rate: 3.20e-05
2025-12-10 11:25:46 - INFO - Epoch: 27.84, Step: 110270, Train Loss: 1.1709, Learning Rate: 3.20e-05
2025-12-10 11:25:57 - INFO - Epoch: 27.84, Step: 110280, Train Loss: 1.2006, Learning Rate: 3.20e-05
2025-12-10 11:26:08 - INFO - Epoch: 27.84, Step: 110290, Train Loss: 1.2054, Learning Rate: 3.20e-05
2025-12-10 11:26:19 - INFO - Epoch: 27.85, Step: 110300, Train Loss: 1.1785, Learning Rate: 3.20e-05
2025-12-10 11:26:31 - INFO - Epoch: 27.85, Step: 110310, Train Loss: 1.2222, Learning Rate: 3.20e-05
2025-12-10 11:26:42 - INFO - Epoch: 27.85, Step: 110320, Train Loss: 1.1648, Learning Rate: 3.20e-05
2025-12-10 11:26:53 - INFO - Epoch: 27.85, Step: 110330, Train Loss: 1.2258, Learning Rate: 3.20e-05
2025-12-10 11:27:04 - INFO - Epoch: 27.86, Step: 110340, Train Loss: 1.2126, Learning Rate: 3.20e-05
2025-12-10 11:27:15 - INFO - Epoch: 27.86, Step: 110350, Train Loss: 1.1943, Learning Rate: 3.20e-05
2025-12-10 11:27:26 - INFO - Epoch: 27.86, Step: 110360, Train Loss: 1.1529, Learning Rate: 3.19e-05
2025-12-10 11:27:37 - INFO - Epoch: 27.86, Step: 110370, Train Loss: 1.1854, Learning Rate: 3.19e-05
2025-12-10 11:27:49 - INFO - Epoch: 27.87, Step: 110380, Train Loss: 1.1709, Learning Rate: 3.19e-05
2025-12-10 11:28:00 - INFO - Epoch: 27.87, Step: 110390, Train Loss: 1.2003, Learning Rate: 3.19e-05
2025-12-10 11:28:11 - INFO - Epoch: 27.87, Step: 110400, Train Loss: 1.1726, Learning Rate: 3.19e-05
2025-12-10 11:28:22 - INFO - Epoch: 27.87, Step: 110410, Train Loss: 1.2006, Learning Rate: 3.19e-05
2025-12-10 11:28:33 - INFO - Epoch: 27.88, Step: 110420, Train Loss: 1.2366, Learning Rate: 3.19e-05
2025-12-10 11:28:44 - INFO - Epoch: 27.88, Step: 110430, Train Loss: 1.1871, Learning Rate: 3.19e-05
2025-12-10 11:28:56 - INFO - Epoch: 27.88, Step: 110440, Train Loss: 1.1971, Learning Rate: 3.19e-05
2025-12-10 11:29:07 - INFO - Epoch: 27.88, Step: 110450, Train Loss: 1.1992, Learning Rate: 3.19e-05
2025-12-10 11:29:18 - INFO - Epoch: 27.89, Step: 110460, Train Loss: 1.2388, Learning Rate: 3.19e-05
2025-12-10 11:29:29 - INFO - Epoch: 27.89, Step: 110470, Train Loss: 1.1801, Learning Rate: 3.19e-05
2025-12-10 11:29:40 - INFO - Epoch: 27.89, Step: 110480, Train Loss: 1.1840, Learning Rate: 3.19e-05
2025-12-10 11:29:51 - INFO - Epoch: 27.89, Step: 110490, Train Loss: 1.1659, Learning Rate: 3.19e-05
2025-12-10 11:30:02 - INFO - Epoch: 27.90, Step: 110500, Train Loss: 1.1730, Learning Rate: 3.19e-05
2025-12-10 11:30:14 - INFO - Epoch: 27.90, Step: 110510, Train Loss: 1.1846, Learning Rate: 3.18e-05
2025-12-10 11:30:25 - INFO - Epoch: 27.90, Step: 110520, Train Loss: 1.1635, Learning Rate: 3.18e-05
2025-12-10 11:30:36 - INFO - Epoch: 27.90, Step: 110530, Train Loss: 1.2093, Learning Rate: 3.18e-05
2025-12-10 11:30:47 - INFO - Epoch: 27.91, Step: 110540, Train Loss: 1.2035, Learning Rate: 3.18e-05
2025-12-10 11:30:58 - INFO - Epoch: 27.91, Step: 110550, Train Loss: 1.2052, Learning Rate: 3.18e-05
2025-12-10 11:31:09 - INFO - Epoch: 27.91, Step: 110560, Train Loss: 1.1806, Learning Rate: 3.18e-05
2025-12-10 11:31:21 - INFO - Epoch: 27.91, Step: 110570, Train Loss: 1.1593, Learning Rate: 3.18e-05
2025-12-10 11:31:32 - INFO - Epoch: 27.92, Step: 110580, Train Loss: 1.1577, Learning Rate: 3.18e-05
2025-12-10 11:31:43 - INFO - Epoch: 27.92, Step: 110590, Train Loss: 1.1737, Learning Rate: 3.18e-05
2025-12-10 11:31:54 - INFO - Epoch: 27.92, Step: 110600, Train Loss: 1.1999, Learning Rate: 3.18e-05
2025-12-10 11:32:05 - INFO - Epoch: 27.92, Step: 110610, Train Loss: 1.1622, Learning Rate: 3.18e-05
2025-12-10 11:32:16 - INFO - Epoch: 27.93, Step: 110620, Train Loss: 1.1836, Learning Rate: 3.18e-05
2025-12-10 11:32:27 - INFO - Epoch: 27.93, Step: 110630, Train Loss: 1.2201, Learning Rate: 3.18e-05
2025-12-10 11:32:39 - INFO - Epoch: 27.93, Step: 110640, Train Loss: 1.1865, Learning Rate: 3.18e-05
2025-12-10 11:32:50 - INFO - Epoch: 27.93, Step: 110650, Train Loss: 1.1696, Learning Rate: 3.18e-05
2025-12-10 11:33:01 - INFO - Epoch: 27.94, Step: 110660, Train Loss: 1.1726, Learning Rate: 3.17e-05
2025-12-10 11:33:12 - INFO - Epoch: 27.94, Step: 110670, Train Loss: 1.2002, Learning Rate: 3.17e-05
2025-12-10 11:33:23 - INFO - Epoch: 27.94, Step: 110680, Train Loss: 1.1810, Learning Rate: 3.17e-05
2025-12-10 11:33:34 - INFO - Epoch: 27.94, Step: 110690, Train Loss: 1.2064, Learning Rate: 3.17e-05
2025-12-10 11:33:46 - INFO - Epoch: 27.95, Step: 110700, Train Loss: 1.1918, Learning Rate: 3.17e-05
2025-12-10 11:33:57 - INFO - Epoch: 27.95, Step: 110710, Train Loss: 1.1901, Learning Rate: 3.17e-05
2025-12-10 11:34:08 - INFO - Epoch: 27.95, Step: 110720, Train Loss: 1.1986, Learning Rate: 3.17e-05
2025-12-10 11:34:19 - INFO - Epoch: 27.96, Step: 110730, Train Loss: 1.1988, Learning Rate: 3.17e-05
2025-12-10 11:34:30 - INFO - Epoch: 27.96, Step: 110740, Train Loss: 1.2027, Learning Rate: 3.17e-05
2025-12-10 11:34:41 - INFO - Epoch: 27.96, Step: 110750, Train Loss: 1.1700, Learning Rate: 3.17e-05
2025-12-10 11:34:52 - INFO - Epoch: 27.96, Step: 110760, Train Loss: 1.2050, Learning Rate: 3.17e-05
2025-12-10 11:35:04 - INFO - Epoch: 27.97, Step: 110770, Train Loss: 1.1846, Learning Rate: 3.17e-05
2025-12-10 11:35:15 - INFO - Epoch: 27.97, Step: 110780, Train Loss: 1.1870, Learning Rate: 3.17e-05
2025-12-10 11:35:26 - INFO - Epoch: 27.97, Step: 110790, Train Loss: 1.2035, Learning Rate: 3.17e-05
2025-12-10 11:35:37 - INFO - Epoch: 27.97, Step: 110800, Train Loss: 1.2141, Learning Rate: 3.17e-05
2025-12-10 11:35:48 - INFO - Epoch: 27.98, Step: 110810, Train Loss: 1.1929, Learning Rate: 3.16e-05
2025-12-10 11:35:59 - INFO - Epoch: 27.98, Step: 110820, Train Loss: 1.1599, Learning Rate: 3.16e-05
2025-12-10 11:36:10 - INFO - Epoch: 27.98, Step: 110830, Train Loss: 1.1908, Learning Rate: 3.16e-05
2025-12-10 11:36:22 - INFO - Epoch: 27.98, Step: 110840, Train Loss: 1.1725, Learning Rate: 3.16e-05
2025-12-10 11:36:33 - INFO - Epoch: 27.99, Step: 110850, Train Loss: 1.1776, Learning Rate: 3.16e-05
2025-12-10 11:36:44 - INFO - Epoch: 27.99, Step: 110860, Train Loss: 1.2050, Learning Rate: 3.16e-05
2025-12-10 11:36:55 - INFO - Epoch: 27.99, Step: 110870, Train Loss: 1.1846, Learning Rate: 3.16e-05
2025-12-10 11:37:06 - INFO - Epoch: 27.99, Step: 110880, Train Loss: 1.1566, Learning Rate: 3.16e-05
2025-12-10 11:37:17 - INFO - Epoch: 28.00, Step: 110890, Train Loss: 1.1642, Learning Rate: 3.16e-05
2025-12-10 11:37:29 - INFO - Epoch: 28.00, Step: 110900, Train Loss: 1.1907, Learning Rate: 3.16e-05
2025-12-10 11:37:40 - INFO - Epoch: 28.00, Step: 110910, Train Loss: 1.1587, Learning Rate: 3.16e-05
2025-12-10 11:37:51 - INFO - Epoch: 28.00, Step: 110920, Train Loss: 1.1652, Learning Rate: 3.16e-05
2025-12-10 11:38:02 - INFO - Epoch: 28.01, Step: 110930, Train Loss: 1.1870, Learning Rate: 3.16e-05
2025-12-10 11:38:13 - INFO - Epoch: 28.01, Step: 110940, Train Loss: 1.1681, Learning Rate: 3.16e-05
2025-12-10 11:38:24 - INFO - Epoch: 28.01, Step: 110950, Train Loss: 1.1552, Learning Rate: 3.16e-05
2025-12-10 11:38:36 - INFO - Epoch: 28.01, Step: 110960, Train Loss: 1.1782, Learning Rate: 3.15e-05
2025-12-10 11:38:47 - INFO - Epoch: 28.02, Step: 110970, Train Loss: 1.2365, Learning Rate: 3.15e-05
2025-12-10 11:38:58 - INFO - Epoch: 28.02, Step: 110980, Train Loss: 1.2096, Learning Rate: 3.15e-05
2025-12-10 11:39:09 - INFO - Epoch: 28.02, Step: 110990, Train Loss: 1.1853, Learning Rate: 3.15e-05
2025-12-10 11:39:20 - INFO - Epoch: 28.02, Step: 111000, Train Loss: 1.1690, Learning Rate: 3.15e-05
2025-12-10 11:39:31 - INFO - Epoch: 28.03, Step: 111010, Train Loss: 1.1851, Learning Rate: 3.15e-05
2025-12-10 11:39:42 - INFO - Epoch: 28.03, Step: 111020, Train Loss: 1.1844, Learning Rate: 3.15e-05
2025-12-10 11:39:54 - INFO - Epoch: 28.03, Step: 111030, Train Loss: 1.1753, Learning Rate: 3.15e-05
2025-12-10 11:40:05 - INFO - Epoch: 28.03, Step: 111040, Train Loss: 1.2004, Learning Rate: 3.15e-05
2025-12-10 11:40:16 - INFO - Epoch: 28.04, Step: 111050, Train Loss: 1.1675, Learning Rate: 3.15e-05
2025-12-10 11:40:27 - INFO - Epoch: 28.04, Step: 111060, Train Loss: 1.1740, Learning Rate: 3.15e-05
2025-12-10 11:40:38 - INFO - Epoch: 28.04, Step: 111070, Train Loss: 1.1532, Learning Rate: 3.15e-05
2025-12-10 11:40:49 - INFO - Epoch: 28.04, Step: 111080, Train Loss: 1.1619, Learning Rate: 3.15e-05
2025-12-10 11:41:01 - INFO - Epoch: 28.05, Step: 111090, Train Loss: 1.1632, Learning Rate: 3.15e-05
2025-12-10 11:41:12 - INFO - Epoch: 28.05, Step: 111100, Train Loss: 1.2063, Learning Rate: 3.15e-05
2025-12-10 11:41:23 - INFO - Epoch: 28.05, Step: 111110, Train Loss: 1.1783, Learning Rate: 3.14e-05
2025-12-10 11:41:34 - INFO - Epoch: 28.05, Step: 111120, Train Loss: 1.1932, Learning Rate: 3.14e-05
2025-12-10 11:41:45 - INFO - Epoch: 28.06, Step: 111130, Train Loss: 1.1798, Learning Rate: 3.14e-05
2025-12-10 11:41:56 - INFO - Epoch: 28.06, Step: 111140, Train Loss: 1.1774, Learning Rate: 3.14e-05
2025-12-10 11:42:07 - INFO - Epoch: 28.06, Step: 111150, Train Loss: 1.1853, Learning Rate: 3.14e-05
2025-12-10 11:42:19 - INFO - Epoch: 28.06, Step: 111160, Train Loss: 1.1899, Learning Rate: 3.14e-05
2025-12-10 11:42:30 - INFO - Epoch: 28.07, Step: 111170, Train Loss: 1.1581, Learning Rate: 3.14e-05
2025-12-10 11:42:41 - INFO - Epoch: 28.07, Step: 111180, Train Loss: 1.2133, Learning Rate: 3.14e-05
2025-12-10 11:42:52 - INFO - Epoch: 28.07, Step: 111190, Train Loss: 1.1940, Learning Rate: 3.14e-05
2025-12-10 11:43:03 - INFO - Epoch: 28.07, Step: 111200, Train Loss: 1.2074, Learning Rate: 3.14e-05
2025-12-10 11:43:14 - INFO - Epoch: 28.08, Step: 111210, Train Loss: 1.1713, Learning Rate: 3.14e-05
2025-12-10 11:43:26 - INFO - Epoch: 28.08, Step: 111220, Train Loss: 1.2001, Learning Rate: 3.14e-05
2025-12-10 11:43:37 - INFO - Epoch: 28.08, Step: 111230, Train Loss: 1.1989, Learning Rate: 3.14e-05
2025-12-10 11:43:48 - INFO - Epoch: 28.08, Step: 111240, Train Loss: 1.2053, Learning Rate: 3.14e-05
2025-12-10 11:43:59 - INFO - Epoch: 28.09, Step: 111250, Train Loss: 1.1785, Learning Rate: 3.14e-05
2025-12-10 11:44:10 - INFO - Epoch: 28.09, Step: 111260, Train Loss: 1.1680, Learning Rate: 3.13e-05
2025-12-10 11:44:21 - INFO - Epoch: 28.09, Step: 111270, Train Loss: 1.2051, Learning Rate: 3.13e-05
2025-12-10 11:44:33 - INFO - Epoch: 28.09, Step: 111280, Train Loss: 1.1834, Learning Rate: 3.13e-05
2025-12-10 11:44:44 - INFO - Epoch: 28.10, Step: 111290, Train Loss: 1.1935, Learning Rate: 3.13e-05
2025-12-10 11:44:55 - INFO - Epoch: 28.10, Step: 111300, Train Loss: 1.2135, Learning Rate: 3.13e-05
2025-12-10 11:45:06 - INFO - Epoch: 28.10, Step: 111310, Train Loss: 1.1899, Learning Rate: 3.13e-05
2025-12-10 11:45:17 - INFO - Epoch: 28.10, Step: 111320, Train Loss: 1.1967, Learning Rate: 3.13e-05
2025-12-10 11:45:28 - INFO - Epoch: 28.11, Step: 111330, Train Loss: 1.1717, Learning Rate: 3.13e-05
2025-12-10 11:45:39 - INFO - Epoch: 28.11, Step: 111340, Train Loss: 1.1954, Learning Rate: 3.13e-05
2025-12-10 11:45:51 - INFO - Epoch: 28.11, Step: 111350, Train Loss: 1.1856, Learning Rate: 3.13e-05
2025-12-10 11:46:02 - INFO - Epoch: 28.11, Step: 111360, Train Loss: 1.1637, Learning Rate: 3.13e-05
2025-12-10 11:46:13 - INFO - Epoch: 28.12, Step: 111370, Train Loss: 1.1804, Learning Rate: 3.13e-05
2025-12-10 11:46:24 - INFO - Epoch: 28.12, Step: 111380, Train Loss: 1.1753, Learning Rate: 3.13e-05
2025-12-10 11:46:35 - INFO - Epoch: 28.12, Step: 111390, Train Loss: 1.1906, Learning Rate: 3.13e-05
2025-12-10 11:46:46 - INFO - Epoch: 28.12, Step: 111400, Train Loss: 1.1381, Learning Rate: 3.13e-05
2025-12-10 11:46:58 - INFO - Epoch: 28.13, Step: 111410, Train Loss: 1.1918, Learning Rate: 3.12e-05
2025-12-10 11:47:09 - INFO - Epoch: 28.13, Step: 111420, Train Loss: 1.1891, Learning Rate: 3.12e-05
2025-12-10 11:47:20 - INFO - Epoch: 28.13, Step: 111430, Train Loss: 1.2204, Learning Rate: 3.12e-05
2025-12-10 11:47:31 - INFO - Epoch: 28.13, Step: 111440, Train Loss: 1.1747, Learning Rate: 3.12e-05
2025-12-10 11:47:42 - INFO - Epoch: 28.14, Step: 111450, Train Loss: 1.2293, Learning Rate: 3.12e-05
2025-12-10 11:47:53 - INFO - Epoch: 28.14, Step: 111460, Train Loss: 1.1786, Learning Rate: 3.12e-05
2025-12-10 11:48:05 - INFO - Epoch: 28.14, Step: 111470, Train Loss: 1.2182, Learning Rate: 3.12e-05
2025-12-10 11:48:16 - INFO - Epoch: 28.14, Step: 111480, Train Loss: 1.1445, Learning Rate: 3.12e-05
2025-12-10 11:48:27 - INFO - Epoch: 28.15, Step: 111490, Train Loss: 1.1474, Learning Rate: 3.12e-05
2025-12-10 11:48:38 - INFO - Epoch: 28.15, Step: 111500, Train Loss: 1.1849, Learning Rate: 3.12e-05
2025-12-10 11:48:49 - INFO - Epoch: 28.15, Step: 111510, Train Loss: 1.1556, Learning Rate: 3.12e-05
2025-12-10 11:49:00 - INFO - Epoch: 28.15, Step: 111520, Train Loss: 1.1652, Learning Rate: 3.12e-05
2025-12-10 11:49:11 - INFO - Epoch: 28.16, Step: 111530, Train Loss: 1.1991, Learning Rate: 3.12e-05
2025-12-10 11:49:23 - INFO - Epoch: 28.16, Step: 111540, Train Loss: 1.1927, Learning Rate: 3.12e-05
2025-12-10 11:49:34 - INFO - Epoch: 28.16, Step: 111550, Train Loss: 1.2016, Learning Rate: 3.12e-05
2025-12-10 11:49:45 - INFO - Epoch: 28.16, Step: 111560, Train Loss: 1.2102, Learning Rate: 3.11e-05
2025-12-10 11:49:56 - INFO - Epoch: 28.17, Step: 111570, Train Loss: 1.1677, Learning Rate: 3.11e-05
2025-12-10 11:50:07 - INFO - Epoch: 28.17, Step: 111580, Train Loss: 1.1872, Learning Rate: 3.11e-05
2025-12-10 11:50:18 - INFO - Epoch: 28.17, Step: 111590, Train Loss: 1.2136, Learning Rate: 3.11e-05
2025-12-10 11:50:30 - INFO - Epoch: 28.17, Step: 111600, Train Loss: 1.2271, Learning Rate: 3.11e-05
2025-12-10 11:50:41 - INFO - Epoch: 28.18, Step: 111610, Train Loss: 1.1876, Learning Rate: 3.11e-05
2025-12-10 11:50:52 - INFO - Epoch: 28.18, Step: 111620, Train Loss: 1.1754, Learning Rate: 3.11e-05
2025-12-10 11:51:03 - INFO - Epoch: 28.18, Step: 111630, Train Loss: 1.1809, Learning Rate: 3.11e-05
2025-12-10 11:51:14 - INFO - Epoch: 28.18, Step: 111640, Train Loss: 1.1798, Learning Rate: 3.11e-05
2025-12-10 11:51:25 - INFO - Epoch: 28.19, Step: 111650, Train Loss: 1.2164, Learning Rate: 3.11e-05
2025-12-10 11:51:36 - INFO - Epoch: 28.19, Step: 111660, Train Loss: 1.1767, Learning Rate: 3.11e-05
2025-12-10 11:51:48 - INFO - Epoch: 28.19, Step: 111670, Train Loss: 1.1934, Learning Rate: 3.11e-05
2025-12-10 11:51:59 - INFO - Epoch: 28.19, Step: 111680, Train Loss: 1.1680, Learning Rate: 3.11e-05
2025-12-10 11:52:10 - INFO - Epoch: 28.20, Step: 111690, Train Loss: 1.1642, Learning Rate: 3.11e-05
2025-12-10 11:52:21 - INFO - Epoch: 28.20, Step: 111700, Train Loss: 1.1671, Learning Rate: 3.11e-05
2025-12-10 11:52:32 - INFO - Epoch: 28.20, Step: 111710, Train Loss: 1.2242, Learning Rate: 3.10e-05
2025-12-10 11:52:43 - INFO - Epoch: 28.20, Step: 111720, Train Loss: 1.1577, Learning Rate: 3.10e-05
2025-12-10 11:52:55 - INFO - Epoch: 28.21, Step: 111730, Train Loss: 1.1891, Learning Rate: 3.10e-05
2025-12-10 11:53:06 - INFO - Epoch: 28.21, Step: 111740, Train Loss: 1.1991, Learning Rate: 3.10e-05
2025-12-10 11:53:17 - INFO - Epoch: 28.21, Step: 111750, Train Loss: 1.1525, Learning Rate: 3.10e-05
2025-12-10 11:53:28 - INFO - Epoch: 28.22, Step: 111760, Train Loss: 1.2117, Learning Rate: 3.10e-05
2025-12-10 11:53:39 - INFO - Epoch: 28.22, Step: 111770, Train Loss: 1.2032, Learning Rate: 3.10e-05
2025-12-10 11:53:50 - INFO - Epoch: 28.22, Step: 111780, Train Loss: 1.1680, Learning Rate: 3.10e-05
2025-12-10 11:54:02 - INFO - Epoch: 28.22, Step: 111790, Train Loss: 1.2030, Learning Rate: 3.10e-05
2025-12-10 11:54:13 - INFO - Epoch: 28.23, Step: 111800, Train Loss: 1.1706, Learning Rate: 3.10e-05
2025-12-10 11:54:24 - INFO - Epoch: 28.23, Step: 111810, Train Loss: 1.1785, Learning Rate: 3.10e-05
2025-12-10 11:54:35 - INFO - Epoch: 28.23, Step: 111820, Train Loss: 1.2132, Learning Rate: 3.10e-05
2025-12-10 11:54:46 - INFO - Epoch: 28.23, Step: 111830, Train Loss: 1.2259, Learning Rate: 3.10e-05
2025-12-10 11:54:57 - INFO - Epoch: 28.24, Step: 111840, Train Loss: 1.1918, Learning Rate: 3.10e-05
2025-12-10 11:55:08 - INFO - Epoch: 28.24, Step: 111850, Train Loss: 1.1854, Learning Rate: 3.10e-05
2025-12-10 11:55:20 - INFO - Epoch: 28.24, Step: 111860, Train Loss: 1.1898, Learning Rate: 3.09e-05
2025-12-10 11:55:31 - INFO - Epoch: 28.24, Step: 111870, Train Loss: 1.2289, Learning Rate: 3.09e-05
2025-12-10 11:55:42 - INFO - Epoch: 28.25, Step: 111880, Train Loss: 1.1765, Learning Rate: 3.09e-05
2025-12-10 11:55:53 - INFO - Epoch: 28.25, Step: 111890, Train Loss: 1.1889, Learning Rate: 3.09e-05
2025-12-10 11:56:04 - INFO - Epoch: 28.25, Step: 111900, Train Loss: 1.1842, Learning Rate: 3.09e-05
2025-12-10 11:56:15 - INFO - Epoch: 28.25, Step: 111910, Train Loss: 1.1969, Learning Rate: 3.09e-05
2025-12-10 11:56:27 - INFO - Epoch: 28.26, Step: 111920, Train Loss: 1.1718, Learning Rate: 3.09e-05
2025-12-10 11:56:38 - INFO - Epoch: 28.26, Step: 111930, Train Loss: 1.1798, Learning Rate: 3.09e-05
2025-12-10 11:56:49 - INFO - Epoch: 28.26, Step: 111940, Train Loss: 1.1700, Learning Rate: 3.09e-05
2025-12-10 11:57:00 - INFO - Epoch: 28.26, Step: 111950, Train Loss: 1.1685, Learning Rate: 3.09e-05
2025-12-10 11:57:11 - INFO - Epoch: 28.27, Step: 111960, Train Loss: 1.1905, Learning Rate: 3.09e-05
2025-12-10 11:57:22 - INFO - Epoch: 28.27, Step: 111970, Train Loss: 1.2394, Learning Rate: 3.09e-05
2025-12-10 11:57:33 - INFO - Epoch: 28.27, Step: 111980, Train Loss: 1.2061, Learning Rate: 3.09e-05
2025-12-10 11:57:45 - INFO - Epoch: 28.27, Step: 111990, Train Loss: 1.1792, Learning Rate: 3.09e-05
2025-12-10 11:57:56 - INFO - Epoch: 28.28, Step: 112000, Train Loss: 1.1934, Learning Rate: 3.09e-05
2025-12-10 11:58:07 - INFO - Epoch: 28.28, Step: 112010, Train Loss: 1.1900, Learning Rate: 3.08e-05
2025-12-10 11:58:18 - INFO - Epoch: 28.28, Step: 112020, Train Loss: 1.1956, Learning Rate: 3.08e-05
2025-12-10 11:58:29 - INFO - Epoch: 28.28, Step: 112030, Train Loss: 1.1900, Learning Rate: 3.08e-05
2025-12-10 11:58:40 - INFO - Epoch: 28.29, Step: 112040, Train Loss: 1.1816, Learning Rate: 3.08e-05
2025-12-10 11:58:52 - INFO - Epoch: 28.29, Step: 112050, Train Loss: 1.1541, Learning Rate: 3.08e-05
2025-12-10 11:59:03 - INFO - Epoch: 28.29, Step: 112060, Train Loss: 1.2379, Learning Rate: 3.08e-05
2025-12-10 11:59:14 - INFO - Epoch: 28.29, Step: 112070, Train Loss: 1.1866, Learning Rate: 3.08e-05
2025-12-10 11:59:25 - INFO - Epoch: 28.30, Step: 112080, Train Loss: 1.1796, Learning Rate: 3.08e-05
2025-12-10 11:59:36 - INFO - Epoch: 28.30, Step: 112090, Train Loss: 1.1205, Learning Rate: 3.08e-05
2025-12-10 11:59:47 - INFO - Epoch: 28.30, Step: 112100, Train Loss: 1.2058, Learning Rate: 3.08e-05
2025-12-10 11:59:59 - INFO - Epoch: 28.30, Step: 112110, Train Loss: 1.1626, Learning Rate: 3.08e-05
2025-12-10 12:00:10 - INFO - Epoch: 28.31, Step: 112120, Train Loss: 1.1548, Learning Rate: 3.08e-05
2025-12-10 12:00:21 - INFO - Epoch: 28.31, Step: 112130, Train Loss: 1.1595, Learning Rate: 3.08e-05
2025-12-10 12:00:32 - INFO - Epoch: 28.31, Step: 112140, Train Loss: 1.1910, Learning Rate: 3.08e-05
2025-12-10 12:00:43 - INFO - Epoch: 28.31, Step: 112150, Train Loss: 1.2043, Learning Rate: 3.08e-05
2025-12-10 12:00:54 - INFO - Epoch: 28.32, Step: 112160, Train Loss: 1.1728, Learning Rate: 3.07e-05
2025-12-10 12:01:05 - INFO - Epoch: 28.32, Step: 112170, Train Loss: 1.1808, Learning Rate: 3.07e-05
2025-12-10 12:01:17 - INFO - Epoch: 28.32, Step: 112180, Train Loss: 1.2243, Learning Rate: 3.07e-05
2025-12-10 12:01:28 - INFO - Epoch: 28.32, Step: 112190, Train Loss: 1.1786, Learning Rate: 3.07e-05
2025-12-10 12:01:39 - INFO - Epoch: 28.33, Step: 112200, Train Loss: 1.1403, Learning Rate: 3.07e-05
2025-12-10 12:01:50 - INFO - Epoch: 28.33, Step: 112210, Train Loss: 1.1607, Learning Rate: 3.07e-05
2025-12-10 12:02:01 - INFO - Epoch: 28.33, Step: 112220, Train Loss: 1.1871, Learning Rate: 3.07e-05
2025-12-10 12:02:12 - INFO - Epoch: 28.33, Step: 112230, Train Loss: 1.1620, Learning Rate: 3.07e-05
2025-12-10 12:02:24 - INFO - Epoch: 28.34, Step: 112240, Train Loss: 1.1848, Learning Rate: 3.07e-05
2025-12-10 12:02:35 - INFO - Epoch: 28.34, Step: 112250, Train Loss: 1.1804, Learning Rate: 3.07e-05
2025-12-10 12:02:46 - INFO - Epoch: 28.34, Step: 112260, Train Loss: 1.1674, Learning Rate: 3.07e-05
2025-12-10 12:02:57 - INFO - Epoch: 28.34, Step: 112270, Train Loss: 1.1858, Learning Rate: 3.07e-05
2025-12-10 12:03:08 - INFO - Epoch: 28.35, Step: 112280, Train Loss: 1.1949, Learning Rate: 3.07e-05
2025-12-10 12:03:19 - INFO - Epoch: 28.35, Step: 112290, Train Loss: 1.1807, Learning Rate: 3.07e-05
2025-12-10 12:03:31 - INFO - Epoch: 28.35, Step: 112300, Train Loss: 1.1938, Learning Rate: 3.07e-05
2025-12-10 12:03:42 - INFO - Epoch: 28.35, Step: 112310, Train Loss: 1.1736, Learning Rate: 3.06e-05
2025-12-10 12:03:53 - INFO - Epoch: 28.36, Step: 112320, Train Loss: 1.1955, Learning Rate: 3.06e-05
2025-12-10 12:04:04 - INFO - Epoch: 28.36, Step: 112330, Train Loss: 1.1913, Learning Rate: 3.06e-05
2025-12-10 12:04:15 - INFO - Epoch: 28.36, Step: 112340, Train Loss: 1.1838, Learning Rate: 3.06e-05
2025-12-10 12:04:26 - INFO - Epoch: 28.36, Step: 112350, Train Loss: 1.2271, Learning Rate: 3.06e-05
2025-12-10 12:04:37 - INFO - Epoch: 28.37, Step: 112360, Train Loss: 1.1650, Learning Rate: 3.06e-05
2025-12-10 12:04:49 - INFO - Epoch: 28.37, Step: 112370, Train Loss: 1.1608, Learning Rate: 3.06e-05
2025-12-10 12:05:00 - INFO - Epoch: 28.37, Step: 112380, Train Loss: 1.1645, Learning Rate: 3.06e-05
2025-12-10 12:05:11 - INFO - Epoch: 28.37, Step: 112390, Train Loss: 1.2391, Learning Rate: 3.06e-05
2025-12-10 12:05:22 - INFO - Epoch: 28.38, Step: 112400, Train Loss: 1.1796, Learning Rate: 3.06e-05
2025-12-10 12:05:33 - INFO - Epoch: 28.38, Step: 112410, Train Loss: 1.1938, Learning Rate: 3.06e-05
2025-12-10 12:05:44 - INFO - Epoch: 28.38, Step: 112420, Train Loss: 1.2280, Learning Rate: 3.06e-05
2025-12-10 12:05:56 - INFO - Epoch: 28.38, Step: 112430, Train Loss: 1.1676, Learning Rate: 3.06e-05
2025-12-10 12:06:07 - INFO - Epoch: 28.39, Step: 112440, Train Loss: 1.1985, Learning Rate: 3.06e-05
2025-12-10 12:06:18 - INFO - Epoch: 28.39, Step: 112450, Train Loss: 1.1806, Learning Rate: 3.06e-05
2025-12-10 12:06:29 - INFO - Epoch: 28.39, Step: 112460, Train Loss: 1.1680, Learning Rate: 3.05e-05
2025-12-10 12:06:40 - INFO - Epoch: 28.39, Step: 112470, Train Loss: 1.1837, Learning Rate: 3.05e-05
2025-12-10 12:06:51 - INFO - Epoch: 28.40, Step: 112480, Train Loss: 1.2242, Learning Rate: 3.05e-05
2025-12-10 12:07:02 - INFO - Epoch: 28.40, Step: 112490, Train Loss: 1.1884, Learning Rate: 3.05e-05
2025-12-10 12:07:14 - INFO - Epoch: 28.40, Step: 112500, Train Loss: 1.2108, Learning Rate: 3.05e-05
2025-12-10 12:07:25 - INFO - Epoch: 28.40, Step: 112510, Train Loss: 1.1601, Learning Rate: 3.05e-05
2025-12-10 12:07:36 - INFO - Epoch: 28.41, Step: 112520, Train Loss: 1.1996, Learning Rate: 3.05e-05
2025-12-10 12:07:47 - INFO - Epoch: 28.41, Step: 112530, Train Loss: 1.1378, Learning Rate: 3.05e-05
2025-12-10 12:07:58 - INFO - Epoch: 28.41, Step: 112540, Train Loss: 1.1956, Learning Rate: 3.05e-05
2025-12-10 12:08:09 - INFO - Epoch: 28.41, Step: 112550, Train Loss: 1.1951, Learning Rate: 3.05e-05
2025-12-10 12:08:21 - INFO - Epoch: 28.42, Step: 112560, Train Loss: 1.1792, Learning Rate: 3.05e-05
2025-12-10 12:08:32 - INFO - Epoch: 28.42, Step: 112570, Train Loss: 1.2091, Learning Rate: 3.05e-05
2025-12-10 12:08:43 - INFO - Epoch: 28.42, Step: 112580, Train Loss: 1.1787, Learning Rate: 3.05e-05
2025-12-10 12:08:54 - INFO - Epoch: 28.42, Step: 112590, Train Loss: 1.1497, Learning Rate: 3.05e-05
2025-12-10 12:09:05 - INFO - Epoch: 28.43, Step: 112600, Train Loss: 1.1928, Learning Rate: 3.05e-05
2025-12-10 12:09:16 - INFO - Epoch: 28.43, Step: 112610, Train Loss: 1.1610, Learning Rate: 3.04e-05
2025-12-10 12:09:28 - INFO - Epoch: 28.43, Step: 112620, Train Loss: 1.2014, Learning Rate: 3.04e-05
2025-12-10 12:09:39 - INFO - Epoch: 28.43, Step: 112630, Train Loss: 1.2030, Learning Rate: 3.04e-05
2025-12-10 12:09:50 - INFO - Epoch: 28.44, Step: 112640, Train Loss: 1.1980, Learning Rate: 3.04e-05
2025-12-10 12:10:01 - INFO - Epoch: 28.44, Step: 112650, Train Loss: 1.2144, Learning Rate: 3.04e-05
2025-12-10 12:10:12 - INFO - Epoch: 28.44, Step: 112660, Train Loss: 1.1577, Learning Rate: 3.04e-05
2025-12-10 12:10:23 - INFO - Epoch: 28.44, Step: 112670, Train Loss: 1.2307, Learning Rate: 3.04e-05
2025-12-10 12:10:34 - INFO - Epoch: 28.45, Step: 112680, Train Loss: 1.1860, Learning Rate: 3.04e-05
2025-12-10 12:10:46 - INFO - Epoch: 28.45, Step: 112690, Train Loss: 1.1764, Learning Rate: 3.04e-05
2025-12-10 12:10:57 - INFO - Epoch: 28.45, Step: 112700, Train Loss: 1.1839, Learning Rate: 3.04e-05
2025-12-10 12:11:08 - INFO - Epoch: 28.45, Step: 112710, Train Loss: 1.1891, Learning Rate: 3.04e-05
2025-12-10 12:11:19 - INFO - Epoch: 28.46, Step: 112720, Train Loss: 1.1252, Learning Rate: 3.04e-05
2025-12-10 12:11:30 - INFO - Epoch: 28.46, Step: 112730, Train Loss: 1.1568, Learning Rate: 3.04e-05
2025-12-10 12:11:41 - INFO - Epoch: 28.46, Step: 112740, Train Loss: 1.1648, Learning Rate: 3.04e-05
2025-12-10 12:11:53 - INFO - Epoch: 28.47, Step: 112750, Train Loss: 1.1587, Learning Rate: 3.04e-05
2025-12-10 12:12:04 - INFO - Epoch: 28.47, Step: 112760, Train Loss: 1.2062, Learning Rate: 3.03e-05
2025-12-10 12:12:15 - INFO - Epoch: 28.47, Step: 112770, Train Loss: 1.1801, Learning Rate: 3.03e-05
2025-12-10 12:12:26 - INFO - Epoch: 28.47, Step: 112780, Train Loss: 1.1736, Learning Rate: 3.03e-05
2025-12-10 12:12:37 - INFO - Epoch: 28.48, Step: 112790, Train Loss: 1.2218, Learning Rate: 3.03e-05
2025-12-10 12:12:48 - INFO - Epoch: 28.48, Step: 112800, Train Loss: 1.1707, Learning Rate: 3.03e-05
2025-12-10 12:13:00 - INFO - Epoch: 28.48, Step: 112810, Train Loss: 1.1841, Learning Rate: 3.03e-05
2025-12-10 12:13:11 - INFO - Epoch: 28.48, Step: 112820, Train Loss: 1.2059, Learning Rate: 3.03e-05
2025-12-10 12:13:22 - INFO - Epoch: 28.49, Step: 112830, Train Loss: 1.1630, Learning Rate: 3.03e-05
2025-12-10 12:13:33 - INFO - Epoch: 28.49, Step: 112840, Train Loss: 1.1667, Learning Rate: 3.03e-05
2025-12-10 12:13:44 - INFO - Epoch: 28.49, Step: 112850, Train Loss: 1.2179, Learning Rate: 3.03e-05
2025-12-10 12:13:55 - INFO - Epoch: 28.49, Step: 112860, Train Loss: 1.1690, Learning Rate: 3.03e-05
2025-12-10 12:14:06 - INFO - Epoch: 28.50, Step: 112870, Train Loss: 1.1839, Learning Rate: 3.03e-05
2025-12-10 12:14:18 - INFO - Epoch: 28.50, Step: 112880, Train Loss: 1.1907, Learning Rate: 3.03e-05
2025-12-10 12:14:29 - INFO - Epoch: 28.50, Step: 112890, Train Loss: 1.2004, Learning Rate: 3.03e-05
2025-12-10 12:14:40 - INFO - Epoch: 28.50, Step: 112900, Train Loss: 1.1858, Learning Rate: 3.03e-05
2025-12-10 12:14:51 - INFO - Epoch: 28.51, Step: 112910, Train Loss: 1.1798, Learning Rate: 3.02e-05
2025-12-10 12:15:02 - INFO - Epoch: 28.51, Step: 112920, Train Loss: 1.1699, Learning Rate: 3.02e-05
2025-12-10 12:15:13 - INFO - Epoch: 28.51, Step: 112930, Train Loss: 1.2080, Learning Rate: 3.02e-05
2025-12-10 12:15:25 - INFO - Epoch: 28.51, Step: 112940, Train Loss: 1.1942, Learning Rate: 3.02e-05
2025-12-10 12:15:36 - INFO - Epoch: 28.52, Step: 112950, Train Loss: 1.2050, Learning Rate: 3.02e-05
2025-12-10 12:15:47 - INFO - Epoch: 28.52, Step: 112960, Train Loss: 1.1813, Learning Rate: 3.02e-05
2025-12-10 12:15:58 - INFO - Epoch: 28.52, Step: 112970, Train Loss: 1.1976, Learning Rate: 3.02e-05
2025-12-10 12:16:09 - INFO - Epoch: 28.52, Step: 112980, Train Loss: 1.1896, Learning Rate: 3.02e-05
2025-12-10 12:16:20 - INFO - Epoch: 28.53, Step: 112990, Train Loss: 1.1578, Learning Rate: 3.02e-05
2025-12-10 12:16:31 - INFO - Epoch: 28.53, Step: 113000, Train Loss: 1.1832, Learning Rate: 3.02e-05
2025-12-10 12:16:43 - INFO - Epoch: 28.53, Step: 113010, Train Loss: 1.2177, Learning Rate: 3.02e-05
2025-12-10 12:16:54 - INFO - Epoch: 28.53, Step: 113020, Train Loss: 1.1576, Learning Rate: 3.02e-05
2025-12-10 12:17:05 - INFO - Epoch: 28.54, Step: 113030, Train Loss: 1.1929, Learning Rate: 3.02e-05
2025-12-10 12:17:16 - INFO - Epoch: 28.54, Step: 113040, Train Loss: 1.1725, Learning Rate: 3.02e-05
2025-12-10 12:17:27 - INFO - Epoch: 28.54, Step: 113050, Train Loss: 1.2100, Learning Rate: 3.02e-05
2025-12-10 12:17:38 - INFO - Epoch: 28.54, Step: 113060, Train Loss: 1.1733, Learning Rate: 3.01e-05
2025-12-10 12:17:50 - INFO - Epoch: 28.55, Step: 113070, Train Loss: 1.1425, Learning Rate: 3.01e-05
2025-12-10 12:18:01 - INFO - Epoch: 28.55, Step: 113080, Train Loss: 1.1335, Learning Rate: 3.01e-05
2025-12-10 12:18:12 - INFO - Epoch: 28.55, Step: 113090, Train Loss: 1.1912, Learning Rate: 3.01e-05
2025-12-10 12:18:23 - INFO - Epoch: 28.55, Step: 113100, Train Loss: 1.1587, Learning Rate: 3.01e-05
2025-12-10 12:18:34 - INFO - Epoch: 28.56, Step: 113110, Train Loss: 1.1707, Learning Rate: 3.01e-05
2025-12-10 12:18:45 - INFO - Epoch: 28.56, Step: 113120, Train Loss: 1.1775, Learning Rate: 3.01e-05
2025-12-10 12:18:57 - INFO - Epoch: 28.56, Step: 113130, Train Loss: 1.1690, Learning Rate: 3.01e-05
2025-12-10 12:19:08 - INFO - Epoch: 28.56, Step: 113140, Train Loss: 1.2003, Learning Rate: 3.01e-05
2025-12-10 12:19:19 - INFO - Epoch: 28.57, Step: 113150, Train Loss: 1.1894, Learning Rate: 3.01e-05
2025-12-10 12:19:30 - INFO - Epoch: 28.57, Step: 113160, Train Loss: 1.1334, Learning Rate: 3.01e-05
2025-12-10 12:19:41 - INFO - Epoch: 28.57, Step: 113170, Train Loss: 1.1721, Learning Rate: 3.01e-05
2025-12-10 12:19:52 - INFO - Epoch: 28.57, Step: 113180, Train Loss: 1.1670, Learning Rate: 3.01e-05
2025-12-10 12:20:03 - INFO - Epoch: 28.58, Step: 113190, Train Loss: 1.2002, Learning Rate: 3.01e-05
2025-12-10 12:20:15 - INFO - Epoch: 28.58, Step: 113200, Train Loss: 1.2026, Learning Rate: 3.01e-05
2025-12-10 12:20:26 - INFO - Epoch: 28.58, Step: 113210, Train Loss: 1.1862, Learning Rate: 3.01e-05
2025-12-10 12:20:37 - INFO - Epoch: 28.58, Step: 113220, Train Loss: 1.1902, Learning Rate: 3.00e-05
2025-12-10 12:20:48 - INFO - Epoch: 28.59, Step: 113230, Train Loss: 1.1646, Learning Rate: 3.00e-05
2025-12-10 12:20:59 - INFO - Epoch: 28.59, Step: 113240, Train Loss: 1.1757, Learning Rate: 3.00e-05
2025-12-10 12:21:10 - INFO - Epoch: 28.59, Step: 113250, Train Loss: 1.1769, Learning Rate: 3.00e-05
2025-12-10 12:21:22 - INFO - Epoch: 28.59, Step: 113260, Train Loss: 1.2122, Learning Rate: 3.00e-05
2025-12-10 12:21:33 - INFO - Epoch: 28.60, Step: 113270, Train Loss: 1.1933, Learning Rate: 3.00e-05
2025-12-10 12:21:44 - INFO - Epoch: 28.60, Step: 113280, Train Loss: 1.1874, Learning Rate: 3.00e-05
2025-12-10 12:21:55 - INFO - Epoch: 28.60, Step: 113290, Train Loss: 1.1820, Learning Rate: 3.00e-05
2025-12-10 12:22:06 - INFO - Epoch: 28.60, Step: 113300, Train Loss: 1.1755, Learning Rate: 3.00e-05
2025-12-10 12:22:17 - INFO - Epoch: 28.61, Step: 113310, Train Loss: 1.1664, Learning Rate: 3.00e-05
2025-12-10 12:22:29 - INFO - Epoch: 28.61, Step: 113320, Train Loss: 1.2122, Learning Rate: 3.00e-05
2025-12-10 12:22:40 - INFO - Epoch: 28.61, Step: 113330, Train Loss: 1.1564, Learning Rate: 3.00e-05
2025-12-10 12:22:51 - INFO - Epoch: 28.61, Step: 113340, Train Loss: 1.1734, Learning Rate: 3.00e-05
2025-12-10 12:23:02 - INFO - Epoch: 28.62, Step: 113350, Train Loss: 1.1568, Learning Rate: 3.00e-05
2025-12-10 12:23:13 - INFO - Epoch: 28.62, Step: 113360, Train Loss: 1.1798, Learning Rate: 3.00e-05
2025-12-10 12:23:24 - INFO - Epoch: 28.62, Step: 113370, Train Loss: 1.1754, Learning Rate: 2.99e-05
2025-12-10 12:23:35 - INFO - Epoch: 28.62, Step: 113380, Train Loss: 1.1544, Learning Rate: 2.99e-05
2025-12-10 12:23:47 - INFO - Epoch: 28.63, Step: 113390, Train Loss: 1.1762, Learning Rate: 2.99e-05
2025-12-10 12:23:58 - INFO - Epoch: 28.63, Step: 113400, Train Loss: 1.1791, Learning Rate: 2.99e-05
2025-12-10 12:24:09 - INFO - Epoch: 28.63, Step: 113410, Train Loss: 1.1975, Learning Rate: 2.99e-05
2025-12-10 12:24:20 - INFO - Epoch: 28.63, Step: 113420, Train Loss: 1.2022, Learning Rate: 2.99e-05
2025-12-10 12:24:31 - INFO - Epoch: 28.64, Step: 113430, Train Loss: 1.1579, Learning Rate: 2.99e-05
2025-12-10 12:24:42 - INFO - Epoch: 28.64, Step: 113440, Train Loss: 1.1279, Learning Rate: 2.99e-05
2025-12-10 12:24:54 - INFO - Epoch: 28.64, Step: 113450, Train Loss: 1.2220, Learning Rate: 2.99e-05
2025-12-10 12:25:05 - INFO - Epoch: 28.64, Step: 113460, Train Loss: 1.2096, Learning Rate: 2.99e-05
2025-12-10 12:25:16 - INFO - Epoch: 28.65, Step: 113470, Train Loss: 1.2108, Learning Rate: 2.99e-05
2025-12-10 12:25:27 - INFO - Epoch: 28.65, Step: 113480, Train Loss: 1.1881, Learning Rate: 2.99e-05
2025-12-10 12:25:38 - INFO - Epoch: 28.65, Step: 113490, Train Loss: 1.2010, Learning Rate: 2.99e-05
2025-12-10 12:25:49 - INFO - Epoch: 28.65, Step: 113500, Train Loss: 1.2010, Learning Rate: 2.99e-05
2025-12-10 12:26:00 - INFO - Epoch: 28.66, Step: 113510, Train Loss: 1.1937, Learning Rate: 2.99e-05
2025-12-10 12:26:12 - INFO - Epoch: 28.66, Step: 113520, Train Loss: 1.2100, Learning Rate: 2.98e-05
2025-12-10 12:26:23 - INFO - Epoch: 28.66, Step: 113530, Train Loss: 1.2047, Learning Rate: 2.98e-05
2025-12-10 12:26:34 - INFO - Epoch: 28.66, Step: 113540, Train Loss: 1.1612, Learning Rate: 2.98e-05
2025-12-10 12:26:45 - INFO - Epoch: 28.67, Step: 113550, Train Loss: 1.1477, Learning Rate: 2.98e-05
2025-12-10 12:26:56 - INFO - Epoch: 28.67, Step: 113560, Train Loss: 1.1298, Learning Rate: 2.98e-05
2025-12-10 12:27:07 - INFO - Epoch: 28.67, Step: 113570, Train Loss: 1.1848, Learning Rate: 2.98e-05
2025-12-10 12:27:19 - INFO - Epoch: 28.67, Step: 113580, Train Loss: 1.2039, Learning Rate: 2.98e-05
2025-12-10 12:27:30 - INFO - Epoch: 28.68, Step: 113590, Train Loss: 1.1660, Learning Rate: 2.98e-05
2025-12-10 12:27:41 - INFO - Epoch: 28.68, Step: 113600, Train Loss: 1.1867, Learning Rate: 2.98e-05
2025-12-10 12:27:52 - INFO - Epoch: 28.68, Step: 113610, Train Loss: 1.1958, Learning Rate: 2.98e-05
2025-12-10 12:28:03 - INFO - Epoch: 28.68, Step: 113620, Train Loss: 1.1700, Learning Rate: 2.98e-05
2025-12-10 12:28:14 - INFO - Epoch: 28.69, Step: 113630, Train Loss: 1.1365, Learning Rate: 2.98e-05
2025-12-10 12:28:26 - INFO - Epoch: 28.69, Step: 113640, Train Loss: 1.1797, Learning Rate: 2.98e-05
2025-12-10 12:28:37 - INFO - Epoch: 28.69, Step: 113650, Train Loss: 1.1959, Learning Rate: 2.98e-05
2025-12-10 12:28:48 - INFO - Epoch: 28.69, Step: 113660, Train Loss: 1.1620, Learning Rate: 2.98e-05
2025-12-10 12:28:59 - INFO - Epoch: 28.70, Step: 113670, Train Loss: 1.1736, Learning Rate: 2.97e-05
2025-12-10 12:29:10 - INFO - Epoch: 28.70, Step: 113680, Train Loss: 1.1487, Learning Rate: 2.97e-05
2025-12-10 12:29:21 - INFO - Epoch: 28.70, Step: 113690, Train Loss: 1.1646, Learning Rate: 2.97e-05
2025-12-10 12:29:32 - INFO - Epoch: 28.70, Step: 113700, Train Loss: 1.1698, Learning Rate: 2.97e-05
2025-12-10 12:29:44 - INFO - Epoch: 28.71, Step: 113710, Train Loss: 1.1680, Learning Rate: 2.97e-05
2025-12-10 12:29:55 - INFO - Epoch: 28.71, Step: 113720, Train Loss: 1.1833, Learning Rate: 2.97e-05
2025-12-10 12:30:06 - INFO - Epoch: 28.71, Step: 113730, Train Loss: 1.2036, Learning Rate: 2.97e-05
2025-12-10 12:30:17 - INFO - Epoch: 28.71, Step: 113740, Train Loss: 1.1401, Learning Rate: 2.97e-05
2025-12-10 12:30:28 - INFO - Epoch: 28.72, Step: 113750, Train Loss: 1.1615, Learning Rate: 2.97e-05
2025-12-10 12:30:39 - INFO - Epoch: 28.72, Step: 113760, Train Loss: 1.1848, Learning Rate: 2.97e-05
2025-12-10 12:30:51 - INFO - Epoch: 28.72, Step: 113770, Train Loss: 1.1668, Learning Rate: 2.97e-05
2025-12-10 12:31:02 - INFO - Epoch: 28.73, Step: 113780, Train Loss: 1.1849, Learning Rate: 2.97e-05
2025-12-10 12:31:13 - INFO - Epoch: 28.73, Step: 113790, Train Loss: 1.1973, Learning Rate: 2.97e-05
2025-12-10 12:31:24 - INFO - Epoch: 28.73, Step: 113800, Train Loss: 1.1829, Learning Rate: 2.97e-05
2025-12-10 12:31:35 - INFO - Epoch: 28.73, Step: 113810, Train Loss: 1.1770, Learning Rate: 2.97e-05
2025-12-10 12:31:46 - INFO - Epoch: 28.74, Step: 113820, Train Loss: 1.1314, Learning Rate: 2.96e-05
2025-12-10 12:31:58 - INFO - Epoch: 28.74, Step: 113830, Train Loss: 1.1990, Learning Rate: 2.96e-05
2025-12-10 12:32:09 - INFO - Epoch: 28.74, Step: 113840, Train Loss: 1.1959, Learning Rate: 2.96e-05
2025-12-10 12:32:20 - INFO - Epoch: 28.74, Step: 113850, Train Loss: 1.1966, Learning Rate: 2.96e-05
2025-12-10 12:32:31 - INFO - Epoch: 28.75, Step: 113860, Train Loss: 1.1766, Learning Rate: 2.96e-05
2025-12-10 12:32:42 - INFO - Epoch: 28.75, Step: 113870, Train Loss: 1.2191, Learning Rate: 2.96e-05
2025-12-10 12:32:53 - INFO - Epoch: 28.75, Step: 113880, Train Loss: 1.1302, Learning Rate: 2.96e-05
2025-12-10 12:33:04 - INFO - Epoch: 28.75, Step: 113890, Train Loss: 1.1605, Learning Rate: 2.96e-05
2025-12-10 12:33:16 - INFO - Epoch: 28.76, Step: 113900, Train Loss: 1.2232, Learning Rate: 2.96e-05
2025-12-10 12:33:27 - INFO - Epoch: 28.76, Step: 113910, Train Loss: 1.1578, Learning Rate: 2.96e-05
2025-12-10 12:33:38 - INFO - Epoch: 28.76, Step: 113920, Train Loss: 1.1824, Learning Rate: 2.96e-05
2025-12-10 12:33:49 - INFO - Epoch: 28.76, Step: 113930, Train Loss: 1.1619, Learning Rate: 2.96e-05
2025-12-10 12:34:00 - INFO - Epoch: 28.77, Step: 113940, Train Loss: 1.1600, Learning Rate: 2.96e-05
2025-12-10 12:34:11 - INFO - Epoch: 28.77, Step: 113950, Train Loss: 1.1633, Learning Rate: 2.96e-05
2025-12-10 12:34:23 - INFO - Epoch: 28.77, Step: 113960, Train Loss: 1.1507, Learning Rate: 2.96e-05
2025-12-10 12:34:34 - INFO - Epoch: 28.77, Step: 113970, Train Loss: 1.1926, Learning Rate: 2.95e-05
2025-12-10 12:34:45 - INFO - Epoch: 28.78, Step: 113980, Train Loss: 1.2345, Learning Rate: 2.95e-05
2025-12-10 12:34:56 - INFO - Epoch: 28.78, Step: 113990, Train Loss: 1.1552, Learning Rate: 2.95e-05
2025-12-10 12:35:07 - INFO - Epoch: 28.78, Step: 114000, Train Loss: 1.1828, Learning Rate: 2.95e-05
2025-12-10 12:35:18 - INFO - Epoch: 28.78, Step: 114010, Train Loss: 1.1780, Learning Rate: 2.95e-05
2025-12-10 12:35:29 - INFO - Epoch: 28.79, Step: 114020, Train Loss: 1.1870, Learning Rate: 2.95e-05
2025-12-10 12:35:41 - INFO - Epoch: 28.79, Step: 114030, Train Loss: 1.1547, Learning Rate: 2.95e-05
2025-12-10 12:35:52 - INFO - Epoch: 28.79, Step: 114040, Train Loss: 1.1809, Learning Rate: 2.95e-05
2025-12-10 12:36:03 - INFO - Epoch: 28.79, Step: 114050, Train Loss: 1.2309, Learning Rate: 2.95e-05
2025-12-10 12:36:14 - INFO - Epoch: 28.80, Step: 114060, Train Loss: 1.1813, Learning Rate: 2.95e-05
2025-12-10 12:36:25 - INFO - Epoch: 28.80, Step: 114070, Train Loss: 1.1781, Learning Rate: 2.95e-05
2025-12-10 12:36:36 - INFO - Epoch: 28.80, Step: 114080, Train Loss: 1.1959, Learning Rate: 2.95e-05
2025-12-10 12:36:48 - INFO - Epoch: 28.80, Step: 114090, Train Loss: 1.1519, Learning Rate: 2.95e-05
2025-12-10 12:36:59 - INFO - Epoch: 28.81, Step: 114100, Train Loss: 1.1294, Learning Rate: 2.95e-05
2025-12-10 12:37:10 - INFO - Epoch: 28.81, Step: 114110, Train Loss: 1.2184, Learning Rate: 2.95e-05
2025-12-10 12:37:21 - INFO - Epoch: 28.81, Step: 114120, Train Loss: 1.1597, Learning Rate: 2.94e-05
2025-12-10 12:37:32 - INFO - Epoch: 28.81, Step: 114130, Train Loss: 1.1876, Learning Rate: 2.94e-05
2025-12-10 12:37:43 - INFO - Epoch: 28.82, Step: 114140, Train Loss: 1.1540, Learning Rate: 2.94e-05
2025-12-10 12:37:55 - INFO - Epoch: 28.82, Step: 114150, Train Loss: 1.1425, Learning Rate: 2.94e-05
2025-12-10 12:38:06 - INFO - Epoch: 28.82, Step: 114160, Train Loss: 1.1696, Learning Rate: 2.94e-05
2025-12-10 12:38:17 - INFO - Epoch: 28.82, Step: 114170, Train Loss: 1.1719, Learning Rate: 2.94e-05
2025-12-10 12:38:28 - INFO - Epoch: 28.83, Step: 114180, Train Loss: 1.1835, Learning Rate: 2.94e-05
2025-12-10 12:38:39 - INFO - Epoch: 28.83, Step: 114190, Train Loss: 1.1880, Learning Rate: 2.94e-05
2025-12-10 12:38:50 - INFO - Epoch: 28.83, Step: 114200, Train Loss: 1.1630, Learning Rate: 2.94e-05
2025-12-10 12:39:01 - INFO - Epoch: 28.83, Step: 114210, Train Loss: 1.1966, Learning Rate: 2.94e-05
2025-12-10 12:39:13 - INFO - Epoch: 28.84, Step: 114220, Train Loss: 1.1967, Learning Rate: 2.94e-05
2025-12-10 12:39:24 - INFO - Epoch: 28.84, Step: 114230, Train Loss: 1.1672, Learning Rate: 2.94e-05
2025-12-10 12:39:35 - INFO - Epoch: 28.84, Step: 114240, Train Loss: 1.2098, Learning Rate: 2.94e-05
2025-12-10 12:39:46 - INFO - Epoch: 28.84, Step: 114250, Train Loss: 1.1963, Learning Rate: 2.94e-05
2025-12-10 12:39:57 - INFO - Epoch: 28.85, Step: 114260, Train Loss: 1.1520, Learning Rate: 2.94e-05
2025-12-10 12:40:08 - INFO - Epoch: 28.85, Step: 114270, Train Loss: 1.1777, Learning Rate: 2.93e-05
2025-12-10 12:40:20 - INFO - Epoch: 28.85, Step: 114280, Train Loss: 1.2069, Learning Rate: 2.93e-05
2025-12-10 12:40:31 - INFO - Epoch: 28.85, Step: 114290, Train Loss: 1.2225, Learning Rate: 2.93e-05
2025-12-10 12:40:42 - INFO - Epoch: 28.86, Step: 114300, Train Loss: 1.1932, Learning Rate: 2.93e-05
2025-12-10 12:40:53 - INFO - Epoch: 28.86, Step: 114310, Train Loss: 1.1927, Learning Rate: 2.93e-05
2025-12-10 12:41:04 - INFO - Epoch: 28.86, Step: 114320, Train Loss: 1.1786, Learning Rate: 2.93e-05
2025-12-10 12:41:15 - INFO - Epoch: 28.86, Step: 114330, Train Loss: 1.1998, Learning Rate: 2.93e-05
2025-12-10 12:41:27 - INFO - Epoch: 28.87, Step: 114340, Train Loss: 1.1722, Learning Rate: 2.93e-05
2025-12-10 12:41:38 - INFO - Epoch: 28.87, Step: 114350, Train Loss: 1.1385, Learning Rate: 2.93e-05
2025-12-10 12:41:49 - INFO - Epoch: 28.87, Step: 114360, Train Loss: 1.1380, Learning Rate: 2.93e-05
2025-12-10 12:42:00 - INFO - Epoch: 28.87, Step: 114370, Train Loss: 1.1535, Learning Rate: 2.93e-05
2025-12-10 12:42:11 - INFO - Epoch: 28.88, Step: 114380, Train Loss: 1.1919, Learning Rate: 2.93e-05
2025-12-10 12:42:22 - INFO - Epoch: 28.88, Step: 114390, Train Loss: 1.1549, Learning Rate: 2.93e-05
2025-12-10 12:42:33 - INFO - Epoch: 28.88, Step: 114400, Train Loss: 1.1555, Learning Rate: 2.93e-05
2025-12-10 12:42:45 - INFO - Epoch: 28.88, Step: 114410, Train Loss: 1.1871, Learning Rate: 2.93e-05
2025-12-10 12:42:56 - INFO - Epoch: 28.89, Step: 114420, Train Loss: 1.1288, Learning Rate: 2.92e-05
2025-12-10 12:43:07 - INFO - Epoch: 28.89, Step: 114430, Train Loss: 1.1407, Learning Rate: 2.92e-05
2025-12-10 12:43:18 - INFO - Epoch: 28.89, Step: 114440, Train Loss: 1.1732, Learning Rate: 2.92e-05
2025-12-10 12:43:29 - INFO - Epoch: 28.89, Step: 114450, Train Loss: 1.1610, Learning Rate: 2.92e-05
2025-12-10 12:43:40 - INFO - Epoch: 28.90, Step: 114460, Train Loss: 1.1914, Learning Rate: 2.92e-05
2025-12-10 12:43:52 - INFO - Epoch: 28.90, Step: 114470, Train Loss: 1.1587, Learning Rate: 2.92e-05
2025-12-10 12:44:03 - INFO - Epoch: 28.90, Step: 114480, Train Loss: 1.1886, Learning Rate: 2.92e-05
2025-12-10 12:44:14 - INFO - Epoch: 28.90, Step: 114490, Train Loss: 1.1819, Learning Rate: 2.92e-05
2025-12-10 12:44:25 - INFO - Epoch: 28.91, Step: 114500, Train Loss: 1.1420, Learning Rate: 2.92e-05
2025-12-10 12:44:36 - INFO - Epoch: 28.91, Step: 114510, Train Loss: 1.2206, Learning Rate: 2.92e-05
2025-12-10 12:44:47 - INFO - Epoch: 28.91, Step: 114520, Train Loss: 1.1662, Learning Rate: 2.92e-05
2025-12-10 12:44:58 - INFO - Epoch: 28.91, Step: 114530, Train Loss: 1.1882, Learning Rate: 2.92e-05
2025-12-10 12:45:10 - INFO - Epoch: 28.92, Step: 114540, Train Loss: 1.1701, Learning Rate: 2.92e-05
2025-12-10 12:45:21 - INFO - Epoch: 28.92, Step: 114550, Train Loss: 1.1796, Learning Rate: 2.92e-05
2025-12-10 12:45:32 - INFO - Epoch: 28.92, Step: 114560, Train Loss: 1.1804, Learning Rate: 2.92e-05
2025-12-10 12:45:43 - INFO - Epoch: 28.92, Step: 114570, Train Loss: 1.1711, Learning Rate: 2.91e-05
2025-12-10 12:45:54 - INFO - Epoch: 28.93, Step: 114580, Train Loss: 1.1901, Learning Rate: 2.91e-05
2025-12-10 12:46:05 - INFO - Epoch: 28.93, Step: 114590, Train Loss: 1.2037, Learning Rate: 2.91e-05
2025-12-10 12:46:17 - INFO - Epoch: 28.93, Step: 114600, Train Loss: 1.2010, Learning Rate: 2.91e-05
2025-12-10 12:46:28 - INFO - Epoch: 28.93, Step: 114610, Train Loss: 1.1789, Learning Rate: 2.91e-05
2025-12-10 12:46:39 - INFO - Epoch: 28.94, Step: 114620, Train Loss: 1.1640, Learning Rate: 2.91e-05
2025-12-10 12:46:50 - INFO - Epoch: 28.94, Step: 114630, Train Loss: 1.2277, Learning Rate: 2.91e-05
2025-12-10 12:47:01 - INFO - Epoch: 28.94, Step: 114640, Train Loss: 1.1887, Learning Rate: 2.91e-05
2025-12-10 12:47:12 - INFO - Epoch: 28.94, Step: 114650, Train Loss: 1.1924, Learning Rate: 2.91e-05
2025-12-10 12:47:24 - INFO - Epoch: 28.95, Step: 114660, Train Loss: 1.1936, Learning Rate: 2.91e-05
2025-12-10 12:47:35 - INFO - Epoch: 28.95, Step: 114670, Train Loss: 1.1850, Learning Rate: 2.91e-05
2025-12-10 12:47:46 - INFO - Epoch: 28.95, Step: 114680, Train Loss: 1.2040, Learning Rate: 2.91e-05
2025-12-10 12:47:57 - INFO - Epoch: 28.95, Step: 114690, Train Loss: 1.1663, Learning Rate: 2.91e-05
2025-12-10 12:48:08 - INFO - Epoch: 28.96, Step: 114700, Train Loss: 1.1927, Learning Rate: 2.91e-05
2025-12-10 12:48:19 - INFO - Epoch: 28.96, Step: 114710, Train Loss: 1.1835, Learning Rate: 2.91e-05
2025-12-10 12:48:30 - INFO - Epoch: 28.96, Step: 114720, Train Loss: 1.1561, Learning Rate: 2.90e-05
2025-12-10 12:48:42 - INFO - Epoch: 28.96, Step: 114730, Train Loss: 1.2124, Learning Rate: 2.90e-05
2025-12-10 12:48:53 - INFO - Epoch: 28.97, Step: 114740, Train Loss: 1.1711, Learning Rate: 2.90e-05
2025-12-10 12:49:04 - INFO - Epoch: 28.97, Step: 114750, Train Loss: 1.1774, Learning Rate: 2.90e-05
2025-12-10 12:49:15 - INFO - Epoch: 28.97, Step: 114760, Train Loss: 1.2131, Learning Rate: 2.90e-05
2025-12-10 12:49:26 - INFO - Epoch: 28.98, Step: 114770, Train Loss: 1.1982, Learning Rate: 2.90e-05
2025-12-10 12:49:37 - INFO - Epoch: 28.98, Step: 114780, Train Loss: 1.1731, Learning Rate: 2.90e-05
2025-12-10 12:49:49 - INFO - Epoch: 28.98, Step: 114790, Train Loss: 1.2113, Learning Rate: 2.90e-05
2025-12-10 12:50:00 - INFO - Epoch: 28.98, Step: 114800, Train Loss: 1.1521, Learning Rate: 2.90e-05
2025-12-10 12:50:11 - INFO - Epoch: 28.99, Step: 114810, Train Loss: 1.2092, Learning Rate: 2.90e-05
2025-12-10 12:50:22 - INFO - Epoch: 28.99, Step: 114820, Train Loss: 1.1762, Learning Rate: 2.90e-05
2025-12-10 12:50:33 - INFO - Epoch: 28.99, Step: 114830, Train Loss: 1.1662, Learning Rate: 2.90e-05
2025-12-10 12:50:44 - INFO - Epoch: 28.99, Step: 114840, Train Loss: 1.1674, Learning Rate: 2.90e-05
2025-12-10 12:50:56 - INFO - Epoch: 29.00, Step: 114850, Train Loss: 1.1599, Learning Rate: 2.90e-05
2025-12-10 12:51:07 - INFO - Epoch: 29.00, Step: 114860, Train Loss: 1.1775, Learning Rate: 2.90e-05
2025-12-10 12:51:18 - INFO - Epoch: 29.00, Step: 114870, Train Loss: 1.1834, Learning Rate: 2.89e-05
2025-12-10 12:51:29 - INFO - Epoch: 29.00, Step: 114880, Train Loss: 1.1910, Learning Rate: 2.89e-05
2025-12-10 12:51:40 - INFO - Epoch: 29.01, Step: 114890, Train Loss: 1.1794, Learning Rate: 2.89e-05
2025-12-10 12:51:51 - INFO - Epoch: 29.01, Step: 114900, Train Loss: 1.1935, Learning Rate: 2.89e-05
2025-12-10 12:52:02 - INFO - Epoch: 29.01, Step: 114910, Train Loss: 1.1828, Learning Rate: 2.89e-05
2025-12-10 12:52:14 - INFO - Epoch: 29.01, Step: 114920, Train Loss: 1.1855, Learning Rate: 2.89e-05
2025-12-10 12:52:25 - INFO - Epoch: 29.02, Step: 114930, Train Loss: 1.1634, Learning Rate: 2.89e-05
2025-12-10 12:52:36 - INFO - Epoch: 29.02, Step: 114940, Train Loss: 1.1767, Learning Rate: 2.89e-05
2025-12-10 12:52:47 - INFO - Epoch: 29.02, Step: 114950, Train Loss: 1.1853, Learning Rate: 2.89e-05
2025-12-10 12:52:58 - INFO - Epoch: 29.02, Step: 114960, Train Loss: 1.2126, Learning Rate: 2.89e-05
2025-12-10 12:53:09 - INFO - Epoch: 29.03, Step: 114970, Train Loss: 1.1826, Learning Rate: 2.89e-05
2025-12-10 12:53:21 - INFO - Epoch: 29.03, Step: 114980, Train Loss: 1.1592, Learning Rate: 2.89e-05
2025-12-10 12:53:32 - INFO - Epoch: 29.03, Step: 114990, Train Loss: 1.1816, Learning Rate: 2.89e-05
2025-12-10 12:53:43 - INFO - Epoch: 29.03, Step: 115000, Train Loss: 1.1886, Learning Rate: 2.89e-05
2025-12-10 12:53:54 - INFO - Epoch: 29.04, Step: 115010, Train Loss: 1.1754, Learning Rate: 2.89e-05
2025-12-10 12:54:05 - INFO - Epoch: 29.04, Step: 115020, Train Loss: 1.1709, Learning Rate: 2.88e-05
2025-12-10 12:54:16 - INFO - Epoch: 29.04, Step: 115030, Train Loss: 1.1415, Learning Rate: 2.88e-05
2025-12-10 12:54:28 - INFO - Epoch: 29.04, Step: 115040, Train Loss: 1.1729, Learning Rate: 2.88e-05
2025-12-10 12:54:39 - INFO - Epoch: 29.05, Step: 115050, Train Loss: 1.2064, Learning Rate: 2.88e-05
2025-12-10 12:54:50 - INFO - Epoch: 29.05, Step: 115060, Train Loss: 1.1593, Learning Rate: 2.88e-05
2025-12-10 12:55:01 - INFO - Epoch: 29.05, Step: 115070, Train Loss: 1.1791, Learning Rate: 2.88e-05
2025-12-10 12:55:12 - INFO - Epoch: 29.05, Step: 115080, Train Loss: 1.1812, Learning Rate: 2.88e-05
2025-12-10 12:55:23 - INFO - Epoch: 29.06, Step: 115090, Train Loss: 1.1625, Learning Rate: 2.88e-05
2025-12-10 12:55:34 - INFO - Epoch: 29.06, Step: 115100, Train Loss: 1.1905, Learning Rate: 2.88e-05
2025-12-10 12:55:46 - INFO - Epoch: 29.06, Step: 115110, Train Loss: 1.1855, Learning Rate: 2.88e-05
2025-12-10 12:55:57 - INFO - Epoch: 29.06, Step: 115120, Train Loss: 1.1863, Learning Rate: 2.88e-05
2025-12-10 12:56:08 - INFO - Epoch: 29.07, Step: 115130, Train Loss: 1.1825, Learning Rate: 2.88e-05
2025-12-10 12:56:19 - INFO - Epoch: 29.07, Step: 115140, Train Loss: 1.1969, Learning Rate: 2.88e-05
2025-12-10 12:56:30 - INFO - Epoch: 29.07, Step: 115150, Train Loss: 1.1856, Learning Rate: 2.88e-05
2025-12-10 12:56:41 - INFO - Epoch: 29.07, Step: 115160, Train Loss: 1.1652, Learning Rate: 2.88e-05
2025-12-10 12:56:53 - INFO - Epoch: 29.08, Step: 115170, Train Loss: 1.1876, Learning Rate: 2.87e-05
2025-12-10 12:57:04 - INFO - Epoch: 29.08, Step: 115180, Train Loss: 1.2067, Learning Rate: 2.87e-05
2025-12-10 12:57:15 - INFO - Epoch: 29.08, Step: 115190, Train Loss: 1.1806, Learning Rate: 2.87e-05
2025-12-10 12:57:26 - INFO - Epoch: 29.08, Step: 115200, Train Loss: 1.1524, Learning Rate: 2.87e-05
2025-12-10 12:57:37 - INFO - Epoch: 29.09, Step: 115210, Train Loss: 1.1814, Learning Rate: 2.87e-05
2025-12-10 12:57:48 - INFO - Epoch: 29.09, Step: 115220, Train Loss: 1.1989, Learning Rate: 2.87e-05
2025-12-10 12:58:00 - INFO - Epoch: 29.09, Step: 115230, Train Loss: 1.1865, Learning Rate: 2.87e-05
2025-12-10 12:58:11 - INFO - Epoch: 29.09, Step: 115240, Train Loss: 1.1668, Learning Rate: 2.87e-05
2025-12-10 12:58:22 - INFO - Epoch: 29.10, Step: 115250, Train Loss: 1.1845, Learning Rate: 2.87e-05
2025-12-10 12:58:33 - INFO - Epoch: 29.10, Step: 115260, Train Loss: 1.1558, Learning Rate: 2.87e-05
2025-12-10 12:58:44 - INFO - Epoch: 29.10, Step: 115270, Train Loss: 1.1609, Learning Rate: 2.87e-05
2025-12-10 12:58:55 - INFO - Epoch: 29.10, Step: 115280, Train Loss: 1.2056, Learning Rate: 2.87e-05
2025-12-10 12:59:06 - INFO - Epoch: 29.11, Step: 115290, Train Loss: 1.1659, Learning Rate: 2.87e-05
2025-12-10 12:59:18 - INFO - Epoch: 29.11, Step: 115300, Train Loss: 1.1395, Learning Rate: 2.87e-05
2025-12-10 12:59:29 - INFO - Epoch: 29.11, Step: 115310, Train Loss: 1.1999, Learning Rate: 2.87e-05
2025-12-10 12:59:40 - INFO - Epoch: 29.11, Step: 115320, Train Loss: 1.1744, Learning Rate: 2.86e-05
2025-12-10 12:59:51 - INFO - Epoch: 29.12, Step: 115330, Train Loss: 1.1620, Learning Rate: 2.86e-05
2025-12-10 13:00:02 - INFO - Epoch: 29.12, Step: 115340, Train Loss: 1.1664, Learning Rate: 2.86e-05
2025-12-10 13:00:13 - INFO - Epoch: 29.12, Step: 115350, Train Loss: 1.1327, Learning Rate: 2.86e-05
2025-12-10 13:00:25 - INFO - Epoch: 29.12, Step: 115360, Train Loss: 1.1815, Learning Rate: 2.86e-05
2025-12-10 13:00:36 - INFO - Epoch: 29.13, Step: 115370, Train Loss: 1.1817, Learning Rate: 2.86e-05
2025-12-10 13:00:47 - INFO - Epoch: 29.13, Step: 115380, Train Loss: 1.1773, Learning Rate: 2.86e-05
2025-12-10 13:00:58 - INFO - Epoch: 29.13, Step: 115390, Train Loss: 1.1741, Learning Rate: 2.86e-05
2025-12-10 13:01:09 - INFO - Epoch: 29.13, Step: 115400, Train Loss: 1.1701, Learning Rate: 2.86e-05
2025-12-10 13:01:20 - INFO - Epoch: 29.14, Step: 115410, Train Loss: 1.1960, Learning Rate: 2.86e-05
2025-12-10 13:01:32 - INFO - Epoch: 29.14, Step: 115420, Train Loss: 1.1631, Learning Rate: 2.86e-05
2025-12-10 13:01:43 - INFO - Epoch: 29.14, Step: 115430, Train Loss: 1.2271, Learning Rate: 2.86e-05
2025-12-10 13:01:54 - INFO - Epoch: 29.14, Step: 115440, Train Loss: 1.1507, Learning Rate: 2.86e-05
2025-12-10 13:02:05 - INFO - Epoch: 29.15, Step: 115450, Train Loss: 1.1578, Learning Rate: 2.86e-05
2025-12-10 13:02:16 - INFO - Epoch: 29.15, Step: 115460, Train Loss: 1.1588, Learning Rate: 2.86e-05
2025-12-10 13:02:27 - INFO - Epoch: 29.15, Step: 115470, Train Loss: 1.2017, Learning Rate: 2.85e-05
2025-12-10 13:02:38 - INFO - Epoch: 29.15, Step: 115480, Train Loss: 1.1876, Learning Rate: 2.85e-05
2025-12-10 13:02:50 - INFO - Epoch: 29.16, Step: 115490, Train Loss: 1.1672, Learning Rate: 2.85e-05
2025-12-10 13:03:01 - INFO - Epoch: 29.16, Step: 115500, Train Loss: 1.2022, Learning Rate: 2.85e-05
2025-12-10 13:03:12 - INFO - Epoch: 29.16, Step: 115510, Train Loss: 1.2059, Learning Rate: 2.85e-05
2025-12-10 13:03:23 - INFO - Epoch: 29.16, Step: 115520, Train Loss: 1.2220, Learning Rate: 2.85e-05
2025-12-10 13:03:34 - INFO - Epoch: 29.17, Step: 115530, Train Loss: 1.1557, Learning Rate: 2.85e-05
2025-12-10 13:03:45 - INFO - Epoch: 29.17, Step: 115540, Train Loss: 1.1614, Learning Rate: 2.85e-05
2025-12-10 13:03:57 - INFO - Epoch: 29.17, Step: 115550, Train Loss: 1.2017, Learning Rate: 2.85e-05
2025-12-10 13:04:08 - INFO - Epoch: 29.17, Step: 115560, Train Loss: 1.1950, Learning Rate: 2.85e-05
2025-12-10 13:04:19 - INFO - Epoch: 29.18, Step: 115570, Train Loss: 1.1310, Learning Rate: 2.85e-05
2025-12-10 13:04:30 - INFO - Epoch: 29.18, Step: 115580, Train Loss: 1.1785, Learning Rate: 2.85e-05
2025-12-10 13:04:41 - INFO - Epoch: 29.18, Step: 115590, Train Loss: 1.1666, Learning Rate: 2.85e-05
2025-12-10 13:04:52 - INFO - Epoch: 29.18, Step: 115600, Train Loss: 1.1738, Learning Rate: 2.85e-05
2025-12-10 13:05:04 - INFO - Epoch: 29.19, Step: 115610, Train Loss: 1.1679, Learning Rate: 2.85e-05
2025-12-10 13:05:15 - INFO - Epoch: 29.19, Step: 115620, Train Loss: 1.1798, Learning Rate: 2.84e-05
2025-12-10 13:05:26 - INFO - Epoch: 29.19, Step: 115630, Train Loss: 1.1576, Learning Rate: 2.84e-05
2025-12-10 13:05:37 - INFO - Epoch: 29.19, Step: 115640, Train Loss: 1.1844, Learning Rate: 2.84e-05
2025-12-10 13:05:48 - INFO - Epoch: 29.20, Step: 115650, Train Loss: 1.1858, Learning Rate: 2.84e-05
2025-12-10 13:05:59 - INFO - Epoch: 29.20, Step: 115660, Train Loss: 1.1971, Learning Rate: 2.84e-05
2025-12-10 13:06:10 - INFO - Epoch: 29.20, Step: 115670, Train Loss: 1.1920, Learning Rate: 2.84e-05
2025-12-10 13:06:22 - INFO - Epoch: 29.20, Step: 115680, Train Loss: 1.2009, Learning Rate: 2.84e-05
2025-12-10 13:06:33 - INFO - Epoch: 29.21, Step: 115690, Train Loss: 1.1554, Learning Rate: 2.84e-05
2025-12-10 13:06:44 - INFO - Epoch: 29.21, Step: 115700, Train Loss: 1.1629, Learning Rate: 2.84e-05
2025-12-10 13:06:55 - INFO - Epoch: 29.21, Step: 115710, Train Loss: 1.1735, Learning Rate: 2.84e-05
2025-12-10 13:07:06 - INFO - Epoch: 29.21, Step: 115720, Train Loss: 1.1448, Learning Rate: 2.84e-05
2025-12-10 13:07:17 - INFO - Epoch: 29.22, Step: 115730, Train Loss: 1.1846, Learning Rate: 2.84e-05
2025-12-10 13:07:29 - INFO - Epoch: 29.22, Step: 115740, Train Loss: 1.2059, Learning Rate: 2.84e-05
2025-12-10 13:07:40 - INFO - Epoch: 29.22, Step: 115750, Train Loss: 1.1699, Learning Rate: 2.84e-05
2025-12-10 13:07:51 - INFO - Epoch: 29.22, Step: 115760, Train Loss: 1.2235, Learning Rate: 2.84e-05
2025-12-10 13:08:02 - INFO - Epoch: 29.23, Step: 115770, Train Loss: 1.1720, Learning Rate: 2.83e-05
2025-12-10 13:08:13 - INFO - Epoch: 29.23, Step: 115780, Train Loss: 1.1844, Learning Rate: 2.83e-05
2025-12-10 13:08:24 - INFO - Epoch: 29.23, Step: 115790, Train Loss: 1.1965, Learning Rate: 2.83e-05
2025-12-10 13:08:36 - INFO - Epoch: 29.24, Step: 115800, Train Loss: 1.1999, Learning Rate: 2.83e-05
2025-12-10 13:08:47 - INFO - Epoch: 29.24, Step: 115810, Train Loss: 1.1719, Learning Rate: 2.83e-05
2025-12-10 13:08:58 - INFO - Epoch: 29.24, Step: 115820, Train Loss: 1.2109, Learning Rate: 2.83e-05
2025-12-10 13:09:09 - INFO - Epoch: 29.24, Step: 115830, Train Loss: 1.1925, Learning Rate: 2.83e-05
2025-12-10 13:09:20 - INFO - Epoch: 29.25, Step: 115840, Train Loss: 1.2046, Learning Rate: 2.83e-05
2025-12-10 13:09:31 - INFO - Epoch: 29.25, Step: 115850, Train Loss: 1.1941, Learning Rate: 2.83e-05
2025-12-10 13:09:42 - INFO - Epoch: 29.25, Step: 115860, Train Loss: 1.1454, Learning Rate: 2.83e-05
2025-12-10 13:09:54 - INFO - Epoch: 29.25, Step: 115870, Train Loss: 1.1617, Learning Rate: 2.83e-05
2025-12-10 13:10:05 - INFO - Epoch: 29.26, Step: 115880, Train Loss: 1.1890, Learning Rate: 2.83e-05
2025-12-10 13:10:16 - INFO - Epoch: 29.26, Step: 115890, Train Loss: 1.1728, Learning Rate: 2.83e-05
2025-12-10 13:10:27 - INFO - Epoch: 29.26, Step: 115900, Train Loss: 1.1371, Learning Rate: 2.83e-05
2025-12-10 13:10:38 - INFO - Epoch: 29.26, Step: 115910, Train Loss: 1.2130, Learning Rate: 2.83e-05
2025-12-10 13:10:49 - INFO - Epoch: 29.27, Step: 115920, Train Loss: 1.2241, Learning Rate: 2.82e-05
2025-12-10 13:11:01 - INFO - Epoch: 29.27, Step: 115930, Train Loss: 1.2255, Learning Rate: 2.82e-05
2025-12-10 13:11:12 - INFO - Epoch: 29.27, Step: 115940, Train Loss: 1.1774, Learning Rate: 2.82e-05
2025-12-10 13:11:23 - INFO - Epoch: 29.27, Step: 115950, Train Loss: 1.1224, Learning Rate: 2.82e-05
2025-12-10 13:11:34 - INFO - Epoch: 29.28, Step: 115960, Train Loss: 1.1897, Learning Rate: 2.82e-05
2025-12-10 13:11:45 - INFO - Epoch: 29.28, Step: 115970, Train Loss: 1.1517, Learning Rate: 2.82e-05
2025-12-10 13:11:56 - INFO - Epoch: 29.28, Step: 115980, Train Loss: 1.2224, Learning Rate: 2.82e-05
2025-12-10 13:12:08 - INFO - Epoch: 29.28, Step: 115990, Train Loss: 1.1532, Learning Rate: 2.82e-05
2025-12-10 13:12:19 - INFO - Epoch: 29.29, Step: 116000, Train Loss: 1.1610, Learning Rate: 2.82e-05
2025-12-10 13:12:30 - INFO - Epoch: 29.29, Step: 116010, Train Loss: 1.1699, Learning Rate: 2.82e-05
2025-12-10 13:12:41 - INFO - Epoch: 29.29, Step: 116020, Train Loss: 1.1897, Learning Rate: 2.82e-05
2025-12-10 13:12:52 - INFO - Epoch: 29.29, Step: 116030, Train Loss: 1.1987, Learning Rate: 2.82e-05
2025-12-10 13:13:03 - INFO - Epoch: 29.30, Step: 116040, Train Loss: 1.1654, Learning Rate: 2.82e-05
2025-12-10 13:13:14 - INFO - Epoch: 29.30, Step: 116050, Train Loss: 1.1537, Learning Rate: 2.82e-05
2025-12-10 13:13:26 - INFO - Epoch: 29.30, Step: 116060, Train Loss: 1.1999, Learning Rate: 2.82e-05
2025-12-10 13:13:37 - INFO - Epoch: 29.30, Step: 116070, Train Loss: 1.1477, Learning Rate: 2.82e-05
2025-12-10 13:13:48 - INFO - Epoch: 29.31, Step: 116080, Train Loss: 1.1630, Learning Rate: 2.81e-05
2025-12-10 13:13:59 - INFO - Epoch: 29.31, Step: 116090, Train Loss: 1.1759, Learning Rate: 2.81e-05
2025-12-10 13:14:10 - INFO - Epoch: 29.31, Step: 116100, Train Loss: 1.1819, Learning Rate: 2.81e-05
2025-12-10 13:14:21 - INFO - Epoch: 29.31, Step: 116110, Train Loss: 1.1858, Learning Rate: 2.81e-05
2025-12-10 13:14:33 - INFO - Epoch: 29.32, Step: 116120, Train Loss: 1.1491, Learning Rate: 2.81e-05
2025-12-10 13:14:44 - INFO - Epoch: 29.32, Step: 116130, Train Loss: 1.1685, Learning Rate: 2.81e-05
2025-12-10 13:14:55 - INFO - Epoch: 29.32, Step: 116140, Train Loss: 1.1477, Learning Rate: 2.81e-05
2025-12-10 13:15:06 - INFO - Epoch: 29.32, Step: 116150, Train Loss: 1.1603, Learning Rate: 2.81e-05
2025-12-10 13:15:17 - INFO - Epoch: 29.33, Step: 116160, Train Loss: 1.1592, Learning Rate: 2.81e-05
2025-12-10 13:15:28 - INFO - Epoch: 29.33, Step: 116170, Train Loss: 1.1384, Learning Rate: 2.81e-05
2025-12-10 13:15:40 - INFO - Epoch: 29.33, Step: 116180, Train Loss: 1.1675, Learning Rate: 2.81e-05
2025-12-10 13:15:51 - INFO - Epoch: 29.33, Step: 116190, Train Loss: 1.1747, Learning Rate: 2.81e-05
2025-12-10 13:16:02 - INFO - Epoch: 29.34, Step: 116200, Train Loss: 1.1592, Learning Rate: 2.81e-05
2025-12-10 13:16:13 - INFO - Epoch: 29.34, Step: 116210, Train Loss: 1.1436, Learning Rate: 2.81e-05
2025-12-10 13:16:24 - INFO - Epoch: 29.34, Step: 116220, Train Loss: 1.1847, Learning Rate: 2.81e-05
2025-12-10 13:16:35 - INFO - Epoch: 29.34, Step: 116230, Train Loss: 1.1503, Learning Rate: 2.80e-05
2025-12-10 13:16:46 - INFO - Epoch: 29.35, Step: 116240, Train Loss: 1.2158, Learning Rate: 2.80e-05
2025-12-10 13:16:58 - INFO - Epoch: 29.35, Step: 116250, Train Loss: 1.1431, Learning Rate: 2.80e-05
2025-12-10 13:17:09 - INFO - Epoch: 29.35, Step: 116260, Train Loss: 1.1705, Learning Rate: 2.80e-05
2025-12-10 13:17:20 - INFO - Epoch: 29.35, Step: 116270, Train Loss: 1.1962, Learning Rate: 2.80e-05
2025-12-10 13:17:31 - INFO - Epoch: 29.36, Step: 116280, Train Loss: 1.1761, Learning Rate: 2.80e-05
2025-12-10 13:17:42 - INFO - Epoch: 29.36, Step: 116290, Train Loss: 1.1550, Learning Rate: 2.80e-05
2025-12-10 13:17:53 - INFO - Epoch: 29.36, Step: 116300, Train Loss: 1.2018, Learning Rate: 2.80e-05
2025-12-10 13:18:05 - INFO - Epoch: 29.36, Step: 116310, Train Loss: 1.1965, Learning Rate: 2.80e-05
2025-12-10 13:18:16 - INFO - Epoch: 29.37, Step: 116320, Train Loss: 1.1816, Learning Rate: 2.80e-05
2025-12-10 13:18:27 - INFO - Epoch: 29.37, Step: 116330, Train Loss: 1.1708, Learning Rate: 2.80e-05
2025-12-10 13:18:38 - INFO - Epoch: 29.37, Step: 116340, Train Loss: 1.1801, Learning Rate: 2.80e-05
2025-12-10 13:18:49 - INFO - Epoch: 29.37, Step: 116350, Train Loss: 1.2001, Learning Rate: 2.80e-05
2025-12-10 13:19:00 - INFO - Epoch: 29.38, Step: 116360, Train Loss: 1.1586, Learning Rate: 2.80e-05
2025-12-10 13:19:12 - INFO - Epoch: 29.38, Step: 116370, Train Loss: 1.1778, Learning Rate: 2.80e-05
2025-12-10 13:19:23 - INFO - Epoch: 29.38, Step: 116380, Train Loss: 1.1747, Learning Rate: 2.79e-05
2025-12-10 13:19:34 - INFO - Epoch: 29.38, Step: 116390, Train Loss: 1.1846, Learning Rate: 2.79e-05
2025-12-10 13:19:45 - INFO - Epoch: 29.39, Step: 116400, Train Loss: 1.2003, Learning Rate: 2.79e-05
2025-12-10 13:19:56 - INFO - Epoch: 29.39, Step: 116410, Train Loss: 1.1753, Learning Rate: 2.79e-05
2025-12-10 13:20:07 - INFO - Epoch: 29.39, Step: 116420, Train Loss: 1.1688, Learning Rate: 2.79e-05
2025-12-10 13:20:18 - INFO - Epoch: 29.39, Step: 116430, Train Loss: 1.1502, Learning Rate: 2.79e-05
2025-12-10 13:20:30 - INFO - Epoch: 29.40, Step: 116440, Train Loss: 1.1544, Learning Rate: 2.79e-05
2025-12-10 13:20:41 - INFO - Epoch: 29.40, Step: 116450, Train Loss: 1.1498, Learning Rate: 2.79e-05
2025-12-10 13:20:52 - INFO - Epoch: 29.40, Step: 116460, Train Loss: 1.1984, Learning Rate: 2.79e-05
2025-12-10 13:21:03 - INFO - Epoch: 29.40, Step: 116470, Train Loss: 1.1788, Learning Rate: 2.79e-05
2025-12-10 13:21:14 - INFO - Epoch: 29.41, Step: 116480, Train Loss: 1.1686, Learning Rate: 2.79e-05
2025-12-10 13:21:25 - INFO - Epoch: 29.41, Step: 116490, Train Loss: 1.2069, Learning Rate: 2.79e-05
2025-12-10 13:21:37 - INFO - Epoch: 29.41, Step: 116500, Train Loss: 1.1521, Learning Rate: 2.79e-05
2025-12-10 13:21:48 - INFO - Epoch: 29.41, Step: 116510, Train Loss: 1.1585, Learning Rate: 2.79e-05
2025-12-10 13:21:59 - INFO - Epoch: 29.42, Step: 116520, Train Loss: 1.2008, Learning Rate: 2.79e-05
2025-12-10 13:22:10 - INFO - Epoch: 29.42, Step: 116530, Train Loss: 1.1917, Learning Rate: 2.78e-05
2025-12-10 13:22:21 - INFO - Epoch: 29.42, Step: 116540, Train Loss: 1.1531, Learning Rate: 2.78e-05
2025-12-10 13:22:32 - INFO - Epoch: 29.42, Step: 116550, Train Loss: 1.1354, Learning Rate: 2.78e-05
2025-12-10 13:22:44 - INFO - Epoch: 29.43, Step: 116560, Train Loss: 1.1997, Learning Rate: 2.78e-05
2025-12-10 13:22:55 - INFO - Epoch: 29.43, Step: 116570, Train Loss: 1.2022, Learning Rate: 2.78e-05
2025-12-10 13:23:06 - INFO - Epoch: 29.43, Step: 116580, Train Loss: 1.1566, Learning Rate: 2.78e-05
2025-12-10 13:23:17 - INFO - Epoch: 29.43, Step: 116590, Train Loss: 1.1860, Learning Rate: 2.78e-05
2025-12-10 13:23:28 - INFO - Epoch: 29.44, Step: 116600, Train Loss: 1.2634, Learning Rate: 2.78e-05
2025-12-10 13:23:39 - INFO - Epoch: 29.44, Step: 116610, Train Loss: 1.1746, Learning Rate: 2.78e-05
2025-12-10 13:23:50 - INFO - Epoch: 29.44, Step: 116620, Train Loss: 1.1670, Learning Rate: 2.78e-05
2025-12-10 13:24:02 - INFO - Epoch: 29.44, Step: 116630, Train Loss: 1.1602, Learning Rate: 2.78e-05
2025-12-10 13:24:13 - INFO - Epoch: 29.45, Step: 116640, Train Loss: 1.1588, Learning Rate: 2.78e-05
2025-12-10 13:24:24 - INFO - Epoch: 29.45, Step: 116650, Train Loss: 1.1671, Learning Rate: 2.78e-05
2025-12-10 13:24:35 - INFO - Epoch: 29.45, Step: 116660, Train Loss: 1.1662, Learning Rate: 2.78e-05
2025-12-10 13:24:46 - INFO - Epoch: 29.45, Step: 116670, Train Loss: 1.1533, Learning Rate: 2.78e-05
2025-12-10 13:24:57 - INFO - Epoch: 29.46, Step: 116680, Train Loss: 1.1508, Learning Rate: 2.77e-05
2025-12-10 13:25:09 - INFO - Epoch: 29.46, Step: 116690, Train Loss: 1.1839, Learning Rate: 2.77e-05
2025-12-10 13:25:20 - INFO - Epoch: 29.46, Step: 116700, Train Loss: 1.1983, Learning Rate: 2.77e-05
2025-12-10 13:25:31 - INFO - Epoch: 29.46, Step: 116710, Train Loss: 1.1970, Learning Rate: 2.77e-05
2025-12-10 13:25:42 - INFO - Epoch: 29.47, Step: 116720, Train Loss: 1.1879, Learning Rate: 2.77e-05
2025-12-10 13:25:53 - INFO - Epoch: 29.47, Step: 116730, Train Loss: 1.1287, Learning Rate: 2.77e-05
2025-12-10 13:26:04 - INFO - Epoch: 29.47, Step: 116740, Train Loss: 1.1995, Learning Rate: 2.77e-05
2025-12-10 13:26:16 - INFO - Epoch: 29.47, Step: 116750, Train Loss: 1.1720, Learning Rate: 2.77e-05
2025-12-10 13:26:27 - INFO - Epoch: 29.48, Step: 116760, Train Loss: 1.2053, Learning Rate: 2.77e-05
2025-12-10 13:26:38 - INFO - Epoch: 29.48, Step: 116770, Train Loss: 1.1708, Learning Rate: 2.77e-05
2025-12-10 13:26:49 - INFO - Epoch: 29.48, Step: 116780, Train Loss: 1.1690, Learning Rate: 2.77e-05
2025-12-10 13:27:00 - INFO - Epoch: 29.48, Step: 116790, Train Loss: 1.1803, Learning Rate: 2.77e-05
2025-12-10 13:27:11 - INFO - Epoch: 29.49, Step: 116800, Train Loss: 1.1681, Learning Rate: 2.77e-05
2025-12-10 13:27:22 - INFO - Epoch: 29.49, Step: 116810, Train Loss: 1.1655, Learning Rate: 2.77e-05
2025-12-10 13:27:34 - INFO - Epoch: 29.49, Step: 116820, Train Loss: 1.1932, Learning Rate: 2.77e-05
2025-12-10 13:27:45 - INFO - Epoch: 29.50, Step: 116830, Train Loss: 1.1394, Learning Rate: 2.76e-05
2025-12-10 13:27:56 - INFO - Epoch: 29.50, Step: 116840, Train Loss: 1.1656, Learning Rate: 2.76e-05
2025-12-10 13:28:07 - INFO - Epoch: 29.50, Step: 116850, Train Loss: 1.1789, Learning Rate: 2.76e-05
2025-12-10 13:28:18 - INFO - Epoch: 29.50, Step: 116860, Train Loss: 1.1521, Learning Rate: 2.76e-05
2025-12-10 13:28:29 - INFO - Epoch: 29.51, Step: 116870, Train Loss: 1.1586, Learning Rate: 2.76e-05
2025-12-10 13:28:41 - INFO - Epoch: 29.51, Step: 116880, Train Loss: 1.2105, Learning Rate: 2.76e-05
2025-12-10 13:28:52 - INFO - Epoch: 29.51, Step: 116890, Train Loss: 1.1662, Learning Rate: 2.76e-05
2025-12-10 13:29:03 - INFO - Epoch: 29.51, Step: 116900, Train Loss: 1.1887, Learning Rate: 2.76e-05
2025-12-10 13:29:14 - INFO - Epoch: 29.52, Step: 116910, Train Loss: 1.1908, Learning Rate: 2.76e-05
2025-12-10 13:29:25 - INFO - Epoch: 29.52, Step: 116920, Train Loss: 1.1872, Learning Rate: 2.76e-05
2025-12-10 13:29:36 - INFO - Epoch: 29.52, Step: 116930, Train Loss: 1.1540, Learning Rate: 2.76e-05
2025-12-10 13:29:48 - INFO - Epoch: 29.52, Step: 116940, Train Loss: 1.1560, Learning Rate: 2.76e-05
2025-12-10 13:29:59 - INFO - Epoch: 29.53, Step: 116950, Train Loss: 1.1693, Learning Rate: 2.76e-05
2025-12-10 13:30:10 - INFO - Epoch: 29.53, Step: 116960, Train Loss: 1.1965, Learning Rate: 2.76e-05
2025-12-10 13:30:21 - INFO - Epoch: 29.53, Step: 116970, Train Loss: 1.1729, Learning Rate: 2.76e-05
2025-12-10 13:30:32 - INFO - Epoch: 29.53, Step: 116980, Train Loss: 1.1520, Learning Rate: 2.75e-05
2025-12-10 13:30:43 - INFO - Epoch: 29.54, Step: 116990, Train Loss: 1.1621, Learning Rate: 2.75e-05
2025-12-10 13:30:54 - INFO - Epoch: 29.54, Step: 117000, Train Loss: 1.1676, Learning Rate: 2.75e-05
2025-12-10 13:31:06 - INFO - Epoch: 29.54, Step: 117010, Train Loss: 1.1832, Learning Rate: 2.75e-05
2025-12-10 13:31:17 - INFO - Epoch: 29.54, Step: 117020, Train Loss: 1.1565, Learning Rate: 2.75e-05
2025-12-10 13:31:28 - INFO - Epoch: 29.55, Step: 117030, Train Loss: 1.1368, Learning Rate: 2.75e-05
2025-12-10 13:31:39 - INFO - Epoch: 29.55, Step: 117040, Train Loss: 1.1386, Learning Rate: 2.75e-05
2025-12-10 13:31:50 - INFO - Epoch: 29.55, Step: 117050, Train Loss: 1.1860, Learning Rate: 2.75e-05
2025-12-10 13:32:01 - INFO - Epoch: 29.55, Step: 117060, Train Loss: 1.1839, Learning Rate: 2.75e-05
2025-12-10 13:32:13 - INFO - Epoch: 29.56, Step: 117070, Train Loss: 1.1677, Learning Rate: 2.75e-05
2025-12-10 13:32:24 - INFO - Epoch: 29.56, Step: 117080, Train Loss: 1.1963, Learning Rate: 2.75e-05
2025-12-10 13:32:35 - INFO - Epoch: 29.56, Step: 117090, Train Loss: 1.1759, Learning Rate: 2.75e-05
2025-12-10 13:32:46 - INFO - Epoch: 29.56, Step: 117100, Train Loss: 1.1963, Learning Rate: 2.75e-05
2025-12-10 13:32:57 - INFO - Epoch: 29.57, Step: 117110, Train Loss: 1.1652, Learning Rate: 2.75e-05
2025-12-10 13:33:08 - INFO - Epoch: 29.57, Step: 117120, Train Loss: 1.1549, Learning Rate: 2.75e-05
2025-12-10 13:33:20 - INFO - Epoch: 29.57, Step: 117130, Train Loss: 1.1729, Learning Rate: 2.74e-05
2025-12-10 13:33:31 - INFO - Epoch: 29.57, Step: 117140, Train Loss: 1.1801, Learning Rate: 2.74e-05
2025-12-10 13:33:42 - INFO - Epoch: 29.58, Step: 117150, Train Loss: 1.1509, Learning Rate: 2.74e-05
2025-12-10 13:33:53 - INFO - Epoch: 29.58, Step: 117160, Train Loss: 1.1745, Learning Rate: 2.74e-05
2025-12-10 13:34:04 - INFO - Epoch: 29.58, Step: 117170, Train Loss: 1.1835, Learning Rate: 2.74e-05
2025-12-10 13:34:15 - INFO - Epoch: 29.58, Step: 117180, Train Loss: 1.1719, Learning Rate: 2.74e-05
2025-12-10 13:34:27 - INFO - Epoch: 29.59, Step: 117190, Train Loss: 1.1686, Learning Rate: 2.74e-05
2025-12-10 13:34:38 - INFO - Epoch: 29.59, Step: 117200, Train Loss: 1.1788, Learning Rate: 2.74e-05
2025-12-10 13:34:49 - INFO - Epoch: 29.59, Step: 117210, Train Loss: 1.1463, Learning Rate: 2.74e-05
2025-12-10 13:35:00 - INFO - Epoch: 29.59, Step: 117220, Train Loss: 1.1867, Learning Rate: 2.74e-05
2025-12-10 13:35:11 - INFO - Epoch: 29.60, Step: 117230, Train Loss: 1.1916, Learning Rate: 2.74e-05
2025-12-10 13:35:22 - INFO - Epoch: 29.60, Step: 117240, Train Loss: 1.2058, Learning Rate: 2.74e-05
2025-12-10 13:35:33 - INFO - Epoch: 29.60, Step: 117250, Train Loss: 1.1797, Learning Rate: 2.74e-05
2025-12-10 13:35:45 - INFO - Epoch: 29.60, Step: 117260, Train Loss: 1.1766, Learning Rate: 2.74e-05
2025-12-10 13:35:56 - INFO - Epoch: 29.61, Step: 117270, Train Loss: 1.1389, Learning Rate: 2.74e-05
2025-12-10 13:36:07 - INFO - Epoch: 29.61, Step: 117280, Train Loss: 1.1896, Learning Rate: 2.73e-05
2025-12-10 13:36:18 - INFO - Epoch: 29.61, Step: 117290, Train Loss: 1.1882, Learning Rate: 2.73e-05
2025-12-10 13:36:29 - INFO - Epoch: 29.61, Step: 117300, Train Loss: 1.1671, Learning Rate: 2.73e-05
2025-12-10 13:36:40 - INFO - Epoch: 29.62, Step: 117310, Train Loss: 1.1489, Learning Rate: 2.73e-05
2025-12-10 13:36:52 - INFO - Epoch: 29.62, Step: 117320, Train Loss: 1.1493, Learning Rate: 2.73e-05
2025-12-10 13:37:03 - INFO - Epoch: 29.62, Step: 117330, Train Loss: 1.1941, Learning Rate: 2.73e-05
2025-12-10 13:37:14 - INFO - Epoch: 29.62, Step: 117340, Train Loss: 1.1649, Learning Rate: 2.73e-05
2025-12-10 13:37:25 - INFO - Epoch: 29.63, Step: 117350, Train Loss: 1.1729, Learning Rate: 2.73e-05
2025-12-10 13:37:36 - INFO - Epoch: 29.63, Step: 117360, Train Loss: 1.1627, Learning Rate: 2.73e-05
2025-12-10 13:37:47 - INFO - Epoch: 29.63, Step: 117370, Train Loss: 1.1776, Learning Rate: 2.73e-05
2025-12-10 13:37:59 - INFO - Epoch: 29.63, Step: 117380, Train Loss: 1.1782, Learning Rate: 2.73e-05
2025-12-10 13:38:10 - INFO - Epoch: 29.64, Step: 117390, Train Loss: 1.1320, Learning Rate: 2.73e-05
2025-12-10 13:38:21 - INFO - Epoch: 29.64, Step: 117400, Train Loss: 1.1818, Learning Rate: 2.73e-05
2025-12-10 13:38:32 - INFO - Epoch: 29.64, Step: 117410, Train Loss: 1.1763, Learning Rate: 2.73e-05
2025-12-10 13:38:43 - INFO - Epoch: 29.64, Step: 117420, Train Loss: 1.2097, Learning Rate: 2.73e-05
2025-12-10 13:38:54 - INFO - Epoch: 29.65, Step: 117430, Train Loss: 1.1965, Learning Rate: 2.72e-05
2025-12-10 13:39:05 - INFO - Epoch: 29.65, Step: 117440, Train Loss: 1.1744, Learning Rate: 2.72e-05
2025-12-10 13:39:17 - INFO - Epoch: 29.65, Step: 117450, Train Loss: 1.1642, Learning Rate: 2.72e-05
2025-12-10 13:39:28 - INFO - Epoch: 29.65, Step: 117460, Train Loss: 1.1775, Learning Rate: 2.72e-05
2025-12-10 13:39:39 - INFO - Epoch: 29.66, Step: 117470, Train Loss: 1.2140, Learning Rate: 2.72e-05
2025-12-10 13:39:50 - INFO - Epoch: 29.66, Step: 117480, Train Loss: 1.1804, Learning Rate: 2.72e-05
2025-12-10 13:40:01 - INFO - Epoch: 29.66, Step: 117490, Train Loss: 1.1575, Learning Rate: 2.72e-05
2025-12-10 13:40:12 - INFO - Epoch: 29.66, Step: 117500, Train Loss: 1.1556, Learning Rate: 2.72e-05
2025-12-10 13:40:24 - INFO - Epoch: 29.67, Step: 117510, Train Loss: 1.1744, Learning Rate: 2.72e-05
2025-12-10 13:40:35 - INFO - Epoch: 29.67, Step: 117520, Train Loss: 1.1949, Learning Rate: 2.72e-05
2025-12-10 13:40:46 - INFO - Epoch: 29.67, Step: 117530, Train Loss: 1.1671, Learning Rate: 2.72e-05
2025-12-10 13:40:57 - INFO - Epoch: 29.67, Step: 117540, Train Loss: 1.1979, Learning Rate: 2.72e-05
2025-12-10 13:41:08 - INFO - Epoch: 29.68, Step: 117550, Train Loss: 1.1890, Learning Rate: 2.72e-05
2025-12-10 13:41:19 - INFO - Epoch: 29.68, Step: 117560, Train Loss: 1.1768, Learning Rate: 2.72e-05
2025-12-10 13:41:31 - INFO - Epoch: 29.68, Step: 117570, Train Loss: 1.1827, Learning Rate: 2.72e-05
2025-12-10 13:41:42 - INFO - Epoch: 29.68, Step: 117580, Train Loss: 1.1791, Learning Rate: 2.71e-05
2025-12-10 13:41:53 - INFO - Epoch: 29.69, Step: 117590, Train Loss: 1.1935, Learning Rate: 2.71e-05
2025-12-10 13:42:04 - INFO - Epoch: 29.69, Step: 117600, Train Loss: 1.1743, Learning Rate: 2.71e-05
2025-12-10 13:42:15 - INFO - Epoch: 29.69, Step: 117610, Train Loss: 1.1989, Learning Rate: 2.71e-05
2025-12-10 13:42:26 - INFO - Epoch: 29.69, Step: 117620, Train Loss: 1.1646, Learning Rate: 2.71e-05
2025-12-10 13:42:37 - INFO - Epoch: 29.70, Step: 117630, Train Loss: 1.1583, Learning Rate: 2.71e-05
2025-12-10 13:42:49 - INFO - Epoch: 29.70, Step: 117640, Train Loss: 1.1785, Learning Rate: 2.71e-05
2025-12-10 13:43:00 - INFO - Epoch: 29.70, Step: 117650, Train Loss: 1.1632, Learning Rate: 2.71e-05
2025-12-10 13:43:11 - INFO - Epoch: 29.70, Step: 117660, Train Loss: 1.1909, Learning Rate: 2.71e-05
2025-12-10 13:43:22 - INFO - Epoch: 29.71, Step: 117670, Train Loss: 1.1686, Learning Rate: 2.71e-05
2025-12-10 13:43:33 - INFO - Epoch: 29.71, Step: 117680, Train Loss: 1.2225, Learning Rate: 2.71e-05
2025-12-10 13:43:44 - INFO - Epoch: 29.71, Step: 117690, Train Loss: 1.1559, Learning Rate: 2.71e-05
2025-12-10 13:43:56 - INFO - Epoch: 29.71, Step: 117700, Train Loss: 1.1642, Learning Rate: 2.71e-05
2025-12-10 13:44:07 - INFO - Epoch: 29.72, Step: 117710, Train Loss: 1.2071, Learning Rate: 2.71e-05
2025-12-10 13:44:18 - INFO - Epoch: 29.72, Step: 117720, Train Loss: 1.2069, Learning Rate: 2.71e-05
2025-12-10 13:44:29 - INFO - Epoch: 29.72, Step: 117730, Train Loss: 1.1940, Learning Rate: 2.70e-05
2025-12-10 13:44:40 - INFO - Epoch: 29.72, Step: 117740, Train Loss: 1.1901, Learning Rate: 2.70e-05
2025-12-10 13:44:51 - INFO - Epoch: 29.73, Step: 117750, Train Loss: 1.1538, Learning Rate: 2.70e-05
2025-12-10 13:45:03 - INFO - Epoch: 29.73, Step: 117760, Train Loss: 1.2067, Learning Rate: 2.70e-05
2025-12-10 13:45:14 - INFO - Epoch: 29.73, Step: 117770, Train Loss: 1.1628, Learning Rate: 2.70e-05
2025-12-10 13:45:25 - INFO - Epoch: 29.73, Step: 117780, Train Loss: 1.1712, Learning Rate: 2.70e-05
2025-12-10 13:45:36 - INFO - Epoch: 29.74, Step: 117790, Train Loss: 1.1901, Learning Rate: 2.70e-05
2025-12-10 13:45:47 - INFO - Epoch: 29.74, Step: 117800, Train Loss: 1.1889, Learning Rate: 2.70e-05
2025-12-10 13:45:58 - INFO - Epoch: 29.74, Step: 117810, Train Loss: 1.1877, Learning Rate: 2.70e-05
2025-12-10 13:46:09 - INFO - Epoch: 29.75, Step: 117820, Train Loss: 1.1954, Learning Rate: 2.70e-05
2025-12-10 13:46:21 - INFO - Epoch: 29.75, Step: 117830, Train Loss: 1.1844, Learning Rate: 2.70e-05
2025-12-10 13:46:32 - INFO - Epoch: 29.75, Step: 117840, Train Loss: 1.1549, Learning Rate: 2.70e-05
2025-12-10 13:46:43 - INFO - Epoch: 29.75, Step: 117850, Train Loss: 1.1873, Learning Rate: 2.70e-05
2025-12-10 13:46:54 - INFO - Epoch: 29.76, Step: 117860, Train Loss: 1.1456, Learning Rate: 2.70e-05
2025-12-10 13:47:05 - INFO - Epoch: 29.76, Step: 117870, Train Loss: 1.1444, Learning Rate: 2.70e-05
2025-12-10 13:47:16 - INFO - Epoch: 29.76, Step: 117880, Train Loss: 1.1774, Learning Rate: 2.69e-05
2025-12-10 13:47:28 - INFO - Epoch: 29.76, Step: 117890, Train Loss: 1.1953, Learning Rate: 2.69e-05
2025-12-10 13:47:39 - INFO - Epoch: 29.77, Step: 117900, Train Loss: 1.1480, Learning Rate: 2.69e-05
2025-12-10 13:47:50 - INFO - Epoch: 29.77, Step: 117910, Train Loss: 1.1854, Learning Rate: 2.69e-05
2025-12-10 13:48:01 - INFO - Epoch: 29.77, Step: 117920, Train Loss: 1.1963, Learning Rate: 2.69e-05
2025-12-10 13:48:12 - INFO - Epoch: 29.77, Step: 117930, Train Loss: 1.1492, Learning Rate: 2.69e-05
2025-12-10 13:48:23 - INFO - Epoch: 29.78, Step: 117940, Train Loss: 1.1925, Learning Rate: 2.69e-05
2025-12-10 13:48:35 - INFO - Epoch: 29.78, Step: 117950, Train Loss: 1.1502, Learning Rate: 2.69e-05
2025-12-10 13:48:46 - INFO - Epoch: 29.78, Step: 117960, Train Loss: 1.1490, Learning Rate: 2.69e-05
2025-12-10 13:48:57 - INFO - Epoch: 29.78, Step: 117970, Train Loss: 1.1698, Learning Rate: 2.69e-05
2025-12-10 13:49:08 - INFO - Epoch: 29.79, Step: 117980, Train Loss: 1.2148, Learning Rate: 2.69e-05
2025-12-10 13:49:19 - INFO - Epoch: 29.79, Step: 117990, Train Loss: 1.1506, Learning Rate: 2.69e-05
2025-12-10 13:49:30 - INFO - Epoch: 29.79, Step: 118000, Train Loss: 1.1618, Learning Rate: 2.69e-05
2025-12-10 13:49:41 - INFO - Epoch: 29.79, Step: 118010, Train Loss: 1.1761, Learning Rate: 2.69e-05
2025-12-10 13:49:53 - INFO - Epoch: 29.80, Step: 118020, Train Loss: 1.1244, Learning Rate: 2.69e-05
2025-12-10 13:50:04 - INFO - Epoch: 29.80, Step: 118030, Train Loss: 1.1912, Learning Rate: 2.68e-05
2025-12-10 13:50:15 - INFO - Epoch: 29.80, Step: 118040, Train Loss: 1.1454, Learning Rate: 2.68e-05
2025-12-10 13:50:26 - INFO - Epoch: 29.80, Step: 118050, Train Loss: 1.1777, Learning Rate: 2.68e-05
2025-12-10 13:50:37 - INFO - Epoch: 29.81, Step: 118060, Train Loss: 1.1462, Learning Rate: 2.68e-05
2025-12-10 13:50:48 - INFO - Epoch: 29.81, Step: 118070, Train Loss: 1.1621, Learning Rate: 2.68e-05
2025-12-10 13:51:00 - INFO - Epoch: 29.81, Step: 118080, Train Loss: 1.1530, Learning Rate: 2.68e-05
2025-12-10 13:51:11 - INFO - Epoch: 29.81, Step: 118090, Train Loss: 1.1660, Learning Rate: 2.68e-05
2025-12-10 13:51:22 - INFO - Epoch: 29.82, Step: 118100, Train Loss: 1.1414, Learning Rate: 2.68e-05
2025-12-10 13:51:33 - INFO - Epoch: 29.82, Step: 118110, Train Loss: 1.1822, Learning Rate: 2.68e-05
2025-12-10 13:51:44 - INFO - Epoch: 29.82, Step: 118120, Train Loss: 1.1983, Learning Rate: 2.68e-05
2025-12-10 13:51:55 - INFO - Epoch: 29.82, Step: 118130, Train Loss: 1.1682, Learning Rate: 2.68e-05
2025-12-10 13:52:07 - INFO - Epoch: 29.83, Step: 118140, Train Loss: 1.1918, Learning Rate: 2.68e-05
2025-12-10 13:52:18 - INFO - Epoch: 29.83, Step: 118150, Train Loss: 1.1732, Learning Rate: 2.68e-05
2025-12-10 13:52:29 - INFO - Epoch: 29.83, Step: 118160, Train Loss: 1.1699, Learning Rate: 2.68e-05
2025-12-10 13:52:40 - INFO - Epoch: 29.83, Step: 118170, Train Loss: 1.2005, Learning Rate: 2.68e-05
2025-12-10 13:52:51 - INFO - Epoch: 29.84, Step: 118180, Train Loss: 1.1910, Learning Rate: 2.67e-05
2025-12-10 13:53:02 - INFO - Epoch: 29.84, Step: 118190, Train Loss: 1.1941, Learning Rate: 2.67e-05
2025-12-10 13:53:13 - INFO - Epoch: 29.84, Step: 118200, Train Loss: 1.1560, Learning Rate: 2.67e-05
2025-12-10 13:53:25 - INFO - Epoch: 29.84, Step: 118210, Train Loss: 1.1813, Learning Rate: 2.67e-05
2025-12-10 13:53:36 - INFO - Epoch: 29.85, Step: 118220, Train Loss: 1.1574, Learning Rate: 2.67e-05
2025-12-10 13:53:47 - INFO - Epoch: 29.85, Step: 118230, Train Loss: 1.1671, Learning Rate: 2.67e-05
2025-12-10 13:53:58 - INFO - Epoch: 29.85, Step: 118240, Train Loss: 1.1699, Learning Rate: 2.67e-05
2025-12-10 13:54:09 - INFO - Epoch: 29.85, Step: 118250, Train Loss: 1.1725, Learning Rate: 2.67e-05
2025-12-10 13:54:20 - INFO - Epoch: 29.86, Step: 118260, Train Loss: 1.1585, Learning Rate: 2.67e-05
2025-12-10 13:54:32 - INFO - Epoch: 29.86, Step: 118270, Train Loss: 1.1618, Learning Rate: 2.67e-05
2025-12-10 13:54:43 - INFO - Epoch: 29.86, Step: 118280, Train Loss: 1.1745, Learning Rate: 2.67e-05
2025-12-10 13:54:54 - INFO - Epoch: 29.86, Step: 118290, Train Loss: 1.1667, Learning Rate: 2.67e-05
2025-12-10 13:55:05 - INFO - Epoch: 29.87, Step: 118300, Train Loss: 1.1793, Learning Rate: 2.67e-05
2025-12-10 13:55:16 - INFO - Epoch: 29.87, Step: 118310, Train Loss: 1.1837, Learning Rate: 2.67e-05
2025-12-10 13:55:27 - INFO - Epoch: 29.87, Step: 118320, Train Loss: 1.1520, Learning Rate: 2.67e-05
2025-12-10 13:55:39 - INFO - Epoch: 29.87, Step: 118330, Train Loss: 1.1627, Learning Rate: 2.66e-05
2025-12-10 13:55:50 - INFO - Epoch: 29.88, Step: 118340, Train Loss: 1.1627, Learning Rate: 2.66e-05
2025-12-10 13:56:01 - INFO - Epoch: 29.88, Step: 118350, Train Loss: 1.1837, Learning Rate: 2.66e-05
2025-12-10 13:56:12 - INFO - Epoch: 29.88, Step: 118360, Train Loss: 1.1821, Learning Rate: 2.66e-05
2025-12-10 13:56:23 - INFO - Epoch: 29.88, Step: 118370, Train Loss: 1.1579, Learning Rate: 2.66e-05
2025-12-10 13:56:34 - INFO - Epoch: 29.89, Step: 118380, Train Loss: 1.1951, Learning Rate: 2.66e-05
2025-12-10 13:56:45 - INFO - Epoch: 29.89, Step: 118390, Train Loss: 1.1538, Learning Rate: 2.66e-05
2025-12-10 13:56:57 - INFO - Epoch: 29.89, Step: 118400, Train Loss: 1.1525, Learning Rate: 2.66e-05
2025-12-10 13:57:08 - INFO - Epoch: 29.89, Step: 118410, Train Loss: 1.1808, Learning Rate: 2.66e-05
2025-12-10 13:57:19 - INFO - Epoch: 29.90, Step: 118420, Train Loss: 1.2026, Learning Rate: 2.66e-05
2025-12-10 13:57:30 - INFO - Epoch: 29.90, Step: 118430, Train Loss: 1.1521, Learning Rate: 2.66e-05
2025-12-10 13:57:41 - INFO - Epoch: 29.90, Step: 118440, Train Loss: 1.1898, Learning Rate: 2.66e-05
2025-12-10 13:57:52 - INFO - Epoch: 29.90, Step: 118450, Train Loss: 1.1767, Learning Rate: 2.66e-05
2025-12-10 13:58:04 - INFO - Epoch: 29.91, Step: 118460, Train Loss: 1.1663, Learning Rate: 2.66e-05
2025-12-10 13:58:15 - INFO - Epoch: 29.91, Step: 118470, Train Loss: 1.1960, Learning Rate: 2.66e-05
2025-12-10 13:58:26 - INFO - Epoch: 29.91, Step: 118480, Train Loss: 1.1569, Learning Rate: 2.65e-05
2025-12-10 13:58:37 - INFO - Epoch: 29.91, Step: 118490, Train Loss: 1.1531, Learning Rate: 2.65e-05
2025-12-10 13:58:48 - INFO - Epoch: 29.92, Step: 118500, Train Loss: 1.1481, Learning Rate: 2.65e-05
2025-12-10 13:58:59 - INFO - Epoch: 29.92, Step: 118510, Train Loss: 1.1428, Learning Rate: 2.65e-05
2025-12-10 13:59:11 - INFO - Epoch: 29.92, Step: 118520, Train Loss: 1.1623, Learning Rate: 2.65e-05
2025-12-10 13:59:22 - INFO - Epoch: 29.92, Step: 118530, Train Loss: 1.1670, Learning Rate: 2.65e-05
2025-12-10 13:59:33 - INFO - Epoch: 29.93, Step: 118540, Train Loss: 1.1857, Learning Rate: 2.65e-05
2025-12-10 13:59:44 - INFO - Epoch: 29.93, Step: 118550, Train Loss: 1.1965, Learning Rate: 2.65e-05
2025-12-10 13:59:55 - INFO - Epoch: 29.93, Step: 118560, Train Loss: 1.1865, Learning Rate: 2.65e-05
2025-12-10 14:00:06 - INFO - Epoch: 29.93, Step: 118570, Train Loss: 1.1961, Learning Rate: 2.65e-05
2025-12-10 14:00:17 - INFO - Epoch: 29.94, Step: 118580, Train Loss: 1.1611, Learning Rate: 2.65e-05
2025-12-10 14:00:29 - INFO - Epoch: 29.94, Step: 118590, Train Loss: 1.2132, Learning Rate: 2.65e-05
2025-12-10 14:00:40 - INFO - Epoch: 29.94, Step: 118600, Train Loss: 1.1612, Learning Rate: 2.65e-05
2025-12-10 14:00:51 - INFO - Epoch: 29.94, Step: 118610, Train Loss: 1.1925, Learning Rate: 2.65e-05
2025-12-10 14:01:02 - INFO - Epoch: 29.95, Step: 118620, Train Loss: 1.1633, Learning Rate: 2.65e-05
2025-12-10 14:01:13 - INFO - Epoch: 29.95, Step: 118630, Train Loss: 1.1639, Learning Rate: 2.64e-05
2025-12-10 14:01:24 - INFO - Epoch: 29.95, Step: 118640, Train Loss: 1.1661, Learning Rate: 2.64e-05
2025-12-10 14:01:36 - INFO - Epoch: 29.95, Step: 118650, Train Loss: 1.2172, Learning Rate: 2.64e-05
2025-12-10 14:01:47 - INFO - Epoch: 29.96, Step: 118660, Train Loss: 1.1695, Learning Rate: 2.64e-05
2025-12-10 14:01:58 - INFO - Epoch: 29.96, Step: 118670, Train Loss: 1.1910, Learning Rate: 2.64e-05
2025-12-10 14:02:09 - INFO - Epoch: 29.96, Step: 118680, Train Loss: 1.2239, Learning Rate: 2.64e-05
2025-12-10 14:02:20 - INFO - Epoch: 29.96, Step: 118690, Train Loss: 1.1677, Learning Rate: 2.64e-05
2025-12-10 14:02:31 - INFO - Epoch: 29.97, Step: 118700, Train Loss: 1.1610, Learning Rate: 2.64e-05
2025-12-10 14:02:43 - INFO - Epoch: 29.97, Step: 118710, Train Loss: 1.1761, Learning Rate: 2.64e-05
2025-12-10 14:02:54 - INFO - Epoch: 29.97, Step: 118720, Train Loss: 1.1283, Learning Rate: 2.64e-05
2025-12-10 14:03:05 - INFO - Epoch: 29.97, Step: 118730, Train Loss: 1.1993, Learning Rate: 2.64e-05
2025-12-10 14:03:16 - INFO - Epoch: 29.98, Step: 118740, Train Loss: 1.1286, Learning Rate: 2.64e-05
2025-12-10 14:03:27 - INFO - Epoch: 29.98, Step: 118750, Train Loss: 1.1571, Learning Rate: 2.64e-05
2025-12-10 14:03:38 - INFO - Epoch: 29.98, Step: 118760, Train Loss: 1.1645, Learning Rate: 2.64e-05
2025-12-10 14:03:49 - INFO - Epoch: 29.98, Step: 118770, Train Loss: 1.1142, Learning Rate: 2.64e-05
2025-12-10 14:04:01 - INFO - Epoch: 29.99, Step: 118780, Train Loss: 1.1718, Learning Rate: 2.63e-05
2025-12-10 14:04:12 - INFO - Epoch: 29.99, Step: 118790, Train Loss: 1.1732, Learning Rate: 2.63e-05
2025-12-10 14:04:23 - INFO - Epoch: 29.99, Step: 118800, Train Loss: 1.1179, Learning Rate: 2.63e-05
2025-12-10 14:04:34 - INFO - Epoch: 29.99, Step: 118810, Train Loss: 1.1550, Learning Rate: 2.63e-05
2025-12-10 14:04:45 - INFO - Epoch: 30.00, Step: 118820, Train Loss: 1.1645, Learning Rate: 2.63e-05
2025-12-10 14:04:56 - INFO - Epoch: 30.00, Step: 118830, Train Loss: 1.2101, Learning Rate: 2.63e-05
2025-12-10 14:05:08 - INFO - Epoch: 30.00, Step: 118840, Train Loss: 1.1725, Learning Rate: 2.63e-05
2025-12-10 14:05:19 - INFO - Epoch: 30.01, Step: 118850, Train Loss: 1.1155, Learning Rate: 2.63e-05
2025-12-10 14:05:30 - INFO - Epoch: 30.01, Step: 118860, Train Loss: 1.1819, Learning Rate: 2.63e-05
2025-12-10 14:05:41 - INFO - Epoch: 30.01, Step: 118870, Train Loss: 1.1486, Learning Rate: 2.63e-05
2025-12-10 14:05:52 - INFO - Epoch: 30.01, Step: 118880, Train Loss: 1.2027, Learning Rate: 2.63e-05
2025-12-10 14:06:03 - INFO - Epoch: 30.02, Step: 118890, Train Loss: 1.1597, Learning Rate: 2.63e-05
2025-12-10 14:06:15 - INFO - Epoch: 30.02, Step: 118900, Train Loss: 1.1495, Learning Rate: 2.63e-05
2025-12-10 14:06:26 - INFO - Epoch: 30.02, Step: 118910, Train Loss: 1.1533, Learning Rate: 2.63e-05
2025-12-10 14:06:37 - INFO - Epoch: 30.02, Step: 118920, Train Loss: 1.1289, Learning Rate: 2.63e-05
2025-12-10 14:06:48 - INFO - Epoch: 30.03, Step: 118930, Train Loss: 1.1430, Learning Rate: 2.63e-05
2025-12-10 14:06:59 - INFO - Epoch: 30.03, Step: 118940, Train Loss: 1.1864, Learning Rate: 2.62e-05
2025-12-10 14:07:10 - INFO - Epoch: 30.03, Step: 118950, Train Loss: 1.1529, Learning Rate: 2.62e-05
2025-12-10 14:07:21 - INFO - Epoch: 30.03, Step: 118960, Train Loss: 1.1717, Learning Rate: 2.62e-05
2025-12-10 14:07:33 - INFO - Epoch: 30.04, Step: 118970, Train Loss: 1.1620, Learning Rate: 2.62e-05
2025-12-10 14:07:44 - INFO - Epoch: 30.04, Step: 118980, Train Loss: 1.1547, Learning Rate: 2.62e-05
2025-12-10 14:07:55 - INFO - Epoch: 30.04, Step: 118990, Train Loss: 1.1805, Learning Rate: 2.62e-05
2025-12-10 14:08:06 - INFO - Epoch: 30.04, Step: 119000, Train Loss: 1.1602, Learning Rate: 2.62e-05
2025-12-10 14:08:17 - INFO - Epoch: 30.05, Step: 119010, Train Loss: 1.1797, Learning Rate: 2.62e-05
2025-12-10 14:08:28 - INFO - Epoch: 30.05, Step: 119020, Train Loss: 1.1425, Learning Rate: 2.62e-05
2025-12-10 14:08:40 - INFO - Epoch: 30.05, Step: 119030, Train Loss: 1.1605, Learning Rate: 2.62e-05
2025-12-10 14:08:51 - INFO - Epoch: 30.05, Step: 119040, Train Loss: 1.1649, Learning Rate: 2.62e-05
2025-12-10 14:09:02 - INFO - Epoch: 30.06, Step: 119050, Train Loss: 1.1647, Learning Rate: 2.62e-05
2025-12-10 14:09:13 - INFO - Epoch: 30.06, Step: 119060, Train Loss: 1.1879, Learning Rate: 2.62e-05
2025-12-10 14:09:24 - INFO - Epoch: 30.06, Step: 119070, Train Loss: 1.1645, Learning Rate: 2.62e-05
2025-12-10 14:09:35 - INFO - Epoch: 30.06, Step: 119080, Train Loss: 1.1617, Learning Rate: 2.62e-05
2025-12-10 14:09:47 - INFO - Epoch: 30.07, Step: 119090, Train Loss: 1.1806, Learning Rate: 2.61e-05
2025-12-10 14:09:58 - INFO - Epoch: 30.07, Step: 119100, Train Loss: 1.1843, Learning Rate: 2.61e-05
2025-12-10 14:10:09 - INFO - Epoch: 30.07, Step: 119110, Train Loss: 1.1468, Learning Rate: 2.61e-05
2025-12-10 14:10:20 - INFO - Epoch: 30.07, Step: 119120, Train Loss: 1.1452, Learning Rate: 2.61e-05
2025-12-10 14:10:31 - INFO - Epoch: 30.08, Step: 119130, Train Loss: 1.2033, Learning Rate: 2.61e-05
2025-12-10 14:10:42 - INFO - Epoch: 30.08, Step: 119140, Train Loss: 1.2106, Learning Rate: 2.61e-05
2025-12-10 14:10:54 - INFO - Epoch: 30.08, Step: 119150, Train Loss: 1.1885, Learning Rate: 2.61e-05
2025-12-10 14:11:05 - INFO - Epoch: 30.08, Step: 119160, Train Loss: 1.1629, Learning Rate: 2.61e-05
2025-12-10 14:11:16 - INFO - Epoch: 30.09, Step: 119170, Train Loss: 1.1760, Learning Rate: 2.61e-05
2025-12-10 14:11:27 - INFO - Epoch: 30.09, Step: 119180, Train Loss: 1.1919, Learning Rate: 2.61e-05
2025-12-10 14:11:38 - INFO - Epoch: 30.09, Step: 119190, Train Loss: 1.1908, Learning Rate: 2.61e-05
2025-12-10 14:11:49 - INFO - Epoch: 30.09, Step: 119200, Train Loss: 1.1850, Learning Rate: 2.61e-05
2025-12-10 14:12:00 - INFO - Epoch: 30.10, Step: 119210, Train Loss: 1.1477, Learning Rate: 2.61e-05
2025-12-10 14:12:12 - INFO - Epoch: 30.10, Step: 119220, Train Loss: 1.1658, Learning Rate: 2.61e-05
2025-12-10 14:12:23 - INFO - Epoch: 30.10, Step: 119230, Train Loss: 1.1835, Learning Rate: 2.61e-05
2025-12-10 14:12:34 - INFO - Epoch: 30.10, Step: 119240, Train Loss: 1.1666, Learning Rate: 2.60e-05
2025-12-10 14:12:45 - INFO - Epoch: 30.11, Step: 119250, Train Loss: 1.1498, Learning Rate: 2.60e-05
2025-12-10 14:12:56 - INFO - Epoch: 30.11, Step: 119260, Train Loss: 1.1447, Learning Rate: 2.60e-05
2025-12-10 14:13:07 - INFO - Epoch: 30.11, Step: 119270, Train Loss: 1.1939, Learning Rate: 2.60e-05
2025-12-10 14:13:19 - INFO - Epoch: 30.11, Step: 119280, Train Loss: 1.1809, Learning Rate: 2.60e-05
2025-12-10 14:13:30 - INFO - Epoch: 30.12, Step: 119290, Train Loss: 1.1675, Learning Rate: 2.60e-05
2025-12-10 14:13:41 - INFO - Epoch: 30.12, Step: 119300, Train Loss: 1.1777, Learning Rate: 2.60e-05
2025-12-10 14:13:52 - INFO - Epoch: 30.12, Step: 119310, Train Loss: 1.1701, Learning Rate: 2.60e-05
2025-12-10 14:14:03 - INFO - Epoch: 30.12, Step: 119320, Train Loss: 1.1927, Learning Rate: 2.60e-05
2025-12-10 14:14:14 - INFO - Epoch: 30.13, Step: 119330, Train Loss: 1.1562, Learning Rate: 2.60e-05
2025-12-10 14:14:26 - INFO - Epoch: 30.13, Step: 119340, Train Loss: 1.1501, Learning Rate: 2.60e-05
2025-12-10 14:14:37 - INFO - Epoch: 30.13, Step: 119350, Train Loss: 1.1509, Learning Rate: 2.60e-05
2025-12-10 14:14:48 - INFO - Epoch: 30.13, Step: 119360, Train Loss: 1.1718, Learning Rate: 2.60e-05
2025-12-10 14:14:59 - INFO - Epoch: 30.14, Step: 119370, Train Loss: 1.1426, Learning Rate: 2.60e-05
2025-12-10 14:15:10 - INFO - Epoch: 30.14, Step: 119380, Train Loss: 1.1819, Learning Rate: 2.60e-05
2025-12-10 14:15:21 - INFO - Epoch: 30.14, Step: 119390, Train Loss: 1.1531, Learning Rate: 2.59e-05
2025-12-10 14:15:32 - INFO - Epoch: 30.14, Step: 119400, Train Loss: 1.1811, Learning Rate: 2.59e-05
2025-12-10 14:15:44 - INFO - Epoch: 30.15, Step: 119410, Train Loss: 1.1360, Learning Rate: 2.59e-05
2025-12-10 14:15:55 - INFO - Epoch: 30.15, Step: 119420, Train Loss: 1.2171, Learning Rate: 2.59e-05
2025-12-10 14:16:06 - INFO - Epoch: 30.15, Step: 119430, Train Loss: 1.2128, Learning Rate: 2.59e-05
2025-12-10 14:16:17 - INFO - Epoch: 30.15, Step: 119440, Train Loss: 1.1653, Learning Rate: 2.59e-05
2025-12-10 14:16:28 - INFO - Epoch: 30.16, Step: 119450, Train Loss: 1.1565, Learning Rate: 2.59e-05
2025-12-10 14:16:39 - INFO - Epoch: 30.16, Step: 119460, Train Loss: 1.1841, Learning Rate: 2.59e-05
2025-12-10 14:16:51 - INFO - Epoch: 30.16, Step: 119470, Train Loss: 1.1770, Learning Rate: 2.59e-05
2025-12-10 14:17:02 - INFO - Epoch: 30.16, Step: 119480, Train Loss: 1.1955, Learning Rate: 2.59e-05
2025-12-10 14:17:13 - INFO - Epoch: 30.17, Step: 119490, Train Loss: 1.1807, Learning Rate: 2.59e-05
2025-12-10 14:17:24 - INFO - Epoch: 30.17, Step: 119500, Train Loss: 1.1452, Learning Rate: 2.59e-05
2025-12-10 14:17:35 - INFO - Epoch: 30.17, Step: 119510, Train Loss: 1.1662, Learning Rate: 2.59e-05
2025-12-10 14:17:46 - INFO - Epoch: 30.17, Step: 119520, Train Loss: 1.1905, Learning Rate: 2.59e-05
2025-12-10 14:17:58 - INFO - Epoch: 30.18, Step: 119530, Train Loss: 1.1791, Learning Rate: 2.59e-05
2025-12-10 14:18:09 - INFO - Epoch: 30.18, Step: 119540, Train Loss: 1.1911, Learning Rate: 2.58e-05
2025-12-10 14:18:20 - INFO - Epoch: 30.18, Step: 119550, Train Loss: 1.1338, Learning Rate: 2.58e-05
2025-12-10 14:18:31 - INFO - Epoch: 30.18, Step: 119560, Train Loss: 1.1754, Learning Rate: 2.58e-05
2025-12-10 14:18:42 - INFO - Epoch: 30.19, Step: 119570, Train Loss: 1.1580, Learning Rate: 2.58e-05
2025-12-10 14:18:53 - INFO - Epoch: 30.19, Step: 119580, Train Loss: 1.1629, Learning Rate: 2.58e-05
2025-12-10 14:19:05 - INFO - Epoch: 30.19, Step: 119590, Train Loss: 1.1674, Learning Rate: 2.58e-05
2025-12-10 14:19:16 - INFO - Epoch: 30.19, Step: 119600, Train Loss: 1.1599, Learning Rate: 2.58e-05
2025-12-10 14:19:27 - INFO - Epoch: 30.20, Step: 119610, Train Loss: 1.1814, Learning Rate: 2.58e-05
2025-12-10 14:19:38 - INFO - Epoch: 30.20, Step: 119620, Train Loss: 1.2140, Learning Rate: 2.58e-05
2025-12-10 14:19:49 - INFO - Epoch: 30.20, Step: 119630, Train Loss: 1.1793, Learning Rate: 2.58e-05
2025-12-10 14:20:00 - INFO - Epoch: 30.20, Step: 119640, Train Loss: 1.1444, Learning Rate: 2.58e-05
2025-12-10 14:20:11 - INFO - Epoch: 30.21, Step: 119650, Train Loss: 1.1321, Learning Rate: 2.58e-05
2025-12-10 14:20:23 - INFO - Epoch: 30.21, Step: 119660, Train Loss: 1.1869, Learning Rate: 2.58e-05
2025-12-10 14:20:34 - INFO - Epoch: 30.21, Step: 119670, Train Loss: 1.1578, Learning Rate: 2.58e-05
2025-12-10 14:20:45 - INFO - Epoch: 30.21, Step: 119680, Train Loss: 1.1705, Learning Rate: 2.58e-05
2025-12-10 14:20:56 - INFO - Epoch: 30.22, Step: 119690, Train Loss: 1.1801, Learning Rate: 2.57e-05
2025-12-10 14:21:07 - INFO - Epoch: 30.22, Step: 119700, Train Loss: 1.2000, Learning Rate: 2.57e-05
2025-12-10 14:21:18 - INFO - Epoch: 30.22, Step: 119710, Train Loss: 1.1774, Learning Rate: 2.57e-05
2025-12-10 14:21:30 - INFO - Epoch: 30.22, Step: 119720, Train Loss: 1.1359, Learning Rate: 2.57e-05
2025-12-10 14:21:41 - INFO - Epoch: 30.23, Step: 119730, Train Loss: 1.1630, Learning Rate: 2.57e-05
2025-12-10 14:21:52 - INFO - Epoch: 30.23, Step: 119740, Train Loss: 1.1759, Learning Rate: 2.57e-05
2025-12-10 14:22:03 - INFO - Epoch: 30.23, Step: 119750, Train Loss: 1.1618, Learning Rate: 2.57e-05
2025-12-10 14:22:14 - INFO - Epoch: 30.23, Step: 119760, Train Loss: 1.1871, Learning Rate: 2.57e-05
2025-12-10 14:22:25 - INFO - Epoch: 30.24, Step: 119770, Train Loss: 1.1787, Learning Rate: 2.57e-05
2025-12-10 14:22:37 - INFO - Epoch: 30.24, Step: 119780, Train Loss: 1.1469, Learning Rate: 2.57e-05
2025-12-10 14:22:48 - INFO - Epoch: 30.24, Step: 119790, Train Loss: 1.1886, Learning Rate: 2.57e-05
2025-12-10 14:22:59 - INFO - Epoch: 30.24, Step: 119800, Train Loss: 1.1899, Learning Rate: 2.57e-05
2025-12-10 14:23:10 - INFO - Epoch: 30.25, Step: 119810, Train Loss: 1.1728, Learning Rate: 2.57e-05
2025-12-10 14:23:21 - INFO - Epoch: 30.25, Step: 119820, Train Loss: 1.1662, Learning Rate: 2.57e-05
2025-12-10 14:23:32 - INFO - Epoch: 30.25, Step: 119830, Train Loss: 1.1734, Learning Rate: 2.57e-05
2025-12-10 14:23:43 - INFO - Epoch: 30.25, Step: 119840, Train Loss: 1.1574, Learning Rate: 2.56e-05
2025-12-10 14:23:55 - INFO - Epoch: 30.26, Step: 119850, Train Loss: 1.1734, Learning Rate: 2.56e-05
2025-12-10 14:24:06 - INFO - Epoch: 30.26, Step: 119860, Train Loss: 1.1665, Learning Rate: 2.56e-05
2025-12-10 14:24:17 - INFO - Epoch: 30.26, Step: 119870, Train Loss: 1.1753, Learning Rate: 2.56e-05
2025-12-10 14:24:28 - INFO - Epoch: 30.27, Step: 119880, Train Loss: 1.1664, Learning Rate: 2.56e-05
2025-12-10 14:24:39 - INFO - Epoch: 30.27, Step: 119890, Train Loss: 1.1363, Learning Rate: 2.56e-05
2025-12-10 14:24:50 - INFO - Epoch: 30.27, Step: 119900, Train Loss: 1.1757, Learning Rate: 2.56e-05
2025-12-10 14:25:02 - INFO - Epoch: 30.27, Step: 119910, Train Loss: 1.1812, Learning Rate: 2.56e-05
2025-12-10 14:25:13 - INFO - Epoch: 30.28, Step: 119920, Train Loss: 1.2128, Learning Rate: 2.56e-05
2025-12-10 14:25:24 - INFO - Epoch: 30.28, Step: 119930, Train Loss: 1.1904, Learning Rate: 2.56e-05
2025-12-10 14:25:35 - INFO - Epoch: 30.28, Step: 119940, Train Loss: 1.1988, Learning Rate: 2.56e-05
2025-12-10 14:25:46 - INFO - Epoch: 30.28, Step: 119950, Train Loss: 1.1853, Learning Rate: 2.56e-05
2025-12-10 14:25:57 - INFO - Epoch: 30.29, Step: 119960, Train Loss: 1.2195, Learning Rate: 2.56e-05
2025-12-10 14:26:09 - INFO - Epoch: 30.29, Step: 119970, Train Loss: 1.1686, Learning Rate: 2.56e-05
2025-12-10 14:26:20 - INFO - Epoch: 30.29, Step: 119980, Train Loss: 1.1411, Learning Rate: 2.56e-05
2025-12-10 14:26:31 - INFO - Epoch: 30.29, Step: 119990, Train Loss: 1.1360, Learning Rate: 2.55e-05
2025-12-10 14:26:42 - INFO - Epoch: 30.30, Step: 120000, Train Loss: 1.1399, Learning Rate: 2.55e-05
2025-12-10 14:26:53 - INFO - Epoch: 30.30, Step: 120010, Train Loss: 1.1715, Learning Rate: 2.55e-05
2025-12-10 14:27:04 - INFO - Epoch: 30.30, Step: 120020, Train Loss: 1.1728, Learning Rate: 2.55e-05
2025-12-10 14:27:16 - INFO - Epoch: 30.30, Step: 120030, Train Loss: 1.1762, Learning Rate: 2.55e-05
2025-12-10 14:27:27 - INFO - Epoch: 30.31, Step: 120040, Train Loss: 1.1760, Learning Rate: 2.55e-05
2025-12-10 14:27:38 - INFO - Epoch: 30.31, Step: 120050, Train Loss: 1.1962, Learning Rate: 2.55e-05
2025-12-10 14:27:49 - INFO - Epoch: 30.31, Step: 120060, Train Loss: 1.1898, Learning Rate: 2.55e-05
2025-12-10 14:28:00 - INFO - Epoch: 30.31, Step: 120070, Train Loss: 1.1514, Learning Rate: 2.55e-05
2025-12-10 14:28:11 - INFO - Epoch: 30.32, Step: 120080, Train Loss: 1.1810, Learning Rate: 2.55e-05
2025-12-10 14:28:22 - INFO - Epoch: 30.32, Step: 120090, Train Loss: 1.1697, Learning Rate: 2.55e-05
2025-12-10 14:28:34 - INFO - Epoch: 30.32, Step: 120100, Train Loss: 1.1659, Learning Rate: 2.55e-05
2025-12-10 14:28:45 - INFO - Epoch: 30.32, Step: 120110, Train Loss: 1.2144, Learning Rate: 2.55e-05
2025-12-10 14:28:56 - INFO - Epoch: 30.33, Step: 120120, Train Loss: 1.2006, Learning Rate: 2.55e-05
2025-12-10 14:29:07 - INFO - Epoch: 30.33, Step: 120130, Train Loss: 1.1882, Learning Rate: 2.55e-05
2025-12-10 14:29:18 - INFO - Epoch: 30.33, Step: 120140, Train Loss: 1.1711, Learning Rate: 2.54e-05
2025-12-10 14:29:29 - INFO - Epoch: 30.33, Step: 120150, Train Loss: 1.1865, Learning Rate: 2.54e-05
2025-12-10 14:29:41 - INFO - Epoch: 30.34, Step: 120160, Train Loss: 1.1720, Learning Rate: 2.54e-05
2025-12-10 14:29:52 - INFO - Epoch: 30.34, Step: 120170, Train Loss: 1.1769, Learning Rate: 2.54e-05
2025-12-10 14:30:03 - INFO - Epoch: 30.34, Step: 120180, Train Loss: 1.1748, Learning Rate: 2.54e-05
2025-12-10 14:30:14 - INFO - Epoch: 30.34, Step: 120190, Train Loss: 1.1639, Learning Rate: 2.54e-05
2025-12-10 14:30:25 - INFO - Epoch: 30.35, Step: 120200, Train Loss: 1.1848, Learning Rate: 2.54e-05
2025-12-10 14:30:36 - INFO - Epoch: 30.35, Step: 120210, Train Loss: 1.2145, Learning Rate: 2.54e-05
2025-12-10 14:30:48 - INFO - Epoch: 30.35, Step: 120220, Train Loss: 1.1771, Learning Rate: 2.54e-05
2025-12-10 14:30:59 - INFO - Epoch: 30.35, Step: 120230, Train Loss: 1.1432, Learning Rate: 2.54e-05
2025-12-10 14:31:10 - INFO - Epoch: 30.36, Step: 120240, Train Loss: 1.2103, Learning Rate: 2.54e-05
2025-12-10 14:31:21 - INFO - Epoch: 30.36, Step: 120250, Train Loss: 1.1438, Learning Rate: 2.54e-05
2025-12-10 14:31:32 - INFO - Epoch: 30.36, Step: 120260, Train Loss: 1.1670, Learning Rate: 2.54e-05
2025-12-10 14:31:43 - INFO - Epoch: 30.36, Step: 120270, Train Loss: 1.1842, Learning Rate: 2.54e-05
2025-12-10 14:31:54 - INFO - Epoch: 30.37, Step: 120280, Train Loss: 1.1705, Learning Rate: 2.54e-05
2025-12-10 14:32:06 - INFO - Epoch: 30.37, Step: 120290, Train Loss: 1.1640, Learning Rate: 2.53e-05
2025-12-10 14:32:17 - INFO - Epoch: 30.37, Step: 120300, Train Loss: 1.1826, Learning Rate: 2.53e-05
2025-12-10 14:32:28 - INFO - Epoch: 30.37, Step: 120310, Train Loss: 1.1661, Learning Rate: 2.53e-05
2025-12-10 14:32:39 - INFO - Epoch: 30.38, Step: 120320, Train Loss: 1.1455, Learning Rate: 2.53e-05
2025-12-10 14:32:50 - INFO - Epoch: 30.38, Step: 120330, Train Loss: 1.1429, Learning Rate: 2.53e-05
2025-12-10 14:33:01 - INFO - Epoch: 30.38, Step: 120340, Train Loss: 1.1913, Learning Rate: 2.53e-05
2025-12-10 14:33:13 - INFO - Epoch: 30.38, Step: 120350, Train Loss: 1.1669, Learning Rate: 2.53e-05
2025-12-10 14:33:24 - INFO - Epoch: 30.39, Step: 120360, Train Loss: 1.1781, Learning Rate: 2.53e-05
2025-12-10 14:33:35 - INFO - Epoch: 30.39, Step: 120370, Train Loss: 1.1886, Learning Rate: 2.53e-05
2025-12-10 14:33:46 - INFO - Epoch: 30.39, Step: 120380, Train Loss: 1.1364, Learning Rate: 2.53e-05
2025-12-10 14:33:57 - INFO - Epoch: 30.39, Step: 120390, Train Loss: 1.1709, Learning Rate: 2.53e-05
2025-12-10 14:34:08 - INFO - Epoch: 30.40, Step: 120400, Train Loss: 1.2151, Learning Rate: 2.53e-05
2025-12-10 14:34:20 - INFO - Epoch: 30.40, Step: 120410, Train Loss: 1.1859, Learning Rate: 2.53e-05
2025-12-10 14:34:31 - INFO - Epoch: 30.40, Step: 120420, Train Loss: 1.1841, Learning Rate: 2.53e-05
2025-12-10 14:34:42 - INFO - Epoch: 30.40, Step: 120430, Train Loss: 1.1373, Learning Rate: 2.53e-05
2025-12-10 14:34:53 - INFO - Epoch: 30.41, Step: 120440, Train Loss: 1.1524, Learning Rate: 2.52e-05
2025-12-10 14:35:04 - INFO - Epoch: 30.41, Step: 120450, Train Loss: 1.1577, Learning Rate: 2.52e-05
2025-12-10 14:35:15 - INFO - Epoch: 30.41, Step: 120460, Train Loss: 1.1622, Learning Rate: 2.52e-05
2025-12-10 14:35:26 - INFO - Epoch: 30.41, Step: 120470, Train Loss: 1.1867, Learning Rate: 2.52e-05
2025-12-10 14:35:38 - INFO - Epoch: 30.42, Step: 120480, Train Loss: 1.1597, Learning Rate: 2.52e-05
2025-12-10 14:35:49 - INFO - Epoch: 30.42, Step: 120490, Train Loss: 1.1790, Learning Rate: 2.52e-05
2025-12-10 14:36:00 - INFO - Epoch: 30.42, Step: 120500, Train Loss: 1.1429, Learning Rate: 2.52e-05
2025-12-10 14:36:11 - INFO - Epoch: 30.42, Step: 120510, Train Loss: 1.1539, Learning Rate: 2.52e-05
2025-12-10 14:36:22 - INFO - Epoch: 30.43, Step: 120520, Train Loss: 1.1703, Learning Rate: 2.52e-05
2025-12-10 14:36:33 - INFO - Epoch: 30.43, Step: 120530, Train Loss: 1.1658, Learning Rate: 2.52e-05
2025-12-10 14:36:45 - INFO - Epoch: 30.43, Step: 120540, Train Loss: 1.2037, Learning Rate: 2.52e-05
2025-12-10 14:36:56 - INFO - Epoch: 30.43, Step: 120550, Train Loss: 1.1620, Learning Rate: 2.52e-05
2025-12-10 14:37:07 - INFO - Epoch: 30.44, Step: 120560, Train Loss: 1.1599, Learning Rate: 2.52e-05
2025-12-10 14:37:18 - INFO - Epoch: 30.44, Step: 120570, Train Loss: 1.1464, Learning Rate: 2.52e-05
2025-12-10 14:37:29 - INFO - Epoch: 30.44, Step: 120580, Train Loss: 1.1721, Learning Rate: 2.52e-05
2025-12-10 14:37:40 - INFO - Epoch: 30.44, Step: 120590, Train Loss: 1.1616, Learning Rate: 2.51e-05
2025-12-10 14:37:52 - INFO - Epoch: 30.45, Step: 120600, Train Loss: 1.1699, Learning Rate: 2.51e-05
2025-12-10 14:38:03 - INFO - Epoch: 30.45, Step: 120610, Train Loss: 1.2015, Learning Rate: 2.51e-05
2025-12-10 14:38:14 - INFO - Epoch: 30.45, Step: 120620, Train Loss: 1.1630, Learning Rate: 2.51e-05
2025-12-10 14:38:25 - INFO - Epoch: 30.45, Step: 120630, Train Loss: 1.1790, Learning Rate: 2.51e-05
2025-12-10 14:38:36 - INFO - Epoch: 30.46, Step: 120640, Train Loss: 1.1661, Learning Rate: 2.51e-05
2025-12-10 14:38:47 - INFO - Epoch: 30.46, Step: 120650, Train Loss: 1.2070, Learning Rate: 2.51e-05
2025-12-10 14:38:59 - INFO - Epoch: 30.46, Step: 120660, Train Loss: 1.1157, Learning Rate: 2.51e-05
2025-12-10 14:39:10 - INFO - Epoch: 30.46, Step: 120670, Train Loss: 1.2064, Learning Rate: 2.51e-05
2025-12-10 14:39:21 - INFO - Epoch: 30.47, Step: 120680, Train Loss: 1.1731, Learning Rate: 2.51e-05
2025-12-10 14:39:32 - INFO - Epoch: 30.47, Step: 120690, Train Loss: 1.1974, Learning Rate: 2.51e-05
2025-12-10 14:39:43 - INFO - Epoch: 30.47, Step: 120700, Train Loss: 1.1580, Learning Rate: 2.51e-05
2025-12-10 14:39:54 - INFO - Epoch: 30.47, Step: 120710, Train Loss: 1.1710, Learning Rate: 2.51e-05
2025-12-10 14:40:05 - INFO - Epoch: 30.48, Step: 120720, Train Loss: 1.1481, Learning Rate: 2.51e-05
2025-12-10 14:40:17 - INFO - Epoch: 30.48, Step: 120730, Train Loss: 1.1643, Learning Rate: 2.51e-05
2025-12-10 14:40:28 - INFO - Epoch: 30.48, Step: 120740, Train Loss: 1.1693, Learning Rate: 2.50e-05
2025-12-10 14:40:39 - INFO - Epoch: 30.48, Step: 120750, Train Loss: 1.2011, Learning Rate: 2.50e-05
2025-12-10 14:40:50 - INFO - Epoch: 30.49, Step: 120760, Train Loss: 1.1654, Learning Rate: 2.50e-05
2025-12-10 14:41:01 - INFO - Epoch: 30.49, Step: 120770, Train Loss: 1.1731, Learning Rate: 2.50e-05
2025-12-10 14:41:12 - INFO - Epoch: 30.49, Step: 120780, Train Loss: 1.1693, Learning Rate: 2.50e-05
2025-12-10 14:41:24 - INFO - Epoch: 30.49, Step: 120790, Train Loss: 1.1894, Learning Rate: 2.50e-05
2025-12-10 14:41:35 - INFO - Epoch: 30.50, Step: 120800, Train Loss: 1.1848, Learning Rate: 2.50e-05
2025-12-10 14:41:46 - INFO - Epoch: 30.50, Step: 120810, Train Loss: 1.1604, Learning Rate: 2.50e-05
2025-12-10 14:41:57 - INFO - Epoch: 30.50, Step: 120820, Train Loss: 1.1963, Learning Rate: 2.50e-05
2025-12-10 14:42:08 - INFO - Epoch: 30.50, Step: 120830, Train Loss: 1.1654, Learning Rate: 2.50e-05
2025-12-10 14:42:19 - INFO - Epoch: 30.51, Step: 120840, Train Loss: 1.1706, Learning Rate: 2.50e-05
2025-12-10 14:42:31 - INFO - Epoch: 30.51, Step: 120850, Train Loss: 1.2312, Learning Rate: 2.50e-05
2025-12-10 14:42:42 - INFO - Epoch: 30.51, Step: 120860, Train Loss: 1.1848, Learning Rate: 2.50e-05
2025-12-10 14:42:53 - INFO - Epoch: 30.52, Step: 120870, Train Loss: 1.1569, Learning Rate: 2.50e-05
2025-12-10 14:43:04 - INFO - Epoch: 30.52, Step: 120880, Train Loss: 1.2001, Learning Rate: 2.50e-05
2025-12-10 14:43:15 - INFO - Epoch: 30.52, Step: 120890, Train Loss: 1.1663, Learning Rate: 2.49e-05
2025-12-10 14:43:26 - INFO - Epoch: 30.52, Step: 120900, Train Loss: 1.1323, Learning Rate: 2.49e-05
2025-12-10 14:43:37 - INFO - Epoch: 30.53, Step: 120910, Train Loss: 1.1606, Learning Rate: 2.49e-05
2025-12-10 14:43:49 - INFO - Epoch: 30.53, Step: 120920, Train Loss: 1.1797, Learning Rate: 2.49e-05
2025-12-10 14:44:00 - INFO - Epoch: 30.53, Step: 120930, Train Loss: 1.1939, Learning Rate: 2.49e-05
2025-12-10 14:44:11 - INFO - Epoch: 30.53, Step: 120940, Train Loss: 1.1154, Learning Rate: 2.49e-05
2025-12-10 14:44:22 - INFO - Epoch: 30.54, Step: 120950, Train Loss: 1.1712, Learning Rate: 2.49e-05
2025-12-10 14:44:33 - INFO - Epoch: 30.54, Step: 120960, Train Loss: 1.1560, Learning Rate: 2.49e-05
2025-12-10 14:44:44 - INFO - Epoch: 30.54, Step: 120970, Train Loss: 1.1593, Learning Rate: 2.49e-05
2025-12-10 14:44:56 - INFO - Epoch: 30.54, Step: 120980, Train Loss: 1.1318, Learning Rate: 2.49e-05
2025-12-10 14:45:07 - INFO - Epoch: 30.55, Step: 120990, Train Loss: 1.1839, Learning Rate: 2.49e-05
2025-12-10 14:45:18 - INFO - Epoch: 30.55, Step: 121000, Train Loss: 1.1753, Learning Rate: 2.49e-05
2025-12-10 14:45:29 - INFO - Epoch: 30.55, Step: 121010, Train Loss: 1.2012, Learning Rate: 2.49e-05
2025-12-10 14:45:40 - INFO - Epoch: 30.55, Step: 121020, Train Loss: 1.1666, Learning Rate: 2.49e-05
2025-12-10 14:45:51 - INFO - Epoch: 30.56, Step: 121030, Train Loss: 1.1891, Learning Rate: 2.49e-05
2025-12-10 14:46:03 - INFO - Epoch: 30.56, Step: 121040, Train Loss: 1.1323, Learning Rate: 2.48e-05
2025-12-10 14:46:14 - INFO - Epoch: 30.56, Step: 121050, Train Loss: 1.1786, Learning Rate: 2.48e-05
2025-12-10 14:46:25 - INFO - Epoch: 30.56, Step: 121060, Train Loss: 1.1973, Learning Rate: 2.48e-05
2025-12-10 14:46:36 - INFO - Epoch: 30.57, Step: 121070, Train Loss: 1.1851, Learning Rate: 2.48e-05
2025-12-10 14:46:47 - INFO - Epoch: 30.57, Step: 121080, Train Loss: 1.1518, Learning Rate: 2.48e-05
2025-12-10 14:46:58 - INFO - Epoch: 30.57, Step: 121090, Train Loss: 1.1499, Learning Rate: 2.48e-05
2025-12-10 14:47:10 - INFO - Epoch: 30.57, Step: 121100, Train Loss: 1.1957, Learning Rate: 2.48e-05
2025-12-10 14:47:21 - INFO - Epoch: 30.58, Step: 121110, Train Loss: 1.1701, Learning Rate: 2.48e-05
2025-12-10 14:47:32 - INFO - Epoch: 30.58, Step: 121120, Train Loss: 1.1765, Learning Rate: 2.48e-05
2025-12-10 14:47:43 - INFO - Epoch: 30.58, Step: 121130, Train Loss: 1.1502, Learning Rate: 2.48e-05
2025-12-10 14:47:54 - INFO - Epoch: 30.58, Step: 121140, Train Loss: 1.1340, Learning Rate: 2.48e-05
2025-12-10 14:48:05 - INFO - Epoch: 30.59, Step: 121150, Train Loss: 1.1968, Learning Rate: 2.48e-05
2025-12-10 14:48:16 - INFO - Epoch: 30.59, Step: 121160, Train Loss: 1.1552, Learning Rate: 2.48e-05
2025-12-10 14:48:28 - INFO - Epoch: 30.59, Step: 121170, Train Loss: 1.1589, Learning Rate: 2.48e-05
2025-12-10 14:48:39 - INFO - Epoch: 30.59, Step: 121180, Train Loss: 1.1818, Learning Rate: 2.48e-05
2025-12-10 14:48:50 - INFO - Epoch: 30.60, Step: 121190, Train Loss: 1.1706, Learning Rate: 2.47e-05
2025-12-10 14:49:01 - INFO - Epoch: 30.60, Step: 121200, Train Loss: 1.1808, Learning Rate: 2.47e-05
2025-12-10 14:49:12 - INFO - Epoch: 30.60, Step: 121210, Train Loss: 1.2279, Learning Rate: 2.47e-05
2025-12-10 14:49:23 - INFO - Epoch: 30.60, Step: 121220, Train Loss: 1.1610, Learning Rate: 2.47e-05
2025-12-10 14:49:35 - INFO - Epoch: 30.61, Step: 121230, Train Loss: 1.1500, Learning Rate: 2.47e-05
2025-12-10 14:49:46 - INFO - Epoch: 30.61, Step: 121240, Train Loss: 1.1353, Learning Rate: 2.47e-05
2025-12-10 14:49:57 - INFO - Epoch: 30.61, Step: 121250, Train Loss: 1.1790, Learning Rate: 2.47e-05
2025-12-10 14:50:08 - INFO - Epoch: 30.61, Step: 121260, Train Loss: 1.1629, Learning Rate: 2.47e-05
2025-12-10 14:50:19 - INFO - Epoch: 30.62, Step: 121270, Train Loss: 1.1923, Learning Rate: 2.47e-05
2025-12-10 14:50:30 - INFO - Epoch: 30.62, Step: 121280, Train Loss: 1.2024, Learning Rate: 2.47e-05
2025-12-10 14:50:42 - INFO - Epoch: 30.62, Step: 121290, Train Loss: 1.1567, Learning Rate: 2.47e-05
2025-12-10 14:50:53 - INFO - Epoch: 30.62, Step: 121300, Train Loss: 1.1407, Learning Rate: 2.47e-05
2025-12-10 14:51:04 - INFO - Epoch: 30.63, Step: 121310, Train Loss: 1.1839, Learning Rate: 2.47e-05
2025-12-10 14:51:15 - INFO - Epoch: 30.63, Step: 121320, Train Loss: 1.1578, Learning Rate: 2.47e-05
2025-12-10 14:51:26 - INFO - Epoch: 30.63, Step: 121330, Train Loss: 1.1414, Learning Rate: 2.47e-05
2025-12-10 14:51:37 - INFO - Epoch: 30.63, Step: 121340, Train Loss: 1.2018, Learning Rate: 2.46e-05
2025-12-10 14:51:48 - INFO - Epoch: 30.64, Step: 121350, Train Loss: 1.1827, Learning Rate: 2.46e-05
2025-12-10 14:52:00 - INFO - Epoch: 30.64, Step: 121360, Train Loss: 1.1845, Learning Rate: 2.46e-05
2025-12-10 14:52:11 - INFO - Epoch: 30.64, Step: 121370, Train Loss: 1.1556, Learning Rate: 2.46e-05
2025-12-10 14:52:22 - INFO - Epoch: 30.64, Step: 121380, Train Loss: 1.1441, Learning Rate: 2.46e-05
2025-12-10 14:52:33 - INFO - Epoch: 30.65, Step: 121390, Train Loss: 1.1779, Learning Rate: 2.46e-05
2025-12-10 14:52:44 - INFO - Epoch: 30.65, Step: 121400, Train Loss: 1.1894, Learning Rate: 2.46e-05
2025-12-10 14:52:55 - INFO - Epoch: 30.65, Step: 121410, Train Loss: 1.1891, Learning Rate: 2.46e-05
2025-12-10 14:53:07 - INFO - Epoch: 30.65, Step: 121420, Train Loss: 1.1690, Learning Rate: 2.46e-05
2025-12-10 14:53:18 - INFO - Epoch: 30.66, Step: 121430, Train Loss: 1.1574, Learning Rate: 2.46e-05
2025-12-10 14:53:29 - INFO - Epoch: 30.66, Step: 121440, Train Loss: 1.1456, Learning Rate: 2.46e-05
2025-12-10 14:53:40 - INFO - Epoch: 30.66, Step: 121450, Train Loss: 1.1415, Learning Rate: 2.46e-05
2025-12-10 14:53:51 - INFO - Epoch: 30.66, Step: 121460, Train Loss: 1.1602, Learning Rate: 2.46e-05
2025-12-10 14:54:02 - INFO - Epoch: 30.67, Step: 121470, Train Loss: 1.1743, Learning Rate: 2.46e-05
2025-12-10 14:54:14 - INFO - Epoch: 30.67, Step: 121480, Train Loss: 1.1922, Learning Rate: 2.46e-05
2025-12-10 14:54:25 - INFO - Epoch: 30.67, Step: 121490, Train Loss: 1.1847, Learning Rate: 2.45e-05
2025-12-10 14:54:36 - INFO - Epoch: 30.67, Step: 121500, Train Loss: 1.1734, Learning Rate: 2.45e-05
2025-12-10 14:54:47 - INFO - Epoch: 30.68, Step: 121510, Train Loss: 1.1427, Learning Rate: 2.45e-05
2025-12-10 14:54:58 - INFO - Epoch: 30.68, Step: 121520, Train Loss: 1.1749, Learning Rate: 2.45e-05
2025-12-10 14:55:09 - INFO - Epoch: 30.68, Step: 121530, Train Loss: 1.1615, Learning Rate: 2.45e-05
2025-12-10 14:55:21 - INFO - Epoch: 30.68, Step: 121540, Train Loss: 1.1934, Learning Rate: 2.45e-05
2025-12-10 14:55:32 - INFO - Epoch: 30.69, Step: 121550, Train Loss: 1.1693, Learning Rate: 2.45e-05
2025-12-10 14:55:43 - INFO - Epoch: 30.69, Step: 121560, Train Loss: 1.1521, Learning Rate: 2.45e-05
2025-12-10 14:55:54 - INFO - Epoch: 30.69, Step: 121570, Train Loss: 1.1517, Learning Rate: 2.45e-05
2025-12-10 14:56:05 - INFO - Epoch: 30.69, Step: 121580, Train Loss: 1.1572, Learning Rate: 2.45e-05
2025-12-10 14:56:16 - INFO - Epoch: 30.70, Step: 121590, Train Loss: 1.1978, Learning Rate: 2.45e-05
2025-12-10 14:56:27 - INFO - Epoch: 30.70, Step: 121600, Train Loss: 1.2032, Learning Rate: 2.45e-05
2025-12-10 14:56:39 - INFO - Epoch: 30.70, Step: 121610, Train Loss: 1.1901, Learning Rate: 2.45e-05
2025-12-10 14:56:50 - INFO - Epoch: 30.70, Step: 121620, Train Loss: 1.1496, Learning Rate: 2.45e-05
2025-12-10 14:57:01 - INFO - Epoch: 30.71, Step: 121630, Train Loss: 1.1491, Learning Rate: 2.45e-05
2025-12-10 14:57:12 - INFO - Epoch: 30.71, Step: 121640, Train Loss: 1.1629, Learning Rate: 2.44e-05
2025-12-10 14:57:23 - INFO - Epoch: 30.71, Step: 121650, Train Loss: 1.1699, Learning Rate: 2.44e-05
2025-12-10 14:57:34 - INFO - Epoch: 30.71, Step: 121660, Train Loss: 1.1494, Learning Rate: 2.44e-05
2025-12-10 14:57:46 - INFO - Epoch: 30.72, Step: 121670, Train Loss: 1.1511, Learning Rate: 2.44e-05
2025-12-10 14:57:57 - INFO - Epoch: 30.72, Step: 121680, Train Loss: 1.1624, Learning Rate: 2.44e-05
2025-12-10 14:58:08 - INFO - Epoch: 30.72, Step: 121690, Train Loss: 1.1878, Learning Rate: 2.44e-05
2025-12-10 14:58:19 - INFO - Epoch: 30.72, Step: 121700, Train Loss: 1.1676, Learning Rate: 2.44e-05
2025-12-10 14:58:30 - INFO - Epoch: 30.73, Step: 121710, Train Loss: 1.1913, Learning Rate: 2.44e-05
2025-12-10 14:58:41 - INFO - Epoch: 30.73, Step: 121720, Train Loss: 1.1566, Learning Rate: 2.44e-05
2025-12-10 14:58:53 - INFO - Epoch: 30.73, Step: 121730, Train Loss: 1.1915, Learning Rate: 2.44e-05
2025-12-10 14:59:04 - INFO - Epoch: 30.73, Step: 121740, Train Loss: 1.1647, Learning Rate: 2.44e-05
2025-12-10 14:59:15 - INFO - Epoch: 30.74, Step: 121750, Train Loss: 1.1568, Learning Rate: 2.44e-05
2025-12-10 14:59:26 - INFO - Epoch: 30.74, Step: 121760, Train Loss: 1.1595, Learning Rate: 2.44e-05
2025-12-10 14:59:37 - INFO - Epoch: 30.74, Step: 121770, Train Loss: 1.1794, Learning Rate: 2.44e-05
2025-12-10 14:59:48 - INFO - Epoch: 30.74, Step: 121780, Train Loss: 1.1590, Learning Rate: 2.44e-05
2025-12-10 14:59:59 - INFO - Epoch: 30.75, Step: 121790, Train Loss: 1.1552, Learning Rate: 2.43e-05
2025-12-10 15:00:11 - INFO - Epoch: 30.75, Step: 121800, Train Loss: 1.1568, Learning Rate: 2.43e-05
2025-12-10 15:00:22 - INFO - Epoch: 30.75, Step: 121810, Train Loss: 1.1399, Learning Rate: 2.43e-05
2025-12-10 15:00:33 - INFO - Epoch: 30.75, Step: 121820, Train Loss: 1.1908, Learning Rate: 2.43e-05
2025-12-10 15:00:44 - INFO - Epoch: 30.76, Step: 121830, Train Loss: 1.1631, Learning Rate: 2.43e-05
2025-12-10 15:00:55 - INFO - Epoch: 30.76, Step: 121840, Train Loss: 1.1760, Learning Rate: 2.43e-05
2025-12-10 15:01:06 - INFO - Epoch: 30.76, Step: 121850, Train Loss: 1.1552, Learning Rate: 2.43e-05
2025-12-10 15:01:18 - INFO - Epoch: 30.76, Step: 121860, Train Loss: 1.2272, Learning Rate: 2.43e-05
2025-12-10 15:01:29 - INFO - Epoch: 30.77, Step: 121870, Train Loss: 1.1889, Learning Rate: 2.43e-05
2025-12-10 15:01:40 - INFO - Epoch: 30.77, Step: 121880, Train Loss: 1.2066, Learning Rate: 2.43e-05
2025-12-10 15:01:51 - INFO - Epoch: 30.77, Step: 121890, Train Loss: 1.1717, Learning Rate: 2.43e-05
2025-12-10 15:02:02 - INFO - Epoch: 30.78, Step: 121900, Train Loss: 1.1657, Learning Rate: 2.43e-05
2025-12-10 15:02:13 - INFO - Epoch: 30.78, Step: 121910, Train Loss: 1.1745, Learning Rate: 2.43e-05
2025-12-10 15:02:25 - INFO - Epoch: 30.78, Step: 121920, Train Loss: 1.1390, Learning Rate: 2.43e-05
2025-12-10 15:02:36 - INFO - Epoch: 30.78, Step: 121930, Train Loss: 1.1467, Learning Rate: 2.43e-05
2025-12-10 15:02:47 - INFO - Epoch: 30.79, Step: 121940, Train Loss: 1.1353, Learning Rate: 2.43e-05
2025-12-10 15:02:58 - INFO - Epoch: 30.79, Step: 121950, Train Loss: 1.1982, Learning Rate: 2.42e-05
2025-12-10 15:03:09 - INFO - Epoch: 30.79, Step: 121960, Train Loss: 1.1525, Learning Rate: 2.42e-05
2025-12-10 15:03:20 - INFO - Epoch: 30.79, Step: 121970, Train Loss: 1.1500, Learning Rate: 2.42e-05
2025-12-10 15:03:31 - INFO - Epoch: 30.80, Step: 121980, Train Loss: 1.1554, Learning Rate: 2.42e-05
2025-12-10 15:03:43 - INFO - Epoch: 30.80, Step: 121990, Train Loss: 1.1805, Learning Rate: 2.42e-05
2025-12-10 15:03:54 - INFO - Epoch: 30.80, Step: 122000, Train Loss: 1.1908, Learning Rate: 2.42e-05
2025-12-10 15:04:05 - INFO - Epoch: 30.80, Step: 122010, Train Loss: 1.1608, Learning Rate: 2.42e-05
2025-12-10 15:04:16 - INFO - Epoch: 30.81, Step: 122020, Train Loss: 1.1541, Learning Rate: 2.42e-05
2025-12-10 15:04:27 - INFO - Epoch: 30.81, Step: 122030, Train Loss: 1.1753, Learning Rate: 2.42e-05
2025-12-10 15:04:38 - INFO - Epoch: 30.81, Step: 122040, Train Loss: 1.1612, Learning Rate: 2.42e-05
2025-12-10 15:04:50 - INFO - Epoch: 30.81, Step: 122050, Train Loss: 1.1709, Learning Rate: 2.42e-05
2025-12-10 15:05:01 - INFO - Epoch: 30.82, Step: 122060, Train Loss: 1.1588, Learning Rate: 2.42e-05
2025-12-10 15:05:12 - INFO - Epoch: 30.82, Step: 122070, Train Loss: 1.1514, Learning Rate: 2.42e-05
2025-12-10 15:05:23 - INFO - Epoch: 30.82, Step: 122080, Train Loss: 1.2123, Learning Rate: 2.42e-05
2025-12-10 15:05:34 - INFO - Epoch: 30.82, Step: 122090, Train Loss: 1.1463, Learning Rate: 2.42e-05
2025-12-10 15:05:45 - INFO - Epoch: 30.83, Step: 122100, Train Loss: 1.1532, Learning Rate: 2.41e-05
2025-12-10 15:05:57 - INFO - Epoch: 30.83, Step: 122110, Train Loss: 1.1522, Learning Rate: 2.41e-05
2025-12-10 15:06:08 - INFO - Epoch: 30.83, Step: 122120, Train Loss: 1.1715, Learning Rate: 2.41e-05
2025-12-10 15:06:19 - INFO - Epoch: 30.83, Step: 122130, Train Loss: 1.1977, Learning Rate: 2.41e-05
2025-12-10 15:06:30 - INFO - Epoch: 30.84, Step: 122140, Train Loss: 1.1188, Learning Rate: 2.41e-05
2025-12-10 15:06:41 - INFO - Epoch: 30.84, Step: 122150, Train Loss: 1.1290, Learning Rate: 2.41e-05
2025-12-10 15:06:52 - INFO - Epoch: 30.84, Step: 122160, Train Loss: 1.1783, Learning Rate: 2.41e-05
2025-12-10 15:07:04 - INFO - Epoch: 30.84, Step: 122170, Train Loss: 1.1675, Learning Rate: 2.41e-05
2025-12-10 15:07:15 - INFO - Epoch: 30.85, Step: 122180, Train Loss: 1.1370, Learning Rate: 2.41e-05
2025-12-10 15:07:26 - INFO - Epoch: 30.85, Step: 122190, Train Loss: 1.2056, Learning Rate: 2.41e-05
2025-12-10 15:07:37 - INFO - Epoch: 30.85, Step: 122200, Train Loss: 1.1522, Learning Rate: 2.41e-05
2025-12-10 15:07:48 - INFO - Epoch: 30.85, Step: 122210, Train Loss: 1.1520, Learning Rate: 2.41e-05
2025-12-10 15:07:59 - INFO - Epoch: 30.86, Step: 122220, Train Loss: 1.1548, Learning Rate: 2.41e-05
2025-12-10 15:08:10 - INFO - Epoch: 30.86, Step: 122230, Train Loss: 1.1367, Learning Rate: 2.41e-05
2025-12-10 15:08:22 - INFO - Epoch: 30.86, Step: 122240, Train Loss: 1.2027, Learning Rate: 2.41e-05
2025-12-10 15:08:33 - INFO - Epoch: 30.86, Step: 122250, Train Loss: 1.1339, Learning Rate: 2.40e-05
2025-12-10 15:08:44 - INFO - Epoch: 30.87, Step: 122260, Train Loss: 1.1185, Learning Rate: 2.40e-05
2025-12-10 15:08:55 - INFO - Epoch: 30.87, Step: 122270, Train Loss: 1.1654, Learning Rate: 2.40e-05
2025-12-10 15:09:06 - INFO - Epoch: 30.87, Step: 122280, Train Loss: 1.1815, Learning Rate: 2.40e-05
2025-12-10 15:09:17 - INFO - Epoch: 30.87, Step: 122290, Train Loss: 1.1751, Learning Rate: 2.40e-05
2025-12-10 15:09:29 - INFO - Epoch: 30.88, Step: 122300, Train Loss: 1.1637, Learning Rate: 2.40e-05
2025-12-10 15:09:40 - INFO - Epoch: 30.88, Step: 122310, Train Loss: 1.1719, Learning Rate: 2.40e-05
2025-12-10 15:09:51 - INFO - Epoch: 30.88, Step: 122320, Train Loss: 1.1480, Learning Rate: 2.40e-05
2025-12-10 15:10:02 - INFO - Epoch: 30.88, Step: 122330, Train Loss: 1.1625, Learning Rate: 2.40e-05
2025-12-10 15:10:13 - INFO - Epoch: 30.89, Step: 122340, Train Loss: 1.1921, Learning Rate: 2.40e-05
2025-12-10 15:10:24 - INFO - Epoch: 30.89, Step: 122350, Train Loss: 1.1491, Learning Rate: 2.40e-05
2025-12-10 15:10:36 - INFO - Epoch: 30.89, Step: 122360, Train Loss: 1.1631, Learning Rate: 2.40e-05
2025-12-10 15:10:47 - INFO - Epoch: 30.89, Step: 122370, Train Loss: 1.1778, Learning Rate: 2.40e-05
2025-12-10 15:10:58 - INFO - Epoch: 30.90, Step: 122380, Train Loss: 1.1616, Learning Rate: 2.40e-05
2025-12-10 15:11:09 - INFO - Epoch: 30.90, Step: 122390, Train Loss: 1.1437, Learning Rate: 2.40e-05
2025-12-10 15:11:20 - INFO - Epoch: 30.90, Step: 122400, Train Loss: 1.1761, Learning Rate: 2.39e-05
2025-12-10 15:11:31 - INFO - Epoch: 30.90, Step: 122410, Train Loss: 1.1583, Learning Rate: 2.39e-05
2025-12-10 15:11:42 - INFO - Epoch: 30.91, Step: 122420, Train Loss: 1.1521, Learning Rate: 2.39e-05
2025-12-10 15:11:54 - INFO - Epoch: 30.91, Step: 122430, Train Loss: 1.1609, Learning Rate: 2.39e-05
2025-12-10 15:12:05 - INFO - Epoch: 30.91, Step: 122440, Train Loss: 1.1664, Learning Rate: 2.39e-05
2025-12-10 15:12:16 - INFO - Epoch: 30.91, Step: 122450, Train Loss: 1.1452, Learning Rate: 2.39e-05
2025-12-10 15:12:27 - INFO - Epoch: 30.92, Step: 122460, Train Loss: 1.1715, Learning Rate: 2.39e-05
2025-12-10 15:12:38 - INFO - Epoch: 30.92, Step: 122470, Train Loss: 1.1590, Learning Rate: 2.39e-05
2025-12-10 15:12:49 - INFO - Epoch: 30.92, Step: 122480, Train Loss: 1.1822, Learning Rate: 2.39e-05
2025-12-10 15:13:01 - INFO - Epoch: 30.92, Step: 122490, Train Loss: 1.1524, Learning Rate: 2.39e-05
2025-12-10 15:13:12 - INFO - Epoch: 30.93, Step: 122500, Train Loss: 1.1950, Learning Rate: 2.39e-05
2025-12-10 15:13:23 - INFO - Epoch: 30.93, Step: 122510, Train Loss: 1.2067, Learning Rate: 2.39e-05
2025-12-10 15:13:34 - INFO - Epoch: 30.93, Step: 122520, Train Loss: 1.1637, Learning Rate: 2.39e-05
2025-12-10 15:13:45 - INFO - Epoch: 30.93, Step: 122530, Train Loss: 1.1937, Learning Rate: 2.39e-05
2025-12-10 15:13:56 - INFO - Epoch: 30.94, Step: 122540, Train Loss: 1.1676, Learning Rate: 2.39e-05
2025-12-10 15:14:08 - INFO - Epoch: 30.94, Step: 122550, Train Loss: 1.1461, Learning Rate: 2.38e-05
2025-12-10 15:14:19 - INFO - Epoch: 30.94, Step: 122560, Train Loss: 1.1654, Learning Rate: 2.38e-05
2025-12-10 15:14:30 - INFO - Epoch: 30.94, Step: 122570, Train Loss: 1.1963, Learning Rate: 2.38e-05
2025-12-10 15:14:41 - INFO - Epoch: 30.95, Step: 122580, Train Loss: 1.1698, Learning Rate: 2.38e-05
2025-12-10 15:14:52 - INFO - Epoch: 30.95, Step: 122590, Train Loss: 1.1622, Learning Rate: 2.38e-05
2025-12-10 15:15:03 - INFO - Epoch: 30.95, Step: 122600, Train Loss: 1.1967, Learning Rate: 2.38e-05
2025-12-10 15:15:15 - INFO - Epoch: 30.95, Step: 122610, Train Loss: 1.1844, Learning Rate: 2.38e-05
2025-12-10 15:15:26 - INFO - Epoch: 30.96, Step: 122620, Train Loss: 1.1606, Learning Rate: 2.38e-05
2025-12-10 15:15:37 - INFO - Epoch: 30.96, Step: 122630, Train Loss: 1.1445, Learning Rate: 2.38e-05
2025-12-10 15:15:48 - INFO - Epoch: 30.96, Step: 122640, Train Loss: 1.1871, Learning Rate: 2.38e-05
2025-12-10 15:15:59 - INFO - Epoch: 30.96, Step: 122650, Train Loss: 1.1768, Learning Rate: 2.38e-05
2025-12-10 15:16:10 - INFO - Epoch: 30.97, Step: 122660, Train Loss: 1.1366, Learning Rate: 2.38e-05
2025-12-10 15:16:21 - INFO - Epoch: 30.97, Step: 122670, Train Loss: 1.1310, Learning Rate: 2.38e-05
2025-12-10 15:16:33 - INFO - Epoch: 30.97, Step: 122680, Train Loss: 1.1573, Learning Rate: 2.38e-05
2025-12-10 15:16:44 - INFO - Epoch: 30.97, Step: 122690, Train Loss: 1.1808, Learning Rate: 2.38e-05
2025-12-10 15:16:55 - INFO - Epoch: 30.98, Step: 122700, Train Loss: 1.1619, Learning Rate: 2.37e-05
2025-12-10 15:17:06 - INFO - Epoch: 30.98, Step: 122710, Train Loss: 1.1240, Learning Rate: 2.37e-05
2025-12-10 15:17:17 - INFO - Epoch: 30.98, Step: 122720, Train Loss: 1.1623, Learning Rate: 2.37e-05
2025-12-10 15:17:28 - INFO - Epoch: 30.98, Step: 122730, Train Loss: 1.1667, Learning Rate: 2.37e-05
2025-12-10 15:17:40 - INFO - Epoch: 30.99, Step: 122740, Train Loss: 1.1885, Learning Rate: 2.37e-05
2025-12-10 15:17:51 - INFO - Epoch: 30.99, Step: 122750, Train Loss: 1.1223, Learning Rate: 2.37e-05
2025-12-10 15:18:02 - INFO - Epoch: 30.99, Step: 122760, Train Loss: 1.1633, Learning Rate: 2.37e-05
2025-12-10 15:18:13 - INFO - Epoch: 30.99, Step: 122770, Train Loss: 1.1132, Learning Rate: 2.37e-05
2025-12-10 15:18:24 - INFO - Epoch: 31.00, Step: 122780, Train Loss: 1.1566, Learning Rate: 2.37e-05
2025-12-10 15:18:35 - INFO - Epoch: 31.00, Step: 122790, Train Loss: 1.1593, Learning Rate: 2.37e-05
2025-12-10 15:18:47 - INFO - Epoch: 31.00, Step: 122800, Train Loss: 1.1555, Learning Rate: 2.37e-05
2025-12-10 15:18:58 - INFO - Epoch: 31.00, Step: 122810, Train Loss: 1.1653, Learning Rate: 2.37e-05
2025-12-10 15:19:09 - INFO - Epoch: 31.01, Step: 122820, Train Loss: 1.1803, Learning Rate: 2.37e-05
2025-12-10 15:19:20 - INFO - Epoch: 31.01, Step: 122830, Train Loss: 1.1959, Learning Rate: 2.37e-05
2025-12-10 15:19:31 - INFO - Epoch: 31.01, Step: 122840, Train Loss: 1.1479, Learning Rate: 2.37e-05
2025-12-10 15:19:42 - INFO - Epoch: 31.01, Step: 122850, Train Loss: 1.1647, Learning Rate: 2.36e-05
2025-12-10 15:19:53 - INFO - Epoch: 31.02, Step: 122860, Train Loss: 1.1673, Learning Rate: 2.36e-05
2025-12-10 15:20:05 - INFO - Epoch: 31.02, Step: 122870, Train Loss: 1.1264, Learning Rate: 2.36e-05
2025-12-10 15:20:16 - INFO - Epoch: 31.02, Step: 122880, Train Loss: 1.1271, Learning Rate: 2.36e-05
2025-12-10 15:20:27 - INFO - Epoch: 31.02, Step: 122890, Train Loss: 1.1350, Learning Rate: 2.36e-05
2025-12-10 15:20:38 - INFO - Epoch: 31.03, Step: 122900, Train Loss: 1.1378, Learning Rate: 2.36e-05
2025-12-10 15:20:49 - INFO - Epoch: 31.03, Step: 122910, Train Loss: 1.1342, Learning Rate: 2.36e-05
2025-12-10 15:21:00 - INFO - Epoch: 31.03, Step: 122920, Train Loss: 1.1579, Learning Rate: 2.36e-05
2025-12-10 15:21:12 - INFO - Epoch: 31.04, Step: 122930, Train Loss: 1.1555, Learning Rate: 2.36e-05
2025-12-10 15:21:23 - INFO - Epoch: 31.04, Step: 122940, Train Loss: 1.1750, Learning Rate: 2.36e-05
2025-12-10 15:21:34 - INFO - Epoch: 31.04, Step: 122950, Train Loss: 1.1415, Learning Rate: 2.36e-05
2025-12-10 15:21:45 - INFO - Epoch: 31.04, Step: 122960, Train Loss: 1.1519, Learning Rate: 2.36e-05
2025-12-10 15:21:56 - INFO - Epoch: 31.05, Step: 122970, Train Loss: 1.1672, Learning Rate: 2.36e-05
2025-12-10 15:22:07 - INFO - Epoch: 31.05, Step: 122980, Train Loss: 1.1348, Learning Rate: 2.36e-05
2025-12-10 15:22:19 - INFO - Epoch: 31.05, Step: 122990, Train Loss: 1.1906, Learning Rate: 2.36e-05
2025-12-10 15:22:30 - INFO - Epoch: 31.05, Step: 123000, Train Loss: 1.1534, Learning Rate: 2.35e-05
2025-12-10 15:22:41 - INFO - Epoch: 31.06, Step: 123010, Train Loss: 1.1436, Learning Rate: 2.35e-05
2025-12-10 15:22:52 - INFO - Epoch: 31.06, Step: 123020, Train Loss: 1.1385, Learning Rate: 2.35e-05
2025-12-10 15:23:03 - INFO - Epoch: 31.06, Step: 123030, Train Loss: 1.1569, Learning Rate: 2.35e-05
2025-12-10 15:23:14 - INFO - Epoch: 31.06, Step: 123040, Train Loss: 1.1767, Learning Rate: 2.35e-05
2025-12-10 15:23:26 - INFO - Epoch: 31.07, Step: 123050, Train Loss: 1.1272, Learning Rate: 2.35e-05
2025-12-10 15:23:37 - INFO - Epoch: 31.07, Step: 123060, Train Loss: 1.1511, Learning Rate: 2.35e-05
2025-12-10 15:23:48 - INFO - Epoch: 31.07, Step: 123070, Train Loss: 1.2015, Learning Rate: 2.35e-05
2025-12-10 15:23:59 - INFO - Epoch: 31.07, Step: 123080, Train Loss: 1.1365, Learning Rate: 2.35e-05
2025-12-10 15:24:10 - INFO - Epoch: 31.08, Step: 123090, Train Loss: 1.1733, Learning Rate: 2.35e-05
2025-12-10 15:24:21 - INFO - Epoch: 31.08, Step: 123100, Train Loss: 1.1398, Learning Rate: 2.35e-05
2025-12-10 15:24:32 - INFO - Epoch: 31.08, Step: 123110, Train Loss: 1.1623, Learning Rate: 2.35e-05
2025-12-10 15:24:44 - INFO - Epoch: 31.08, Step: 123120, Train Loss: 1.1377, Learning Rate: 2.35e-05
2025-12-10 15:24:55 - INFO - Epoch: 31.09, Step: 123130, Train Loss: 1.1594, Learning Rate: 2.35e-05
2025-12-10 15:25:06 - INFO - Epoch: 31.09, Step: 123140, Train Loss: 1.1864, Learning Rate: 2.35e-05
2025-12-10 15:25:17 - INFO - Epoch: 31.09, Step: 123150, Train Loss: 1.1354, Learning Rate: 2.34e-05
2025-12-10 15:25:28 - INFO - Epoch: 31.09, Step: 123160, Train Loss: 1.1547, Learning Rate: 2.34e-05
2025-12-10 15:25:39 - INFO - Epoch: 31.10, Step: 123170, Train Loss: 1.1727, Learning Rate: 2.34e-05
2025-12-10 15:25:51 - INFO - Epoch: 31.10, Step: 123180, Train Loss: 1.2276, Learning Rate: 2.34e-05
2025-12-10 15:26:02 - INFO - Epoch: 31.10, Step: 123190, Train Loss: 1.1559, Learning Rate: 2.34e-05
2025-12-10 15:26:13 - INFO - Epoch: 31.10, Step: 123200, Train Loss: 1.1852, Learning Rate: 2.34e-05
2025-12-10 15:26:24 - INFO - Epoch: 31.11, Step: 123210, Train Loss: 1.1795, Learning Rate: 2.34e-05
2025-12-10 15:26:35 - INFO - Epoch: 31.11, Step: 123220, Train Loss: 1.2066, Learning Rate: 2.34e-05
2025-12-10 15:26:46 - INFO - Epoch: 31.11, Step: 123230, Train Loss: 1.1811, Learning Rate: 2.34e-05
2025-12-10 15:26:58 - INFO - Epoch: 31.11, Step: 123240, Train Loss: 1.1650, Learning Rate: 2.34e-05
2025-12-10 15:27:09 - INFO - Epoch: 31.12, Step: 123250, Train Loss: 1.1531, Learning Rate: 2.34e-05
2025-12-10 15:27:20 - INFO - Epoch: 31.12, Step: 123260, Train Loss: 1.1943, Learning Rate: 2.34e-05
2025-12-10 15:27:31 - INFO - Epoch: 31.12, Step: 123270, Train Loss: 1.1814, Learning Rate: 2.34e-05
2025-12-10 15:27:42 - INFO - Epoch: 31.12, Step: 123280, Train Loss: 1.1713, Learning Rate: 2.34e-05
2025-12-10 15:27:53 - INFO - Epoch: 31.13, Step: 123290, Train Loss: 1.1432, Learning Rate: 2.34e-05
2025-12-10 15:28:04 - INFO - Epoch: 31.13, Step: 123300, Train Loss: 1.1815, Learning Rate: 2.33e-05
2025-12-10 15:28:16 - INFO - Epoch: 31.13, Step: 123310, Train Loss: 1.1857, Learning Rate: 2.33e-05
2025-12-10 15:28:27 - INFO - Epoch: 31.13, Step: 123320, Train Loss: 1.1546, Learning Rate: 2.33e-05
2025-12-10 15:28:38 - INFO - Epoch: 31.14, Step: 123330, Train Loss: 1.1660, Learning Rate: 2.33e-05
2025-12-10 15:28:49 - INFO - Epoch: 31.14, Step: 123340, Train Loss: 1.1652, Learning Rate: 2.33e-05
2025-12-10 15:29:00 - INFO - Epoch: 31.14, Step: 123350, Train Loss: 1.1793, Learning Rate: 2.33e-05
2025-12-10 15:29:11 - INFO - Epoch: 31.14, Step: 123360, Train Loss: 1.1512, Learning Rate: 2.33e-05
2025-12-10 15:29:23 - INFO - Epoch: 31.15, Step: 123370, Train Loss: 1.1642, Learning Rate: 2.33e-05
2025-12-10 15:29:34 - INFO - Epoch: 31.15, Step: 123380, Train Loss: 1.1390, Learning Rate: 2.33e-05
2025-12-10 15:29:45 - INFO - Epoch: 31.15, Step: 123390, Train Loss: 1.1689, Learning Rate: 2.33e-05
2025-12-10 15:29:56 - INFO - Epoch: 31.15, Step: 123400, Train Loss: 1.1588, Learning Rate: 2.33e-05
2025-12-10 15:30:07 - INFO - Epoch: 31.16, Step: 123410, Train Loss: 1.1854, Learning Rate: 2.33e-05
2025-12-10 15:30:18 - INFO - Epoch: 31.16, Step: 123420, Train Loss: 1.2050, Learning Rate: 2.33e-05
2025-12-10 15:30:30 - INFO - Epoch: 31.16, Step: 123430, Train Loss: 1.2148, Learning Rate: 2.33e-05
2025-12-10 15:30:41 - INFO - Epoch: 31.16, Step: 123440, Train Loss: 1.1669, Learning Rate: 2.33e-05
2025-12-10 15:30:52 - INFO - Epoch: 31.17, Step: 123450, Train Loss: 1.1632, Learning Rate: 2.32e-05
2025-12-10 15:31:03 - INFO - Epoch: 31.17, Step: 123460, Train Loss: 1.1784, Learning Rate: 2.32e-05
2025-12-10 15:31:14 - INFO - Epoch: 31.17, Step: 123470, Train Loss: 1.1614, Learning Rate: 2.32e-05
2025-12-10 15:31:25 - INFO - Epoch: 31.17, Step: 123480, Train Loss: 1.1764, Learning Rate: 2.32e-05
2025-12-10 15:31:37 - INFO - Epoch: 31.18, Step: 123490, Train Loss: 1.1581, Learning Rate: 2.32e-05
2025-12-10 15:31:48 - INFO - Epoch: 31.18, Step: 123500, Train Loss: 1.1290, Learning Rate: 2.32e-05
2025-12-10 15:31:59 - INFO - Epoch: 31.18, Step: 123510, Train Loss: 1.1559, Learning Rate: 2.32e-05
2025-12-10 15:32:10 - INFO - Epoch: 31.18, Step: 123520, Train Loss: 1.1802, Learning Rate: 2.32e-05
2025-12-10 15:32:21 - INFO - Epoch: 31.19, Step: 123530, Train Loss: 1.1475, Learning Rate: 2.32e-05
2025-12-10 15:32:32 - INFO - Epoch: 31.19, Step: 123540, Train Loss: 1.1591, Learning Rate: 2.32e-05
2025-12-10 15:32:43 - INFO - Epoch: 31.19, Step: 123550, Train Loss: 1.1694, Learning Rate: 2.32e-05
2025-12-10 15:32:55 - INFO - Epoch: 31.19, Step: 123560, Train Loss: 1.1408, Learning Rate: 2.32e-05
2025-12-10 15:33:06 - INFO - Epoch: 31.20, Step: 123570, Train Loss: 1.1698, Learning Rate: 2.32e-05
2025-12-10 15:33:17 - INFO - Epoch: 31.20, Step: 123580, Train Loss: 1.1885, Learning Rate: 2.32e-05
2025-12-10 15:33:28 - INFO - Epoch: 31.20, Step: 123590, Train Loss: 1.1689, Learning Rate: 2.32e-05
2025-12-10 15:33:39 - INFO - Epoch: 31.20, Step: 123600, Train Loss: 1.1875, Learning Rate: 2.31e-05
2025-12-10 15:33:50 - INFO - Epoch: 31.21, Step: 123610, Train Loss: 1.1685, Learning Rate: 2.31e-05
2025-12-10 15:34:02 - INFO - Epoch: 31.21, Step: 123620, Train Loss: 1.2012, Learning Rate: 2.31e-05
2025-12-10 15:34:13 - INFO - Epoch: 31.21, Step: 123630, Train Loss: 1.2023, Learning Rate: 2.31e-05
2025-12-10 15:34:24 - INFO - Epoch: 31.21, Step: 123640, Train Loss: 1.2012, Learning Rate: 2.31e-05
2025-12-10 15:34:35 - INFO - Epoch: 31.22, Step: 123650, Train Loss: 1.1495, Learning Rate: 2.31e-05
2025-12-10 15:34:46 - INFO - Epoch: 31.22, Step: 123660, Train Loss: 1.1766, Learning Rate: 2.31e-05
2025-12-10 15:34:57 - INFO - Epoch: 31.22, Step: 123670, Train Loss: 1.1809, Learning Rate: 2.31e-05
2025-12-10 15:35:09 - INFO - Epoch: 31.22, Step: 123680, Train Loss: 1.1242, Learning Rate: 2.31e-05
2025-12-10 15:35:20 - INFO - Epoch: 31.23, Step: 123690, Train Loss: 1.1222, Learning Rate: 2.31e-05
2025-12-10 15:35:31 - INFO - Epoch: 31.23, Step: 123700, Train Loss: 1.1660, Learning Rate: 2.31e-05
2025-12-10 15:35:42 - INFO - Epoch: 31.23, Step: 123710, Train Loss: 1.2002, Learning Rate: 2.31e-05
2025-12-10 15:35:53 - INFO - Epoch: 31.23, Step: 123720, Train Loss: 1.1691, Learning Rate: 2.31e-05
2025-12-10 15:36:04 - INFO - Epoch: 31.24, Step: 123730, Train Loss: 1.1597, Learning Rate: 2.31e-05
2025-12-10 15:36:15 - INFO - Epoch: 31.24, Step: 123740, Train Loss: 1.1721, Learning Rate: 2.31e-05
2025-12-10 15:36:27 - INFO - Epoch: 31.24, Step: 123750, Train Loss: 1.1701, Learning Rate: 2.30e-05
2025-12-10 15:36:38 - INFO - Epoch: 31.24, Step: 123760, Train Loss: 1.1419, Learning Rate: 2.30e-05
2025-12-10 15:36:49 - INFO - Epoch: 31.25, Step: 123770, Train Loss: 1.1618, Learning Rate: 2.30e-05
2025-12-10 15:37:00 - INFO - Epoch: 31.25, Step: 123780, Train Loss: 1.1769, Learning Rate: 2.30e-05
2025-12-10 15:37:11 - INFO - Epoch: 31.25, Step: 123790, Train Loss: 1.1747, Learning Rate: 2.30e-05
2025-12-10 15:37:22 - INFO - Epoch: 31.25, Step: 123800, Train Loss: 1.1278, Learning Rate: 2.30e-05
2025-12-10 15:37:34 - INFO - Epoch: 31.26, Step: 123810, Train Loss: 1.1787, Learning Rate: 2.30e-05
2025-12-10 15:37:45 - INFO - Epoch: 31.26, Step: 123820, Train Loss: 1.1661, Learning Rate: 2.30e-05
2025-12-10 15:37:56 - INFO - Epoch: 31.26, Step: 123830, Train Loss: 1.1639, Learning Rate: 2.30e-05
2025-12-10 15:38:07 - INFO - Epoch: 31.26, Step: 123840, Train Loss: 1.1943, Learning Rate: 2.30e-05
2025-12-10 15:38:18 - INFO - Epoch: 31.27, Step: 123850, Train Loss: 1.1330, Learning Rate: 2.30e-05
2025-12-10 15:38:29 - INFO - Epoch: 31.27, Step: 123860, Train Loss: 1.1683, Learning Rate: 2.30e-05
2025-12-10 15:38:41 - INFO - Epoch: 31.27, Step: 123870, Train Loss: 1.2071, Learning Rate: 2.30e-05
2025-12-10 15:38:52 - INFO - Epoch: 31.27, Step: 123880, Train Loss: 1.1346, Learning Rate: 2.30e-05
2025-12-10 15:39:03 - INFO - Epoch: 31.28, Step: 123890, Train Loss: 1.1441, Learning Rate: 2.30e-05
2025-12-10 15:39:14 - INFO - Epoch: 31.28, Step: 123900, Train Loss: 1.1448, Learning Rate: 2.29e-05
2025-12-10 15:39:25 - INFO - Epoch: 31.28, Step: 123910, Train Loss: 1.1570, Learning Rate: 2.29e-05
2025-12-10 15:39:36 - INFO - Epoch: 31.29, Step: 123920, Train Loss: 1.1931, Learning Rate: 2.29e-05
2025-12-10 15:39:47 - INFO - Epoch: 31.29, Step: 123930, Train Loss: 1.1892, Learning Rate: 2.29e-05
2025-12-10 15:39:59 - INFO - Epoch: 31.29, Step: 123940, Train Loss: 1.1778, Learning Rate: 2.29e-05
2025-12-10 15:40:10 - INFO - Epoch: 31.29, Step: 123950, Train Loss: 1.1818, Learning Rate: 2.29e-05
2025-12-10 15:40:21 - INFO - Epoch: 31.30, Step: 123960, Train Loss: 1.1270, Learning Rate: 2.29e-05
2025-12-10 15:40:32 - INFO - Epoch: 31.30, Step: 123970, Train Loss: 1.1999, Learning Rate: 2.29e-05
2025-12-10 15:40:43 - INFO - Epoch: 31.30, Step: 123980, Train Loss: 1.1468, Learning Rate: 2.29e-05
2025-12-10 15:40:54 - INFO - Epoch: 31.30, Step: 123990, Train Loss: 1.1987, Learning Rate: 2.29e-05
2025-12-10 15:41:06 - INFO - Epoch: 31.31, Step: 124000, Train Loss: 1.1750, Learning Rate: 2.29e-05
2025-12-10 15:41:17 - INFO - Epoch: 31.31, Step: 124010, Train Loss: 1.1751, Learning Rate: 2.29e-05
2025-12-10 15:41:28 - INFO - Epoch: 31.31, Step: 124020, Train Loss: 1.1281, Learning Rate: 2.29e-05
2025-12-10 15:41:39 - INFO - Epoch: 31.31, Step: 124030, Train Loss: 1.1831, Learning Rate: 2.29e-05
2025-12-10 15:41:50 - INFO - Epoch: 31.32, Step: 124040, Train Loss: 1.1588, Learning Rate: 2.29e-05
2025-12-10 15:42:01 - INFO - Epoch: 31.32, Step: 124050, Train Loss: 1.1706, Learning Rate: 2.28e-05
2025-12-10 15:42:13 - INFO - Epoch: 31.32, Step: 124060, Train Loss: 1.1555, Learning Rate: 2.28e-05
2025-12-10 15:42:24 - INFO - Epoch: 31.32, Step: 124070, Train Loss: 1.1810, Learning Rate: 2.28e-05
2025-12-10 15:42:35 - INFO - Epoch: 31.33, Step: 124080, Train Loss: 1.1528, Learning Rate: 2.28e-05
2025-12-10 15:42:46 - INFO - Epoch: 31.33, Step: 124090, Train Loss: 1.1698, Learning Rate: 2.28e-05
2025-12-10 15:42:57 - INFO - Epoch: 31.33, Step: 124100, Train Loss: 1.1623, Learning Rate: 2.28e-05
2025-12-10 15:43:08 - INFO - Epoch: 31.33, Step: 124110, Train Loss: 1.1528, Learning Rate: 2.28e-05
2025-12-10 15:43:20 - INFO - Epoch: 31.34, Step: 124120, Train Loss: 1.1494, Learning Rate: 2.28e-05
2025-12-10 15:43:31 - INFO - Epoch: 31.34, Step: 124130, Train Loss: 1.1620, Learning Rate: 2.28e-05
2025-12-10 15:43:42 - INFO - Epoch: 31.34, Step: 124140, Train Loss: 1.1611, Learning Rate: 2.28e-05
2025-12-10 15:43:53 - INFO - Epoch: 31.34, Step: 124150, Train Loss: 1.1440, Learning Rate: 2.28e-05
2025-12-10 15:44:04 - INFO - Epoch: 31.35, Step: 124160, Train Loss: 1.1311, Learning Rate: 2.28e-05
2025-12-10 15:44:15 - INFO - Epoch: 31.35, Step: 124170, Train Loss: 1.1702, Learning Rate: 2.28e-05
2025-12-10 15:44:26 - INFO - Epoch: 31.35, Step: 124180, Train Loss: 1.1859, Learning Rate: 2.28e-05
2025-12-10 15:44:38 - INFO - Epoch: 31.35, Step: 124190, Train Loss: 1.1749, Learning Rate: 2.28e-05
2025-12-10 15:44:49 - INFO - Epoch: 31.36, Step: 124200, Train Loss: 1.1381, Learning Rate: 2.27e-05
2025-12-10 15:45:00 - INFO - Epoch: 31.36, Step: 124210, Train Loss: 1.1003, Learning Rate: 2.27e-05
2025-12-10 15:45:11 - INFO - Epoch: 31.36, Step: 124220, Train Loss: 1.1791, Learning Rate: 2.27e-05
2025-12-10 15:45:22 - INFO - Epoch: 31.36, Step: 124230, Train Loss: 1.1391, Learning Rate: 2.27e-05
2025-12-10 15:45:33 - INFO - Epoch: 31.37, Step: 124240, Train Loss: 1.1658, Learning Rate: 2.27e-05
2025-12-10 15:45:45 - INFO - Epoch: 31.37, Step: 124250, Train Loss: 1.1481, Learning Rate: 2.27e-05
2025-12-10 15:45:56 - INFO - Epoch: 31.37, Step: 124260, Train Loss: 1.1490, Learning Rate: 2.27e-05
2025-12-10 15:46:07 - INFO - Epoch: 31.37, Step: 124270, Train Loss: 1.1744, Learning Rate: 2.27e-05
2025-12-10 15:46:18 - INFO - Epoch: 31.38, Step: 124280, Train Loss: 1.1305, Learning Rate: 2.27e-05
2025-12-10 15:46:29 - INFO - Epoch: 31.38, Step: 124290, Train Loss: 1.1230, Learning Rate: 2.27e-05
2025-12-10 15:46:40 - INFO - Epoch: 31.38, Step: 124300, Train Loss: 1.1839, Learning Rate: 2.27e-05
2025-12-10 15:46:52 - INFO - Epoch: 31.38, Step: 124310, Train Loss: 1.1763, Learning Rate: 2.27e-05
2025-12-10 15:47:03 - INFO - Epoch: 31.39, Step: 124320, Train Loss: 1.1634, Learning Rate: 2.27e-05
2025-12-10 15:47:14 - INFO - Epoch: 31.39, Step: 124330, Train Loss: 1.1756, Learning Rate: 2.27e-05
2025-12-10 15:47:25 - INFO - Epoch: 31.39, Step: 124340, Train Loss: 1.1739, Learning Rate: 2.27e-05
2025-12-10 15:47:36 - INFO - Epoch: 31.39, Step: 124350, Train Loss: 1.1953, Learning Rate: 2.26e-05
2025-12-10 15:47:47 - INFO - Epoch: 31.40, Step: 124360, Train Loss: 1.1390, Learning Rate: 2.26e-05
2025-12-10 15:47:58 - INFO - Epoch: 31.40, Step: 124370, Train Loss: 1.1644, Learning Rate: 2.26e-05
2025-12-10 15:48:10 - INFO - Epoch: 31.40, Step: 124380, Train Loss: 1.1437, Learning Rate: 2.26e-05
2025-12-10 15:48:21 - INFO - Epoch: 31.40, Step: 124390, Train Loss: 1.1810, Learning Rate: 2.26e-05
2025-12-10 15:48:32 - INFO - Epoch: 31.41, Step: 124400, Train Loss: 1.2083, Learning Rate: 2.26e-05
2025-12-10 15:48:43 - INFO - Epoch: 31.41, Step: 124410, Train Loss: 1.1888, Learning Rate: 2.26e-05
2025-12-10 15:48:54 - INFO - Epoch: 31.41, Step: 124420, Train Loss: 1.1931, Learning Rate: 2.26e-05
2025-12-10 15:49:05 - INFO - Epoch: 31.41, Step: 124430, Train Loss: 1.1619, Learning Rate: 2.26e-05
2025-12-10 15:49:17 - INFO - Epoch: 31.42, Step: 124440, Train Loss: 1.1559, Learning Rate: 2.26e-05
2025-12-10 15:49:28 - INFO - Epoch: 31.42, Step: 124450, Train Loss: 1.1666, Learning Rate: 2.26e-05
2025-12-10 15:49:39 - INFO - Epoch: 31.42, Step: 124460, Train Loss: 1.2427, Learning Rate: 2.26e-05
2025-12-10 15:49:50 - INFO - Epoch: 31.42, Step: 124470, Train Loss: 1.1834, Learning Rate: 2.26e-05
2025-12-10 15:50:01 - INFO - Epoch: 31.43, Step: 124480, Train Loss: 1.1212, Learning Rate: 2.26e-05
2025-12-10 15:50:12 - INFO - Epoch: 31.43, Step: 124490, Train Loss: 1.1593, Learning Rate: 2.26e-05
2025-12-10 15:50:24 - INFO - Epoch: 31.43, Step: 124500, Train Loss: 1.1947, Learning Rate: 2.25e-05
2025-12-10 15:50:35 - INFO - Epoch: 31.43, Step: 124510, Train Loss: 1.1189, Learning Rate: 2.25e-05
2025-12-10 15:50:46 - INFO - Epoch: 31.44, Step: 124520, Train Loss: 1.1617, Learning Rate: 2.25e-05
2025-12-10 15:50:57 - INFO - Epoch: 31.44, Step: 124530, Train Loss: 1.1882, Learning Rate: 2.25e-05
2025-12-10 15:51:08 - INFO - Epoch: 31.44, Step: 124540, Train Loss: 1.1641, Learning Rate: 2.25e-05
2025-12-10 15:51:19 - INFO - Epoch: 31.44, Step: 124550, Train Loss: 1.1687, Learning Rate: 2.25e-05
2025-12-10 15:51:31 - INFO - Epoch: 31.45, Step: 124560, Train Loss: 1.1575, Learning Rate: 2.25e-05
2025-12-10 15:51:42 - INFO - Epoch: 31.45, Step: 124570, Train Loss: 1.1527, Learning Rate: 2.25e-05
2025-12-10 15:51:53 - INFO - Epoch: 31.45, Step: 124580, Train Loss: 1.1590, Learning Rate: 2.25e-05
2025-12-10 15:52:04 - INFO - Epoch: 31.45, Step: 124590, Train Loss: 1.1744, Learning Rate: 2.25e-05
2025-12-10 15:52:15 - INFO - Epoch: 31.46, Step: 124600, Train Loss: 1.1850, Learning Rate: 2.25e-05
2025-12-10 15:52:26 - INFO - Epoch: 31.46, Step: 124610, Train Loss: 1.1459, Learning Rate: 2.25e-05
2025-12-10 15:52:37 - INFO - Epoch: 31.46, Step: 124620, Train Loss: 1.1416, Learning Rate: 2.25e-05
2025-12-10 15:52:49 - INFO - Epoch: 31.46, Step: 124630, Train Loss: 1.1441, Learning Rate: 2.25e-05
2025-12-10 15:53:00 - INFO - Epoch: 31.47, Step: 124640, Train Loss: 1.1713, Learning Rate: 2.25e-05
2025-12-10 15:53:11 - INFO - Epoch: 31.47, Step: 124650, Train Loss: 1.2042, Learning Rate: 2.24e-05
2025-12-10 15:53:22 - INFO - Epoch: 31.47, Step: 124660, Train Loss: 1.1706, Learning Rate: 2.24e-05
2025-12-10 15:53:33 - INFO - Epoch: 31.47, Step: 124670, Train Loss: 1.1529, Learning Rate: 2.24e-05
2025-12-10 15:53:44 - INFO - Epoch: 31.48, Step: 124680, Train Loss: 1.1216, Learning Rate: 2.24e-05
2025-12-10 15:53:56 - INFO - Epoch: 31.48, Step: 124690, Train Loss: 1.1643, Learning Rate: 2.24e-05
2025-12-10 15:54:07 - INFO - Epoch: 31.48, Step: 124700, Train Loss: 1.1454, Learning Rate: 2.24e-05
2025-12-10 15:54:18 - INFO - Epoch: 31.48, Step: 124710, Train Loss: 1.1742, Learning Rate: 2.24e-05
2025-12-10 15:54:29 - INFO - Epoch: 31.49, Step: 124720, Train Loss: 1.1817, Learning Rate: 2.24e-05
2025-12-10 15:54:40 - INFO - Epoch: 31.49, Step: 124730, Train Loss: 1.1777, Learning Rate: 2.24e-05
2025-12-10 15:54:51 - INFO - Epoch: 31.49, Step: 124740, Train Loss: 1.1403, Learning Rate: 2.24e-05
2025-12-10 15:55:03 - INFO - Epoch: 31.49, Step: 124750, Train Loss: 1.1454, Learning Rate: 2.24e-05
2025-12-10 15:55:14 - INFO - Epoch: 31.50, Step: 124760, Train Loss: 1.1725, Learning Rate: 2.24e-05
2025-12-10 15:55:25 - INFO - Epoch: 31.50, Step: 124770, Train Loss: 1.1736, Learning Rate: 2.24e-05
2025-12-10 15:55:36 - INFO - Epoch: 31.50, Step: 124780, Train Loss: 1.1660, Learning Rate: 2.24e-05
2025-12-10 15:55:47 - INFO - Epoch: 31.50, Step: 124790, Train Loss: 1.1420, Learning Rate: 2.24e-05
2025-12-10 15:55:58 - INFO - Epoch: 31.51, Step: 124800, Train Loss: 1.1889, Learning Rate: 2.24e-05
2025-12-10 15:56:09 - INFO - Epoch: 31.51, Step: 124810, Train Loss: 1.1543, Learning Rate: 2.23e-05
2025-12-10 15:56:21 - INFO - Epoch: 31.51, Step: 124820, Train Loss: 1.1464, Learning Rate: 2.23e-05
2025-12-10 15:56:32 - INFO - Epoch: 31.51, Step: 124830, Train Loss: 1.1549, Learning Rate: 2.23e-05
2025-12-10 15:56:43 - INFO - Epoch: 31.52, Step: 124840, Train Loss: 1.1641, Learning Rate: 2.23e-05
2025-12-10 15:56:54 - INFO - Epoch: 31.52, Step: 124850, Train Loss: 1.1700, Learning Rate: 2.23e-05
2025-12-10 15:57:05 - INFO - Epoch: 31.52, Step: 124860, Train Loss: 1.1436, Learning Rate: 2.23e-05
2025-12-10 15:57:16 - INFO - Epoch: 31.52, Step: 124870, Train Loss: 1.1539, Learning Rate: 2.23e-05
2025-12-10 15:57:28 - INFO - Epoch: 31.53, Step: 124880, Train Loss: 1.1416, Learning Rate: 2.23e-05
2025-12-10 15:57:39 - INFO - Epoch: 31.53, Step: 124890, Train Loss: 1.1715, Learning Rate: 2.23e-05
2025-12-10 15:57:50 - INFO - Epoch: 31.53, Step: 124900, Train Loss: 1.1318, Learning Rate: 2.23e-05
2025-12-10 15:58:01 - INFO - Epoch: 31.53, Step: 124910, Train Loss: 1.1965, Learning Rate: 2.23e-05
2025-12-10 15:58:12 - INFO - Epoch: 31.54, Step: 124920, Train Loss: 1.1957, Learning Rate: 2.23e-05
2025-12-10 15:58:23 - INFO - Epoch: 31.54, Step: 124930, Train Loss: 1.1711, Learning Rate: 2.23e-05
2025-12-10 15:58:35 - INFO - Epoch: 31.54, Step: 124940, Train Loss: 1.1901, Learning Rate: 2.23e-05
2025-12-10 15:58:46 - INFO - Epoch: 31.55, Step: 124950, Train Loss: 1.1895, Learning Rate: 2.23e-05
2025-12-10 15:58:57 - INFO - Epoch: 31.55, Step: 124960, Train Loss: 1.1603, Learning Rate: 2.22e-05
2025-12-10 15:59:08 - INFO - Epoch: 31.55, Step: 124970, Train Loss: 1.1761, Learning Rate: 2.22e-05
2025-12-10 15:59:19 - INFO - Epoch: 31.55, Step: 124980, Train Loss: 1.1747, Learning Rate: 2.22e-05
2025-12-10 15:59:30 - INFO - Epoch: 31.56, Step: 124990, Train Loss: 1.1830, Learning Rate: 2.22e-05
2025-12-10 15:59:42 - INFO - Epoch: 31.56, Step: 125000, Train Loss: 1.1642, Learning Rate: 2.22e-05
2025-12-10 15:59:53 - INFO - Epoch: 31.56, Step: 125010, Train Loss: 1.1643, Learning Rate: 2.22e-05
2025-12-10 16:00:04 - INFO - Epoch: 31.56, Step: 125020, Train Loss: 1.1463, Learning Rate: 2.22e-05
2025-12-10 16:00:15 - INFO - Epoch: 31.57, Step: 125030, Train Loss: 1.1789, Learning Rate: 2.22e-05
2025-12-10 16:00:26 - INFO - Epoch: 31.57, Step: 125040, Train Loss: 1.1670, Learning Rate: 2.22e-05
2025-12-10 16:00:37 - INFO - Epoch: 31.57, Step: 125050, Train Loss: 1.1546, Learning Rate: 2.22e-05
2025-12-10 16:00:48 - INFO - Epoch: 31.57, Step: 125060, Train Loss: 1.1811, Learning Rate: 2.22e-05
2025-12-10 16:01:00 - INFO - Epoch: 31.58, Step: 125070, Train Loss: 1.1960, Learning Rate: 2.22e-05
2025-12-10 16:01:11 - INFO - Epoch: 31.58, Step: 125080, Train Loss: 1.1448, Learning Rate: 2.22e-05
2025-12-10 16:01:22 - INFO - Epoch: 31.58, Step: 125090, Train Loss: 1.1475, Learning Rate: 2.22e-05
2025-12-10 16:01:33 - INFO - Epoch: 31.58, Step: 125100, Train Loss: 1.1449, Learning Rate: 2.22e-05
2025-12-10 16:01:44 - INFO - Epoch: 31.59, Step: 125110, Train Loss: 1.1560, Learning Rate: 2.21e-05
2025-12-10 16:01:55 - INFO - Epoch: 31.59, Step: 125120, Train Loss: 1.1460, Learning Rate: 2.21e-05
2025-12-10 16:02:07 - INFO - Epoch: 31.59, Step: 125130, Train Loss: 1.2132, Learning Rate: 2.21e-05
2025-12-10 16:02:18 - INFO - Epoch: 31.59, Step: 125140, Train Loss: 1.1314, Learning Rate: 2.21e-05
2025-12-10 16:02:29 - INFO - Epoch: 31.60, Step: 125150, Train Loss: 1.1798, Learning Rate: 2.21e-05
2025-12-10 16:02:40 - INFO - Epoch: 31.60, Step: 125160, Train Loss: 1.1461, Learning Rate: 2.21e-05
2025-12-10 16:02:51 - INFO - Epoch: 31.60, Step: 125170, Train Loss: 1.1505, Learning Rate: 2.21e-05
2025-12-10 16:03:02 - INFO - Epoch: 31.60, Step: 125180, Train Loss: 1.1786, Learning Rate: 2.21e-05
2025-12-10 16:03:14 - INFO - Epoch: 31.61, Step: 125190, Train Loss: 1.1523, Learning Rate: 2.21e-05
2025-12-10 16:03:25 - INFO - Epoch: 31.61, Step: 125200, Train Loss: 1.1441, Learning Rate: 2.21e-05
2025-12-10 16:03:36 - INFO - Epoch: 31.61, Step: 125210, Train Loss: 1.1630, Learning Rate: 2.21e-05
2025-12-10 16:03:47 - INFO - Epoch: 31.61, Step: 125220, Train Loss: 1.1581, Learning Rate: 2.21e-05
2025-12-10 16:03:58 - INFO - Epoch: 31.62, Step: 125230, Train Loss: 1.1556, Learning Rate: 2.21e-05
2025-12-10 16:04:09 - INFO - Epoch: 31.62, Step: 125240, Train Loss: 1.1069, Learning Rate: 2.21e-05
2025-12-10 16:04:20 - INFO - Epoch: 31.62, Step: 125250, Train Loss: 1.1459, Learning Rate: 2.21e-05
2025-12-10 16:04:32 - INFO - Epoch: 31.62, Step: 125260, Train Loss: 1.1823, Learning Rate: 2.20e-05
2025-12-10 16:04:43 - INFO - Epoch: 31.63, Step: 125270, Train Loss: 1.1810, Learning Rate: 2.20e-05
2025-12-10 16:04:54 - INFO - Epoch: 31.63, Step: 125280, Train Loss: 1.1579, Learning Rate: 2.20e-05
2025-12-10 16:05:05 - INFO - Epoch: 31.63, Step: 125290, Train Loss: 1.1513, Learning Rate: 2.20e-05
2025-12-10 16:05:16 - INFO - Epoch: 31.63, Step: 125300, Train Loss: 1.1927, Learning Rate: 2.20e-05
2025-12-10 16:05:27 - INFO - Epoch: 31.64, Step: 125310, Train Loss: 1.1658, Learning Rate: 2.20e-05
2025-12-10 16:05:39 - INFO - Epoch: 31.64, Step: 125320, Train Loss: 1.1773, Learning Rate: 2.20e-05
2025-12-10 16:05:50 - INFO - Epoch: 31.64, Step: 125330, Train Loss: 1.1614, Learning Rate: 2.20e-05
2025-12-10 16:06:01 - INFO - Epoch: 31.64, Step: 125340, Train Loss: 1.1645, Learning Rate: 2.20e-05
2025-12-10 16:06:12 - INFO - Epoch: 31.65, Step: 125350, Train Loss: 1.1955, Learning Rate: 2.20e-05
2025-12-10 16:06:23 - INFO - Epoch: 31.65, Step: 125360, Train Loss: 1.1137, Learning Rate: 2.20e-05
2025-12-10 16:06:34 - INFO - Epoch: 31.65, Step: 125370, Train Loss: 1.1708, Learning Rate: 2.20e-05
2025-12-10 16:06:46 - INFO - Epoch: 31.65, Step: 125380, Train Loss: 1.1421, Learning Rate: 2.20e-05
2025-12-10 16:06:57 - INFO - Epoch: 31.66, Step: 125390, Train Loss: 1.1639, Learning Rate: 2.20e-05
2025-12-10 16:07:08 - INFO - Epoch: 31.66, Step: 125400, Train Loss: 1.1664, Learning Rate: 2.20e-05
2025-12-10 16:07:19 - INFO - Epoch: 31.66, Step: 125410, Train Loss: 1.1771, Learning Rate: 2.19e-05
2025-12-10 16:07:30 - INFO - Epoch: 31.66, Step: 125420, Train Loss: 1.1563, Learning Rate: 2.19e-05
2025-12-10 16:07:41 - INFO - Epoch: 31.67, Step: 125430, Train Loss: 1.1692, Learning Rate: 2.19e-05
2025-12-10 16:07:53 - INFO - Epoch: 31.67, Step: 125440, Train Loss: 1.1842, Learning Rate: 2.19e-05
2025-12-10 16:08:04 - INFO - Epoch: 31.67, Step: 125450, Train Loss: 1.1586, Learning Rate: 2.19e-05
2025-12-10 16:08:15 - INFO - Epoch: 31.67, Step: 125460, Train Loss: 1.1831, Learning Rate: 2.19e-05
2025-12-10 16:08:26 - INFO - Epoch: 31.68, Step: 125470, Train Loss: 1.1923, Learning Rate: 2.19e-05
2025-12-10 16:08:37 - INFO - Epoch: 31.68, Step: 125480, Train Loss: 1.1377, Learning Rate: 2.19e-05
2025-12-10 16:08:48 - INFO - Epoch: 31.68, Step: 125490, Train Loss: 1.1673, Learning Rate: 2.19e-05
2025-12-10 16:08:59 - INFO - Epoch: 31.68, Step: 125500, Train Loss: 1.1729, Learning Rate: 2.19e-05
2025-12-10 16:09:11 - INFO - Epoch: 31.69, Step: 125510, Train Loss: 1.1515, Learning Rate: 2.19e-05
2025-12-10 16:09:22 - INFO - Epoch: 31.69, Step: 125520, Train Loss: 1.1618, Learning Rate: 2.19e-05
2025-12-10 16:09:33 - INFO - Epoch: 31.69, Step: 125530, Train Loss: 1.1657, Learning Rate: 2.19e-05
2025-12-10 16:09:44 - INFO - Epoch: 31.69, Step: 125540, Train Loss: 1.1568, Learning Rate: 2.19e-05
2025-12-10 16:09:55 - INFO - Epoch: 31.70, Step: 125550, Train Loss: 1.1672, Learning Rate: 2.19e-05
2025-12-10 16:10:06 - INFO - Epoch: 31.70, Step: 125560, Train Loss: 1.1659, Learning Rate: 2.18e-05
2025-12-10 16:10:18 - INFO - Epoch: 31.70, Step: 125570, Train Loss: 1.1491, Learning Rate: 2.18e-05
2025-12-10 16:10:29 - INFO - Epoch: 31.70, Step: 125580, Train Loss: 1.1574, Learning Rate: 2.18e-05
2025-12-10 16:10:40 - INFO - Epoch: 31.71, Step: 125590, Train Loss: 1.1560, Learning Rate: 2.18e-05
2025-12-10 16:10:51 - INFO - Epoch: 31.71, Step: 125600, Train Loss: 1.1382, Learning Rate: 2.18e-05
2025-12-10 16:11:02 - INFO - Epoch: 31.71, Step: 125610, Train Loss: 1.1560, Learning Rate: 2.18e-05
2025-12-10 16:11:13 - INFO - Epoch: 31.71, Step: 125620, Train Loss: 1.1697, Learning Rate: 2.18e-05
2025-12-10 16:11:25 - INFO - Epoch: 31.72, Step: 125630, Train Loss: 1.1721, Learning Rate: 2.18e-05
2025-12-10 16:11:36 - INFO - Epoch: 31.72, Step: 125640, Train Loss: 1.1797, Learning Rate: 2.18e-05
2025-12-10 16:11:47 - INFO - Epoch: 31.72, Step: 125650, Train Loss: 1.1620, Learning Rate: 2.18e-05
2025-12-10 16:11:58 - INFO - Epoch: 31.72, Step: 125660, Train Loss: 1.1502, Learning Rate: 2.18e-05
2025-12-10 16:12:09 - INFO - Epoch: 31.73, Step: 125670, Train Loss: 1.1188, Learning Rate: 2.18e-05
2025-12-10 16:12:20 - INFO - Epoch: 31.73, Step: 125680, Train Loss: 1.1656, Learning Rate: 2.18e-05
2025-12-10 16:12:31 - INFO - Epoch: 31.73, Step: 125690, Train Loss: 1.1682, Learning Rate: 2.18e-05
2025-12-10 16:12:43 - INFO - Epoch: 31.73, Step: 125700, Train Loss: 1.1488, Learning Rate: 2.18e-05
2025-12-10 16:12:54 - INFO - Epoch: 31.74, Step: 125710, Train Loss: 1.2093, Learning Rate: 2.17e-05
2025-12-10 16:13:05 - INFO - Epoch: 31.74, Step: 125720, Train Loss: 1.1895, Learning Rate: 2.17e-05
2025-12-10 16:13:16 - INFO - Epoch: 31.74, Step: 125730, Train Loss: 1.1777, Learning Rate: 2.17e-05
2025-12-10 16:13:27 - INFO - Epoch: 31.74, Step: 125740, Train Loss: 1.1343, Learning Rate: 2.17e-05
2025-12-10 16:13:38 - INFO - Epoch: 31.75, Step: 125750, Train Loss: 1.1617, Learning Rate: 2.17e-05
2025-12-10 16:13:50 - INFO - Epoch: 31.75, Step: 125760, Train Loss: 1.1770, Learning Rate: 2.17e-05
2025-12-10 16:14:01 - INFO - Epoch: 31.75, Step: 125770, Train Loss: 1.1485, Learning Rate: 2.17e-05
2025-12-10 16:14:12 - INFO - Epoch: 31.75, Step: 125780, Train Loss: 1.1714, Learning Rate: 2.17e-05
2025-12-10 16:14:23 - INFO - Epoch: 31.76, Step: 125790, Train Loss: 1.1925, Learning Rate: 2.17e-05
2025-12-10 16:14:34 - INFO - Epoch: 31.76, Step: 125800, Train Loss: 1.1469, Learning Rate: 2.17e-05
2025-12-10 16:14:45 - INFO - Epoch: 31.76, Step: 125810, Train Loss: 1.1892, Learning Rate: 2.17e-05
2025-12-10 16:14:57 - INFO - Epoch: 31.76, Step: 125820, Train Loss: 1.1488, Learning Rate: 2.17e-05
2025-12-10 16:15:08 - INFO - Epoch: 31.77, Step: 125830, Train Loss: 1.1994, Learning Rate: 2.17e-05
2025-12-10 16:15:19 - INFO - Epoch: 31.77, Step: 125840, Train Loss: 1.2139, Learning Rate: 2.17e-05
2025-12-10 16:15:30 - INFO - Epoch: 31.77, Step: 125850, Train Loss: 1.1891, Learning Rate: 2.17e-05
2025-12-10 16:15:41 - INFO - Epoch: 31.77, Step: 125860, Train Loss: 1.1672, Learning Rate: 2.16e-05
2025-12-10 16:15:52 - INFO - Epoch: 31.78, Step: 125870, Train Loss: 1.1540, Learning Rate: 2.16e-05
2025-12-10 16:16:04 - INFO - Epoch: 31.78, Step: 125880, Train Loss: 1.1518, Learning Rate: 2.16e-05
2025-12-10 16:16:15 - INFO - Epoch: 31.78, Step: 125890, Train Loss: 1.1267, Learning Rate: 2.16e-05
2025-12-10 16:16:26 - INFO - Epoch: 31.78, Step: 125900, Train Loss: 1.1592, Learning Rate: 2.16e-05
2025-12-10 16:16:37 - INFO - Epoch: 31.79, Step: 125910, Train Loss: 1.1559, Learning Rate: 2.16e-05
2025-12-10 16:16:48 - INFO - Epoch: 31.79, Step: 125920, Train Loss: 1.1589, Learning Rate: 2.16e-05
2025-12-10 16:16:59 - INFO - Epoch: 31.79, Step: 125930, Train Loss: 1.1639, Learning Rate: 2.16e-05
2025-12-10 16:17:10 - INFO - Epoch: 31.80, Step: 125940, Train Loss: 1.1808, Learning Rate: 2.16e-05
2025-12-10 16:17:22 - INFO - Epoch: 31.80, Step: 125950, Train Loss: 1.1340, Learning Rate: 2.16e-05
2025-12-10 16:17:33 - INFO - Epoch: 31.80, Step: 125960, Train Loss: 1.1459, Learning Rate: 2.16e-05
2025-12-10 16:17:44 - INFO - Epoch: 31.80, Step: 125970, Train Loss: 1.1415, Learning Rate: 2.16e-05
2025-12-10 16:17:55 - INFO - Epoch: 31.81, Step: 125980, Train Loss: 1.1878, Learning Rate: 2.16e-05
2025-12-10 16:18:06 - INFO - Epoch: 31.81, Step: 125990, Train Loss: 1.1530, Learning Rate: 2.16e-05
2025-12-10 16:18:17 - INFO - Epoch: 31.81, Step: 126000, Train Loss: 1.1916, Learning Rate: 2.16e-05
2025-12-10 16:18:29 - INFO - Epoch: 31.81, Step: 126010, Train Loss: 1.1863, Learning Rate: 2.15e-05
2025-12-10 16:18:40 - INFO - Epoch: 31.82, Step: 126020, Train Loss: 1.1357, Learning Rate: 2.15e-05
2025-12-10 16:18:51 - INFO - Epoch: 31.82, Step: 126030, Train Loss: 1.1699, Learning Rate: 2.15e-05
2025-12-10 16:19:02 - INFO - Epoch: 31.82, Step: 126040, Train Loss: 1.1596, Learning Rate: 2.15e-05
2025-12-10 16:19:13 - INFO - Epoch: 31.82, Step: 126050, Train Loss: 1.1567, Learning Rate: 2.15e-05
2025-12-10 16:19:24 - INFO - Epoch: 31.83, Step: 126060, Train Loss: 1.1833, Learning Rate: 2.15e-05
2025-12-10 16:19:36 - INFO - Epoch: 31.83, Step: 126070, Train Loss: 1.1740, Learning Rate: 2.15e-05
2025-12-10 16:19:47 - INFO - Epoch: 31.83, Step: 126080, Train Loss: 1.1617, Learning Rate: 2.15e-05
2025-12-10 16:19:58 - INFO - Epoch: 31.83, Step: 126090, Train Loss: 1.1756, Learning Rate: 2.15e-05
2025-12-10 16:20:09 - INFO - Epoch: 31.84, Step: 126100, Train Loss: 1.1439, Learning Rate: 2.15e-05
2025-12-10 16:20:20 - INFO - Epoch: 31.84, Step: 126110, Train Loss: 1.1748, Learning Rate: 2.15e-05
2025-12-10 16:20:31 - INFO - Epoch: 31.84, Step: 126120, Train Loss: 1.1283, Learning Rate: 2.15e-05
2025-12-10 16:20:42 - INFO - Epoch: 31.84, Step: 126130, Train Loss: 1.1327, Learning Rate: 2.15e-05
2025-12-10 16:20:54 - INFO - Epoch: 31.85, Step: 126140, Train Loss: 1.1205, Learning Rate: 2.15e-05
2025-12-10 16:21:05 - INFO - Epoch: 31.85, Step: 126150, Train Loss: 1.1580, Learning Rate: 2.15e-05
2025-12-10 16:21:16 - INFO - Epoch: 31.85, Step: 126160, Train Loss: 1.1539, Learning Rate: 2.14e-05
2025-12-10 16:21:27 - INFO - Epoch: 31.85, Step: 126170, Train Loss: 1.1120, Learning Rate: 2.14e-05
2025-12-10 16:21:38 - INFO - Epoch: 31.86, Step: 126180, Train Loss: 1.1643, Learning Rate: 2.14e-05
2025-12-10 16:21:49 - INFO - Epoch: 31.86, Step: 126190, Train Loss: 1.1479, Learning Rate: 2.14e-05
2025-12-10 16:22:01 - INFO - Epoch: 31.86, Step: 126200, Train Loss: 1.1772, Learning Rate: 2.14e-05
2025-12-10 16:22:12 - INFO - Epoch: 31.86, Step: 126210, Train Loss: 1.1326, Learning Rate: 2.14e-05
2025-12-10 16:22:23 - INFO - Epoch: 31.87, Step: 126220, Train Loss: 1.1916, Learning Rate: 2.14e-05
2025-12-10 16:22:34 - INFO - Epoch: 31.87, Step: 126230, Train Loss: 1.1385, Learning Rate: 2.14e-05
2025-12-10 16:22:45 - INFO - Epoch: 31.87, Step: 126240, Train Loss: 1.1646, Learning Rate: 2.14e-05
2025-12-10 16:22:56 - INFO - Epoch: 31.87, Step: 126250, Train Loss: 1.1738, Learning Rate: 2.14e-05
2025-12-10 16:23:08 - INFO - Epoch: 31.88, Step: 126260, Train Loss: 1.1337, Learning Rate: 2.14e-05
2025-12-10 16:23:19 - INFO - Epoch: 31.88, Step: 126270, Train Loss: 1.1853, Learning Rate: 2.14e-05
2025-12-10 16:23:30 - INFO - Epoch: 31.88, Step: 126280, Train Loss: 1.1425, Learning Rate: 2.14e-05
2025-12-10 16:23:41 - INFO - Epoch: 31.88, Step: 126290, Train Loss: 1.1584, Learning Rate: 2.14e-05
2025-12-10 16:23:52 - INFO - Epoch: 31.89, Step: 126300, Train Loss: 1.1560, Learning Rate: 2.14e-05
2025-12-10 16:24:03 - INFO - Epoch: 31.89, Step: 126310, Train Loss: 1.1984, Learning Rate: 2.13e-05
2025-12-10 16:24:15 - INFO - Epoch: 31.89, Step: 126320, Train Loss: 1.1646, Learning Rate: 2.13e-05
2025-12-10 16:24:26 - INFO - Epoch: 31.89, Step: 126330, Train Loss: 1.1703, Learning Rate: 2.13e-05
2025-12-10 16:24:37 - INFO - Epoch: 31.90, Step: 126340, Train Loss: 1.1390, Learning Rate: 2.13e-05
2025-12-10 16:24:48 - INFO - Epoch: 31.90, Step: 126350, Train Loss: 1.1393, Learning Rate: 2.13e-05
2025-12-10 16:24:59 - INFO - Epoch: 31.90, Step: 126360, Train Loss: 1.1829, Learning Rate: 2.13e-05
2025-12-10 16:25:10 - INFO - Epoch: 31.90, Step: 126370, Train Loss: 1.1839, Learning Rate: 2.13e-05
2025-12-10 16:25:21 - INFO - Epoch: 31.91, Step: 126380, Train Loss: 1.1725, Learning Rate: 2.13e-05
2025-12-10 16:25:33 - INFO - Epoch: 31.91, Step: 126390, Train Loss: 1.1675, Learning Rate: 2.13e-05
2025-12-10 16:25:44 - INFO - Epoch: 31.91, Step: 126400, Train Loss: 1.2089, Learning Rate: 2.13e-05
2025-12-10 16:25:55 - INFO - Epoch: 31.91, Step: 126410, Train Loss: 1.1608, Learning Rate: 2.13e-05
2025-12-10 16:26:06 - INFO - Epoch: 31.92, Step: 126420, Train Loss: 1.1250, Learning Rate: 2.13e-05
2025-12-10 16:26:17 - INFO - Epoch: 31.92, Step: 126430, Train Loss: 1.1474, Learning Rate: 2.13e-05
2025-12-10 16:26:28 - INFO - Epoch: 31.92, Step: 126440, Train Loss: 1.1719, Learning Rate: 2.13e-05
2025-12-10 16:26:40 - INFO - Epoch: 31.92, Step: 126450, Train Loss: 1.1558, Learning Rate: 2.13e-05
2025-12-10 16:26:51 - INFO - Epoch: 31.93, Step: 126460, Train Loss: 1.1807, Learning Rate: 2.12e-05
2025-12-10 16:27:02 - INFO - Epoch: 31.93, Step: 126470, Train Loss: 1.1326, Learning Rate: 2.12e-05
2025-12-10 16:27:13 - INFO - Epoch: 31.93, Step: 126480, Train Loss: 1.1667, Learning Rate: 2.12e-05
2025-12-10 16:27:24 - INFO - Epoch: 31.93, Step: 126490, Train Loss: 1.1402, Learning Rate: 2.12e-05
2025-12-10 16:27:35 - INFO - Epoch: 31.94, Step: 126500, Train Loss: 1.1536, Learning Rate: 2.12e-05
2025-12-10 16:27:47 - INFO - Epoch: 31.94, Step: 126510, Train Loss: 1.1882, Learning Rate: 2.12e-05
2025-12-10 16:27:58 - INFO - Epoch: 31.94, Step: 126520, Train Loss: 1.1651, Learning Rate: 2.12e-05
2025-12-10 16:28:09 - INFO - Epoch: 31.94, Step: 126530, Train Loss: 1.1634, Learning Rate: 2.12e-05
2025-12-10 16:28:20 - INFO - Epoch: 31.95, Step: 126540, Train Loss: 1.1442, Learning Rate: 2.12e-05
2025-12-10 16:28:31 - INFO - Epoch: 31.95, Step: 126550, Train Loss: 1.1518, Learning Rate: 2.12e-05
2025-12-10 16:28:42 - INFO - Epoch: 31.95, Step: 126560, Train Loss: 1.1990, Learning Rate: 2.12e-05
2025-12-10 16:28:53 - INFO - Epoch: 31.95, Step: 126570, Train Loss: 1.1807, Learning Rate: 2.12e-05
2025-12-10 16:29:05 - INFO - Epoch: 31.96, Step: 126580, Train Loss: 1.2117, Learning Rate: 2.12e-05
2025-12-10 16:29:16 - INFO - Epoch: 31.96, Step: 126590, Train Loss: 1.1673, Learning Rate: 2.12e-05
2025-12-10 16:29:27 - INFO - Epoch: 31.96, Step: 126600, Train Loss: 1.1737, Learning Rate: 2.12e-05
2025-12-10 16:29:38 - INFO - Epoch: 31.96, Step: 126610, Train Loss: 1.1807, Learning Rate: 2.11e-05
2025-12-10 16:29:49 - INFO - Epoch: 31.97, Step: 126620, Train Loss: 1.1931, Learning Rate: 2.11e-05
2025-12-10 16:30:00 - INFO - Epoch: 31.97, Step: 126630, Train Loss: 1.1560, Learning Rate: 2.11e-05
2025-12-10 16:30:12 - INFO - Epoch: 31.97, Step: 126640, Train Loss: 1.1698, Learning Rate: 2.11e-05
2025-12-10 16:30:23 - INFO - Epoch: 31.97, Step: 126650, Train Loss: 1.1630, Learning Rate: 2.11e-05
2025-12-10 16:30:34 - INFO - Epoch: 31.98, Step: 126660, Train Loss: 1.1524, Learning Rate: 2.11e-05
2025-12-10 16:30:45 - INFO - Epoch: 31.98, Step: 126670, Train Loss: 1.1257, Learning Rate: 2.11e-05
2025-12-10 16:30:56 - INFO - Epoch: 31.98, Step: 126680, Train Loss: 1.1293, Learning Rate: 2.11e-05
2025-12-10 16:31:07 - INFO - Epoch: 31.98, Step: 126690, Train Loss: 1.1448, Learning Rate: 2.11e-05
2025-12-10 16:31:19 - INFO - Epoch: 31.99, Step: 126700, Train Loss: 1.1548, Learning Rate: 2.11e-05
2025-12-10 16:31:30 - INFO - Epoch: 31.99, Step: 126710, Train Loss: 1.1504, Learning Rate: 2.11e-05
2025-12-10 16:31:41 - INFO - Epoch: 31.99, Step: 126720, Train Loss: 1.1580, Learning Rate: 2.11e-05
2025-12-10 16:31:52 - INFO - Epoch: 31.99, Step: 126730, Train Loss: 1.1410, Learning Rate: 2.11e-05
2025-12-10 16:32:03 - INFO - Epoch: 32.00, Step: 126740, Train Loss: 1.1822, Learning Rate: 2.11e-05
2025-12-10 16:32:14 - INFO - Epoch: 32.00, Step: 126750, Train Loss: 1.1232, Learning Rate: 2.11e-05
2025-12-10 16:32:29 - INFO - Epoch: 32.00, Step: 126760, Train Loss: 1.1814, Learning Rate: 2.10e-05
2025-12-10 16:32:45 - INFO - Epoch: 32.00, Step: 126770, Train Loss: 1.1893, Learning Rate: 2.10e-05
2025-12-10 16:33:01 - INFO - Epoch: 32.01, Step: 126780, Train Loss: 1.1443, Learning Rate: 2.10e-05
2025-12-10 16:33:16 - INFO - Epoch: 32.01, Step: 126790, Train Loss: 1.1510, Learning Rate: 2.10e-05
2025-12-10 16:33:32 - INFO - Epoch: 32.01, Step: 126800, Train Loss: 1.1849, Learning Rate: 2.10e-05
2025-12-10 16:33:48 - INFO - Epoch: 32.01, Step: 126810, Train Loss: 1.1948, Learning Rate: 2.10e-05
2025-12-10 16:34:04 - INFO - Epoch: 32.02, Step: 126820, Train Loss: 1.1850, Learning Rate: 2.10e-05
2025-12-10 16:34:19 - INFO - Epoch: 32.02, Step: 126830, Train Loss: 1.1663, Learning Rate: 2.10e-05
2025-12-10 16:34:35 - INFO - Epoch: 32.02, Step: 126840, Train Loss: 1.1416, Learning Rate: 2.10e-05
2025-12-10 16:34:51 - INFO - Epoch: 32.02, Step: 126850, Train Loss: 1.1112, Learning Rate: 2.10e-05
2025-12-10 16:35:07 - INFO - Epoch: 32.03, Step: 126860, Train Loss: 1.1491, Learning Rate: 2.10e-05
2025-12-10 16:35:22 - INFO - Epoch: 32.03, Step: 126870, Train Loss: 1.1448, Learning Rate: 2.10e-05
2025-12-10 16:35:38 - INFO - Epoch: 32.03, Step: 126880, Train Loss: 1.1695, Learning Rate: 2.10e-05
2025-12-10 16:35:54 - INFO - Epoch: 32.03, Step: 126890, Train Loss: 1.1508, Learning Rate: 2.10e-05
2025-12-10 16:36:10 - INFO - Epoch: 32.04, Step: 126900, Train Loss: 1.1501, Learning Rate: 2.10e-05
2025-12-10 16:36:25 - INFO - Epoch: 32.04, Step: 126910, Train Loss: 1.1568, Learning Rate: 2.09e-05
2025-12-10 16:36:41 - INFO - Epoch: 32.04, Step: 126920, Train Loss: 1.1704, Learning Rate: 2.09e-05
2025-12-10 16:36:57 - INFO - Epoch: 32.04, Step: 126930, Train Loss: 1.1929, Learning Rate: 2.09e-05
2025-12-10 16:37:13 - INFO - Epoch: 32.05, Step: 126940, Train Loss: 1.1411, Learning Rate: 2.09e-05
2025-12-10 16:37:28 - INFO - Epoch: 32.05, Step: 126950, Train Loss: 1.1560, Learning Rate: 2.09e-05
2025-12-10 16:37:44 - INFO - Epoch: 32.05, Step: 126960, Train Loss: 1.1228, Learning Rate: 2.09e-05
2025-12-10 16:38:00 - INFO - Epoch: 32.06, Step: 126970, Train Loss: 1.1528, Learning Rate: 2.09e-05
2025-12-10 16:38:15 - INFO - Epoch: 32.06, Step: 126980, Train Loss: 1.1577, Learning Rate: 2.09e-05
2025-12-10 16:38:31 - INFO - Epoch: 32.06, Step: 126990, Train Loss: 1.1601, Learning Rate: 2.09e-05
2025-12-10 16:38:47 - INFO - Epoch: 32.06, Step: 127000, Train Loss: 1.1631, Learning Rate: 2.09e-05
2025-12-10 16:39:03 - INFO - Epoch: 32.07, Step: 127010, Train Loss: 1.1840, Learning Rate: 2.09e-05
2025-12-10 16:39:18 - INFO - Epoch: 32.07, Step: 127020, Train Loss: 1.1200, Learning Rate: 2.09e-05
2025-12-10 16:39:34 - INFO - Epoch: 32.07, Step: 127030, Train Loss: 1.1850, Learning Rate: 2.09e-05
2025-12-10 16:39:50 - INFO - Epoch: 32.07, Step: 127040, Train Loss: 1.1688, Learning Rate: 2.09e-05
2025-12-10 16:40:06 - INFO - Epoch: 32.08, Step: 127050, Train Loss: 1.1760, Learning Rate: 2.09e-05
2025-12-10 16:40:21 - INFO - Epoch: 32.08, Step: 127060, Train Loss: 1.1478, Learning Rate: 2.08e-05
2025-12-10 16:40:37 - INFO - Epoch: 32.08, Step: 127070, Train Loss: 1.2005, Learning Rate: 2.08e-05
2025-12-10 16:40:53 - INFO - Epoch: 32.08, Step: 127080, Train Loss: 1.1802, Learning Rate: 2.08e-05
2025-12-10 16:41:09 - INFO - Epoch: 32.09, Step: 127090, Train Loss: 1.1988, Learning Rate: 2.08e-05
2025-12-10 16:41:24 - INFO - Epoch: 32.09, Step: 127100, Train Loss: 1.1626, Learning Rate: 2.08e-05
2025-12-10 16:41:40 - INFO - Epoch: 32.09, Step: 127110, Train Loss: 1.1489, Learning Rate: 2.08e-05
2025-12-10 16:41:56 - INFO - Epoch: 32.09, Step: 127120, Train Loss: 1.1503, Learning Rate: 2.08e-05
2025-12-10 16:42:12 - INFO - Epoch: 32.10, Step: 127130, Train Loss: 1.1735, Learning Rate: 2.08e-05
2025-12-10 16:42:27 - INFO - Epoch: 32.10, Step: 127140, Train Loss: 1.1639, Learning Rate: 2.08e-05
2025-12-10 16:42:43 - INFO - Epoch: 32.10, Step: 127150, Train Loss: 1.1649, Learning Rate: 2.08e-05
2025-12-10 16:42:59 - INFO - Epoch: 32.10, Step: 127160, Train Loss: 1.1832, Learning Rate: 2.08e-05
2025-12-10 16:43:15 - INFO - Epoch: 32.11, Step: 127170, Train Loss: 1.1313, Learning Rate: 2.08e-05
2025-12-10 16:43:30 - INFO - Epoch: 32.11, Step: 127180, Train Loss: 1.1791, Learning Rate: 2.08e-05
2025-12-10 16:43:46 - INFO - Epoch: 32.11, Step: 127190, Train Loss: 1.1587, Learning Rate: 2.08e-05
2025-12-10 16:44:02 - INFO - Epoch: 32.11, Step: 127200, Train Loss: 1.1450, Learning Rate: 2.08e-05
2025-12-10 16:44:18 - INFO - Epoch: 32.12, Step: 127210, Train Loss: 1.1343, Learning Rate: 2.07e-05
2025-12-10 16:44:33 - INFO - Epoch: 32.12, Step: 127220, Train Loss: 1.1359, Learning Rate: 2.07e-05
2025-12-10 16:44:49 - INFO - Epoch: 32.12, Step: 127230, Train Loss: 1.1458, Learning Rate: 2.07e-05
2025-12-10 16:45:05 - INFO - Epoch: 32.12, Step: 127240, Train Loss: 1.1941, Learning Rate: 2.07e-05
2025-12-10 16:45:21 - INFO - Epoch: 32.13, Step: 127250, Train Loss: 1.1602, Learning Rate: 2.07e-05
2025-12-10 16:45:36 - INFO - Epoch: 32.13, Step: 127260, Train Loss: 1.1370, Learning Rate: 2.07e-05
2025-12-10 16:45:52 - INFO - Epoch: 32.13, Step: 127270, Train Loss: 1.1576, Learning Rate: 2.07e-05
2025-12-10 16:46:08 - INFO - Epoch: 32.13, Step: 127280, Train Loss: 1.1692, Learning Rate: 2.07e-05
2025-12-10 16:46:23 - INFO - Epoch: 32.14, Step: 127290, Train Loss: 1.1725, Learning Rate: 2.07e-05
2025-12-10 16:46:39 - INFO - Epoch: 32.14, Step: 127300, Train Loss: 1.1786, Learning Rate: 2.07e-05
2025-12-10 16:46:55 - INFO - Epoch: 32.14, Step: 127310, Train Loss: 1.1639, Learning Rate: 2.07e-05
2025-12-10 16:47:11 - INFO - Epoch: 32.14, Step: 127320, Train Loss: 1.1255, Learning Rate: 2.07e-05
2025-12-10 16:47:26 - INFO - Epoch: 32.15, Step: 127330, Train Loss: 1.1231, Learning Rate: 2.07e-05
2025-12-10 16:47:42 - INFO - Epoch: 32.15, Step: 127340, Train Loss: 1.1492, Learning Rate: 2.07e-05
2025-12-10 16:47:58 - INFO - Epoch: 32.15, Step: 127350, Train Loss: 1.1464, Learning Rate: 2.07e-05
2025-12-10 16:48:14 - INFO - Epoch: 32.15, Step: 127360, Train Loss: 1.1796, Learning Rate: 2.06e-05
2025-12-10 16:48:29 - INFO - Epoch: 32.16, Step: 127370, Train Loss: 1.1703, Learning Rate: 2.06e-05
2025-12-10 16:48:45 - INFO - Epoch: 32.16, Step: 127380, Train Loss: 1.1245, Learning Rate: 2.06e-05
2025-12-10 16:49:01 - INFO - Epoch: 32.16, Step: 127390, Train Loss: 1.1702, Learning Rate: 2.06e-05
2025-12-10 16:49:17 - INFO - Epoch: 32.16, Step: 127400, Train Loss: 1.1778, Learning Rate: 2.06e-05
2025-12-10 16:49:32 - INFO - Epoch: 32.17, Step: 127410, Train Loss: 1.1796, Learning Rate: 2.06e-05
2025-12-10 16:49:48 - INFO - Epoch: 32.17, Step: 127420, Train Loss: 1.1593, Learning Rate: 2.06e-05
2025-12-10 16:50:04 - INFO - Epoch: 32.17, Step: 127430, Train Loss: 1.1547, Learning Rate: 2.06e-05
2025-12-10 16:50:20 - INFO - Epoch: 32.17, Step: 127440, Train Loss: 1.1725, Learning Rate: 2.06e-05
2025-12-10 16:50:35 - INFO - Epoch: 32.18, Step: 127450, Train Loss: 1.1780, Learning Rate: 2.06e-05
2025-12-10 16:50:51 - INFO - Epoch: 32.18, Step: 127460, Train Loss: 1.1280, Learning Rate: 2.06e-05
2025-12-10 16:51:07 - INFO - Epoch: 32.18, Step: 127470, Train Loss: 1.1916, Learning Rate: 2.06e-05
2025-12-10 16:51:23 - INFO - Epoch: 32.18, Step: 127480, Train Loss: 1.1445, Learning Rate: 2.06e-05
2025-12-10 16:51:38 - INFO - Epoch: 32.19, Step: 127490, Train Loss: 1.1412, Learning Rate: 2.06e-05
2025-12-10 16:51:54 - INFO - Epoch: 32.19, Step: 127500, Train Loss: 1.1741, Learning Rate: 2.06e-05
2025-12-10 16:52:10 - INFO - Epoch: 32.19, Step: 127510, Train Loss: 1.1354, Learning Rate: 2.05e-05
2025-12-10 16:52:26 - INFO - Epoch: 32.19, Step: 127520, Train Loss: 1.1524, Learning Rate: 2.05e-05
2025-12-10 16:52:41 - INFO - Epoch: 32.20, Step: 127530, Train Loss: 1.1426, Learning Rate: 2.05e-05
2025-12-10 16:52:57 - INFO - Epoch: 32.20, Step: 127540, Train Loss: 1.1357, Learning Rate: 2.05e-05
2025-12-10 16:53:13 - INFO - Epoch: 32.20, Step: 127550, Train Loss: 1.1637, Learning Rate: 2.05e-05
2025-12-10 16:53:29 - INFO - Epoch: 32.20, Step: 127560, Train Loss: 1.1535, Learning Rate: 2.05e-05
2025-12-10 16:53:44 - INFO - Epoch: 32.21, Step: 127570, Train Loss: 1.1596, Learning Rate: 2.05e-05
2025-12-10 16:54:00 - INFO - Epoch: 32.21, Step: 127580, Train Loss: 1.1521, Learning Rate: 2.05e-05
2025-12-10 16:54:16 - INFO - Epoch: 32.21, Step: 127590, Train Loss: 1.1534, Learning Rate: 2.05e-05
2025-12-10 16:54:31 - INFO - Epoch: 32.21, Step: 127600, Train Loss: 1.1447, Learning Rate: 2.05e-05
2025-12-10 16:54:47 - INFO - Epoch: 32.22, Step: 127610, Train Loss: 1.1687, Learning Rate: 2.05e-05
2025-12-10 16:55:03 - INFO - Epoch: 32.22, Step: 127620, Train Loss: 1.1439, Learning Rate: 2.05e-05
2025-12-10 16:55:19 - INFO - Epoch: 32.22, Step: 127630, Train Loss: 1.1385, Learning Rate: 2.05e-05
2025-12-10 16:55:34 - INFO - Epoch: 32.22, Step: 127640, Train Loss: 1.1609, Learning Rate: 2.05e-05
2025-12-10 16:55:50 - INFO - Epoch: 32.23, Step: 127650, Train Loss: 1.1526, Learning Rate: 2.05e-05
2025-12-10 16:56:06 - INFO - Epoch: 32.23, Step: 127660, Train Loss: 1.1412, Learning Rate: 2.05e-05
2025-12-10 16:56:22 - INFO - Epoch: 32.23, Step: 127670, Train Loss: 1.1772, Learning Rate: 2.04e-05
2025-12-10 16:56:37 - INFO - Epoch: 32.23, Step: 127680, Train Loss: 1.1731, Learning Rate: 2.04e-05
2025-12-10 16:56:53 - INFO - Epoch: 32.24, Step: 127690, Train Loss: 1.1666, Learning Rate: 2.04e-05
2025-12-10 16:57:09 - INFO - Epoch: 32.24, Step: 127700, Train Loss: 1.1815, Learning Rate: 2.04e-05
2025-12-10 16:57:25 - INFO - Epoch: 32.24, Step: 127710, Train Loss: 1.1431, Learning Rate: 2.04e-05
2025-12-10 16:57:40 - INFO - Epoch: 32.24, Step: 127720, Train Loss: 1.2169, Learning Rate: 2.04e-05
2025-12-10 16:57:56 - INFO - Epoch: 32.25, Step: 127730, Train Loss: 1.1771, Learning Rate: 2.04e-05
2025-12-10 16:58:12 - INFO - Epoch: 32.25, Step: 127740, Train Loss: 1.1421, Learning Rate: 2.04e-05
2025-12-10 16:58:28 - INFO - Epoch: 32.25, Step: 127750, Train Loss: 1.1958, Learning Rate: 2.04e-05
2025-12-10 16:58:43 - INFO - Epoch: 32.25, Step: 127760, Train Loss: 1.1798, Learning Rate: 2.04e-05
2025-12-10 16:58:59 - INFO - Epoch: 32.26, Step: 127770, Train Loss: 1.1932, Learning Rate: 2.04e-05
2025-12-10 16:59:15 - INFO - Epoch: 32.26, Step: 127780, Train Loss: 1.2080, Learning Rate: 2.04e-05
2025-12-10 16:59:31 - INFO - Epoch: 32.26, Step: 127790, Train Loss: 1.1614, Learning Rate: 2.04e-05
2025-12-10 16:59:46 - INFO - Epoch: 32.26, Step: 127800, Train Loss: 1.1481, Learning Rate: 2.04e-05
2025-12-10 17:00:02 - INFO - Epoch: 32.27, Step: 127810, Train Loss: 1.1798, Learning Rate: 2.04e-05
2025-12-10 17:00:18 - INFO - Epoch: 32.27, Step: 127820, Train Loss: 1.1712, Learning Rate: 2.03e-05
2025-12-10 17:00:34 - INFO - Epoch: 32.27, Step: 127830, Train Loss: 1.1468, Learning Rate: 2.03e-05
2025-12-10 17:00:49 - INFO - Epoch: 32.27, Step: 127840, Train Loss: 1.1446, Learning Rate: 2.03e-05
2025-12-10 17:01:05 - INFO - Epoch: 32.28, Step: 127850, Train Loss: 1.1713, Learning Rate: 2.03e-05
2025-12-10 17:01:21 - INFO - Epoch: 32.28, Step: 127860, Train Loss: 1.1483, Learning Rate: 2.03e-05
2025-12-10 17:01:37 - INFO - Epoch: 32.28, Step: 127870, Train Loss: 1.1654, Learning Rate: 2.03e-05
2025-12-10 17:01:52 - INFO - Epoch: 32.28, Step: 127880, Train Loss: 1.1725, Learning Rate: 2.03e-05
2025-12-10 17:02:08 - INFO - Epoch: 32.29, Step: 127890, Train Loss: 1.1554, Learning Rate: 2.03e-05
2025-12-10 17:02:24 - INFO - Epoch: 32.29, Step: 127900, Train Loss: 1.1664, Learning Rate: 2.03e-05
2025-12-10 17:02:39 - INFO - Epoch: 32.29, Step: 127910, Train Loss: 1.1426, Learning Rate: 2.03e-05
2025-12-10 17:02:55 - INFO - Epoch: 32.29, Step: 127920, Train Loss: 1.1454, Learning Rate: 2.03e-05
2025-12-10 17:03:11 - INFO - Epoch: 32.30, Step: 127930, Train Loss: 1.1638, Learning Rate: 2.03e-05
2025-12-10 17:03:27 - INFO - Epoch: 32.30, Step: 127940, Train Loss: 1.1652, Learning Rate: 2.03e-05
2025-12-10 17:03:42 - INFO - Epoch: 32.30, Step: 127950, Train Loss: 1.1279, Learning Rate: 2.03e-05
2025-12-10 17:03:58 - INFO - Epoch: 32.30, Step: 127960, Train Loss: 1.1679, Learning Rate: 2.03e-05
2025-12-10 17:04:14 - INFO - Epoch: 32.31, Step: 127970, Train Loss: 1.1576, Learning Rate: 2.02e-05
2025-12-10 17:04:30 - INFO - Epoch: 32.31, Step: 127980, Train Loss: 1.1426, Learning Rate: 2.02e-05
2025-12-10 17:04:45 - INFO - Epoch: 32.31, Step: 127990, Train Loss: 1.1740, Learning Rate: 2.02e-05
2025-12-10 17:05:01 - INFO - Epoch: 32.32, Step: 128000, Train Loss: 1.1415, Learning Rate: 2.02e-05
2025-12-10 17:05:17 - INFO - Epoch: 32.32, Step: 128010, Train Loss: 1.1584, Learning Rate: 2.02e-05
2025-12-10 17:05:33 - INFO - Epoch: 32.32, Step: 128020, Train Loss: 1.1827, Learning Rate: 2.02e-05
2025-12-10 17:05:48 - INFO - Epoch: 32.32, Step: 128030, Train Loss: 1.1440, Learning Rate: 2.02e-05
2025-12-10 17:06:04 - INFO - Epoch: 32.33, Step: 128040, Train Loss: 1.1390, Learning Rate: 2.02e-05
2025-12-10 17:06:20 - INFO - Epoch: 32.33, Step: 128050, Train Loss: 1.1729, Learning Rate: 2.02e-05
2025-12-10 17:06:36 - INFO - Epoch: 32.33, Step: 128060, Train Loss: 1.1671, Learning Rate: 2.02e-05
2025-12-10 17:06:51 - INFO - Epoch: 32.33, Step: 128070, Train Loss: 1.1542, Learning Rate: 2.02e-05
2025-12-10 17:07:07 - INFO - Epoch: 32.34, Step: 128080, Train Loss: 1.1420, Learning Rate: 2.02e-05
2025-12-10 17:07:23 - INFO - Epoch: 32.34, Step: 128090, Train Loss: 1.1519, Learning Rate: 2.02e-05
2025-12-10 17:07:39 - INFO - Epoch: 32.34, Step: 128100, Train Loss: 1.1408, Learning Rate: 2.02e-05
2025-12-10 17:07:54 - INFO - Epoch: 32.34, Step: 128110, Train Loss: 1.1781, Learning Rate: 2.02e-05
2025-12-10 17:08:10 - INFO - Epoch: 32.35, Step: 128120, Train Loss: 1.1216, Learning Rate: 2.01e-05
2025-12-10 17:08:26 - INFO - Epoch: 32.35, Step: 128130, Train Loss: 1.1307, Learning Rate: 2.01e-05
2025-12-10 17:08:42 - INFO - Epoch: 32.35, Step: 128140, Train Loss: 1.1572, Learning Rate: 2.01e-05
2025-12-10 17:08:57 - INFO - Epoch: 32.35, Step: 128150, Train Loss: 1.1695, Learning Rate: 2.01e-05
2025-12-10 17:09:13 - INFO - Epoch: 32.36, Step: 128160, Train Loss: 1.1796, Learning Rate: 2.01e-05
2025-12-10 17:09:29 - INFO - Epoch: 32.36, Step: 128170, Train Loss: 1.1703, Learning Rate: 2.01e-05
2025-12-10 17:09:45 - INFO - Epoch: 32.36, Step: 128180, Train Loss: 1.1398, Learning Rate: 2.01e-05
2025-12-10 17:10:00 - INFO - Epoch: 32.36, Step: 128190, Train Loss: 1.1263, Learning Rate: 2.01e-05
2025-12-10 17:10:16 - INFO - Epoch: 32.37, Step: 128200, Train Loss: 1.1801, Learning Rate: 2.01e-05
2025-12-10 17:10:32 - INFO - Epoch: 32.37, Step: 128210, Train Loss: 1.2186, Learning Rate: 2.01e-05
2025-12-10 17:10:47 - INFO - Epoch: 32.37, Step: 128220, Train Loss: 1.1719, Learning Rate: 2.01e-05
2025-12-10 17:11:03 - INFO - Epoch: 32.37, Step: 128230, Train Loss: 1.1549, Learning Rate: 2.01e-05
2025-12-10 17:11:19 - INFO - Epoch: 32.38, Step: 128240, Train Loss: 1.1504, Learning Rate: 2.01e-05
2025-12-10 17:11:35 - INFO - Epoch: 32.38, Step: 128250, Train Loss: 1.1313, Learning Rate: 2.01e-05
2025-12-10 17:11:50 - INFO - Epoch: 32.38, Step: 128260, Train Loss: 1.1545, Learning Rate: 2.01e-05
2025-12-10 17:12:06 - INFO - Epoch: 32.38, Step: 128270, Train Loss: 1.1783, Learning Rate: 2.00e-05
2025-12-10 17:12:22 - INFO - Epoch: 32.39, Step: 128280, Train Loss: 1.1833, Learning Rate: 2.00e-05
2025-12-10 17:12:38 - INFO - Epoch: 32.39, Step: 128290, Train Loss: 1.1375, Learning Rate: 2.00e-05
2025-12-10 17:12:53 - INFO - Epoch: 32.39, Step: 128300, Train Loss: 1.1591, Learning Rate: 2.00e-05
2025-12-10 17:13:09 - INFO - Epoch: 32.39, Step: 128310, Train Loss: 1.1626, Learning Rate: 2.00e-05
2025-12-10 17:13:25 - INFO - Epoch: 32.40, Step: 128320, Train Loss: 1.1434, Learning Rate: 2.00e-05
2025-12-10 17:13:41 - INFO - Epoch: 32.40, Step: 128330, Train Loss: 1.1650, Learning Rate: 2.00e-05
2025-12-10 17:13:56 - INFO - Epoch: 32.40, Step: 128340, Train Loss: 1.1445, Learning Rate: 2.00e-05
2025-12-10 17:14:12 - INFO - Epoch: 32.40, Step: 128350, Train Loss: 1.1300, Learning Rate: 2.00e-05
2025-12-10 17:14:28 - INFO - Epoch: 32.41, Step: 128360, Train Loss: 1.1722, Learning Rate: 2.00e-05
2025-12-10 17:14:44 - INFO - Epoch: 32.41, Step: 128370, Train Loss: 1.1916, Learning Rate: 2.00e-05
2025-12-10 17:14:59 - INFO - Epoch: 32.41, Step: 128380, Train Loss: 1.1776, Learning Rate: 2.00e-05
2025-12-10 17:15:15 - INFO - Epoch: 32.41, Step: 128390, Train Loss: 1.1544, Learning Rate: 2.00e-05
2025-12-10 17:15:31 - INFO - Epoch: 32.42, Step: 128400, Train Loss: 1.1609, Learning Rate: 2.00e-05
2025-12-10 17:15:47 - INFO - Epoch: 32.42, Step: 128410, Train Loss: 1.1495, Learning Rate: 2.00e-05
2025-12-10 17:16:02 - INFO - Epoch: 32.42, Step: 128420, Train Loss: 1.1418, Learning Rate: 1.99e-05
2025-12-10 17:16:18 - INFO - Epoch: 32.42, Step: 128430, Train Loss: 1.1065, Learning Rate: 1.99e-05
2025-12-10 17:16:34 - INFO - Epoch: 32.43, Step: 128440, Train Loss: 1.2002, Learning Rate: 1.99e-05
2025-12-10 17:16:50 - INFO - Epoch: 32.43, Step: 128450, Train Loss: 1.1404, Learning Rate: 1.99e-05
2025-12-10 17:17:05 - INFO - Epoch: 32.43, Step: 128460, Train Loss: 1.1319, Learning Rate: 1.99e-05
2025-12-10 17:17:21 - INFO - Epoch: 32.43, Step: 128470, Train Loss: 1.1593, Learning Rate: 1.99e-05
2025-12-10 17:17:37 - INFO - Epoch: 32.44, Step: 128480, Train Loss: 1.1777, Learning Rate: 1.99e-05
2025-12-10 17:17:53 - INFO - Epoch: 32.44, Step: 128490, Train Loss: 1.1542, Learning Rate: 1.99e-05
2025-12-10 17:18:08 - INFO - Epoch: 32.44, Step: 128500, Train Loss: 1.1922, Learning Rate: 1.99e-05
2025-12-10 17:18:24 - INFO - Epoch: 32.44, Step: 128510, Train Loss: 1.1454, Learning Rate: 1.99e-05
2025-12-10 17:18:40 - INFO - Epoch: 32.45, Step: 128520, Train Loss: 1.1531, Learning Rate: 1.99e-05
2025-12-10 17:18:55 - INFO - Epoch: 32.45, Step: 128530, Train Loss: 1.1565, Learning Rate: 1.99e-05
2025-12-10 17:19:11 - INFO - Epoch: 32.45, Step: 128540, Train Loss: 1.1260, Learning Rate: 1.99e-05
2025-12-10 17:19:27 - INFO - Epoch: 32.45, Step: 128550, Train Loss: 1.1206, Learning Rate: 1.99e-05
2025-12-10 17:19:43 - INFO - Epoch: 32.46, Step: 128560, Train Loss: 1.1696, Learning Rate: 1.99e-05
2025-12-10 17:19:58 - INFO - Epoch: 32.46, Step: 128570, Train Loss: 1.1369, Learning Rate: 1.98e-05
2025-12-10 17:20:14 - INFO - Epoch: 32.46, Step: 128580, Train Loss: 1.1500, Learning Rate: 1.98e-05
2025-12-10 17:20:30 - INFO - Epoch: 32.46, Step: 128590, Train Loss: 1.1736, Learning Rate: 1.98e-05
2025-12-10 17:20:46 - INFO - Epoch: 32.47, Step: 128600, Train Loss: 1.1643, Learning Rate: 1.98e-05
2025-12-10 17:21:01 - INFO - Epoch: 32.47, Step: 128610, Train Loss: 1.1674, Learning Rate: 1.98e-05
2025-12-10 17:21:17 - INFO - Epoch: 32.47, Step: 128620, Train Loss: 1.1409, Learning Rate: 1.98e-05
2025-12-10 17:21:33 - INFO - Epoch: 32.47, Step: 128630, Train Loss: 1.1687, Learning Rate: 1.98e-05
2025-12-10 17:21:49 - INFO - Epoch: 32.48, Step: 128640, Train Loss: 1.1431, Learning Rate: 1.98e-05
2025-12-10 17:22:04 - INFO - Epoch: 32.48, Step: 128650, Train Loss: 1.1416, Learning Rate: 1.98e-05
2025-12-10 17:22:20 - INFO - Epoch: 32.48, Step: 128660, Train Loss: 1.2133, Learning Rate: 1.98e-05
2025-12-10 17:22:36 - INFO - Epoch: 32.48, Step: 128670, Train Loss: 1.1743, Learning Rate: 1.98e-05
2025-12-10 17:22:52 - INFO - Epoch: 32.49, Step: 128680, Train Loss: 1.1314, Learning Rate: 1.98e-05
2025-12-10 17:23:07 - INFO - Epoch: 32.49, Step: 128690, Train Loss: 1.1440, Learning Rate: 1.98e-05
2025-12-10 17:23:23 - INFO - Epoch: 32.49, Step: 128700, Train Loss: 1.1813, Learning Rate: 1.98e-05
2025-12-10 17:23:39 - INFO - Epoch: 32.49, Step: 128710, Train Loss: 1.1417, Learning Rate: 1.98e-05
2025-12-10 17:23:55 - INFO - Epoch: 32.50, Step: 128720, Train Loss: 1.1489, Learning Rate: 1.97e-05
2025-12-10 17:24:10 - INFO - Epoch: 32.50, Step: 128730, Train Loss: 1.1853, Learning Rate: 1.97e-05
2025-12-10 17:24:26 - INFO - Epoch: 32.50, Step: 128740, Train Loss: 1.1402, Learning Rate: 1.97e-05
2025-12-10 17:24:42 - INFO - Epoch: 32.50, Step: 128750, Train Loss: 1.1836, Learning Rate: 1.97e-05
2025-12-10 17:24:58 - INFO - Epoch: 32.51, Step: 128760, Train Loss: 1.1608, Learning Rate: 1.97e-05
2025-12-10 17:25:13 - INFO - Epoch: 32.51, Step: 128770, Train Loss: 1.1429, Learning Rate: 1.97e-05
2025-12-10 17:25:29 - INFO - Epoch: 32.51, Step: 128780, Train Loss: 1.1693, Learning Rate: 1.97e-05
2025-12-10 17:25:45 - INFO - Epoch: 32.51, Step: 128790, Train Loss: 1.1463, Learning Rate: 1.97e-05
2025-12-10 17:26:01 - INFO - Epoch: 32.52, Step: 128800, Train Loss: 1.1413, Learning Rate: 1.97e-05
2025-12-10 17:26:16 - INFO - Epoch: 32.52, Step: 128810, Train Loss: 1.1343, Learning Rate: 1.97e-05
2025-12-10 17:26:32 - INFO - Epoch: 32.52, Step: 128820, Train Loss: 1.1481, Learning Rate: 1.97e-05
2025-12-10 17:26:48 - INFO - Epoch: 32.52, Step: 128830, Train Loss: 1.1478, Learning Rate: 1.97e-05
2025-12-10 17:27:03 - INFO - Epoch: 32.53, Step: 128840, Train Loss: 1.1397, Learning Rate: 1.97e-05
2025-12-10 17:27:19 - INFO - Epoch: 32.53, Step: 128850, Train Loss: 1.2023, Learning Rate: 1.97e-05
2025-12-10 17:27:35 - INFO - Epoch: 32.53, Step: 128860, Train Loss: 1.2115, Learning Rate: 1.97e-05
2025-12-10 17:27:51 - INFO - Epoch: 32.53, Step: 128870, Train Loss: 1.1338, Learning Rate: 1.96e-05
2025-12-10 17:28:06 - INFO - Epoch: 32.54, Step: 128880, Train Loss: 1.1672, Learning Rate: 1.96e-05
2025-12-10 17:28:22 - INFO - Epoch: 32.54, Step: 128890, Train Loss: 1.1592, Learning Rate: 1.96e-05
2025-12-10 17:28:38 - INFO - Epoch: 32.54, Step: 128900, Train Loss: 1.1841, Learning Rate: 1.96e-05
2025-12-10 17:28:54 - INFO - Epoch: 32.54, Step: 128910, Train Loss: 1.1520, Learning Rate: 1.96e-05
2025-12-10 17:29:09 - INFO - Epoch: 32.55, Step: 128920, Train Loss: 1.1273, Learning Rate: 1.96e-05
2025-12-10 17:29:25 - INFO - Epoch: 32.55, Step: 128930, Train Loss: 1.1569, Learning Rate: 1.96e-05
2025-12-10 17:29:41 - INFO - Epoch: 32.55, Step: 128940, Train Loss: 1.1474, Learning Rate: 1.96e-05
2025-12-10 17:29:57 - INFO - Epoch: 32.55, Step: 128950, Train Loss: 1.1694, Learning Rate: 1.96e-05
2025-12-10 17:30:12 - INFO - Epoch: 32.56, Step: 128960, Train Loss: 1.1716, Learning Rate: 1.96e-05
2025-12-10 17:30:28 - INFO - Epoch: 32.56, Step: 128970, Train Loss: 1.1530, Learning Rate: 1.96e-05
2025-12-10 17:30:44 - INFO - Epoch: 32.56, Step: 128980, Train Loss: 1.1631, Learning Rate: 1.96e-05
2025-12-10 17:31:00 - INFO - Epoch: 32.57, Step: 128990, Train Loss: 1.1402, Learning Rate: 1.96e-05
2025-12-10 17:31:15 - INFO - Epoch: 32.57, Step: 129000, Train Loss: 1.1862, Learning Rate: 1.96e-05
2025-12-10 17:31:31 - INFO - Epoch: 32.57, Step: 129010, Train Loss: 1.1679, Learning Rate: 1.96e-05
2025-12-10 17:31:47 - INFO - Epoch: 32.57, Step: 129020, Train Loss: 1.1392, Learning Rate: 1.95e-05
2025-12-10 17:32:03 - INFO - Epoch: 32.58, Step: 129030, Train Loss: 1.1498, Learning Rate: 1.95e-05
2025-12-10 17:32:18 - INFO - Epoch: 32.58, Step: 129040, Train Loss: 1.1868, Learning Rate: 1.95e-05
2025-12-10 17:32:34 - INFO - Epoch: 32.58, Step: 129050, Train Loss: 1.1919, Learning Rate: 1.95e-05
2025-12-10 17:32:50 - INFO - Epoch: 32.58, Step: 129060, Train Loss: 1.1599, Learning Rate: 1.95e-05
2025-12-10 17:33:06 - INFO - Epoch: 32.59, Step: 129070, Train Loss: 1.1704, Learning Rate: 1.95e-05
2025-12-10 17:33:21 - INFO - Epoch: 32.59, Step: 129080, Train Loss: 1.1236, Learning Rate: 1.95e-05
2025-12-10 17:33:37 - INFO - Epoch: 32.59, Step: 129090, Train Loss: 1.1751, Learning Rate: 1.95e-05
2025-12-10 17:33:53 - INFO - Epoch: 32.59, Step: 129100, Train Loss: 1.1341, Learning Rate: 1.95e-05
2025-12-10 17:34:09 - INFO - Epoch: 32.60, Step: 129110, Train Loss: 1.1660, Learning Rate: 1.95e-05
2025-12-10 17:34:24 - INFO - Epoch: 32.60, Step: 129120, Train Loss: 1.1227, Learning Rate: 1.95e-05
2025-12-10 17:34:40 - INFO - Epoch: 32.60, Step: 129130, Train Loss: 1.1146, Learning Rate: 1.95e-05
2025-12-10 17:34:56 - INFO - Epoch: 32.60, Step: 129140, Train Loss: 1.1746, Learning Rate: 1.95e-05
2025-12-10 17:35:11 - INFO - Epoch: 32.61, Step: 129150, Train Loss: 1.2056, Learning Rate: 1.95e-05
2025-12-10 17:35:27 - INFO - Epoch: 32.61, Step: 129160, Train Loss: 1.1608, Learning Rate: 1.95e-05
2025-12-10 17:35:43 - INFO - Epoch: 32.61, Step: 129170, Train Loss: 1.1630, Learning Rate: 1.94e-05
2025-12-10 17:35:59 - INFO - Epoch: 32.61, Step: 129180, Train Loss: 1.1389, Learning Rate: 1.94e-05
2025-12-10 17:36:14 - INFO - Epoch: 32.62, Step: 129190, Train Loss: 1.1622, Learning Rate: 1.94e-05
2025-12-10 17:36:30 - INFO - Epoch: 32.62, Step: 129200, Train Loss: 1.1333, Learning Rate: 1.94e-05
2025-12-10 17:36:46 - INFO - Epoch: 32.62, Step: 129210, Train Loss: 1.1225, Learning Rate: 1.94e-05
2025-12-10 17:37:02 - INFO - Epoch: 32.62, Step: 129220, Train Loss: 1.1564, Learning Rate: 1.94e-05
2025-12-10 17:37:17 - INFO - Epoch: 32.63, Step: 129230, Train Loss: 1.1627, Learning Rate: 1.94e-05
2025-12-10 17:37:33 - INFO - Epoch: 32.63, Step: 129240, Train Loss: 1.1378, Learning Rate: 1.94e-05
2025-12-10 17:37:49 - INFO - Epoch: 32.63, Step: 129250, Train Loss: 1.1232, Learning Rate: 1.94e-05
2025-12-10 17:38:05 - INFO - Epoch: 32.63, Step: 129260, Train Loss: 1.1622, Learning Rate: 1.94e-05
2025-12-10 17:38:20 - INFO - Epoch: 32.64, Step: 129270, Train Loss: 1.1318, Learning Rate: 1.94e-05
2025-12-10 17:38:36 - INFO - Epoch: 32.64, Step: 129280, Train Loss: 1.1752, Learning Rate: 1.94e-05
2025-12-10 17:38:52 - INFO - Epoch: 32.64, Step: 129290, Train Loss: 1.1397, Learning Rate: 1.94e-05
2025-12-10 17:39:08 - INFO - Epoch: 32.64, Step: 129300, Train Loss: 1.1454, Learning Rate: 1.94e-05
2025-12-10 17:39:23 - INFO - Epoch: 32.65, Step: 129310, Train Loss: 1.1605, Learning Rate: 1.94e-05
2025-12-10 17:39:39 - INFO - Epoch: 32.65, Step: 129320, Train Loss: 1.1195, Learning Rate: 1.93e-05
2025-12-10 17:39:55 - INFO - Epoch: 32.65, Step: 129330, Train Loss: 1.1884, Learning Rate: 1.93e-05
2025-12-10 17:40:11 - INFO - Epoch: 32.65, Step: 129340, Train Loss: 1.1575, Learning Rate: 1.93e-05
2025-12-10 17:40:26 - INFO - Epoch: 32.66, Step: 129350, Train Loss: 1.1490, Learning Rate: 1.93e-05
2025-12-10 17:40:42 - INFO - Epoch: 32.66, Step: 129360, Train Loss: 1.1579, Learning Rate: 1.93e-05
2025-12-10 17:40:58 - INFO - Epoch: 32.66, Step: 129370, Train Loss: 1.1656, Learning Rate: 1.93e-05
2025-12-10 17:41:14 - INFO - Epoch: 32.66, Step: 129380, Train Loss: 1.1580, Learning Rate: 1.93e-05
2025-12-10 17:41:29 - INFO - Epoch: 32.67, Step: 129390, Train Loss: 1.1514, Learning Rate: 1.93e-05
2025-12-10 17:41:45 - INFO - Epoch: 32.67, Step: 129400, Train Loss: 1.1455, Learning Rate: 1.93e-05
2025-12-10 17:42:01 - INFO - Epoch: 32.67, Step: 129410, Train Loss: 1.1484, Learning Rate: 1.93e-05
2025-12-10 17:42:17 - INFO - Epoch: 32.67, Step: 129420, Train Loss: 1.1501, Learning Rate: 1.93e-05
2025-12-10 17:42:32 - INFO - Epoch: 32.68, Step: 129430, Train Loss: 1.1784, Learning Rate: 1.93e-05
2025-12-10 17:42:48 - INFO - Epoch: 32.68, Step: 129440, Train Loss: 1.1967, Learning Rate: 1.93e-05
2025-12-10 17:43:04 - INFO - Epoch: 32.68, Step: 129450, Train Loss: 1.1711, Learning Rate: 1.93e-05
2025-12-10 17:43:19 - INFO - Epoch: 32.68, Step: 129460, Train Loss: 1.1832, Learning Rate: 1.93e-05
2025-12-10 17:43:35 - INFO - Epoch: 32.69, Step: 129470, Train Loss: 1.1835, Learning Rate: 1.92e-05
2025-12-10 17:43:51 - INFO - Epoch: 32.69, Step: 129480, Train Loss: 1.1463, Learning Rate: 1.92e-05
2025-12-10 17:44:07 - INFO - Epoch: 32.69, Step: 129490, Train Loss: 1.1299, Learning Rate: 1.92e-05
2025-12-10 17:44:22 - INFO - Epoch: 32.69, Step: 129500, Train Loss: 1.1365, Learning Rate: 1.92e-05
2025-12-10 17:44:38 - INFO - Epoch: 32.70, Step: 129510, Train Loss: 1.1599, Learning Rate: 1.92e-05
2025-12-10 17:44:54 - INFO - Epoch: 32.70, Step: 129520, Train Loss: 1.1799, Learning Rate: 1.92e-05
2025-12-10 17:45:10 - INFO - Epoch: 32.70, Step: 129530, Train Loss: 1.1833, Learning Rate: 1.92e-05
2025-12-10 17:45:25 - INFO - Epoch: 32.70, Step: 129540, Train Loss: 1.1594, Learning Rate: 1.92e-05
2025-12-10 17:45:41 - INFO - Epoch: 32.71, Step: 129550, Train Loss: 1.1451, Learning Rate: 1.92e-05
2025-12-10 17:45:57 - INFO - Epoch: 32.71, Step: 129560, Train Loss: 1.1498, Learning Rate: 1.92e-05
2025-12-10 17:46:13 - INFO - Epoch: 32.71, Step: 129570, Train Loss: 1.1993, Learning Rate: 1.92e-05
2025-12-10 17:46:28 - INFO - Epoch: 32.71, Step: 129580, Train Loss: 1.1461, Learning Rate: 1.92e-05
2025-12-10 17:46:44 - INFO - Epoch: 32.72, Step: 129590, Train Loss: 1.1515, Learning Rate: 1.92e-05
2025-12-10 17:47:00 - INFO - Epoch: 32.72, Step: 129600, Train Loss: 1.1408, Learning Rate: 1.92e-05
2025-12-10 17:47:16 - INFO - Epoch: 32.72, Step: 129610, Train Loss: 1.1468, Learning Rate: 1.92e-05
2025-12-10 17:47:31 - INFO - Epoch: 32.72, Step: 129620, Train Loss: 1.1444, Learning Rate: 1.91e-05
2025-12-10 17:47:47 - INFO - Epoch: 32.73, Step: 129630, Train Loss: 1.1515, Learning Rate: 1.91e-05
2025-12-10 17:48:03 - INFO - Epoch: 32.73, Step: 129640, Train Loss: 1.1633, Learning Rate: 1.91e-05
2025-12-10 17:48:19 - INFO - Epoch: 32.73, Step: 129650, Train Loss: 1.1982, Learning Rate: 1.91e-05
2025-12-10 17:48:34 - INFO - Epoch: 32.73, Step: 129660, Train Loss: 1.1804, Learning Rate: 1.91e-05
2025-12-10 17:48:50 - INFO - Epoch: 32.74, Step: 129670, Train Loss: 1.1706, Learning Rate: 1.91e-05
2025-12-10 17:49:06 - INFO - Epoch: 32.74, Step: 129680, Train Loss: 1.1239, Learning Rate: 1.91e-05
2025-12-10 17:49:22 - INFO - Epoch: 32.74, Step: 129690, Train Loss: 1.1590, Learning Rate: 1.91e-05
2025-12-10 17:49:37 - INFO - Epoch: 32.74, Step: 129700, Train Loss: 1.1233, Learning Rate: 1.91e-05
2025-12-10 17:49:53 - INFO - Epoch: 32.75, Step: 129710, Train Loss: 1.1729, Learning Rate: 1.91e-05
2025-12-10 17:50:09 - INFO - Epoch: 32.75, Step: 129720, Train Loss: 1.1440, Learning Rate: 1.91e-05
2025-12-10 17:50:25 - INFO - Epoch: 32.75, Step: 129730, Train Loss: 1.1497, Learning Rate: 1.91e-05
2025-12-10 17:50:40 - INFO - Epoch: 32.75, Step: 129740, Train Loss: 1.1547, Learning Rate: 1.91e-05
2025-12-10 17:50:56 - INFO - Epoch: 32.76, Step: 129750, Train Loss: 1.1685, Learning Rate: 1.91e-05
2025-12-10 17:51:12 - INFO - Epoch: 32.76, Step: 129760, Train Loss: 1.1631, Learning Rate: 1.91e-05
2025-12-10 17:51:27 - INFO - Epoch: 32.76, Step: 129770, Train Loss: 1.1533, Learning Rate: 1.90e-05
2025-12-10 17:51:43 - INFO - Epoch: 32.76, Step: 129780, Train Loss: 1.1646, Learning Rate: 1.90e-05
2025-12-10 17:51:59 - INFO - Epoch: 32.77, Step: 129790, Train Loss: 1.1968, Learning Rate: 1.90e-05
2025-12-10 17:52:15 - INFO - Epoch: 32.77, Step: 129800, Train Loss: 1.1296, Learning Rate: 1.90e-05
2025-12-10 17:52:30 - INFO - Epoch: 32.77, Step: 129810, Train Loss: 1.1406, Learning Rate: 1.90e-05
2025-12-10 17:52:46 - INFO - Epoch: 32.77, Step: 129820, Train Loss: 1.1333, Learning Rate: 1.90e-05
2025-12-10 17:53:02 - INFO - Epoch: 32.78, Step: 129830, Train Loss: 1.1555, Learning Rate: 1.90e-05
2025-12-10 17:53:18 - INFO - Epoch: 32.78, Step: 129840, Train Loss: 1.1511, Learning Rate: 1.90e-05
2025-12-10 17:53:33 - INFO - Epoch: 32.78, Step: 129850, Train Loss: 1.2080, Learning Rate: 1.90e-05
2025-12-10 17:53:49 - INFO - Epoch: 32.78, Step: 129860, Train Loss: 1.1455, Learning Rate: 1.90e-05
2025-12-10 17:54:05 - INFO - Epoch: 32.79, Step: 129870, Train Loss: 1.1708, Learning Rate: 1.90e-05
2025-12-10 17:54:21 - INFO - Epoch: 32.79, Step: 129880, Train Loss: 1.1430, Learning Rate: 1.90e-05
2025-12-10 17:54:36 - INFO - Epoch: 32.79, Step: 129890, Train Loss: 1.1469, Learning Rate: 1.90e-05
2025-12-10 17:54:52 - INFO - Epoch: 32.79, Step: 129900, Train Loss: 1.1332, Learning Rate: 1.90e-05
2025-12-10 17:55:08 - INFO - Epoch: 32.80, Step: 129910, Train Loss: 1.1494, Learning Rate: 1.90e-05
2025-12-10 17:55:24 - INFO - Epoch: 32.80, Step: 129920, Train Loss: 1.1606, Learning Rate: 1.89e-05
2025-12-10 17:55:39 - INFO - Epoch: 32.80, Step: 129930, Train Loss: 1.1331, Learning Rate: 1.89e-05
2025-12-10 17:55:55 - INFO - Epoch: 32.80, Step: 129940, Train Loss: 1.1757, Learning Rate: 1.89e-05
2025-12-10 17:56:11 - INFO - Epoch: 32.81, Step: 129950, Train Loss: 1.1629, Learning Rate: 1.89e-05
2025-12-10 17:56:27 - INFO - Epoch: 32.81, Step: 129960, Train Loss: 1.1918, Learning Rate: 1.89e-05
2025-12-10 17:56:42 - INFO - Epoch: 32.81, Step: 129970, Train Loss: 1.1548, Learning Rate: 1.89e-05
2025-12-10 17:56:58 - INFO - Epoch: 32.81, Step: 129980, Train Loss: 1.1829, Learning Rate: 1.89e-05
2025-12-10 17:57:14 - INFO - Epoch: 32.82, Step: 129990, Train Loss: 1.1678, Learning Rate: 1.89e-05
2025-12-10 17:57:30 - INFO - Epoch: 32.82, Step: 130000, Train Loss: 1.1305, Learning Rate: 1.89e-05
2025-12-10 17:57:45 - INFO - Epoch: 32.82, Step: 130010, Train Loss: 1.1694, Learning Rate: 1.89e-05
2025-12-10 17:58:01 - INFO - Epoch: 32.83, Step: 130020, Train Loss: 1.1440, Learning Rate: 1.89e-05
2025-12-10 17:58:17 - INFO - Epoch: 32.83, Step: 130030, Train Loss: 1.1201, Learning Rate: 1.89e-05
2025-12-10 17:58:33 - INFO - Epoch: 32.83, Step: 130040, Train Loss: 1.1353, Learning Rate: 1.89e-05
2025-12-10 17:58:48 - INFO - Epoch: 32.83, Step: 130050, Train Loss: 1.1414, Learning Rate: 1.89e-05
2025-12-10 17:59:04 - INFO - Epoch: 32.84, Step: 130060, Train Loss: 1.1482, Learning Rate: 1.89e-05
2025-12-10 17:59:20 - INFO - Epoch: 32.84, Step: 130070, Train Loss: 1.1436, Learning Rate: 1.88e-05
2025-12-10 17:59:35 - INFO - Epoch: 32.84, Step: 130080, Train Loss: 1.1739, Learning Rate: 1.88e-05
2025-12-10 17:59:51 - INFO - Epoch: 32.84, Step: 130090, Train Loss: 1.1994, Learning Rate: 1.88e-05
2025-12-10 18:00:07 - INFO - Epoch: 32.85, Step: 130100, Train Loss: 1.1597, Learning Rate: 1.88e-05
2025-12-10 18:00:23 - INFO - Epoch: 32.85, Step: 130110, Train Loss: 1.1707, Learning Rate: 1.88e-05
2025-12-10 18:00:38 - INFO - Epoch: 32.85, Step: 130120, Train Loss: 1.1398, Learning Rate: 1.88e-05
2025-12-10 18:00:54 - INFO - Epoch: 32.85, Step: 130130, Train Loss: 1.1707, Learning Rate: 1.88e-05
2025-12-10 18:01:10 - INFO - Epoch: 32.86, Step: 130140, Train Loss: 1.1541, Learning Rate: 1.88e-05
2025-12-10 18:01:26 - INFO - Epoch: 32.86, Step: 130150, Train Loss: 1.1680, Learning Rate: 1.88e-05
2025-12-10 18:01:41 - INFO - Epoch: 32.86, Step: 130160, Train Loss: 1.1330, Learning Rate: 1.88e-05
2025-12-10 18:01:57 - INFO - Epoch: 32.86, Step: 130170, Train Loss: 1.1384, Learning Rate: 1.88e-05
2025-12-10 18:02:13 - INFO - Epoch: 32.87, Step: 130180, Train Loss: 1.1549, Learning Rate: 1.88e-05
2025-12-10 18:02:29 - INFO - Epoch: 32.87, Step: 130190, Train Loss: 1.1487, Learning Rate: 1.88e-05
2025-12-10 18:02:44 - INFO - Epoch: 32.87, Step: 130200, Train Loss: 1.1628, Learning Rate: 1.88e-05
2025-12-10 18:03:00 - INFO - Epoch: 32.87, Step: 130210, Train Loss: 1.1619, Learning Rate: 1.88e-05
2025-12-10 18:03:16 - INFO - Epoch: 32.88, Step: 130220, Train Loss: 1.1589, Learning Rate: 1.87e-05
2025-12-10 18:03:32 - INFO - Epoch: 32.88, Step: 130230, Train Loss: 1.1653, Learning Rate: 1.87e-05
2025-12-10 18:03:47 - INFO - Epoch: 32.88, Step: 130240, Train Loss: 1.1573, Learning Rate: 1.87e-05
2025-12-10 18:04:03 - INFO - Epoch: 32.88, Step: 130250, Train Loss: 1.1263, Learning Rate: 1.87e-05
2025-12-10 18:04:19 - INFO - Epoch: 32.89, Step: 130260, Train Loss: 1.1717, Learning Rate: 1.87e-05
2025-12-10 18:04:35 - INFO - Epoch: 32.89, Step: 130270, Train Loss: 1.1653, Learning Rate: 1.87e-05
2025-12-10 18:04:50 - INFO - Epoch: 32.89, Step: 130280, Train Loss: 1.1461, Learning Rate: 1.87e-05
2025-12-10 18:05:06 - INFO - Epoch: 32.89, Step: 130290, Train Loss: 1.1310, Learning Rate: 1.87e-05
2025-12-10 18:05:22 - INFO - Epoch: 32.90, Step: 130300, Train Loss: 1.1492, Learning Rate: 1.87e-05
2025-12-10 18:05:38 - INFO - Epoch: 32.90, Step: 130310, Train Loss: 1.1793, Learning Rate: 1.87e-05
2025-12-10 18:05:53 - INFO - Epoch: 32.90, Step: 130320, Train Loss: 1.1524, Learning Rate: 1.87e-05
2025-12-10 18:06:09 - INFO - Epoch: 32.90, Step: 130330, Train Loss: 1.1583, Learning Rate: 1.87e-05
2025-12-10 18:06:25 - INFO - Epoch: 32.91, Step: 130340, Train Loss: 1.1396, Learning Rate: 1.87e-05
2025-12-10 18:06:41 - INFO - Epoch: 32.91, Step: 130350, Train Loss: 1.1824, Learning Rate: 1.87e-05
2025-12-10 18:06:56 - INFO - Epoch: 32.91, Step: 130360, Train Loss: 1.1685, Learning Rate: 1.87e-05
2025-12-10 18:07:12 - INFO - Epoch: 32.91, Step: 130370, Train Loss: 1.1071, Learning Rate: 1.86e-05
2025-12-10 18:07:28 - INFO - Epoch: 32.92, Step: 130380, Train Loss: 1.1568, Learning Rate: 1.86e-05
2025-12-10 18:07:43 - INFO - Epoch: 32.92, Step: 130390, Train Loss: 1.1367, Learning Rate: 1.86e-05
2025-12-10 18:07:59 - INFO - Epoch: 32.92, Step: 130400, Train Loss: 1.1774, Learning Rate: 1.86e-05
2025-12-10 18:08:15 - INFO - Epoch: 32.92, Step: 130410, Train Loss: 1.1288, Learning Rate: 1.86e-05
2025-12-10 18:08:31 - INFO - Epoch: 32.93, Step: 130420, Train Loss: 1.1302, Learning Rate: 1.86e-05
2025-12-10 18:08:46 - INFO - Epoch: 32.93, Step: 130430, Train Loss: 1.1493, Learning Rate: 1.86e-05
2025-12-10 18:09:02 - INFO - Epoch: 32.93, Step: 130440, Train Loss: 1.1920, Learning Rate: 1.86e-05
2025-12-10 18:09:18 - INFO - Epoch: 32.93, Step: 130450, Train Loss: 1.1674, Learning Rate: 1.86e-05
2025-12-10 18:09:34 - INFO - Epoch: 32.94, Step: 130460, Train Loss: 1.1376, Learning Rate: 1.86e-05
2025-12-10 18:09:49 - INFO - Epoch: 32.94, Step: 130470, Train Loss: 1.1752, Learning Rate: 1.86e-05
2025-12-10 18:10:05 - INFO - Epoch: 32.94, Step: 130480, Train Loss: 1.1600, Learning Rate: 1.86e-05
2025-12-10 18:10:21 - INFO - Epoch: 32.94, Step: 130490, Train Loss: 1.1737, Learning Rate: 1.86e-05
2025-12-10 18:10:37 - INFO - Epoch: 32.95, Step: 130500, Train Loss: 1.1674, Learning Rate: 1.86e-05
2025-12-10 18:10:52 - INFO - Epoch: 32.95, Step: 130510, Train Loss: 1.1815, Learning Rate: 1.86e-05
2025-12-10 18:11:08 - INFO - Epoch: 32.95, Step: 130520, Train Loss: 1.1770, Learning Rate: 1.85e-05
2025-12-10 18:11:24 - INFO - Epoch: 32.95, Step: 130530, Train Loss: 1.1420, Learning Rate: 1.85e-05
2025-12-10 18:11:40 - INFO - Epoch: 32.96, Step: 130540, Train Loss: 1.1702, Learning Rate: 1.85e-05
2025-12-10 18:11:55 - INFO - Epoch: 32.96, Step: 130550, Train Loss: 1.1804, Learning Rate: 1.85e-05
2025-12-10 18:12:11 - INFO - Epoch: 32.96, Step: 130560, Train Loss: 1.1326, Learning Rate: 1.85e-05
2025-12-10 18:12:27 - INFO - Epoch: 32.96, Step: 130570, Train Loss: 1.2106, Learning Rate: 1.85e-05
2025-12-10 18:12:43 - INFO - Epoch: 32.97, Step: 130580, Train Loss: 1.1810, Learning Rate: 1.85e-05
2025-12-10 18:12:58 - INFO - Epoch: 32.97, Step: 130590, Train Loss: 1.1677, Learning Rate: 1.85e-05
2025-12-10 18:13:14 - INFO - Epoch: 32.97, Step: 130600, Train Loss: 1.1497, Learning Rate: 1.85e-05
2025-12-10 18:13:30 - INFO - Epoch: 32.97, Step: 130610, Train Loss: 1.1459, Learning Rate: 1.85e-05
2025-12-10 18:13:46 - INFO - Epoch: 32.98, Step: 130620, Train Loss: 1.1498, Learning Rate: 1.85e-05
2025-12-10 18:14:01 - INFO - Epoch: 32.98, Step: 130630, Train Loss: 1.1633, Learning Rate: 1.85e-05
2025-12-10 18:14:17 - INFO - Epoch: 32.98, Step: 130640, Train Loss: 1.1640, Learning Rate: 1.85e-05
2025-12-10 18:14:33 - INFO - Epoch: 32.98, Step: 130650, Train Loss: 1.1838, Learning Rate: 1.85e-05
2025-12-10 18:14:49 - INFO - Epoch: 32.99, Step: 130660, Train Loss: 1.1650, Learning Rate: 1.85e-05
2025-12-10 18:15:04 - INFO - Epoch: 32.99, Step: 130670, Train Loss: 1.1575, Learning Rate: 1.85e-05
2025-12-10 18:15:20 - INFO - Epoch: 32.99, Step: 130680, Train Loss: 1.1764, Learning Rate: 1.84e-05
2025-12-10 18:15:36 - INFO - Epoch: 32.99, Step: 130690, Train Loss: 1.1577, Learning Rate: 1.84e-05
2025-12-10 18:15:51 - INFO - Epoch: 33.00, Step: 130700, Train Loss: 1.1468, Learning Rate: 1.84e-05
2025-12-10 18:16:07 - INFO - Epoch: 33.00, Step: 130710, Train Loss: 1.1662, Learning Rate: 1.84e-05
2025-12-10 18:16:21 - INFO - Epoch: 33.00, Step: 130720, Train Loss: 1.1240, Learning Rate: 1.84e-05
2025-12-10 18:16:35 - INFO - Epoch: 33.00, Step: 130730, Train Loss: 1.1378, Learning Rate: 1.84e-05
2025-12-10 18:16:48 - INFO - Epoch: 33.01, Step: 130740, Train Loss: 1.1544, Learning Rate: 1.84e-05
2025-12-10 18:17:02 - INFO - Epoch: 33.01, Step: 130750, Train Loss: 1.1448, Learning Rate: 1.84e-05
2025-12-10 18:17:15 - INFO - Epoch: 33.01, Step: 130760, Train Loss: 1.1576, Learning Rate: 1.84e-05
2025-12-10 18:17:29 - INFO - Epoch: 33.01, Step: 130770, Train Loss: 1.1518, Learning Rate: 1.84e-05
2025-12-10 18:17:42 - INFO - Epoch: 33.02, Step: 130780, Train Loss: 1.1675, Learning Rate: 1.84e-05
2025-12-10 18:17:55 - INFO - Epoch: 33.02, Step: 130790, Train Loss: 1.1786, Learning Rate: 1.84e-05
2025-12-10 18:18:09 - INFO - Epoch: 33.02, Step: 130800, Train Loss: 1.1409, Learning Rate: 1.84e-05
2025-12-10 18:18:22 - INFO - Epoch: 33.02, Step: 130810, Train Loss: 1.1831, Learning Rate: 1.84e-05
2025-12-10 18:18:36 - INFO - Epoch: 33.03, Step: 130820, Train Loss: 1.1572, Learning Rate: 1.84e-05
2025-12-10 18:18:49 - INFO - Epoch: 33.03, Step: 130830, Train Loss: 1.1797, Learning Rate: 1.83e-05
2025-12-10 18:19:03 - INFO - Epoch: 33.03, Step: 130840, Train Loss: 1.1183, Learning Rate: 1.83e-05
2025-12-10 18:19:16 - INFO - Epoch: 33.03, Step: 130850, Train Loss: 1.1682, Learning Rate: 1.83e-05
2025-12-10 18:19:29 - INFO - Epoch: 33.04, Step: 130860, Train Loss: 1.2052, Learning Rate: 1.83e-05
2025-12-10 18:19:43 - INFO - Epoch: 33.04, Step: 130870, Train Loss: 1.1676, Learning Rate: 1.83e-05
2025-12-10 18:19:56 - INFO - Epoch: 33.04, Step: 130880, Train Loss: 1.1226, Learning Rate: 1.83e-05
2025-12-10 18:20:10 - INFO - Epoch: 33.04, Step: 130890, Train Loss: 1.1437, Learning Rate: 1.83e-05
2025-12-10 18:20:23 - INFO - Epoch: 33.05, Step: 130900, Train Loss: 1.1144, Learning Rate: 1.83e-05
2025-12-10 18:20:37 - INFO - Epoch: 33.05, Step: 130910, Train Loss: 1.1567, Learning Rate: 1.83e-05
2025-12-10 18:20:50 - INFO - Epoch: 33.05, Step: 130920, Train Loss: 1.1565, Learning Rate: 1.83e-05
2025-12-10 18:21:03 - INFO - Epoch: 33.05, Step: 130930, Train Loss: 1.1694, Learning Rate: 1.83e-05
2025-12-10 18:21:17 - INFO - Epoch: 33.06, Step: 130940, Train Loss: 1.2150, Learning Rate: 1.83e-05
2025-12-10 18:21:30 - INFO - Epoch: 33.06, Step: 130950, Train Loss: 1.1735, Learning Rate: 1.83e-05
2025-12-10 18:21:44 - INFO - Epoch: 33.06, Step: 130960, Train Loss: 1.2158, Learning Rate: 1.83e-05
2025-12-10 18:21:57 - INFO - Epoch: 33.06, Step: 130970, Train Loss: 1.1311, Learning Rate: 1.83e-05
2025-12-10 18:22:11 - INFO - Epoch: 33.07, Step: 130980, Train Loss: 1.1398, Learning Rate: 1.82e-05
2025-12-10 18:22:24 - INFO - Epoch: 33.07, Step: 130990, Train Loss: 1.1407, Learning Rate: 1.82e-05
2025-12-10 18:22:38 - INFO - Epoch: 33.07, Step: 131000, Train Loss: 1.1564, Learning Rate: 1.82e-05
2025-12-10 18:22:51 - INFO - Epoch: 33.07, Step: 131010, Train Loss: 1.1817, Learning Rate: 1.82e-05
2025-12-10 18:23:04 - INFO - Epoch: 33.08, Step: 131020, Train Loss: 1.1593, Learning Rate: 1.82e-05
2025-12-10 18:23:18 - INFO - Epoch: 33.08, Step: 131030, Train Loss: 1.1429, Learning Rate: 1.82e-05
2025-12-10 18:23:31 - INFO - Epoch: 33.08, Step: 131040, Train Loss: 1.1441, Learning Rate: 1.82e-05
2025-12-10 18:23:45 - INFO - Epoch: 33.09, Step: 131050, Train Loss: 1.1616, Learning Rate: 1.82e-05
2025-12-10 18:23:58 - INFO - Epoch: 33.09, Step: 131060, Train Loss: 1.1624, Learning Rate: 1.82e-05
2025-12-10 18:24:12 - INFO - Epoch: 33.09, Step: 131070, Train Loss: 1.1300, Learning Rate: 1.82e-05
2025-12-10 18:24:25 - INFO - Epoch: 33.09, Step: 131080, Train Loss: 1.1488, Learning Rate: 1.82e-05
2025-12-10 18:24:38 - INFO - Epoch: 33.10, Step: 131090, Train Loss: 1.1590, Learning Rate: 1.82e-05
2025-12-10 18:24:52 - INFO - Epoch: 33.10, Step: 131100, Train Loss: 1.1321, Learning Rate: 1.82e-05
2025-12-10 18:25:05 - INFO - Epoch: 33.10, Step: 131110, Train Loss: 1.1371, Learning Rate: 1.82e-05
2025-12-10 18:25:19 - INFO - Epoch: 33.10, Step: 131120, Train Loss: 1.1710, Learning Rate: 1.82e-05
2025-12-10 18:25:32 - INFO - Epoch: 33.11, Step: 131130, Train Loss: 1.1733, Learning Rate: 1.81e-05
2025-12-10 18:25:46 - INFO - Epoch: 33.11, Step: 131140, Train Loss: 1.1585, Learning Rate: 1.81e-05
2025-12-10 18:25:59 - INFO - Epoch: 33.11, Step: 131150, Train Loss: 1.1749, Learning Rate: 1.81e-05
2025-12-10 18:26:12 - INFO - Epoch: 33.11, Step: 131160, Train Loss: 1.1691, Learning Rate: 1.81e-05
2025-12-10 18:26:26 - INFO - Epoch: 33.12, Step: 131170, Train Loss: 1.1352, Learning Rate: 1.81e-05
2025-12-10 18:26:39 - INFO - Epoch: 33.12, Step: 131180, Train Loss: 1.1435, Learning Rate: 1.81e-05
2025-12-10 18:26:53 - INFO - Epoch: 33.12, Step: 131190, Train Loss: 1.1355, Learning Rate: 1.81e-05
2025-12-10 18:27:06 - INFO - Epoch: 33.12, Step: 131200, Train Loss: 1.1346, Learning Rate: 1.81e-05
2025-12-10 18:27:20 - INFO - Epoch: 33.13, Step: 131210, Train Loss: 1.1698, Learning Rate: 1.81e-05
2025-12-10 18:27:33 - INFO - Epoch: 33.13, Step: 131220, Train Loss: 1.1655, Learning Rate: 1.81e-05
2025-12-10 18:27:47 - INFO - Epoch: 33.13, Step: 131230, Train Loss: 1.1684, Learning Rate: 1.81e-05
2025-12-10 18:28:00 - INFO - Epoch: 33.13, Step: 131240, Train Loss: 1.1757, Learning Rate: 1.81e-05
2025-12-10 18:28:13 - INFO - Epoch: 33.14, Step: 131250, Train Loss: 1.1495, Learning Rate: 1.81e-05
2025-12-10 18:28:27 - INFO - Epoch: 33.14, Step: 131260, Train Loss: 1.1394, Learning Rate: 1.81e-05
2025-12-10 18:28:40 - INFO - Epoch: 33.14, Step: 131270, Train Loss: 1.1422, Learning Rate: 1.81e-05
2025-12-10 18:28:54 - INFO - Epoch: 33.14, Step: 131280, Train Loss: 1.2018, Learning Rate: 1.80e-05
2025-12-10 18:29:07 - INFO - Epoch: 33.15, Step: 131290, Train Loss: 1.1722, Learning Rate: 1.80e-05
2025-12-10 18:29:21 - INFO - Epoch: 33.15, Step: 131300, Train Loss: 1.1452, Learning Rate: 1.80e-05
2025-12-10 18:29:34 - INFO - Epoch: 33.15, Step: 131310, Train Loss: 1.1681, Learning Rate: 1.80e-05
2025-12-10 18:29:47 - INFO - Epoch: 33.15, Step: 131320, Train Loss: 1.1605, Learning Rate: 1.80e-05
2025-12-10 18:30:01 - INFO - Epoch: 33.16, Step: 131330, Train Loss: 1.1663, Learning Rate: 1.80e-05
2025-12-10 18:30:14 - INFO - Epoch: 33.16, Step: 131340, Train Loss: 1.1724, Learning Rate: 1.80e-05
2025-12-10 18:30:28 - INFO - Epoch: 33.16, Step: 131350, Train Loss: 1.1536, Learning Rate: 1.80e-05
2025-12-10 18:30:41 - INFO - Epoch: 33.16, Step: 131360, Train Loss: 1.1930, Learning Rate: 1.80e-05
2025-12-10 18:30:55 - INFO - Epoch: 33.17, Step: 131370, Train Loss: 1.1849, Learning Rate: 1.80e-05
2025-12-10 18:31:08 - INFO - Epoch: 33.17, Step: 131380, Train Loss: 1.1467, Learning Rate: 1.80e-05
2025-12-10 18:31:21 - INFO - Epoch: 33.17, Step: 131390, Train Loss: 1.1621, Learning Rate: 1.80e-05
2025-12-10 18:31:35 - INFO - Epoch: 33.17, Step: 131400, Train Loss: 1.1390, Learning Rate: 1.80e-05
2025-12-10 18:31:48 - INFO - Epoch: 33.18, Step: 131410, Train Loss: 1.1742, Learning Rate: 1.80e-05
2025-12-10 18:32:02 - INFO - Epoch: 33.18, Step: 131420, Train Loss: 1.1651, Learning Rate: 1.80e-05
2025-12-10 18:32:15 - INFO - Epoch: 33.18, Step: 131430, Train Loss: 1.1356, Learning Rate: 1.79e-05
2025-12-10 18:32:29 - INFO - Epoch: 33.18, Step: 131440, Train Loss: 1.1624, Learning Rate: 1.79e-05
2025-12-10 18:32:42 - INFO - Epoch: 33.19, Step: 131450, Train Loss: 1.1568, Learning Rate: 1.79e-05
2025-12-10 18:32:55 - INFO - Epoch: 33.19, Step: 131460, Train Loss: 1.1944, Learning Rate: 1.79e-05
2025-12-10 18:33:09 - INFO - Epoch: 33.19, Step: 131470, Train Loss: 1.1438, Learning Rate: 1.79e-05
2025-12-10 18:33:22 - INFO - Epoch: 33.19, Step: 131480, Train Loss: 1.1439, Learning Rate: 1.79e-05
2025-12-10 18:33:36 - INFO - Epoch: 33.20, Step: 131490, Train Loss: 1.1620, Learning Rate: 1.79e-05
2025-12-10 18:33:49 - INFO - Epoch: 33.20, Step: 131500, Train Loss: 1.1583, Learning Rate: 1.79e-05
2025-12-10 18:34:03 - INFO - Epoch: 33.20, Step: 131510, Train Loss: 1.1468, Learning Rate: 1.79e-05
2025-12-10 18:34:16 - INFO - Epoch: 33.20, Step: 131520, Train Loss: 1.1443, Learning Rate: 1.79e-05
2025-12-10 18:34:30 - INFO - Epoch: 33.21, Step: 131530, Train Loss: 1.1249, Learning Rate: 1.79e-05
2025-12-10 18:34:43 - INFO - Epoch: 33.21, Step: 131540, Train Loss: 1.1084, Learning Rate: 1.79e-05
2025-12-10 18:34:56 - INFO - Epoch: 33.21, Step: 131550, Train Loss: 1.1718, Learning Rate: 1.79e-05
2025-12-10 18:35:10 - INFO - Epoch: 33.21, Step: 131560, Train Loss: 1.0913, Learning Rate: 1.79e-05
2025-12-10 18:35:23 - INFO - Epoch: 33.22, Step: 131570, Train Loss: 1.1530, Learning Rate: 1.79e-05
2025-12-10 18:35:37 - INFO - Epoch: 33.22, Step: 131580, Train Loss: 1.1911, Learning Rate: 1.78e-05
2025-12-10 18:35:50 - INFO - Epoch: 33.22, Step: 131590, Train Loss: 1.1831, Learning Rate: 1.78e-05
2025-12-10 18:36:04 - INFO - Epoch: 33.22, Step: 131600, Train Loss: 1.1377, Learning Rate: 1.78e-05
2025-12-10 18:36:17 - INFO - Epoch: 33.23, Step: 131610, Train Loss: 1.1504, Learning Rate: 1.78e-05
2025-12-10 18:36:30 - INFO - Epoch: 33.23, Step: 131620, Train Loss: 1.1524, Learning Rate: 1.78e-05
2025-12-10 18:36:44 - INFO - Epoch: 33.23, Step: 131630, Train Loss: 1.1705, Learning Rate: 1.78e-05
2025-12-10 18:36:57 - INFO - Epoch: 33.23, Step: 131640, Train Loss: 1.1627, Learning Rate: 1.78e-05
2025-12-10 18:37:11 - INFO - Epoch: 33.24, Step: 131650, Train Loss: 1.1505, Learning Rate: 1.78e-05
2025-12-10 18:37:24 - INFO - Epoch: 33.24, Step: 131660, Train Loss: 1.1795, Learning Rate: 1.78e-05
2025-12-10 18:37:38 - INFO - Epoch: 33.24, Step: 131670, Train Loss: 1.1890, Learning Rate: 1.78e-05
2025-12-10 18:37:51 - INFO - Epoch: 33.24, Step: 131680, Train Loss: 1.1202, Learning Rate: 1.78e-05
2025-12-10 18:38:04 - INFO - Epoch: 33.25, Step: 131690, Train Loss: 1.1999, Learning Rate: 1.78e-05
2025-12-10 18:38:18 - INFO - Epoch: 33.25, Step: 131700, Train Loss: 1.1331, Learning Rate: 1.78e-05
2025-12-10 18:38:31 - INFO - Epoch: 33.25, Step: 131710, Train Loss: 1.1795, Learning Rate: 1.78e-05
2025-12-10 18:38:45 - INFO - Epoch: 33.25, Step: 131720, Train Loss: 1.1322, Learning Rate: 1.78e-05
2025-12-10 18:38:58 - INFO - Epoch: 33.26, Step: 131730, Train Loss: 1.1563, Learning Rate: 1.77e-05
2025-12-10 18:39:12 - INFO - Epoch: 33.26, Step: 131740, Train Loss: 1.1656, Learning Rate: 1.77e-05
2025-12-10 18:39:25 - INFO - Epoch: 33.26, Step: 131750, Train Loss: 1.1611, Learning Rate: 1.77e-05
2025-12-10 18:39:39 - INFO - Epoch: 33.26, Step: 131760, Train Loss: 1.1587, Learning Rate: 1.77e-05
2025-12-10 18:39:52 - INFO - Epoch: 33.27, Step: 131770, Train Loss: 1.1637, Learning Rate: 1.77e-05
2025-12-10 18:40:05 - INFO - Epoch: 33.27, Step: 131780, Train Loss: 1.1271, Learning Rate: 1.77e-05
2025-12-10 18:40:19 - INFO - Epoch: 33.27, Step: 131790, Train Loss: 1.1982, Learning Rate: 1.77e-05
2025-12-10 18:40:32 - INFO - Epoch: 33.27, Step: 131800, Train Loss: 1.1448, Learning Rate: 1.77e-05
2025-12-10 18:40:46 - INFO - Epoch: 33.28, Step: 131810, Train Loss: 1.1353, Learning Rate: 1.77e-05
2025-12-10 18:40:59 - INFO - Epoch: 33.28, Step: 131820, Train Loss: 1.1566, Learning Rate: 1.77e-05
2025-12-10 18:41:13 - INFO - Epoch: 33.28, Step: 131830, Train Loss: 1.1388, Learning Rate: 1.77e-05
2025-12-10 18:41:26 - INFO - Epoch: 33.28, Step: 131840, Train Loss: 1.1560, Learning Rate: 1.77e-05
2025-12-10 18:41:39 - INFO - Epoch: 33.29, Step: 131850, Train Loss: 1.1308, Learning Rate: 1.77e-05
2025-12-10 18:41:53 - INFO - Epoch: 33.29, Step: 131860, Train Loss: 1.1607, Learning Rate: 1.77e-05
2025-12-10 18:42:06 - INFO - Epoch: 33.29, Step: 131870, Train Loss: 1.1266, Learning Rate: 1.77e-05
2025-12-10 18:42:20 - INFO - Epoch: 33.29, Step: 131880, Train Loss: 1.1740, Learning Rate: 1.76e-05
2025-12-10 18:42:33 - INFO - Epoch: 33.30, Step: 131890, Train Loss: 1.1224, Learning Rate: 1.76e-05
2025-12-10 18:42:47 - INFO - Epoch: 33.30, Step: 131900, Train Loss: 1.1165, Learning Rate: 1.76e-05
2025-12-10 18:43:00 - INFO - Epoch: 33.30, Step: 131910, Train Loss: 1.1680, Learning Rate: 1.76e-05
2025-12-10 18:43:13 - INFO - Epoch: 33.30, Step: 131920, Train Loss: 1.1372, Learning Rate: 1.76e-05
2025-12-10 18:43:27 - INFO - Epoch: 33.31, Step: 131930, Train Loss: 1.1822, Learning Rate: 1.76e-05
2025-12-10 18:43:40 - INFO - Epoch: 33.31, Step: 131940, Train Loss: 1.1209, Learning Rate: 1.76e-05
2025-12-10 18:43:54 - INFO - Epoch: 33.31, Step: 131950, Train Loss: 1.1156, Learning Rate: 1.76e-05
2025-12-10 18:44:07 - INFO - Epoch: 33.31, Step: 131960, Train Loss: 1.1823, Learning Rate: 1.76e-05
2025-12-10 18:44:21 - INFO - Epoch: 33.32, Step: 131970, Train Loss: 1.1522, Learning Rate: 1.76e-05
2025-12-10 18:44:34 - INFO - Epoch: 33.32, Step: 131980, Train Loss: 1.1181, Learning Rate: 1.76e-05
2025-12-10 18:44:48 - INFO - Epoch: 33.32, Step: 131990, Train Loss: 1.1228, Learning Rate: 1.76e-05
2025-12-10 18:45:01 - INFO - Epoch: 33.32, Step: 132000, Train Loss: 1.1632, Learning Rate: 1.76e-05
2025-12-10 18:45:14 - INFO - Epoch: 33.33, Step: 132010, Train Loss: 1.1621, Learning Rate: 1.76e-05
2025-12-10 18:45:28 - INFO - Epoch: 33.33, Step: 132020, Train Loss: 1.1273, Learning Rate: 1.76e-05
2025-12-10 18:45:41 - INFO - Epoch: 33.33, Step: 132030, Train Loss: 1.1660, Learning Rate: 1.75e-05
2025-12-10 18:45:55 - INFO - Epoch: 33.34, Step: 132040, Train Loss: 1.1147, Learning Rate: 1.75e-05
2025-12-10 18:46:08 - INFO - Epoch: 33.34, Step: 132050, Train Loss: 1.1435, Learning Rate: 1.75e-05
2025-12-10 18:46:22 - INFO - Epoch: 33.34, Step: 132060, Train Loss: 1.1346, Learning Rate: 1.75e-05
2025-12-10 18:46:35 - INFO - Epoch: 33.34, Step: 132070, Train Loss: 1.1647, Learning Rate: 1.75e-05
2025-12-10 18:46:48 - INFO - Epoch: 33.35, Step: 132080, Train Loss: 1.1838, Learning Rate: 1.75e-05
2025-12-10 18:47:02 - INFO - Epoch: 33.35, Step: 132090, Train Loss: 1.1496, Learning Rate: 1.75e-05
2025-12-10 18:47:15 - INFO - Epoch: 33.35, Step: 132100, Train Loss: 1.1433, Learning Rate: 1.75e-05
2025-12-10 18:47:29 - INFO - Epoch: 33.35, Step: 132110, Train Loss: 1.1335, Learning Rate: 1.75e-05
2025-12-10 18:47:42 - INFO - Epoch: 33.36, Step: 132120, Train Loss: 1.1819, Learning Rate: 1.75e-05
2025-12-10 18:47:56 - INFO - Epoch: 33.36, Step: 132130, Train Loss: 1.1570, Learning Rate: 1.75e-05
2025-12-10 18:48:09 - INFO - Epoch: 33.36, Step: 132140, Train Loss: 1.1448, Learning Rate: 1.75e-05
2025-12-10 18:48:22 - INFO - Epoch: 33.36, Step: 132150, Train Loss: 1.1331, Learning Rate: 1.75e-05
2025-12-10 18:48:36 - INFO - Epoch: 33.37, Step: 132160, Train Loss: 1.1674, Learning Rate: 1.75e-05
2025-12-10 18:48:49 - INFO - Epoch: 33.37, Step: 132170, Train Loss: 1.1401, Learning Rate: 1.75e-05
2025-12-10 18:49:03 - INFO - Epoch: 33.37, Step: 132180, Train Loss: 1.1444, Learning Rate: 1.74e-05
2025-12-10 18:49:16 - INFO - Epoch: 33.37, Step: 132190, Train Loss: 1.1833, Learning Rate: 1.74e-05
2025-12-10 18:49:30 - INFO - Epoch: 33.38, Step: 132200, Train Loss: 1.1573, Learning Rate: 1.74e-05
2025-12-10 18:49:43 - INFO - Epoch: 33.38, Step: 132210, Train Loss: 1.1218, Learning Rate: 1.74e-05
2025-12-10 18:49:57 - INFO - Epoch: 33.38, Step: 132220, Train Loss: 1.1430, Learning Rate: 1.74e-05
2025-12-10 18:50:10 - INFO - Epoch: 33.38, Step: 132230, Train Loss: 1.1893, Learning Rate: 1.74e-05
2025-12-10 18:50:23 - INFO - Epoch: 33.39, Step: 132240, Train Loss: 1.1809, Learning Rate: 1.74e-05
2025-12-10 18:50:37 - INFO - Epoch: 33.39, Step: 132250, Train Loss: 1.1162, Learning Rate: 1.74e-05
2025-12-10 18:50:50 - INFO - Epoch: 33.39, Step: 132260, Train Loss: 1.1556, Learning Rate: 1.74e-05
2025-12-10 18:51:04 - INFO - Epoch: 33.39, Step: 132270, Train Loss: 1.1671, Learning Rate: 1.74e-05
2025-12-10 18:51:17 - INFO - Epoch: 33.40, Step: 132280, Train Loss: 1.1639, Learning Rate: 1.74e-05
2025-12-10 18:51:31 - INFO - Epoch: 33.40, Step: 132290, Train Loss: 1.1009, Learning Rate: 1.74e-05
2025-12-10 18:51:44 - INFO - Epoch: 33.40, Step: 132300, Train Loss: 1.1684, Learning Rate: 1.74e-05
2025-12-10 18:51:57 - INFO - Epoch: 33.40, Step: 132310, Train Loss: 1.1220, Learning Rate: 1.74e-05
2025-12-10 18:52:11 - INFO - Epoch: 33.41, Step: 132320, Train Loss: 1.1383, Learning Rate: 1.74e-05
2025-12-10 18:52:24 - INFO - Epoch: 33.41, Step: 132330, Train Loss: 1.1834, Learning Rate: 1.73e-05
2025-12-10 18:52:38 - INFO - Epoch: 33.41, Step: 132340, Train Loss: 1.1745, Learning Rate: 1.73e-05
2025-12-10 18:52:51 - INFO - Epoch: 33.41, Step: 132350, Train Loss: 1.1714, Learning Rate: 1.73e-05
2025-12-10 18:53:05 - INFO - Epoch: 33.42, Step: 132360, Train Loss: 1.1547, Learning Rate: 1.73e-05
2025-12-10 18:53:18 - INFO - Epoch: 33.42, Step: 132370, Train Loss: 1.1374, Learning Rate: 1.73e-05
2025-12-10 18:53:31 - INFO - Epoch: 33.42, Step: 132380, Train Loss: 1.1370, Learning Rate: 1.73e-05
2025-12-10 18:53:45 - INFO - Epoch: 33.42, Step: 132390, Train Loss: 1.1635, Learning Rate: 1.73e-05
2025-12-10 18:53:58 - INFO - Epoch: 33.43, Step: 132400, Train Loss: 1.1519, Learning Rate: 1.73e-05
2025-12-10 18:54:12 - INFO - Epoch: 33.43, Step: 132410, Train Loss: 1.1689, Learning Rate: 1.73e-05
2025-12-10 18:54:25 - INFO - Epoch: 33.43, Step: 132420, Train Loss: 1.1399, Learning Rate: 1.73e-05
2025-12-10 18:54:39 - INFO - Epoch: 33.43, Step: 132430, Train Loss: 1.1365, Learning Rate: 1.73e-05
2025-12-10 18:54:52 - INFO - Epoch: 33.44, Step: 132440, Train Loss: 1.1986, Learning Rate: 1.73e-05
2025-12-10 18:55:06 - INFO - Epoch: 33.44, Step: 132450, Train Loss: 1.1401, Learning Rate: 1.73e-05
2025-12-10 18:55:19 - INFO - Epoch: 33.44, Step: 132460, Train Loss: 1.1295, Learning Rate: 1.73e-05
2025-12-10 18:55:32 - INFO - Epoch: 33.44, Step: 132470, Train Loss: 1.1173, Learning Rate: 1.73e-05
2025-12-10 18:55:46 - INFO - Epoch: 33.45, Step: 132480, Train Loss: 1.1534, Learning Rate: 1.72e-05
2025-12-10 18:55:59 - INFO - Epoch: 33.45, Step: 132490, Train Loss: 1.1468, Learning Rate: 1.72e-05
2025-12-10 18:56:13 - INFO - Epoch: 33.45, Step: 132500, Train Loss: 1.1490, Learning Rate: 1.72e-05
2025-12-10 18:56:26 - INFO - Epoch: 33.45, Step: 132510, Train Loss: 1.1399, Learning Rate: 1.72e-05
2025-12-10 18:56:40 - INFO - Epoch: 33.46, Step: 132520, Train Loss: 1.1875, Learning Rate: 1.72e-05
2025-12-10 18:56:53 - INFO - Epoch: 33.46, Step: 132530, Train Loss: 1.1499, Learning Rate: 1.72e-05
2025-12-10 18:57:06 - INFO - Epoch: 33.46, Step: 132540, Train Loss: 1.2083, Learning Rate: 1.72e-05
2025-12-10 18:57:20 - INFO - Epoch: 33.46, Step: 132550, Train Loss: 1.1151, Learning Rate: 1.72e-05
2025-12-10 18:57:33 - INFO - Epoch: 33.47, Step: 132560, Train Loss: 1.1305, Learning Rate: 1.72e-05
2025-12-10 18:57:47 - INFO - Epoch: 33.47, Step: 132570, Train Loss: 1.1718, Learning Rate: 1.72e-05
2025-12-10 18:58:00 - INFO - Epoch: 33.47, Step: 132580, Train Loss: 1.1716, Learning Rate: 1.72e-05
2025-12-10 18:58:14 - INFO - Epoch: 33.47, Step: 132590, Train Loss: 1.1745, Learning Rate: 1.72e-05
2025-12-10 18:58:27 - INFO - Epoch: 33.48, Step: 132600, Train Loss: 1.1788, Learning Rate: 1.72e-05
2025-12-10 18:58:40 - INFO - Epoch: 33.48, Step: 132610, Train Loss: 1.1697, Learning Rate: 1.72e-05
2025-12-10 18:58:54 - INFO - Epoch: 33.48, Step: 132620, Train Loss: 1.1542, Learning Rate: 1.72e-05
2025-12-10 18:59:07 - INFO - Epoch: 33.48, Step: 132630, Train Loss: 1.1502, Learning Rate: 1.71e-05
2025-12-10 18:59:21 - INFO - Epoch: 33.49, Step: 132640, Train Loss: 1.1558, Learning Rate: 1.71e-05
2025-12-10 18:59:34 - INFO - Epoch: 33.49, Step: 132650, Train Loss: 1.1550, Learning Rate: 1.71e-05
2025-12-10 18:59:48 - INFO - Epoch: 33.49, Step: 132660, Train Loss: 1.1597, Learning Rate: 1.71e-05
2025-12-10 19:00:01 - INFO - Epoch: 33.49, Step: 132670, Train Loss: 1.1428, Learning Rate: 1.71e-05
2025-12-10 19:00:14 - INFO - Epoch: 33.50, Step: 132680, Train Loss: 1.1594, Learning Rate: 1.71e-05
2025-12-10 19:00:28 - INFO - Epoch: 33.50, Step: 132690, Train Loss: 1.1682, Learning Rate: 1.71e-05
2025-12-10 19:00:41 - INFO - Epoch: 33.50, Step: 132700, Train Loss: 1.0809, Learning Rate: 1.71e-05
2025-12-10 19:00:55 - INFO - Epoch: 33.50, Step: 132710, Train Loss: 1.1284, Learning Rate: 1.71e-05
2025-12-10 19:01:08 - INFO - Epoch: 33.51, Step: 132720, Train Loss: 1.1623, Learning Rate: 1.71e-05
2025-12-10 19:01:22 - INFO - Epoch: 33.51, Step: 132730, Train Loss: 1.1552, Learning Rate: 1.71e-05
2025-12-10 19:01:35 - INFO - Epoch: 33.51, Step: 132740, Train Loss: 1.1365, Learning Rate: 1.71e-05
2025-12-10 19:01:49 - INFO - Epoch: 33.51, Step: 132750, Train Loss: 1.1566, Learning Rate: 1.71e-05
2025-12-10 19:02:02 - INFO - Epoch: 33.52, Step: 132760, Train Loss: 1.1569, Learning Rate: 1.71e-05
2025-12-10 19:02:15 - INFO - Epoch: 33.52, Step: 132770, Train Loss: 1.1593, Learning Rate: 1.71e-05
2025-12-10 19:02:29 - INFO - Epoch: 33.52, Step: 132780, Train Loss: 1.1284, Learning Rate: 1.70e-05
2025-12-10 19:02:42 - INFO - Epoch: 33.52, Step: 132790, Train Loss: 1.1435, Learning Rate: 1.70e-05
2025-12-10 19:02:56 - INFO - Epoch: 33.53, Step: 132800, Train Loss: 1.1668, Learning Rate: 1.70e-05
2025-12-10 19:03:09 - INFO - Epoch: 33.53, Step: 132810, Train Loss: 1.1579, Learning Rate: 1.70e-05
2025-12-10 19:03:23 - INFO - Epoch: 33.53, Step: 132820, Train Loss: 1.1335, Learning Rate: 1.70e-05
2025-12-10 19:03:36 - INFO - Epoch: 33.53, Step: 132830, Train Loss: 1.1605, Learning Rate: 1.70e-05
2025-12-10 19:03:49 - INFO - Epoch: 33.54, Step: 132840, Train Loss: 1.1630, Learning Rate: 1.70e-05
2025-12-10 19:04:03 - INFO - Epoch: 33.54, Step: 132850, Train Loss: 1.1685, Learning Rate: 1.70e-05
2025-12-10 19:04:16 - INFO - Epoch: 33.54, Step: 132860, Train Loss: 1.1608, Learning Rate: 1.70e-05
2025-12-10 19:04:30 - INFO - Epoch: 33.54, Step: 132870, Train Loss: 1.1534, Learning Rate: 1.70e-05
2025-12-10 19:04:43 - INFO - Epoch: 33.55, Step: 132880, Train Loss: 1.1946, Learning Rate: 1.70e-05
2025-12-10 19:04:57 - INFO - Epoch: 33.55, Step: 132890, Train Loss: 1.1413, Learning Rate: 1.70e-05
2025-12-10 19:05:10 - INFO - Epoch: 33.55, Step: 132900, Train Loss: 1.1467, Learning Rate: 1.70e-05
2025-12-10 19:05:23 - INFO - Epoch: 33.55, Step: 132910, Train Loss: 1.1656, Learning Rate: 1.70e-05
2025-12-10 19:05:37 - INFO - Epoch: 33.56, Step: 132920, Train Loss: 1.1537, Learning Rate: 1.70e-05
2025-12-10 19:05:50 - INFO - Epoch: 33.56, Step: 132930, Train Loss: 1.1039, Learning Rate: 1.69e-05
2025-12-10 19:06:04 - INFO - Epoch: 33.56, Step: 132940, Train Loss: 1.1546, Learning Rate: 1.69e-05
2025-12-10 19:06:17 - INFO - Epoch: 33.56, Step: 132950, Train Loss: 1.1228, Learning Rate: 1.69e-05
2025-12-10 19:06:31 - INFO - Epoch: 33.57, Step: 132960, Train Loss: 1.1204, Learning Rate: 1.69e-05
2025-12-10 19:06:44 - INFO - Epoch: 33.57, Step: 132970, Train Loss: 1.1719, Learning Rate: 1.69e-05
2025-12-10 19:06:58 - INFO - Epoch: 33.57, Step: 132980, Train Loss: 1.1572, Learning Rate: 1.69e-05
2025-12-10 19:07:11 - INFO - Epoch: 33.57, Step: 132990, Train Loss: 1.1642, Learning Rate: 1.69e-05
2025-12-10 19:07:24 - INFO - Epoch: 33.58, Step: 133000, Train Loss: 1.1292, Learning Rate: 1.69e-05
2025-12-10 19:07:38 - INFO - Epoch: 33.58, Step: 133010, Train Loss: 1.1339, Learning Rate: 1.69e-05
2025-12-10 19:07:51 - INFO - Epoch: 33.58, Step: 133020, Train Loss: 1.1427, Learning Rate: 1.69e-05
2025-12-10 19:08:05 - INFO - Epoch: 33.58, Step: 133030, Train Loss: 1.1221, Learning Rate: 1.69e-05
2025-12-10 19:08:18 - INFO - Epoch: 33.59, Step: 133040, Train Loss: 1.1550, Learning Rate: 1.69e-05
2025-12-10 19:08:32 - INFO - Epoch: 33.59, Step: 133050, Train Loss: 1.1426, Learning Rate: 1.69e-05
2025-12-10 19:08:45 - INFO - Epoch: 33.59, Step: 133060, Train Loss: 1.1445, Learning Rate: 1.69e-05
2025-12-10 19:08:58 - INFO - Epoch: 33.60, Step: 133070, Train Loss: 1.1327, Learning Rate: 1.69e-05
2025-12-10 19:09:12 - INFO - Epoch: 33.60, Step: 133080, Train Loss: 1.1682, Learning Rate: 1.68e-05
2025-12-10 19:09:25 - INFO - Epoch: 33.60, Step: 133090, Train Loss: 1.1433, Learning Rate: 1.68e-05
2025-12-10 19:09:39 - INFO - Epoch: 33.60, Step: 133100, Train Loss: 1.1767, Learning Rate: 1.68e-05
2025-12-10 19:09:52 - INFO - Epoch: 33.61, Step: 133110, Train Loss: 1.1445, Learning Rate: 1.68e-05
2025-12-10 19:10:06 - INFO - Epoch: 33.61, Step: 133120, Train Loss: 1.1782, Learning Rate: 1.68e-05
2025-12-10 19:10:19 - INFO - Epoch: 33.61, Step: 133130, Train Loss: 1.1637, Learning Rate: 1.68e-05
2025-12-10 19:10:32 - INFO - Epoch: 33.61, Step: 133140, Train Loss: 1.1697, Learning Rate: 1.68e-05
2025-12-10 19:10:46 - INFO - Epoch: 33.62, Step: 133150, Train Loss: 1.1329, Learning Rate: 1.68e-05
2025-12-10 19:10:59 - INFO - Epoch: 33.62, Step: 133160, Train Loss: 1.1495, Learning Rate: 1.68e-05
2025-12-10 19:11:13 - INFO - Epoch: 33.62, Step: 133170, Train Loss: 1.1573, Learning Rate: 1.68e-05
2025-12-10 19:11:26 - INFO - Epoch: 33.62, Step: 133180, Train Loss: 1.1717, Learning Rate: 1.68e-05
2025-12-10 19:11:40 - INFO - Epoch: 33.63, Step: 133190, Train Loss: 1.1612, Learning Rate: 1.68e-05
2025-12-10 19:11:53 - INFO - Epoch: 33.63, Step: 133200, Train Loss: 1.1392, Learning Rate: 1.68e-05
2025-12-10 19:12:07 - INFO - Epoch: 33.63, Step: 133210, Train Loss: 1.1529, Learning Rate: 1.68e-05
2025-12-10 19:12:20 - INFO - Epoch: 33.63, Step: 133220, Train Loss: 1.1507, Learning Rate: 1.68e-05
2025-12-10 19:12:33 - INFO - Epoch: 33.64, Step: 133230, Train Loss: 1.1671, Learning Rate: 1.67e-05
2025-12-10 19:12:47 - INFO - Epoch: 33.64, Step: 133240, Train Loss: 1.1439, Learning Rate: 1.67e-05
2025-12-10 19:13:00 - INFO - Epoch: 33.64, Step: 133250, Train Loss: 1.1128, Learning Rate: 1.67e-05
2025-12-10 19:13:14 - INFO - Epoch: 33.64, Step: 133260, Train Loss: 1.1730, Learning Rate: 1.67e-05
2025-12-10 19:13:27 - INFO - Epoch: 33.65, Step: 133270, Train Loss: 1.1399, Learning Rate: 1.67e-05
2025-12-10 19:13:41 - INFO - Epoch: 33.65, Step: 133280, Train Loss: 1.1650, Learning Rate: 1.67e-05
2025-12-10 19:13:54 - INFO - Epoch: 33.65, Step: 133290, Train Loss: 1.1517, Learning Rate: 1.67e-05
2025-12-10 19:14:07 - INFO - Epoch: 33.65, Step: 133300, Train Loss: 1.2093, Learning Rate: 1.67e-05
2025-12-10 19:14:21 - INFO - Epoch: 33.66, Step: 133310, Train Loss: 1.1386, Learning Rate: 1.67e-05
2025-12-10 19:14:34 - INFO - Epoch: 33.66, Step: 133320, Train Loss: 1.1746, Learning Rate: 1.67e-05
2025-12-10 19:14:48 - INFO - Epoch: 33.66, Step: 133330, Train Loss: 1.1711, Learning Rate: 1.67e-05
2025-12-10 19:15:01 - INFO - Epoch: 33.66, Step: 133340, Train Loss: 1.1545, Learning Rate: 1.67e-05
2025-12-10 19:15:15 - INFO - Epoch: 33.67, Step: 133350, Train Loss: 1.1612, Learning Rate: 1.67e-05
2025-12-10 19:15:28 - INFO - Epoch: 33.67, Step: 133360, Train Loss: 1.1518, Learning Rate: 1.67e-05
2025-12-10 19:15:41 - INFO - Epoch: 33.67, Step: 133370, Train Loss: 1.1604, Learning Rate: 1.67e-05
2025-12-10 19:15:55 - INFO - Epoch: 33.67, Step: 133380, Train Loss: 1.1813, Learning Rate: 1.66e-05
2025-12-10 19:16:08 - INFO - Epoch: 33.68, Step: 133390, Train Loss: 1.1395, Learning Rate: 1.66e-05
2025-12-10 19:16:22 - INFO - Epoch: 33.68, Step: 133400, Train Loss: 1.1345, Learning Rate: 1.66e-05
2025-12-10 19:16:35 - INFO - Epoch: 33.68, Step: 133410, Train Loss: 1.1698, Learning Rate: 1.66e-05
2025-12-10 19:16:49 - INFO - Epoch: 33.68, Step: 133420, Train Loss: 1.1553, Learning Rate: 1.66e-05
2025-12-10 19:17:02 - INFO - Epoch: 33.69, Step: 133430, Train Loss: 1.1571, Learning Rate: 1.66e-05
2025-12-10 19:17:16 - INFO - Epoch: 33.69, Step: 133440, Train Loss: 1.1590, Learning Rate: 1.66e-05
2025-12-10 19:17:29 - INFO - Epoch: 33.69, Step: 133450, Train Loss: 1.1522, Learning Rate: 1.66e-05
2025-12-10 19:17:42 - INFO - Epoch: 33.69, Step: 133460, Train Loss: 1.1442, Learning Rate: 1.66e-05
2025-12-10 19:17:56 - INFO - Epoch: 33.70, Step: 133470, Train Loss: 1.1437, Learning Rate: 1.66e-05
2025-12-10 19:18:09 - INFO - Epoch: 33.70, Step: 133480, Train Loss: 1.1813, Learning Rate: 1.66e-05
2025-12-10 19:18:23 - INFO - Epoch: 33.70, Step: 133490, Train Loss: 1.1378, Learning Rate: 1.66e-05
2025-12-10 19:18:36 - INFO - Epoch: 33.70, Step: 133500, Train Loss: 1.1521, Learning Rate: 1.66e-05
2025-12-10 19:18:50 - INFO - Epoch: 33.71, Step: 133510, Train Loss: 1.1884, Learning Rate: 1.66e-05
2025-12-10 19:19:03 - INFO - Epoch: 33.71, Step: 133520, Train Loss: 1.1685, Learning Rate: 1.66e-05
2025-12-10 19:19:16 - INFO - Epoch: 33.71, Step: 133530, Train Loss: 1.1490, Learning Rate: 1.66e-05
2025-12-10 19:19:30 - INFO - Epoch: 33.71, Step: 133540, Train Loss: 1.1732, Learning Rate: 1.65e-05
2025-12-10 19:19:43 - INFO - Epoch: 33.72, Step: 133550, Train Loss: 1.1804, Learning Rate: 1.65e-05
2025-12-10 19:19:57 - INFO - Epoch: 33.72, Step: 133560, Train Loss: 1.1435, Learning Rate: 1.65e-05
2025-12-10 19:20:10 - INFO - Epoch: 33.72, Step: 133570, Train Loss: 1.1624, Learning Rate: 1.65e-05
2025-12-10 19:20:24 - INFO - Epoch: 33.72, Step: 133580, Train Loss: 1.1529, Learning Rate: 1.65e-05
2025-12-10 19:20:37 - INFO - Epoch: 33.73, Step: 133590, Train Loss: 1.1480, Learning Rate: 1.65e-05
2025-12-10 19:20:50 - INFO - Epoch: 33.73, Step: 133600, Train Loss: 1.1377, Learning Rate: 1.65e-05
2025-12-10 19:21:04 - INFO - Epoch: 33.73, Step: 133610, Train Loss: 1.1689, Learning Rate: 1.65e-05
2025-12-10 19:21:17 - INFO - Epoch: 33.73, Step: 133620, Train Loss: 1.1506, Learning Rate: 1.65e-05
2025-12-10 19:21:31 - INFO - Epoch: 33.74, Step: 133630, Train Loss: 1.1074, Learning Rate: 1.65e-05
2025-12-10 19:21:44 - INFO - Epoch: 33.74, Step: 133640, Train Loss: 1.1700, Learning Rate: 1.65e-05
2025-12-10 19:21:58 - INFO - Epoch: 33.74, Step: 133650, Train Loss: 1.1907, Learning Rate: 1.65e-05
2025-12-10 19:22:11 - INFO - Epoch: 33.74, Step: 133660, Train Loss: 1.1736, Learning Rate: 1.65e-05
2025-12-10 19:22:25 - INFO - Epoch: 33.75, Step: 133670, Train Loss: 1.1461, Learning Rate: 1.65e-05
2025-12-10 19:22:38 - INFO - Epoch: 33.75, Step: 133680, Train Loss: 1.1120, Learning Rate: 1.65e-05
2025-12-10 19:22:51 - INFO - Epoch: 33.75, Step: 133690, Train Loss: 1.1194, Learning Rate: 1.64e-05
2025-12-10 19:23:05 - INFO - Epoch: 33.75, Step: 133700, Train Loss: 1.1680, Learning Rate: 1.64e-05
2025-12-10 19:23:18 - INFO - Epoch: 33.76, Step: 133710, Train Loss: 1.1432, Learning Rate: 1.64e-05
2025-12-10 19:23:32 - INFO - Epoch: 33.76, Step: 133720, Train Loss: 1.1744, Learning Rate: 1.64e-05
2025-12-10 19:23:45 - INFO - Epoch: 33.76, Step: 133730, Train Loss: 1.1010, Learning Rate: 1.64e-05
2025-12-10 19:23:59 - INFO - Epoch: 33.76, Step: 133740, Train Loss: 1.1808, Learning Rate: 1.64e-05
2025-12-10 19:24:12 - INFO - Epoch: 33.77, Step: 133750, Train Loss: 1.1440, Learning Rate: 1.64e-05
2025-12-10 19:24:25 - INFO - Epoch: 33.77, Step: 133760, Train Loss: 1.1529, Learning Rate: 1.64e-05
2025-12-10 19:24:39 - INFO - Epoch: 33.77, Step: 133770, Train Loss: 1.1334, Learning Rate: 1.64e-05
2025-12-10 19:24:52 - INFO - Epoch: 33.77, Step: 133780, Train Loss: 1.1742, Learning Rate: 1.64e-05
2025-12-10 19:25:06 - INFO - Epoch: 33.78, Step: 133790, Train Loss: 1.1482, Learning Rate: 1.64e-05
2025-12-10 19:25:19 - INFO - Epoch: 33.78, Step: 133800, Train Loss: 1.1389, Learning Rate: 1.64e-05
2025-12-10 19:25:33 - INFO - Epoch: 33.78, Step: 133810, Train Loss: 1.1883, Learning Rate: 1.64e-05
2025-12-10 19:25:46 - INFO - Epoch: 33.78, Step: 133820, Train Loss: 1.1754, Learning Rate: 1.64e-05
2025-12-10 19:25:59 - INFO - Epoch: 33.79, Step: 133830, Train Loss: 1.1334, Learning Rate: 1.64e-05
2025-12-10 19:26:13 - INFO - Epoch: 33.79, Step: 133840, Train Loss: 1.1409, Learning Rate: 1.63e-05
2025-12-10 19:26:26 - INFO - Epoch: 33.79, Step: 133850, Train Loss: 1.1174, Learning Rate: 1.63e-05
2025-12-10 19:26:40 - INFO - Epoch: 33.79, Step: 133860, Train Loss: 1.1173, Learning Rate: 1.63e-05
2025-12-10 19:26:53 - INFO - Epoch: 33.80, Step: 133870, Train Loss: 1.1738, Learning Rate: 1.63e-05
2025-12-10 19:27:07 - INFO - Epoch: 33.80, Step: 133880, Train Loss: 1.1615, Learning Rate: 1.63e-05
2025-12-10 19:27:20 - INFO - Epoch: 33.80, Step: 133890, Train Loss: 1.1107, Learning Rate: 1.63e-05
2025-12-10 19:27:33 - INFO - Epoch: 33.80, Step: 133900, Train Loss: 1.1580, Learning Rate: 1.63e-05
2025-12-10 19:27:47 - INFO - Epoch: 33.81, Step: 133910, Train Loss: 1.1245, Learning Rate: 1.63e-05
2025-12-10 19:28:00 - INFO - Epoch: 33.81, Step: 133920, Train Loss: 1.1200, Learning Rate: 1.63e-05
2025-12-10 19:28:14 - INFO - Epoch: 33.81, Step: 133930, Train Loss: 1.1405, Learning Rate: 1.63e-05
2025-12-10 19:28:27 - INFO - Epoch: 33.81, Step: 133940, Train Loss: 1.1673, Learning Rate: 1.63e-05
2025-12-10 19:28:41 - INFO - Epoch: 33.82, Step: 133950, Train Loss: 1.1591, Learning Rate: 1.63e-05
2025-12-10 19:28:54 - INFO - Epoch: 33.82, Step: 133960, Train Loss: 1.1364, Learning Rate: 1.63e-05
2025-12-10 19:29:08 - INFO - Epoch: 33.82, Step: 133970, Train Loss: 1.1399, Learning Rate: 1.63e-05
2025-12-10 19:29:21 - INFO - Epoch: 33.82, Step: 133980, Train Loss: 1.1440, Learning Rate: 1.63e-05
2025-12-10 19:29:34 - INFO - Epoch: 33.83, Step: 133990, Train Loss: 1.1650, Learning Rate: 1.62e-05
2025-12-10 19:29:48 - INFO - Epoch: 33.83, Step: 134000, Train Loss: 1.1628, Learning Rate: 1.62e-05
2025-12-10 19:30:01 - INFO - Epoch: 33.83, Step: 134010, Train Loss: 1.1368, Learning Rate: 1.62e-05
2025-12-10 19:30:15 - INFO - Epoch: 33.83, Step: 134020, Train Loss: 1.1425, Learning Rate: 1.62e-05
2025-12-10 19:30:28 - INFO - Epoch: 33.84, Step: 134030, Train Loss: 1.1748, Learning Rate: 1.62e-05
2025-12-10 19:30:42 - INFO - Epoch: 33.84, Step: 134040, Train Loss: 1.1701, Learning Rate: 1.62e-05
2025-12-10 19:30:55 - INFO - Epoch: 33.84, Step: 134050, Train Loss: 1.1664, Learning Rate: 1.62e-05
2025-12-10 19:31:08 - INFO - Epoch: 33.84, Step: 134060, Train Loss: 1.1760, Learning Rate: 1.62e-05
2025-12-10 19:31:22 - INFO - Epoch: 33.85, Step: 134070, Train Loss: 1.1522, Learning Rate: 1.62e-05
2025-12-10 19:31:35 - INFO - Epoch: 33.85, Step: 134080, Train Loss: 1.1420, Learning Rate: 1.62e-05
2025-12-10 19:31:49 - INFO - Epoch: 33.85, Step: 134090, Train Loss: 1.1465, Learning Rate: 1.62e-05
2025-12-10 19:32:02 - INFO - Epoch: 33.86, Step: 134100, Train Loss: 1.1704, Learning Rate: 1.62e-05
2025-12-10 19:32:16 - INFO - Epoch: 33.86, Step: 134110, Train Loss: 1.1369, Learning Rate: 1.62e-05
2025-12-10 19:32:29 - INFO - Epoch: 33.86, Step: 134120, Train Loss: 1.1337, Learning Rate: 1.62e-05
2025-12-10 19:32:42 - INFO - Epoch: 33.86, Step: 134130, Train Loss: 1.1718, Learning Rate: 1.62e-05
2025-12-10 19:32:56 - INFO - Epoch: 33.87, Step: 134140, Train Loss: 1.1438, Learning Rate: 1.61e-05
2025-12-10 19:33:09 - INFO - Epoch: 33.87, Step: 134150, Train Loss: 1.1459, Learning Rate: 1.61e-05
2025-12-10 19:33:23 - INFO - Epoch: 33.87, Step: 134160, Train Loss: 1.1250, Learning Rate: 1.61e-05
2025-12-10 19:33:36 - INFO - Epoch: 33.87, Step: 134170, Train Loss: 1.1544, Learning Rate: 1.61e-05
2025-12-10 19:33:50 - INFO - Epoch: 33.88, Step: 134180, Train Loss: 1.1610, Learning Rate: 1.61e-05
2025-12-10 19:34:03 - INFO - Epoch: 33.88, Step: 134190, Train Loss: 1.1651, Learning Rate: 1.61e-05
2025-12-10 19:34:17 - INFO - Epoch: 33.88, Step: 134200, Train Loss: 1.1462, Learning Rate: 1.61e-05
2025-12-10 19:34:30 - INFO - Epoch: 33.88, Step: 134210, Train Loss: 1.1633, Learning Rate: 1.61e-05
2025-12-10 19:34:43 - INFO - Epoch: 33.89, Step: 134220, Train Loss: 1.1378, Learning Rate: 1.61e-05
2025-12-10 19:34:57 - INFO - Epoch: 33.89, Step: 134230, Train Loss: 1.1499, Learning Rate: 1.61e-05
2025-12-10 19:35:10 - INFO - Epoch: 33.89, Step: 134240, Train Loss: 1.1186, Learning Rate: 1.61e-05
2025-12-10 19:35:24 - INFO - Epoch: 33.89, Step: 134250, Train Loss: 1.1689, Learning Rate: 1.61e-05
2025-12-10 19:35:37 - INFO - Epoch: 33.90, Step: 134260, Train Loss: 1.1464, Learning Rate: 1.61e-05
2025-12-10 19:35:51 - INFO - Epoch: 33.90, Step: 134270, Train Loss: 1.1806, Learning Rate: 1.61e-05
2025-12-10 19:36:04 - INFO - Epoch: 33.90, Step: 134280, Train Loss: 1.1356, Learning Rate: 1.61e-05
2025-12-10 19:36:17 - INFO - Epoch: 33.90, Step: 134290, Train Loss: 1.1685, Learning Rate: 1.60e-05
2025-12-10 19:36:31 - INFO - Epoch: 33.91, Step: 134300, Train Loss: 1.1435, Learning Rate: 1.60e-05
2025-12-10 19:36:44 - INFO - Epoch: 33.91, Step: 134310, Train Loss: 1.1584, Learning Rate: 1.60e-05
2025-12-10 19:36:58 - INFO - Epoch: 33.91, Step: 134320, Train Loss: 1.1348, Learning Rate: 1.60e-05
2025-12-10 19:37:11 - INFO - Epoch: 33.91, Step: 134330, Train Loss: 1.1592, Learning Rate: 1.60e-05
2025-12-10 19:37:25 - INFO - Epoch: 33.92, Step: 134340, Train Loss: 1.1224, Learning Rate: 1.60e-05
2025-12-10 19:37:38 - INFO - Epoch: 33.92, Step: 134350, Train Loss: 1.1185, Learning Rate: 1.60e-05
2025-12-10 19:37:51 - INFO - Epoch: 33.92, Step: 134360, Train Loss: 1.1332, Learning Rate: 1.60e-05
2025-12-10 19:38:05 - INFO - Epoch: 33.92, Step: 134370, Train Loss: 1.1648, Learning Rate: 1.60e-05
2025-12-10 19:38:18 - INFO - Epoch: 33.93, Step: 134380, Train Loss: 1.1168, Learning Rate: 1.60e-05
2025-12-10 19:38:32 - INFO - Epoch: 33.93, Step: 134390, Train Loss: 1.1584, Learning Rate: 1.60e-05
2025-12-10 19:38:45 - INFO - Epoch: 33.93, Step: 134400, Train Loss: 1.1309, Learning Rate: 1.60e-05
2025-12-10 19:38:59 - INFO - Epoch: 33.93, Step: 134410, Train Loss: 1.1240, Learning Rate: 1.60e-05
2025-12-10 19:39:12 - INFO - Epoch: 33.94, Step: 134420, Train Loss: 1.1404, Learning Rate: 1.60e-05
2025-12-10 19:39:26 - INFO - Epoch: 33.94, Step: 134430, Train Loss: 1.1415, Learning Rate: 1.60e-05
2025-12-10 19:39:39 - INFO - Epoch: 33.94, Step: 134440, Train Loss: 1.1663, Learning Rate: 1.59e-05
2025-12-10 19:39:52 - INFO - Epoch: 33.94, Step: 134450, Train Loss: 1.1282, Learning Rate: 1.59e-05
2025-12-10 19:40:06 - INFO - Epoch: 33.95, Step: 134460, Train Loss: 1.1260, Learning Rate: 1.59e-05
2025-12-10 19:40:19 - INFO - Epoch: 33.95, Step: 134470, Train Loss: 1.1646, Learning Rate: 1.59e-05
2025-12-10 19:40:33 - INFO - Epoch: 33.95, Step: 134480, Train Loss: 1.1594, Learning Rate: 1.59e-05
2025-12-10 19:40:46 - INFO - Epoch: 33.95, Step: 134490, Train Loss: 1.1414, Learning Rate: 1.59e-05
2025-12-10 19:41:00 - INFO - Epoch: 33.96, Step: 134500, Train Loss: 1.1396, Learning Rate: 1.59e-05
2025-12-10 19:41:13 - INFO - Epoch: 33.96, Step: 134510, Train Loss: 1.1867, Learning Rate: 1.59e-05
2025-12-10 19:41:26 - INFO - Epoch: 33.96, Step: 134520, Train Loss: 1.1451, Learning Rate: 1.59e-05
2025-12-10 19:41:40 - INFO - Epoch: 33.96, Step: 134530, Train Loss: 1.1766, Learning Rate: 1.59e-05
2025-12-10 19:41:53 - INFO - Epoch: 33.97, Step: 134540, Train Loss: 1.1607, Learning Rate: 1.59e-05
2025-12-10 19:42:07 - INFO - Epoch: 33.97, Step: 134550, Train Loss: 1.1155, Learning Rate: 1.59e-05
2025-12-10 19:42:20 - INFO - Epoch: 33.97, Step: 134560, Train Loss: 1.1865, Learning Rate: 1.59e-05
2025-12-10 19:42:34 - INFO - Epoch: 33.97, Step: 134570, Train Loss: 1.1473, Learning Rate: 1.59e-05
2025-12-10 19:42:47 - INFO - Epoch: 33.98, Step: 134580, Train Loss: 1.1514, Learning Rate: 1.59e-05
2025-12-10 19:43:00 - INFO - Epoch: 33.98, Step: 134590, Train Loss: 1.1278, Learning Rate: 1.58e-05
2025-12-10 19:43:14 - INFO - Epoch: 33.98, Step: 134600, Train Loss: 1.1427, Learning Rate: 1.58e-05
2025-12-10 19:43:27 - INFO - Epoch: 33.98, Step: 134610, Train Loss: 1.1430, Learning Rate: 1.58e-05
2025-12-10 19:43:41 - INFO - Epoch: 33.99, Step: 134620, Train Loss: 1.1525, Learning Rate: 1.58e-05
2025-12-10 19:43:54 - INFO - Epoch: 33.99, Step: 134630, Train Loss: 1.1520, Learning Rate: 1.58e-05
2025-12-10 19:44:08 - INFO - Epoch: 33.99, Step: 134640, Train Loss: 1.1386, Learning Rate: 1.58e-05
2025-12-10 19:44:21 - INFO - Epoch: 33.99, Step: 134650, Train Loss: 1.1409, Learning Rate: 1.58e-05
2025-12-10 19:44:35 - INFO - Epoch: 34.00, Step: 134660, Train Loss: 1.1259, Learning Rate: 1.58e-05
2025-12-10 19:44:48 - INFO - Epoch: 34.00, Step: 134670, Train Loss: 1.1429, Learning Rate: 1.58e-05
2025-12-10 19:45:00 - INFO - Epoch: 34.00, Step: 134680, Train Loss: 1.1428, Learning Rate: 1.58e-05
2025-12-10 19:45:11 - INFO - Epoch: 34.00, Step: 134690, Train Loss: 1.1424, Learning Rate: 1.58e-05
2025-12-10 19:45:22 - INFO - Epoch: 34.01, Step: 134700, Train Loss: 1.1477, Learning Rate: 1.58e-05
2025-12-10 19:45:33 - INFO - Epoch: 34.01, Step: 134710, Train Loss: 1.1213, Learning Rate: 1.58e-05
2025-12-10 19:45:45 - INFO - Epoch: 34.01, Step: 134720, Train Loss: 1.1273, Learning Rate: 1.58e-05
2025-12-10 19:45:56 - INFO - Epoch: 34.01, Step: 134730, Train Loss: 1.1340, Learning Rate: 1.58e-05
2025-12-10 19:46:07 - INFO - Epoch: 34.02, Step: 134740, Train Loss: 1.1377, Learning Rate: 1.57e-05
2025-12-10 19:46:18 - INFO - Epoch: 34.02, Step: 134750, Train Loss: 1.1844, Learning Rate: 1.57e-05
2025-12-10 19:46:29 - INFO - Epoch: 34.02, Step: 134760, Train Loss: 1.1796, Learning Rate: 1.57e-05
2025-12-10 19:46:40 - INFO - Epoch: 34.02, Step: 134770, Train Loss: 1.1247, Learning Rate: 1.57e-05
2025-12-10 19:46:52 - INFO - Epoch: 34.03, Step: 134780, Train Loss: 1.1484, Learning Rate: 1.57e-05
2025-12-10 19:47:03 - INFO - Epoch: 34.03, Step: 134790, Train Loss: 1.1502, Learning Rate: 1.57e-05
2025-12-10 19:47:14 - INFO - Epoch: 34.03, Step: 134800, Train Loss: 1.1745, Learning Rate: 1.57e-05
2025-12-10 19:47:25 - INFO - Epoch: 34.03, Step: 134810, Train Loss: 1.1328, Learning Rate: 1.57e-05
2025-12-10 19:47:36 - INFO - Epoch: 34.04, Step: 134820, Train Loss: 1.1659, Learning Rate: 1.57e-05
2025-12-10 19:47:47 - INFO - Epoch: 34.04, Step: 134830, Train Loss: 1.1486, Learning Rate: 1.57e-05
2025-12-10 19:47:58 - INFO - Epoch: 34.04, Step: 134840, Train Loss: 1.1524, Learning Rate: 1.57e-05
2025-12-10 19:48:10 - INFO - Epoch: 34.04, Step: 134850, Train Loss: 1.0988, Learning Rate: 1.57e-05
2025-12-10 19:48:21 - INFO - Epoch: 34.05, Step: 134860, Train Loss: 1.1502, Learning Rate: 1.57e-05
2025-12-10 19:48:32 - INFO - Epoch: 34.05, Step: 134870, Train Loss: 1.1496, Learning Rate: 1.57e-05
2025-12-10 19:48:43 - INFO - Epoch: 34.05, Step: 134880, Train Loss: 1.0993, Learning Rate: 1.57e-05
2025-12-10 19:48:54 - INFO - Epoch: 34.05, Step: 134890, Train Loss: 1.1444, Learning Rate: 1.56e-05
2025-12-10 19:49:05 - INFO - Epoch: 34.06, Step: 134900, Train Loss: 1.1557, Learning Rate: 1.56e-05
2025-12-10 19:49:17 - INFO - Epoch: 34.06, Step: 134910, Train Loss: 1.1450, Learning Rate: 1.56e-05
2025-12-10 19:49:28 - INFO - Epoch: 34.06, Step: 134920, Train Loss: 1.1612, Learning Rate: 1.56e-05
2025-12-10 19:49:39 - INFO - Epoch: 34.06, Step: 134930, Train Loss: 1.1559, Learning Rate: 1.56e-05
2025-12-10 19:49:50 - INFO - Epoch: 34.07, Step: 134940, Train Loss: 1.1764, Learning Rate: 1.56e-05
2025-12-10 19:50:01 - INFO - Epoch: 34.07, Step: 134950, Train Loss: 1.1758, Learning Rate: 1.56e-05
2025-12-10 19:50:12 - INFO - Epoch: 34.07, Step: 134960, Train Loss: 1.1350, Learning Rate: 1.56e-05
2025-12-10 19:50:23 - INFO - Epoch: 34.07, Step: 134970, Train Loss: 1.1271, Learning Rate: 1.56e-05
2025-12-10 19:50:35 - INFO - Epoch: 34.08, Step: 134980, Train Loss: 1.1747, Learning Rate: 1.56e-05
2025-12-10 19:50:46 - INFO - Epoch: 34.08, Step: 134990, Train Loss: 1.1885, Learning Rate: 1.56e-05
2025-12-10 19:50:57 - INFO - Epoch: 34.08, Step: 135000, Train Loss: 1.1631, Learning Rate: 1.56e-05
2025-12-10 19:51:08 - INFO - Epoch: 34.08, Step: 135010, Train Loss: 1.1319, Learning Rate: 1.56e-05
2025-12-10 19:51:19 - INFO - Epoch: 34.09, Step: 135020, Train Loss: 1.1640, Learning Rate: 1.56e-05
2025-12-10 19:51:30 - INFO - Epoch: 34.09, Step: 135030, Train Loss: 1.1686, Learning Rate: 1.56e-05
2025-12-10 19:51:41 - INFO - Epoch: 34.09, Step: 135040, Train Loss: 1.1328, Learning Rate: 1.55e-05
2025-12-10 19:51:53 - INFO - Epoch: 34.09, Step: 135050, Train Loss: 1.1494, Learning Rate: 1.55e-05
2025-12-10 19:52:04 - INFO - Epoch: 34.10, Step: 135060, Train Loss: 1.1373, Learning Rate: 1.55e-05
2025-12-10 19:52:15 - INFO - Epoch: 34.10, Step: 135070, Train Loss: 1.1576, Learning Rate: 1.55e-05
2025-12-10 19:52:26 - INFO - Epoch: 34.10, Step: 135080, Train Loss: 1.1619, Learning Rate: 1.55e-05
2025-12-10 19:52:37 - INFO - Epoch: 34.11, Step: 135090, Train Loss: 1.1657, Learning Rate: 1.55e-05
2025-12-10 19:52:48 - INFO - Epoch: 34.11, Step: 135100, Train Loss: 1.1614, Learning Rate: 1.55e-05
2025-12-10 19:53:00 - INFO - Epoch: 34.11, Step: 135110, Train Loss: 1.1294, Learning Rate: 1.55e-05
2025-12-10 19:53:11 - INFO - Epoch: 34.11, Step: 135120, Train Loss: 1.1692, Learning Rate: 1.55e-05
2025-12-10 19:53:22 - INFO - Epoch: 34.12, Step: 135130, Train Loss: 1.1486, Learning Rate: 1.55e-05
2025-12-10 19:53:33 - INFO - Epoch: 34.12, Step: 135140, Train Loss: 1.1418, Learning Rate: 1.55e-05
2025-12-10 19:53:44 - INFO - Epoch: 34.12, Step: 135150, Train Loss: 1.1149, Learning Rate: 1.55e-05
2025-12-10 19:53:55 - INFO - Epoch: 34.12, Step: 135160, Train Loss: 1.1399, Learning Rate: 1.55e-05
2025-12-10 19:54:06 - INFO - Epoch: 34.13, Step: 135170, Train Loss: 1.1729, Learning Rate: 1.55e-05
2025-12-10 19:54:18 - INFO - Epoch: 34.13, Step: 135180, Train Loss: 1.1813, Learning Rate: 1.55e-05
2025-12-10 19:54:29 - INFO - Epoch: 34.13, Step: 135190, Train Loss: 1.1187, Learning Rate: 1.54e-05
2025-12-10 19:54:40 - INFO - Epoch: 34.13, Step: 135200, Train Loss: 1.1676, Learning Rate: 1.54e-05
2025-12-10 19:54:51 - INFO - Epoch: 34.14, Step: 135210, Train Loss: 1.1429, Learning Rate: 1.54e-05
2025-12-10 19:55:02 - INFO - Epoch: 34.14, Step: 135220, Train Loss: 1.1562, Learning Rate: 1.54e-05
2025-12-10 19:55:13 - INFO - Epoch: 34.14, Step: 135230, Train Loss: 1.1239, Learning Rate: 1.54e-05
2025-12-10 19:55:25 - INFO - Epoch: 34.14, Step: 135240, Train Loss: 1.1411, Learning Rate: 1.54e-05
2025-12-10 19:55:36 - INFO - Epoch: 34.15, Step: 135250, Train Loss: 1.1181, Learning Rate: 1.54e-05
2025-12-10 19:55:47 - INFO - Epoch: 34.15, Step: 135260, Train Loss: 1.1516, Learning Rate: 1.54e-05
2025-12-10 19:55:58 - INFO - Epoch: 34.15, Step: 135270, Train Loss: 1.1510, Learning Rate: 1.54e-05
2025-12-10 19:56:09 - INFO - Epoch: 34.15, Step: 135280, Train Loss: 1.1049, Learning Rate: 1.54e-05
2025-12-10 19:56:20 - INFO - Epoch: 34.16, Step: 135290, Train Loss: 1.1660, Learning Rate: 1.54e-05
2025-12-10 19:56:31 - INFO - Epoch: 34.16, Step: 135300, Train Loss: 1.1881, Learning Rate: 1.54e-05
2025-12-10 19:56:43 - INFO - Epoch: 34.16, Step: 135310, Train Loss: 1.1387, Learning Rate: 1.54e-05
2025-12-10 19:56:54 - INFO - Epoch: 34.16, Step: 135320, Train Loss: 1.1449, Learning Rate: 1.54e-05
2025-12-10 19:57:05 - INFO - Epoch: 34.17, Step: 135330, Train Loss: 1.1384, Learning Rate: 1.54e-05
2025-12-10 19:57:16 - INFO - Epoch: 34.17, Step: 135340, Train Loss: 1.1379, Learning Rate: 1.53e-05
2025-12-10 19:57:27 - INFO - Epoch: 34.17, Step: 135350, Train Loss: 1.1624, Learning Rate: 1.53e-05
2025-12-10 19:57:38 - INFO - Epoch: 34.17, Step: 135360, Train Loss: 1.1432, Learning Rate: 1.53e-05
2025-12-10 19:57:49 - INFO - Epoch: 34.18, Step: 135370, Train Loss: 1.1581, Learning Rate: 1.53e-05
2025-12-10 19:58:01 - INFO - Epoch: 34.18, Step: 135380, Train Loss: 1.1469, Learning Rate: 1.53e-05
2025-12-10 19:58:12 - INFO - Epoch: 34.18, Step: 135390, Train Loss: 1.1563, Learning Rate: 1.53e-05
2025-12-10 19:58:23 - INFO - Epoch: 34.18, Step: 135400, Train Loss: 1.1717, Learning Rate: 1.53e-05
2025-12-10 19:58:34 - INFO - Epoch: 34.19, Step: 135410, Train Loss: 1.1221, Learning Rate: 1.53e-05
2025-12-10 19:58:45 - INFO - Epoch: 34.19, Step: 135420, Train Loss: 1.1171, Learning Rate: 1.53e-05
2025-12-10 19:58:56 - INFO - Epoch: 34.19, Step: 135430, Train Loss: 1.1728, Learning Rate: 1.53e-05
2025-12-10 19:59:08 - INFO - Epoch: 34.19, Step: 135440, Train Loss: 1.1870, Learning Rate: 1.53e-05
2025-12-10 19:59:19 - INFO - Epoch: 34.20, Step: 135450, Train Loss: 1.1444, Learning Rate: 1.53e-05
2025-12-10 19:59:30 - INFO - Epoch: 34.20, Step: 135460, Train Loss: 1.1539, Learning Rate: 1.53e-05
2025-12-10 19:59:41 - INFO - Epoch: 34.20, Step: 135470, Train Loss: 1.1748, Learning Rate: 1.53e-05
2025-12-10 19:59:52 - INFO - Epoch: 34.20, Step: 135480, Train Loss: 1.1389, Learning Rate: 1.53e-05
2025-12-10 20:00:03 - INFO - Epoch: 34.21, Step: 135490, Train Loss: 1.1517, Learning Rate: 1.52e-05
2025-12-10 20:00:14 - INFO - Epoch: 34.21, Step: 135500, Train Loss: 1.1716, Learning Rate: 1.52e-05
2025-12-10 20:00:26 - INFO - Epoch: 34.21, Step: 135510, Train Loss: 1.1611, Learning Rate: 1.52e-05
2025-12-10 20:00:37 - INFO - Epoch: 34.21, Step: 135520, Train Loss: 1.1582, Learning Rate: 1.52e-05
2025-12-10 20:00:48 - INFO - Epoch: 34.22, Step: 135530, Train Loss: 1.1465, Learning Rate: 1.52e-05
2025-12-10 20:00:59 - INFO - Epoch: 34.22, Step: 135540, Train Loss: 1.1797, Learning Rate: 1.52e-05
2025-12-10 20:01:10 - INFO - Epoch: 34.22, Step: 135550, Train Loss: 1.1203, Learning Rate: 1.52e-05
2025-12-10 20:01:21 - INFO - Epoch: 34.22, Step: 135560, Train Loss: 1.1449, Learning Rate: 1.52e-05
2025-12-10 20:01:33 - INFO - Epoch: 34.23, Step: 135570, Train Loss: 1.1530, Learning Rate: 1.52e-05
2025-12-10 20:01:44 - INFO - Epoch: 34.23, Step: 135580, Train Loss: 1.2069, Learning Rate: 1.52e-05
2025-12-10 20:01:55 - INFO - Epoch: 34.23, Step: 135590, Train Loss: 1.1347, Learning Rate: 1.52e-05
2025-12-10 20:02:06 - INFO - Epoch: 34.23, Step: 135600, Train Loss: 1.1406, Learning Rate: 1.52e-05
2025-12-10 20:02:17 - INFO - Epoch: 34.24, Step: 135610, Train Loss: 1.1986, Learning Rate: 1.52e-05
2025-12-10 20:02:28 - INFO - Epoch: 34.24, Step: 135620, Train Loss: 1.1329, Learning Rate: 1.52e-05
2025-12-10 20:02:39 - INFO - Epoch: 34.24, Step: 135630, Train Loss: 1.1083, Learning Rate: 1.52e-05
2025-12-10 20:02:51 - INFO - Epoch: 34.24, Step: 135640, Train Loss: 1.1673, Learning Rate: 1.51e-05
2025-12-10 20:03:02 - INFO - Epoch: 34.25, Step: 135650, Train Loss: 1.1648, Learning Rate: 1.51e-05
2025-12-10 20:03:13 - INFO - Epoch: 34.25, Step: 135660, Train Loss: 1.1689, Learning Rate: 1.51e-05
2025-12-10 20:03:24 - INFO - Epoch: 34.25, Step: 135670, Train Loss: 1.1571, Learning Rate: 1.51e-05
2025-12-10 20:03:35 - INFO - Epoch: 34.25, Step: 135680, Train Loss: 1.1341, Learning Rate: 1.51e-05
2025-12-10 20:03:46 - INFO - Epoch: 34.26, Step: 135690, Train Loss: 1.1516, Learning Rate: 1.51e-05
2025-12-10 20:03:58 - INFO - Epoch: 34.26, Step: 135700, Train Loss: 1.1526, Learning Rate: 1.51e-05
2025-12-10 20:04:09 - INFO - Epoch: 34.26, Step: 135710, Train Loss: 1.1351, Learning Rate: 1.51e-05
2025-12-10 20:04:20 - INFO - Epoch: 34.26, Step: 135720, Train Loss: 1.1205, Learning Rate: 1.51e-05
2025-12-10 20:04:31 - INFO - Epoch: 34.27, Step: 135730, Train Loss: 1.1439, Learning Rate: 1.51e-05
2025-12-10 20:04:42 - INFO - Epoch: 34.27, Step: 135740, Train Loss: 1.1087, Learning Rate: 1.51e-05
2025-12-10 20:04:53 - INFO - Epoch: 34.27, Step: 135750, Train Loss: 1.1328, Learning Rate: 1.51e-05
2025-12-10 20:05:04 - INFO - Epoch: 34.27, Step: 135760, Train Loss: 1.1559, Learning Rate: 1.51e-05
2025-12-10 20:05:16 - INFO - Epoch: 34.28, Step: 135770, Train Loss: 1.1500, Learning Rate: 1.51e-05
2025-12-10 20:05:27 - INFO - Epoch: 34.28, Step: 135780, Train Loss: 1.1516, Learning Rate: 1.51e-05
2025-12-10 20:05:38 - INFO - Epoch: 34.28, Step: 135790, Train Loss: 1.1446, Learning Rate: 1.50e-05
2025-12-10 20:05:49 - INFO - Epoch: 34.28, Step: 135800, Train Loss: 1.1488, Learning Rate: 1.50e-05
2025-12-10 20:06:00 - INFO - Epoch: 34.29, Step: 135810, Train Loss: 1.1047, Learning Rate: 1.50e-05
2025-12-10 20:06:11 - INFO - Epoch: 34.29, Step: 135820, Train Loss: 1.1353, Learning Rate: 1.50e-05
2025-12-10 20:06:22 - INFO - Epoch: 34.29, Step: 135830, Train Loss: 1.1503, Learning Rate: 1.50e-05
2025-12-10 20:06:34 - INFO - Epoch: 34.29, Step: 135840, Train Loss: 1.1304, Learning Rate: 1.50e-05
2025-12-10 20:06:45 - INFO - Epoch: 34.30, Step: 135850, Train Loss: 1.1690, Learning Rate: 1.50e-05
2025-12-10 20:06:56 - INFO - Epoch: 34.30, Step: 135860, Train Loss: 1.1448, Learning Rate: 1.50e-05
2025-12-10 20:07:07 - INFO - Epoch: 34.30, Step: 135870, Train Loss: 1.1604, Learning Rate: 1.50e-05
2025-12-10 20:07:18 - INFO - Epoch: 34.30, Step: 135880, Train Loss: 1.1350, Learning Rate: 1.50e-05
2025-12-10 20:07:29 - INFO - Epoch: 34.31, Step: 135890, Train Loss: 1.1316, Learning Rate: 1.50e-05
2025-12-10 20:07:41 - INFO - Epoch: 34.31, Step: 135900, Train Loss: 1.1654, Learning Rate: 1.50e-05
2025-12-10 20:07:52 - INFO - Epoch: 34.31, Step: 135910, Train Loss: 1.1725, Learning Rate: 1.50e-05
2025-12-10 20:08:03 - INFO - Epoch: 34.31, Step: 135920, Train Loss: 1.1148, Learning Rate: 1.50e-05
2025-12-10 20:08:14 - INFO - Epoch: 34.32, Step: 135930, Train Loss: 1.1526, Learning Rate: 1.50e-05
2025-12-10 20:08:25 - INFO - Epoch: 34.32, Step: 135940, Train Loss: 1.1238, Learning Rate: 1.49e-05
2025-12-10 20:08:36 - INFO - Epoch: 34.32, Step: 135950, Train Loss: 1.1554, Learning Rate: 1.49e-05
2025-12-10 20:08:47 - INFO - Epoch: 34.32, Step: 135960, Train Loss: 1.1531, Learning Rate: 1.49e-05
2025-12-10 20:08:59 - INFO - Epoch: 34.33, Step: 135970, Train Loss: 1.1148, Learning Rate: 1.49e-05
2025-12-10 20:09:10 - INFO - Epoch: 34.33, Step: 135980, Train Loss: 1.1668, Learning Rate: 1.49e-05
2025-12-10 20:09:21 - INFO - Epoch: 34.33, Step: 135990, Train Loss: 1.1601, Learning Rate: 1.49e-05
2025-12-10 20:09:32 - INFO - Epoch: 34.33, Step: 136000, Train Loss: 1.1183, Learning Rate: 1.49e-05
2025-12-10 20:09:43 - INFO - Epoch: 34.34, Step: 136010, Train Loss: 1.1335, Learning Rate: 1.49e-05
2025-12-10 20:09:54 - INFO - Epoch: 34.34, Step: 136020, Train Loss: 1.1410, Learning Rate: 1.49e-05
2025-12-10 20:10:06 - INFO - Epoch: 34.34, Step: 136030, Train Loss: 1.1237, Learning Rate: 1.49e-05
2025-12-10 20:10:17 - INFO - Epoch: 34.34, Step: 136040, Train Loss: 1.1297, Learning Rate: 1.49e-05
2025-12-10 20:10:28 - INFO - Epoch: 34.35, Step: 136050, Train Loss: 1.1538, Learning Rate: 1.49e-05
2025-12-10 20:10:39 - INFO - Epoch: 34.35, Step: 136060, Train Loss: 1.1056, Learning Rate: 1.49e-05
2025-12-10 20:10:50 - INFO - Epoch: 34.35, Step: 136070, Train Loss: 1.1600, Learning Rate: 1.49e-05
2025-12-10 20:11:01 - INFO - Epoch: 34.35, Step: 136080, Train Loss: 1.1394, Learning Rate: 1.49e-05
2025-12-10 20:11:12 - INFO - Epoch: 34.36, Step: 136090, Train Loss: 1.1381, Learning Rate: 1.48e-05
2025-12-10 20:11:24 - INFO - Epoch: 34.36, Step: 136100, Train Loss: 1.1257, Learning Rate: 1.48e-05
2025-12-10 20:11:35 - INFO - Epoch: 34.36, Step: 136110, Train Loss: 1.1569, Learning Rate: 1.48e-05
2025-12-10 20:11:46 - INFO - Epoch: 34.37, Step: 136120, Train Loss: 1.1652, Learning Rate: 1.48e-05
2025-12-10 20:11:57 - INFO - Epoch: 34.37, Step: 136130, Train Loss: 1.1620, Learning Rate: 1.48e-05
2025-12-10 20:12:08 - INFO - Epoch: 34.37, Step: 136140, Train Loss: 1.1273, Learning Rate: 1.48e-05
2025-12-10 20:12:19 - INFO - Epoch: 34.37, Step: 136150, Train Loss: 1.1604, Learning Rate: 1.48e-05
2025-12-10 20:12:30 - INFO - Epoch: 34.38, Step: 136160, Train Loss: 1.1527, Learning Rate: 1.48e-05
2025-12-10 20:12:42 - INFO - Epoch: 34.38, Step: 136170, Train Loss: 1.1765, Learning Rate: 1.48e-05
2025-12-10 20:12:53 - INFO - Epoch: 34.38, Step: 136180, Train Loss: 1.1354, Learning Rate: 1.48e-05
2025-12-10 20:13:04 - INFO - Epoch: 34.38, Step: 136190, Train Loss: 1.1327, Learning Rate: 1.48e-05
2025-12-10 20:13:15 - INFO - Epoch: 34.39, Step: 136200, Train Loss: 1.1283, Learning Rate: 1.48e-05
2025-12-10 20:13:26 - INFO - Epoch: 34.39, Step: 136210, Train Loss: 1.1587, Learning Rate: 1.48e-05
2025-12-10 20:13:37 - INFO - Epoch: 34.39, Step: 136220, Train Loss: 1.1497, Learning Rate: 1.48e-05
2025-12-10 20:13:49 - INFO - Epoch: 34.39, Step: 136230, Train Loss: 1.1174, Learning Rate: 1.48e-05
2025-12-10 20:14:00 - INFO - Epoch: 34.40, Step: 136240, Train Loss: 1.1506, Learning Rate: 1.47e-05
2025-12-10 20:14:11 - INFO - Epoch: 34.40, Step: 136250, Train Loss: 1.1774, Learning Rate: 1.47e-05
2025-12-10 20:14:22 - INFO - Epoch: 34.40, Step: 136260, Train Loss: 1.1797, Learning Rate: 1.47e-05
2025-12-10 20:14:33 - INFO - Epoch: 34.40, Step: 136270, Train Loss: 1.1719, Learning Rate: 1.47e-05
2025-12-10 20:14:44 - INFO - Epoch: 34.41, Step: 136280, Train Loss: 1.1695, Learning Rate: 1.47e-05
2025-12-10 20:14:55 - INFO - Epoch: 34.41, Step: 136290, Train Loss: 1.1303, Learning Rate: 1.47e-05
2025-12-10 20:15:07 - INFO - Epoch: 34.41, Step: 136300, Train Loss: 1.1457, Learning Rate: 1.47e-05
2025-12-10 20:15:18 - INFO - Epoch: 34.41, Step: 136310, Train Loss: 1.1520, Learning Rate: 1.47e-05
2025-12-10 20:15:29 - INFO - Epoch: 34.42, Step: 136320, Train Loss: 1.1178, Learning Rate: 1.47e-05
2025-12-10 20:15:40 - INFO - Epoch: 34.42, Step: 136330, Train Loss: 1.1340, Learning Rate: 1.47e-05
2025-12-10 20:15:51 - INFO - Epoch: 34.42, Step: 136340, Train Loss: 1.1020, Learning Rate: 1.47e-05
2025-12-10 20:16:02 - INFO - Epoch: 34.42, Step: 136350, Train Loss: 1.1540, Learning Rate: 1.47e-05
2025-12-10 20:16:14 - INFO - Epoch: 34.43, Step: 136360, Train Loss: 1.1322, Learning Rate: 1.47e-05
2025-12-10 20:16:25 - INFO - Epoch: 34.43, Step: 136370, Train Loss: 1.1497, Learning Rate: 1.47e-05
2025-12-10 20:16:36 - INFO - Epoch: 34.43, Step: 136380, Train Loss: 1.1375, Learning Rate: 1.47e-05
2025-12-10 20:16:47 - INFO - Epoch: 34.43, Step: 136390, Train Loss: 1.1583, Learning Rate: 1.47e-05
2025-12-10 20:16:58 - INFO - Epoch: 34.44, Step: 136400, Train Loss: 1.1660, Learning Rate: 1.46e-05
2025-12-10 20:17:09 - INFO - Epoch: 34.44, Step: 136410, Train Loss: 1.1339, Learning Rate: 1.46e-05
2025-12-10 20:17:20 - INFO - Epoch: 34.44, Step: 136420, Train Loss: 1.1363, Learning Rate: 1.46e-05
2025-12-10 20:17:32 - INFO - Epoch: 34.44, Step: 136430, Train Loss: 1.1319, Learning Rate: 1.46e-05
2025-12-10 20:17:43 - INFO - Epoch: 34.45, Step: 136440, Train Loss: 1.1300, Learning Rate: 1.46e-05
2025-12-10 20:17:54 - INFO - Epoch: 34.45, Step: 136450, Train Loss: 1.1561, Learning Rate: 1.46e-05
2025-12-10 20:18:05 - INFO - Epoch: 34.45, Step: 136460, Train Loss: 1.1424, Learning Rate: 1.46e-05
2025-12-10 20:18:16 - INFO - Epoch: 34.45, Step: 136470, Train Loss: 1.1581, Learning Rate: 1.46e-05
2025-12-10 20:18:27 - INFO - Epoch: 34.46, Step: 136480, Train Loss: 1.1566, Learning Rate: 1.46e-05
2025-12-10 20:18:38 - INFO - Epoch: 34.46, Step: 136490, Train Loss: 1.1421, Learning Rate: 1.46e-05
2025-12-10 20:18:50 - INFO - Epoch: 34.46, Step: 136500, Train Loss: 1.1488, Learning Rate: 1.46e-05
2025-12-10 20:19:01 - INFO - Epoch: 34.46, Step: 136510, Train Loss: 1.1217, Learning Rate: 1.46e-05
2025-12-10 20:19:12 - INFO - Epoch: 34.47, Step: 136520, Train Loss: 1.0957, Learning Rate: 1.46e-05
2025-12-10 20:19:23 - INFO - Epoch: 34.47, Step: 136530, Train Loss: 1.1887, Learning Rate: 1.46e-05
2025-12-10 20:19:34 - INFO - Epoch: 34.47, Step: 136540, Train Loss: 1.1171, Learning Rate: 1.46e-05
2025-12-10 20:19:45 - INFO - Epoch: 34.47, Step: 136550, Train Loss: 1.0864, Learning Rate: 1.45e-05
2025-12-10 20:19:57 - INFO - Epoch: 34.48, Step: 136560, Train Loss: 1.1541, Learning Rate: 1.45e-05
2025-12-10 20:20:08 - INFO - Epoch: 34.48, Step: 136570, Train Loss: 1.1408, Learning Rate: 1.45e-05
2025-12-10 20:20:19 - INFO - Epoch: 34.48, Step: 136580, Train Loss: 1.1427, Learning Rate: 1.45e-05
2025-12-10 20:20:30 - INFO - Epoch: 34.48, Step: 136590, Train Loss: 1.1369, Learning Rate: 1.45e-05
2025-12-10 20:20:41 - INFO - Epoch: 34.49, Step: 136600, Train Loss: 1.1674, Learning Rate: 1.45e-05
2025-12-10 20:20:52 - INFO - Epoch: 34.49, Step: 136610, Train Loss: 1.1498, Learning Rate: 1.45e-05
2025-12-10 20:21:03 - INFO - Epoch: 34.49, Step: 136620, Train Loss: 1.1566, Learning Rate: 1.45e-05
2025-12-10 20:21:15 - INFO - Epoch: 34.49, Step: 136630, Train Loss: 1.0804, Learning Rate: 1.45e-05
2025-12-10 20:21:26 - INFO - Epoch: 34.50, Step: 136640, Train Loss: 1.1422, Learning Rate: 1.45e-05
2025-12-10 20:21:37 - INFO - Epoch: 34.50, Step: 136650, Train Loss: 1.1030, Learning Rate: 1.45e-05
2025-12-10 20:21:48 - INFO - Epoch: 34.50, Step: 136660, Train Loss: 1.1528, Learning Rate: 1.45e-05
2025-12-10 20:21:59 - INFO - Epoch: 34.50, Step: 136670, Train Loss: 1.1697, Learning Rate: 1.45e-05
2025-12-10 20:22:10 - INFO - Epoch: 34.51, Step: 136680, Train Loss: 1.1440, Learning Rate: 1.45e-05
2025-12-10 20:22:22 - INFO - Epoch: 34.51, Step: 136690, Train Loss: 1.1851, Learning Rate: 1.45e-05
2025-12-10 20:22:33 - INFO - Epoch: 34.51, Step: 136700, Train Loss: 1.1456, Learning Rate: 1.44e-05
2025-12-10 20:22:44 - INFO - Epoch: 34.51, Step: 136710, Train Loss: 1.1865, Learning Rate: 1.44e-05
2025-12-10 20:22:55 - INFO - Epoch: 34.52, Step: 136720, Train Loss: 1.1623, Learning Rate: 1.44e-05
2025-12-10 20:23:06 - INFO - Epoch: 34.52, Step: 136730, Train Loss: 1.1656, Learning Rate: 1.44e-05
2025-12-10 20:23:17 - INFO - Epoch: 34.52, Step: 136740, Train Loss: 1.1762, Learning Rate: 1.44e-05
2025-12-10 20:23:28 - INFO - Epoch: 34.52, Step: 136750, Train Loss: 1.1456, Learning Rate: 1.44e-05
2025-12-10 20:23:40 - INFO - Epoch: 34.53, Step: 136760, Train Loss: 1.1244, Learning Rate: 1.44e-05
2025-12-10 20:23:51 - INFO - Epoch: 34.53, Step: 136770, Train Loss: 1.1608, Learning Rate: 1.44e-05
2025-12-10 20:24:02 - INFO - Epoch: 34.53, Step: 136780, Train Loss: 1.1149, Learning Rate: 1.44e-05
2025-12-10 20:24:13 - INFO - Epoch: 34.53, Step: 136790, Train Loss: 1.1440, Learning Rate: 1.44e-05
2025-12-10 20:24:24 - INFO - Epoch: 34.54, Step: 136800, Train Loss: 1.1653, Learning Rate: 1.44e-05
2025-12-10 20:24:35 - INFO - Epoch: 34.54, Step: 136810, Train Loss: 1.1372, Learning Rate: 1.44e-05
2025-12-10 20:24:47 - INFO - Epoch: 34.54, Step: 136820, Train Loss: 1.1642, Learning Rate: 1.44e-05
2025-12-10 20:24:58 - INFO - Epoch: 34.54, Step: 136830, Train Loss: 1.1680, Learning Rate: 1.44e-05
2025-12-10 20:25:09 - INFO - Epoch: 34.55, Step: 136840, Train Loss: 1.1246, Learning Rate: 1.44e-05
2025-12-10 20:25:20 - INFO - Epoch: 34.55, Step: 136850, Train Loss: 1.1342, Learning Rate: 1.43e-05
2025-12-10 20:25:31 - INFO - Epoch: 34.55, Step: 136860, Train Loss: 1.1493, Learning Rate: 1.43e-05
2025-12-10 20:25:42 - INFO - Epoch: 34.55, Step: 136870, Train Loss: 1.1626, Learning Rate: 1.43e-05
2025-12-10 20:25:53 - INFO - Epoch: 34.56, Step: 136880, Train Loss: 1.1605, Learning Rate: 1.43e-05
2025-12-10 20:26:05 - INFO - Epoch: 34.56, Step: 136890, Train Loss: 1.1257, Learning Rate: 1.43e-05
2025-12-10 20:26:16 - INFO - Epoch: 34.56, Step: 136900, Train Loss: 1.1559, Learning Rate: 1.43e-05
2025-12-10 20:26:27 - INFO - Epoch: 34.56, Step: 136910, Train Loss: 1.1589, Learning Rate: 1.43e-05
2025-12-10 20:26:38 - INFO - Epoch: 34.57, Step: 136920, Train Loss: 1.1296, Learning Rate: 1.43e-05
2025-12-10 20:26:49 - INFO - Epoch: 34.57, Step: 136930, Train Loss: 1.1467, Learning Rate: 1.43e-05
2025-12-10 20:27:00 - INFO - Epoch: 34.57, Step: 136940, Train Loss: 1.1529, Learning Rate: 1.43e-05
2025-12-10 20:27:11 - INFO - Epoch: 34.57, Step: 136950, Train Loss: 1.1430, Learning Rate: 1.43e-05
2025-12-10 20:27:23 - INFO - Epoch: 34.58, Step: 136960, Train Loss: 1.1494, Learning Rate: 1.43e-05
2025-12-10 20:27:34 - INFO - Epoch: 34.58, Step: 136970, Train Loss: 1.1656, Learning Rate: 1.43e-05
2025-12-10 20:27:45 - INFO - Epoch: 34.58, Step: 136980, Train Loss: 1.1428, Learning Rate: 1.43e-05
2025-12-10 20:27:56 - INFO - Epoch: 34.58, Step: 136990, Train Loss: 1.1570, Learning Rate: 1.43e-05
2025-12-10 20:28:07 - INFO - Epoch: 34.59, Step: 137000, Train Loss: 1.1425, Learning Rate: 1.42e-05
2025-12-10 20:28:18 - INFO - Epoch: 34.59, Step: 137010, Train Loss: 1.1544, Learning Rate: 1.42e-05
2025-12-10 20:28:30 - INFO - Epoch: 34.59, Step: 137020, Train Loss: 1.1378, Learning Rate: 1.42e-05
2025-12-10 20:28:41 - INFO - Epoch: 34.59, Step: 137030, Train Loss: 1.1418, Learning Rate: 1.42e-05
2025-12-10 20:28:52 - INFO - Epoch: 34.60, Step: 137040, Train Loss: 1.1484, Learning Rate: 1.42e-05
2025-12-10 20:29:03 - INFO - Epoch: 34.60, Step: 137050, Train Loss: 1.1324, Learning Rate: 1.42e-05
2025-12-10 20:29:14 - INFO - Epoch: 34.60, Step: 137060, Train Loss: 1.1668, Learning Rate: 1.42e-05
2025-12-10 20:29:25 - INFO - Epoch: 34.60, Step: 137070, Train Loss: 1.1366, Learning Rate: 1.42e-05
2025-12-10 20:29:36 - INFO - Epoch: 34.61, Step: 137080, Train Loss: 1.1765, Learning Rate: 1.42e-05
2025-12-10 20:29:48 - INFO - Epoch: 34.61, Step: 137090, Train Loss: 1.1589, Learning Rate: 1.42e-05
2025-12-10 20:29:59 - INFO - Epoch: 34.61, Step: 137100, Train Loss: 1.1566, Learning Rate: 1.42e-05
2025-12-10 20:30:10 - INFO - Epoch: 34.61, Step: 137110, Train Loss: 1.1787, Learning Rate: 1.42e-05
2025-12-10 20:30:21 - INFO - Epoch: 34.62, Step: 137120, Train Loss: 1.1591, Learning Rate: 1.42e-05
2025-12-10 20:30:32 - INFO - Epoch: 34.62, Step: 137130, Train Loss: 1.1267, Learning Rate: 1.42e-05
2025-12-10 20:30:43 - INFO - Epoch: 34.62, Step: 137140, Train Loss: 1.1517, Learning Rate: 1.42e-05
2025-12-10 20:30:55 - INFO - Epoch: 34.63, Step: 137150, Train Loss: 1.1561, Learning Rate: 1.41e-05
2025-12-10 20:31:06 - INFO - Epoch: 34.63, Step: 137160, Train Loss: 1.1513, Learning Rate: 1.41e-05
2025-12-10 20:31:17 - INFO - Epoch: 34.63, Step: 137170, Train Loss: 1.1512, Learning Rate: 1.41e-05
2025-12-10 20:31:28 - INFO - Epoch: 34.63, Step: 137180, Train Loss: 1.1859, Learning Rate: 1.41e-05
2025-12-10 20:31:39 - INFO - Epoch: 34.64, Step: 137190, Train Loss: 1.1370, Learning Rate: 1.41e-05
2025-12-10 20:31:50 - INFO - Epoch: 34.64, Step: 137200, Train Loss: 1.1676, Learning Rate: 1.41e-05
2025-12-10 20:32:01 - INFO - Epoch: 34.64, Step: 137210, Train Loss: 1.1422, Learning Rate: 1.41e-05
2025-12-10 20:32:13 - INFO - Epoch: 34.64, Step: 137220, Train Loss: 1.1310, Learning Rate: 1.41e-05
2025-12-10 20:32:24 - INFO - Epoch: 34.65, Step: 137230, Train Loss: 1.1539, Learning Rate: 1.41e-05
2025-12-10 20:32:35 - INFO - Epoch: 34.65, Step: 137240, Train Loss: 1.1635, Learning Rate: 1.41e-05
2025-12-10 20:32:46 - INFO - Epoch: 34.65, Step: 137250, Train Loss: 1.1818, Learning Rate: 1.41e-05
2025-12-10 20:32:57 - INFO - Epoch: 34.65, Step: 137260, Train Loss: 1.1753, Learning Rate: 1.41e-05
2025-12-10 20:33:08 - INFO - Epoch: 34.66, Step: 137270, Train Loss: 1.1200, Learning Rate: 1.41e-05
2025-12-10 20:33:19 - INFO - Epoch: 34.66, Step: 137280, Train Loss: 1.1482, Learning Rate: 1.41e-05
2025-12-10 20:33:31 - INFO - Epoch: 34.66, Step: 137290, Train Loss: 1.1462, Learning Rate: 1.41e-05
2025-12-10 20:33:42 - INFO - Epoch: 34.66, Step: 137300, Train Loss: 1.1470, Learning Rate: 1.40e-05
2025-12-10 20:33:53 - INFO - Epoch: 34.67, Step: 137310, Train Loss: 1.1576, Learning Rate: 1.40e-05
2025-12-10 20:34:04 - INFO - Epoch: 34.67, Step: 137320, Train Loss: 1.1485, Learning Rate: 1.40e-05
2025-12-10 20:34:15 - INFO - Epoch: 34.67, Step: 137330, Train Loss: 1.1352, Learning Rate: 1.40e-05
2025-12-10 20:34:26 - INFO - Epoch: 34.67, Step: 137340, Train Loss: 1.1709, Learning Rate: 1.40e-05
2025-12-10 20:34:38 - INFO - Epoch: 34.68, Step: 137350, Train Loss: 1.1643, Learning Rate: 1.40e-05
2025-12-10 20:34:49 - INFO - Epoch: 34.68, Step: 137360, Train Loss: 1.1529, Learning Rate: 1.40e-05
2025-12-10 20:35:00 - INFO - Epoch: 34.68, Step: 137370, Train Loss: 1.1400, Learning Rate: 1.40e-05
2025-12-10 20:35:11 - INFO - Epoch: 34.68, Step: 137380, Train Loss: 1.1478, Learning Rate: 1.40e-05
2025-12-10 20:35:22 - INFO - Epoch: 34.69, Step: 137390, Train Loss: 1.1518, Learning Rate: 1.40e-05
2025-12-10 20:35:33 - INFO - Epoch: 34.69, Step: 137400, Train Loss: 1.1312, Learning Rate: 1.40e-05
2025-12-10 20:35:44 - INFO - Epoch: 34.69, Step: 137410, Train Loss: 1.1480, Learning Rate: 1.40e-05
2025-12-10 20:35:56 - INFO - Epoch: 34.69, Step: 137420, Train Loss: 1.1496, Learning Rate: 1.40e-05
2025-12-10 20:36:07 - INFO - Epoch: 34.70, Step: 137430, Train Loss: 1.1716, Learning Rate: 1.40e-05
2025-12-10 20:36:18 - INFO - Epoch: 34.70, Step: 137440, Train Loss: 1.1920, Learning Rate: 1.40e-05
2025-12-10 20:36:29 - INFO - Epoch: 34.70, Step: 137450, Train Loss: 1.1830, Learning Rate: 1.39e-05
2025-12-10 20:36:40 - INFO - Epoch: 34.70, Step: 137460, Train Loss: 1.1277, Learning Rate: 1.39e-05
2025-12-10 20:36:51 - INFO - Epoch: 34.71, Step: 137470, Train Loss: 1.1322, Learning Rate: 1.39e-05
2025-12-10 20:37:03 - INFO - Epoch: 34.71, Step: 137480, Train Loss: 1.1520, Learning Rate: 1.39e-05
2025-12-10 20:37:14 - INFO - Epoch: 34.71, Step: 137490, Train Loss: 1.1814, Learning Rate: 1.39e-05
2025-12-10 20:37:25 - INFO - Epoch: 34.71, Step: 137500, Train Loss: 1.1473, Learning Rate: 1.39e-05
2025-12-10 20:37:36 - INFO - Epoch: 34.72, Step: 137510, Train Loss: 1.1177, Learning Rate: 1.39e-05
2025-12-10 20:37:47 - INFO - Epoch: 34.72, Step: 137520, Train Loss: 1.1297, Learning Rate: 1.39e-05
2025-12-10 20:37:58 - INFO - Epoch: 34.72, Step: 137530, Train Loss: 1.1207, Learning Rate: 1.39e-05
2025-12-10 20:38:09 - INFO - Epoch: 34.72, Step: 137540, Train Loss: 1.1299, Learning Rate: 1.39e-05
2025-12-10 20:38:21 - INFO - Epoch: 34.73, Step: 137550, Train Loss: 1.1744, Learning Rate: 1.39e-05
2025-12-10 20:38:32 - INFO - Epoch: 34.73, Step: 137560, Train Loss: 1.1485, Learning Rate: 1.39e-05
2025-12-10 20:38:43 - INFO - Epoch: 34.73, Step: 137570, Train Loss: 1.1167, Learning Rate: 1.39e-05
2025-12-10 20:38:54 - INFO - Epoch: 34.73, Step: 137580, Train Loss: 1.1130, Learning Rate: 1.39e-05
2025-12-10 20:39:05 - INFO - Epoch: 34.74, Step: 137590, Train Loss: 1.1358, Learning Rate: 1.39e-05
2025-12-10 20:39:16 - INFO - Epoch: 34.74, Step: 137600, Train Loss: 1.1321, Learning Rate: 1.38e-05
2025-12-10 20:39:28 - INFO - Epoch: 34.74, Step: 137610, Train Loss: 1.1786, Learning Rate: 1.38e-05
2025-12-10 20:39:39 - INFO - Epoch: 34.74, Step: 137620, Train Loss: 1.1816, Learning Rate: 1.38e-05
2025-12-10 20:39:50 - INFO - Epoch: 34.75, Step: 137630, Train Loss: 1.1708, Learning Rate: 1.38e-05
2025-12-10 20:40:01 - INFO - Epoch: 34.75, Step: 137640, Train Loss: 1.1419, Learning Rate: 1.38e-05
2025-12-10 20:40:12 - INFO - Epoch: 34.75, Step: 137650, Train Loss: 1.1379, Learning Rate: 1.38e-05
2025-12-10 20:40:23 - INFO - Epoch: 34.75, Step: 137660, Train Loss: 1.1561, Learning Rate: 1.38e-05
2025-12-10 20:40:34 - INFO - Epoch: 34.76, Step: 137670, Train Loss: 1.1459, Learning Rate: 1.38e-05
2025-12-10 20:40:46 - INFO - Epoch: 34.76, Step: 137680, Train Loss: 1.1319, Learning Rate: 1.38e-05
2025-12-10 20:40:57 - INFO - Epoch: 34.76, Step: 137690, Train Loss: 1.1117, Learning Rate: 1.38e-05
2025-12-10 20:41:08 - INFO - Epoch: 34.76, Step: 137700, Train Loss: 1.1409, Learning Rate: 1.38e-05
2025-12-10 20:41:19 - INFO - Epoch: 34.77, Step: 137710, Train Loss: 1.1441, Learning Rate: 1.38e-05
2025-12-10 20:41:30 - INFO - Epoch: 34.77, Step: 137720, Train Loss: 1.1592, Learning Rate: 1.38e-05
2025-12-10 20:41:41 - INFO - Epoch: 34.77, Step: 137730, Train Loss: 1.1544, Learning Rate: 1.38e-05
2025-12-10 20:41:52 - INFO - Epoch: 34.77, Step: 137740, Train Loss: 1.1457, Learning Rate: 1.38e-05
2025-12-10 20:42:04 - INFO - Epoch: 34.78, Step: 137750, Train Loss: 1.1501, Learning Rate: 1.37e-05
2025-12-10 20:42:15 - INFO - Epoch: 34.78, Step: 137760, Train Loss: 1.1372, Learning Rate: 1.37e-05
2025-12-10 20:42:26 - INFO - Epoch: 34.78, Step: 137770, Train Loss: 1.1329, Learning Rate: 1.37e-05
2025-12-10 20:42:37 - INFO - Epoch: 34.78, Step: 137780, Train Loss: 1.1490, Learning Rate: 1.37e-05
2025-12-10 20:42:48 - INFO - Epoch: 34.79, Step: 137790, Train Loss: 1.2086, Learning Rate: 1.37e-05
2025-12-10 20:42:59 - INFO - Epoch: 34.79, Step: 137800, Train Loss: 1.1482, Learning Rate: 1.37e-05
2025-12-10 20:43:11 - INFO - Epoch: 34.79, Step: 137810, Train Loss: 1.1427, Learning Rate: 1.37e-05
2025-12-10 20:43:22 - INFO - Epoch: 34.79, Step: 137820, Train Loss: 1.1287, Learning Rate: 1.37e-05
2025-12-10 20:43:33 - INFO - Epoch: 34.80, Step: 137830, Train Loss: 1.1405, Learning Rate: 1.37e-05
2025-12-10 20:43:44 - INFO - Epoch: 34.80, Step: 137840, Train Loss: 1.1538, Learning Rate: 1.37e-05
2025-12-10 20:43:55 - INFO - Epoch: 34.80, Step: 137850, Train Loss: 1.1226, Learning Rate: 1.37e-05
2025-12-10 20:44:06 - INFO - Epoch: 34.80, Step: 137860, Train Loss: 1.1704, Learning Rate: 1.37e-05
2025-12-10 20:44:17 - INFO - Epoch: 34.81, Step: 137870, Train Loss: 1.1429, Learning Rate: 1.37e-05
2025-12-10 20:44:29 - INFO - Epoch: 34.81, Step: 137880, Train Loss: 1.1781, Learning Rate: 1.37e-05
2025-12-10 20:44:40 - INFO - Epoch: 34.81, Step: 137890, Train Loss: 1.1119, Learning Rate: 1.37e-05
2025-12-10 20:44:51 - INFO - Epoch: 34.81, Step: 137900, Train Loss: 1.1391, Learning Rate: 1.36e-05
2025-12-10 20:45:02 - INFO - Epoch: 34.82, Step: 137910, Train Loss: 1.1376, Learning Rate: 1.36e-05
2025-12-10 20:45:13 - INFO - Epoch: 34.82, Step: 137920, Train Loss: 1.1513, Learning Rate: 1.36e-05
2025-12-10 20:45:24 - INFO - Epoch: 34.82, Step: 137930, Train Loss: 1.1254, Learning Rate: 1.36e-05
2025-12-10 20:45:36 - INFO - Epoch: 34.82, Step: 137940, Train Loss: 1.1652, Learning Rate: 1.36e-05
2025-12-10 20:45:47 - INFO - Epoch: 34.83, Step: 137950, Train Loss: 1.1656, Learning Rate: 1.36e-05
2025-12-10 20:45:58 - INFO - Epoch: 34.83, Step: 137960, Train Loss: 1.1526, Learning Rate: 1.36e-05
2025-12-10 20:46:09 - INFO - Epoch: 34.83, Step: 137970, Train Loss: 1.1291, Learning Rate: 1.36e-05
2025-12-10 20:46:20 - INFO - Epoch: 34.83, Step: 137980, Train Loss: 1.1600, Learning Rate: 1.36e-05
2025-12-10 20:46:31 - INFO - Epoch: 34.84, Step: 137990, Train Loss: 1.1678, Learning Rate: 1.36e-05
2025-12-10 20:46:42 - INFO - Epoch: 34.84, Step: 138000, Train Loss: 1.1799, Learning Rate: 1.36e-05
2025-12-10 20:46:54 - INFO - Epoch: 34.84, Step: 138010, Train Loss: 1.1631, Learning Rate: 1.36e-05
2025-12-10 20:47:05 - INFO - Epoch: 34.84, Step: 138020, Train Loss: 1.1384, Learning Rate: 1.36e-05
2025-12-10 20:47:16 - INFO - Epoch: 34.85, Step: 138030, Train Loss: 1.1453, Learning Rate: 1.36e-05
2025-12-10 20:47:27 - INFO - Epoch: 34.85, Step: 138040, Train Loss: 1.1520, Learning Rate: 1.36e-05
2025-12-10 20:47:38 - INFO - Epoch: 34.85, Step: 138050, Train Loss: 1.1503, Learning Rate: 1.35e-05
2025-12-10 20:47:49 - INFO - Epoch: 34.85, Step: 138060, Train Loss: 1.1487, Learning Rate: 1.35e-05
2025-12-10 20:48:00 - INFO - Epoch: 34.86, Step: 138070, Train Loss: 1.1271, Learning Rate: 1.35e-05
2025-12-10 20:48:12 - INFO - Epoch: 34.86, Step: 138080, Train Loss: 1.1761, Learning Rate: 1.35e-05
2025-12-10 20:48:23 - INFO - Epoch: 34.86, Step: 138090, Train Loss: 1.1622, Learning Rate: 1.35e-05
2025-12-10 20:48:34 - INFO - Epoch: 34.86, Step: 138100, Train Loss: 1.1347, Learning Rate: 1.35e-05
2025-12-10 20:48:45 - INFO - Epoch: 34.87, Step: 138110, Train Loss: 1.1403, Learning Rate: 1.35e-05
2025-12-10 20:48:56 - INFO - Epoch: 34.87, Step: 138120, Train Loss: 1.1881, Learning Rate: 1.35e-05
2025-12-10 20:49:07 - INFO - Epoch: 34.87, Step: 138130, Train Loss: 1.1742, Learning Rate: 1.35e-05
2025-12-10 20:49:19 - INFO - Epoch: 34.88, Step: 138140, Train Loss: 1.1351, Learning Rate: 1.35e-05
2025-12-10 20:49:30 - INFO - Epoch: 34.88, Step: 138150, Train Loss: 1.1523, Learning Rate: 1.35e-05
2025-12-10 20:49:41 - INFO - Epoch: 34.88, Step: 138160, Train Loss: 1.1560, Learning Rate: 1.35e-05
2025-12-10 20:49:52 - INFO - Epoch: 34.88, Step: 138170, Train Loss: 1.1299, Learning Rate: 1.35e-05
2025-12-10 20:50:03 - INFO - Epoch: 34.89, Step: 138180, Train Loss: 1.1026, Learning Rate: 1.35e-05
2025-12-10 20:50:14 - INFO - Epoch: 34.89, Step: 138190, Train Loss: 1.1943, Learning Rate: 1.35e-05
2025-12-10 20:50:25 - INFO - Epoch: 34.89, Step: 138200, Train Loss: 1.1613, Learning Rate: 1.34e-05
2025-12-10 20:50:37 - INFO - Epoch: 34.89, Step: 138210, Train Loss: 1.1908, Learning Rate: 1.34e-05
2025-12-10 20:50:48 - INFO - Epoch: 34.90, Step: 138220, Train Loss: 1.1462, Learning Rate: 1.34e-05
2025-12-10 20:50:59 - INFO - Epoch: 34.90, Step: 138230, Train Loss: 1.1949, Learning Rate: 1.34e-05
2025-12-10 20:51:10 - INFO - Epoch: 34.90, Step: 138240, Train Loss: 1.1276, Learning Rate: 1.34e-05
2025-12-10 20:51:21 - INFO - Epoch: 34.90, Step: 138250, Train Loss: 1.1285, Learning Rate: 1.34e-05
2025-12-10 20:51:32 - INFO - Epoch: 34.91, Step: 138260, Train Loss: 1.1551, Learning Rate: 1.34e-05
2025-12-10 20:51:44 - INFO - Epoch: 34.91, Step: 138270, Train Loss: 1.1517, Learning Rate: 1.34e-05
2025-12-10 20:51:55 - INFO - Epoch: 34.91, Step: 138280, Train Loss: 1.1736, Learning Rate: 1.34e-05
2025-12-10 20:52:06 - INFO - Epoch: 34.91, Step: 138290, Train Loss: 1.1622, Learning Rate: 1.34e-05
2025-12-10 20:52:17 - INFO - Epoch: 34.92, Step: 138300, Train Loss: 1.1342, Learning Rate: 1.34e-05
2025-12-10 20:52:28 - INFO - Epoch: 34.92, Step: 138310, Train Loss: 1.1690, Learning Rate: 1.34e-05
2025-12-10 20:52:39 - INFO - Epoch: 34.92, Step: 138320, Train Loss: 1.1943, Learning Rate: 1.34e-05
2025-12-10 20:52:50 - INFO - Epoch: 34.92, Step: 138330, Train Loss: 1.1243, Learning Rate: 1.34e-05
2025-12-10 20:53:02 - INFO - Epoch: 34.93, Step: 138340, Train Loss: 1.1616, Learning Rate: 1.34e-05
2025-12-10 20:53:13 - INFO - Epoch: 34.93, Step: 138350, Train Loss: 1.1408, Learning Rate: 1.33e-05
2025-12-10 20:53:24 - INFO - Epoch: 34.93, Step: 138360, Train Loss: 1.1539, Learning Rate: 1.33e-05
2025-12-10 20:53:35 - INFO - Epoch: 34.93, Step: 138370, Train Loss: 1.1514, Learning Rate: 1.33e-05
2025-12-10 20:53:46 - INFO - Epoch: 34.94, Step: 138380, Train Loss: 1.1454, Learning Rate: 1.33e-05
2025-12-10 20:53:57 - INFO - Epoch: 34.94, Step: 138390, Train Loss: 1.1718, Learning Rate: 1.33e-05
2025-12-10 20:54:09 - INFO - Epoch: 34.94, Step: 138400, Train Loss: 1.1322, Learning Rate: 1.33e-05
2025-12-10 20:54:20 - INFO - Epoch: 34.94, Step: 138410, Train Loss: 1.1489, Learning Rate: 1.33e-05
2025-12-10 20:54:31 - INFO - Epoch: 34.95, Step: 138420, Train Loss: 1.1295, Learning Rate: 1.33e-05
2025-12-10 20:54:42 - INFO - Epoch: 34.95, Step: 138430, Train Loss: 1.1503, Learning Rate: 1.33e-05
2025-12-10 20:54:53 - INFO - Epoch: 34.95, Step: 138440, Train Loss: 1.1681, Learning Rate: 1.33e-05
2025-12-10 20:55:04 - INFO - Epoch: 34.95, Step: 138450, Train Loss: 1.1437, Learning Rate: 1.33e-05
2025-12-10 20:55:15 - INFO - Epoch: 34.96, Step: 138460, Train Loss: 1.1439, Learning Rate: 1.33e-05
2025-12-10 20:55:27 - INFO - Epoch: 34.96, Step: 138470, Train Loss: 1.1388, Learning Rate: 1.33e-05
2025-12-10 20:55:38 - INFO - Epoch: 34.96, Step: 138480, Train Loss: 1.1537, Learning Rate: 1.33e-05
2025-12-10 20:55:49 - INFO - Epoch: 34.96, Step: 138490, Train Loss: 1.1640, Learning Rate: 1.33e-05
2025-12-10 20:56:00 - INFO - Epoch: 34.97, Step: 138500, Train Loss: 1.1019, Learning Rate: 1.32e-05
2025-12-10 20:56:11 - INFO - Epoch: 34.97, Step: 138510, Train Loss: 1.1588, Learning Rate: 1.32e-05
2025-12-10 20:56:22 - INFO - Epoch: 34.97, Step: 138520, Train Loss: 1.1416, Learning Rate: 1.32e-05
2025-12-10 20:56:33 - INFO - Epoch: 34.97, Step: 138530, Train Loss: 1.1226, Learning Rate: 1.32e-05
2025-12-10 20:56:45 - INFO - Epoch: 34.98, Step: 138540, Train Loss: 1.1449, Learning Rate: 1.32e-05
2025-12-10 20:56:56 - INFO - Epoch: 34.98, Step: 138550, Train Loss: 1.1425, Learning Rate: 1.32e-05
2025-12-10 20:57:07 - INFO - Epoch: 34.98, Step: 138560, Train Loss: 1.1436, Learning Rate: 1.32e-05
2025-12-10 20:57:18 - INFO - Epoch: 34.98, Step: 138570, Train Loss: 1.1375, Learning Rate: 1.32e-05
2025-12-10 20:57:29 - INFO - Epoch: 34.99, Step: 138580, Train Loss: 1.1255, Learning Rate: 1.32e-05
2025-12-10 20:57:40 - INFO - Epoch: 34.99, Step: 138590, Train Loss: 1.1244, Learning Rate: 1.32e-05
2025-12-10 20:57:52 - INFO - Epoch: 34.99, Step: 138600, Train Loss: 1.1520, Learning Rate: 1.32e-05
2025-12-10 20:58:03 - INFO - Epoch: 34.99, Step: 138610, Train Loss: 1.1617, Learning Rate: 1.32e-05
2025-12-10 20:58:14 - INFO - Epoch: 35.00, Step: 138620, Train Loss: 1.1410, Learning Rate: 1.32e-05
2025-12-10 20:58:25 - INFO - Epoch: 35.00, Step: 138630, Train Loss: 1.1529, Learning Rate: 1.32e-05
2025-12-10 20:58:36 - INFO - Epoch: 35.00, Step: 138640, Train Loss: 1.1047, Learning Rate: 1.32e-05
2025-12-10 20:58:47 - INFO - Epoch: 35.00, Step: 138650, Train Loss: 1.1362, Learning Rate: 1.31e-05
2025-12-10 20:58:58 - INFO - Epoch: 35.01, Step: 138660, Train Loss: 1.1187, Learning Rate: 1.31e-05
2025-12-10 20:59:10 - INFO - Epoch: 35.01, Step: 138670, Train Loss: 1.1336, Learning Rate: 1.31e-05
2025-12-10 20:59:21 - INFO - Epoch: 35.01, Step: 138680, Train Loss: 1.1386, Learning Rate: 1.31e-05
2025-12-10 20:59:32 - INFO - Epoch: 35.01, Step: 138690, Train Loss: 1.1299, Learning Rate: 1.31e-05
2025-12-10 20:59:43 - INFO - Epoch: 35.02, Step: 138700, Train Loss: 1.1540, Learning Rate: 1.31e-05
2025-12-10 20:59:54 - INFO - Epoch: 35.02, Step: 138710, Train Loss: 1.1239, Learning Rate: 1.31e-05
2025-12-10 21:00:05 - INFO - Epoch: 35.02, Step: 138720, Train Loss: 1.1493, Learning Rate: 1.31e-05
2025-12-10 21:00:17 - INFO - Epoch: 35.02, Step: 138730, Train Loss: 1.1785, Learning Rate: 1.31e-05
2025-12-10 21:00:28 - INFO - Epoch: 35.03, Step: 138740, Train Loss: 1.1403, Learning Rate: 1.31e-05
2025-12-10 21:00:39 - INFO - Epoch: 35.03, Step: 138750, Train Loss: 1.1766, Learning Rate: 1.31e-05
2025-12-10 21:00:50 - INFO - Epoch: 35.03, Step: 138760, Train Loss: 1.1376, Learning Rate: 1.31e-05
2025-12-10 21:01:01 - INFO - Epoch: 35.03, Step: 138770, Train Loss: 1.1442, Learning Rate: 1.31e-05
2025-12-10 21:01:12 - INFO - Epoch: 35.04, Step: 138780, Train Loss: 1.1560, Learning Rate: 1.31e-05
2025-12-10 21:01:23 - INFO - Epoch: 35.04, Step: 138790, Train Loss: 1.1031, Learning Rate: 1.31e-05
2025-12-10 21:01:35 - INFO - Epoch: 35.04, Step: 138800, Train Loss: 1.1357, Learning Rate: 1.30e-05
2025-12-10 21:01:46 - INFO - Epoch: 35.04, Step: 138810, Train Loss: 1.2012, Learning Rate: 1.30e-05
2025-12-10 21:01:57 - INFO - Epoch: 35.05, Step: 138820, Train Loss: 1.1310, Learning Rate: 1.30e-05
2025-12-10 21:02:08 - INFO - Epoch: 35.05, Step: 138830, Train Loss: 1.1564, Learning Rate: 1.30e-05
2025-12-10 21:02:19 - INFO - Epoch: 35.05, Step: 138840, Train Loss: 1.1242, Learning Rate: 1.30e-05
2025-12-10 21:02:30 - INFO - Epoch: 35.05, Step: 138850, Train Loss: 1.1637, Learning Rate: 1.30e-05
2025-12-10 21:02:41 - INFO - Epoch: 35.06, Step: 138860, Train Loss: 1.1194, Learning Rate: 1.30e-05
2025-12-10 21:02:53 - INFO - Epoch: 35.06, Step: 138870, Train Loss: 1.1421, Learning Rate: 1.30e-05
2025-12-10 21:03:04 - INFO - Epoch: 35.06, Step: 138880, Train Loss: 1.1664, Learning Rate: 1.30e-05
2025-12-10 21:03:15 - INFO - Epoch: 35.06, Step: 138890, Train Loss: 1.1497, Learning Rate: 1.30e-05
2025-12-10 21:03:26 - INFO - Epoch: 35.07, Step: 138900, Train Loss: 1.1801, Learning Rate: 1.30e-05
2025-12-10 21:03:37 - INFO - Epoch: 35.07, Step: 138910, Train Loss: 1.1579, Learning Rate: 1.30e-05
2025-12-10 21:03:48 - INFO - Epoch: 35.07, Step: 138920, Train Loss: 1.1406, Learning Rate: 1.30e-05
2025-12-10 21:04:00 - INFO - Epoch: 35.07, Step: 138930, Train Loss: 1.1457, Learning Rate: 1.30e-05
2025-12-10 21:04:11 - INFO - Epoch: 35.08, Step: 138940, Train Loss: 1.1313, Learning Rate: 1.30e-05
2025-12-10 21:04:22 - INFO - Epoch: 35.08, Step: 138950, Train Loss: 1.1207, Learning Rate: 1.29e-05
2025-12-10 21:04:33 - INFO - Epoch: 35.08, Step: 138960, Train Loss: 1.1722, Learning Rate: 1.29e-05
2025-12-10 21:04:44 - INFO - Epoch: 35.08, Step: 138970, Train Loss: 1.1196, Learning Rate: 1.29e-05
2025-12-10 21:04:55 - INFO - Epoch: 35.09, Step: 138980, Train Loss: 1.1365, Learning Rate: 1.29e-05
2025-12-10 21:05:06 - INFO - Epoch: 35.09, Step: 138990, Train Loss: 1.1422, Learning Rate: 1.29e-05
2025-12-10 21:05:18 - INFO - Epoch: 35.09, Step: 139000, Train Loss: 1.1642, Learning Rate: 1.29e-05
2025-12-10 21:05:29 - INFO - Epoch: 35.09, Step: 139010, Train Loss: 1.1805, Learning Rate: 1.29e-05
2025-12-10 21:05:40 - INFO - Epoch: 35.10, Step: 139020, Train Loss: 1.1227, Learning Rate: 1.29e-05
2025-12-10 21:05:51 - INFO - Epoch: 35.10, Step: 139030, Train Loss: 1.1023, Learning Rate: 1.29e-05
2025-12-10 21:06:02 - INFO - Epoch: 35.10, Step: 139040, Train Loss: 1.1839, Learning Rate: 1.29e-05
2025-12-10 21:06:13 - INFO - Epoch: 35.10, Step: 139050, Train Loss: 1.1340, Learning Rate: 1.29e-05
2025-12-10 21:06:25 - INFO - Epoch: 35.11, Step: 139060, Train Loss: 1.1241, Learning Rate: 1.29e-05
2025-12-10 21:06:36 - INFO - Epoch: 35.11, Step: 139070, Train Loss: 1.0976, Learning Rate: 1.29e-05
2025-12-10 21:06:47 - INFO - Epoch: 35.11, Step: 139080, Train Loss: 1.1374, Learning Rate: 1.29e-05
2025-12-10 21:06:58 - INFO - Epoch: 35.11, Step: 139090, Train Loss: 1.1512, Learning Rate: 1.29e-05
2025-12-10 21:07:09 - INFO - Epoch: 35.12, Step: 139100, Train Loss: 1.1561, Learning Rate: 1.28e-05
2025-12-10 21:07:20 - INFO - Epoch: 35.12, Step: 139110, Train Loss: 1.1231, Learning Rate: 1.28e-05
2025-12-10 21:07:31 - INFO - Epoch: 35.12, Step: 139120, Train Loss: 1.1614, Learning Rate: 1.28e-05
2025-12-10 21:07:43 - INFO - Epoch: 35.12, Step: 139130, Train Loss: 1.1404, Learning Rate: 1.28e-05
2025-12-10 21:07:54 - INFO - Epoch: 35.13, Step: 139140, Train Loss: 1.1275, Learning Rate: 1.28e-05
2025-12-10 21:08:05 - INFO - Epoch: 35.13, Step: 139150, Train Loss: 1.1431, Learning Rate: 1.28e-05
2025-12-10 21:08:16 - INFO - Epoch: 35.13, Step: 139160, Train Loss: 1.1269, Learning Rate: 1.28e-05
2025-12-10 21:08:27 - INFO - Epoch: 35.14, Step: 139170, Train Loss: 1.1542, Learning Rate: 1.28e-05
2025-12-10 21:08:38 - INFO - Epoch: 35.14, Step: 139180, Train Loss: 1.1169, Learning Rate: 1.28e-05
2025-12-10 21:08:50 - INFO - Epoch: 35.14, Step: 139190, Train Loss: 1.1050, Learning Rate: 1.28e-05
2025-12-10 21:09:01 - INFO - Epoch: 35.14, Step: 139200, Train Loss: 1.1347, Learning Rate: 1.28e-05
2025-12-10 21:09:12 - INFO - Epoch: 35.15, Step: 139210, Train Loss: 1.1640, Learning Rate: 1.28e-05
2025-12-10 21:09:23 - INFO - Epoch: 35.15, Step: 139220, Train Loss: 1.1557, Learning Rate: 1.28e-05
2025-12-10 21:09:34 - INFO - Epoch: 35.15, Step: 139230, Train Loss: 1.1125, Learning Rate: 1.28e-05
2025-12-10 21:09:45 - INFO - Epoch: 35.15, Step: 139240, Train Loss: 1.1527, Learning Rate: 1.28e-05
2025-12-10 21:09:56 - INFO - Epoch: 35.16, Step: 139250, Train Loss: 1.1186, Learning Rate: 1.27e-05
2025-12-10 21:10:08 - INFO - Epoch: 35.16, Step: 139260, Train Loss: 1.1551, Learning Rate: 1.27e-05
2025-12-10 21:10:19 - INFO - Epoch: 35.16, Step: 139270, Train Loss: 1.1266, Learning Rate: 1.27e-05
2025-12-10 21:10:30 - INFO - Epoch: 35.16, Step: 139280, Train Loss: 1.1353, Learning Rate: 1.27e-05
2025-12-10 21:10:41 - INFO - Epoch: 35.17, Step: 139290, Train Loss: 1.1165, Learning Rate: 1.27e-05
2025-12-10 21:10:52 - INFO - Epoch: 35.17, Step: 139300, Train Loss: 1.1353, Learning Rate: 1.27e-05
2025-12-10 21:11:03 - INFO - Epoch: 35.17, Step: 139310, Train Loss: 1.1498, Learning Rate: 1.27e-05
2025-12-10 21:11:15 - INFO - Epoch: 35.17, Step: 139320, Train Loss: 1.1517, Learning Rate: 1.27e-05
2025-12-10 21:11:26 - INFO - Epoch: 35.18, Step: 139330, Train Loss: 1.1869, Learning Rate: 1.27e-05
2025-12-10 21:11:37 - INFO - Epoch: 35.18, Step: 139340, Train Loss: 1.1585, Learning Rate: 1.27e-05
2025-12-10 21:11:48 - INFO - Epoch: 35.18, Step: 139350, Train Loss: 1.1447, Learning Rate: 1.27e-05
2025-12-10 21:11:59 - INFO - Epoch: 35.18, Step: 139360, Train Loss: 1.1375, Learning Rate: 1.27e-05
2025-12-10 21:12:10 - INFO - Epoch: 35.19, Step: 139370, Train Loss: 1.1648, Learning Rate: 1.27e-05
2025-12-10 21:12:21 - INFO - Epoch: 35.19, Step: 139380, Train Loss: 1.1264, Learning Rate: 1.27e-05
2025-12-10 21:12:33 - INFO - Epoch: 35.19, Step: 139390, Train Loss: 1.1378, Learning Rate: 1.27e-05
2025-12-10 21:12:44 - INFO - Epoch: 35.19, Step: 139400, Train Loss: 1.1307, Learning Rate: 1.27e-05
2025-12-10 21:12:55 - INFO - Epoch: 35.20, Step: 139410, Train Loss: 1.1234, Learning Rate: 1.26e-05
2025-12-10 21:13:06 - INFO - Epoch: 35.20, Step: 139420, Train Loss: 1.1041, Learning Rate: 1.26e-05
2025-12-10 21:13:17 - INFO - Epoch: 35.20, Step: 139430, Train Loss: 1.1697, Learning Rate: 1.26e-05
2025-12-10 21:13:28 - INFO - Epoch: 35.20, Step: 139440, Train Loss: 1.1418, Learning Rate: 1.26e-05
2025-12-10 21:13:39 - INFO - Epoch: 35.21, Step: 139450, Train Loss: 1.1714, Learning Rate: 1.26e-05
2025-12-10 21:13:51 - INFO - Epoch: 35.21, Step: 139460, Train Loss: 1.1493, Learning Rate: 1.26e-05
2025-12-10 21:14:02 - INFO - Epoch: 35.21, Step: 139470, Train Loss: 1.1627, Learning Rate: 1.26e-05
2025-12-10 21:14:13 - INFO - Epoch: 35.21, Step: 139480, Train Loss: 1.1879, Learning Rate: 1.26e-05
2025-12-10 21:14:24 - INFO - Epoch: 35.22, Step: 139490, Train Loss: 1.1478, Learning Rate: 1.26e-05
2025-12-10 21:14:35 - INFO - Epoch: 35.22, Step: 139500, Train Loss: 1.1272, Learning Rate: 1.26e-05
2025-12-10 21:14:46 - INFO - Epoch: 35.22, Step: 139510, Train Loss: 1.1742, Learning Rate: 1.26e-05
2025-12-10 21:14:58 - INFO - Epoch: 35.22, Step: 139520, Train Loss: 1.1634, Learning Rate: 1.26e-05
2025-12-10 21:15:09 - INFO - Epoch: 35.23, Step: 139530, Train Loss: 1.0983, Learning Rate: 1.26e-05
2025-12-10 21:15:20 - INFO - Epoch: 35.23, Step: 139540, Train Loss: 1.1297, Learning Rate: 1.26e-05
2025-12-10 21:15:31 - INFO - Epoch: 35.23, Step: 139550, Train Loss: 1.1638, Learning Rate: 1.26e-05
2025-12-10 21:15:42 - INFO - Epoch: 35.23, Step: 139560, Train Loss: 1.1882, Learning Rate: 1.25e-05
2025-12-10 21:15:53 - INFO - Epoch: 35.24, Step: 139570, Train Loss: 1.1339, Learning Rate: 1.25e-05
2025-12-10 21:16:04 - INFO - Epoch: 35.24, Step: 139580, Train Loss: 1.1167, Learning Rate: 1.25e-05
2025-12-10 21:16:16 - INFO - Epoch: 35.24, Step: 139590, Train Loss: 1.1742, Learning Rate: 1.25e-05
2025-12-10 21:16:27 - INFO - Epoch: 35.24, Step: 139600, Train Loss: 1.1643, Learning Rate: 1.25e-05
2025-12-10 21:16:38 - INFO - Epoch: 35.25, Step: 139610, Train Loss: 1.1323, Learning Rate: 1.25e-05
2025-12-10 21:16:49 - INFO - Epoch: 35.25, Step: 139620, Train Loss: 1.1970, Learning Rate: 1.25e-05
2025-12-10 21:17:00 - INFO - Epoch: 35.25, Step: 139630, Train Loss: 1.1743, Learning Rate: 1.25e-05
2025-12-10 21:17:11 - INFO - Epoch: 35.25, Step: 139640, Train Loss: 1.1464, Learning Rate: 1.25e-05
2025-12-10 21:17:23 - INFO - Epoch: 35.26, Step: 139650, Train Loss: 1.1155, Learning Rate: 1.25e-05
2025-12-10 21:17:34 - INFO - Epoch: 35.26, Step: 139660, Train Loss: 1.1474, Learning Rate: 1.25e-05
2025-12-10 21:17:45 - INFO - Epoch: 35.26, Step: 139670, Train Loss: 1.1633, Learning Rate: 1.25e-05
2025-12-10 21:17:56 - INFO - Epoch: 35.26, Step: 139680, Train Loss: 1.1465, Learning Rate: 1.25e-05
2025-12-10 21:18:07 - INFO - Epoch: 35.27, Step: 139690, Train Loss: 1.1468, Learning Rate: 1.25e-05
2025-12-10 21:18:18 - INFO - Epoch: 35.27, Step: 139700, Train Loss: 1.1150, Learning Rate: 1.25e-05
2025-12-10 21:18:29 - INFO - Epoch: 35.27, Step: 139710, Train Loss: 1.1373, Learning Rate: 1.24e-05
2025-12-10 21:18:41 - INFO - Epoch: 35.27, Step: 139720, Train Loss: 1.1512, Learning Rate: 1.24e-05
2025-12-10 21:18:52 - INFO - Epoch: 35.28, Step: 139730, Train Loss: 1.1558, Learning Rate: 1.24e-05
2025-12-10 21:19:03 - INFO - Epoch: 35.28, Step: 139740, Train Loss: 1.1140, Learning Rate: 1.24e-05
2025-12-10 21:19:14 - INFO - Epoch: 35.28, Step: 139750, Train Loss: 1.1084, Learning Rate: 1.24e-05
2025-12-10 21:19:25 - INFO - Epoch: 35.28, Step: 139760, Train Loss: 1.1543, Learning Rate: 1.24e-05
2025-12-10 21:19:36 - INFO - Epoch: 35.29, Step: 139770, Train Loss: 1.1022, Learning Rate: 1.24e-05
2025-12-10 21:19:48 - INFO - Epoch: 35.29, Step: 139780, Train Loss: 1.1399, Learning Rate: 1.24e-05
2025-12-10 21:19:59 - INFO - Epoch: 35.29, Step: 139790, Train Loss: 1.1852, Learning Rate: 1.24e-05
2025-12-10 21:20:10 - INFO - Epoch: 35.29, Step: 139800, Train Loss: 1.1870, Learning Rate: 1.24e-05
2025-12-10 21:20:21 - INFO - Epoch: 35.30, Step: 139810, Train Loss: 1.1548, Learning Rate: 1.24e-05
2025-12-10 21:20:32 - INFO - Epoch: 35.30, Step: 139820, Train Loss: 1.1497, Learning Rate: 1.24e-05
2025-12-10 21:20:43 - INFO - Epoch: 35.30, Step: 139830, Train Loss: 1.1456, Learning Rate: 1.24e-05
2025-12-10 21:20:54 - INFO - Epoch: 35.30, Step: 139840, Train Loss: 1.1457, Learning Rate: 1.24e-05
2025-12-10 21:21:06 - INFO - Epoch: 35.31, Step: 139850, Train Loss: 1.1928, Learning Rate: 1.24e-05
2025-12-10 21:21:17 - INFO - Epoch: 35.31, Step: 139860, Train Loss: 1.1532, Learning Rate: 1.23e-05
2025-12-10 21:21:28 - INFO - Epoch: 35.31, Step: 139870, Train Loss: 1.1310, Learning Rate: 1.23e-05
2025-12-10 21:21:39 - INFO - Epoch: 35.31, Step: 139880, Train Loss: 1.1382, Learning Rate: 1.23e-05
2025-12-10 21:21:50 - INFO - Epoch: 35.32, Step: 139890, Train Loss: 1.1673, Learning Rate: 1.23e-05
2025-12-10 21:22:01 - INFO - Epoch: 35.32, Step: 139900, Train Loss: 1.1541, Learning Rate: 1.23e-05
2025-12-10 21:22:12 - INFO - Epoch: 35.32, Step: 139910, Train Loss: 1.1400, Learning Rate: 1.23e-05
2025-12-10 21:22:24 - INFO - Epoch: 35.32, Step: 139920, Train Loss: 1.1812, Learning Rate: 1.23e-05
2025-12-10 21:22:35 - INFO - Epoch: 35.33, Step: 139930, Train Loss: 1.1744, Learning Rate: 1.23e-05
2025-12-10 21:22:46 - INFO - Epoch: 35.33, Step: 139940, Train Loss: 1.1464, Learning Rate: 1.23e-05
2025-12-10 21:22:57 - INFO - Epoch: 35.33, Step: 139950, Train Loss: 1.1739, Learning Rate: 1.23e-05
2025-12-10 21:23:08 - INFO - Epoch: 35.33, Step: 139960, Train Loss: 1.1347, Learning Rate: 1.23e-05
2025-12-10 21:23:19 - INFO - Epoch: 35.34, Step: 139970, Train Loss: 1.1462, Learning Rate: 1.23e-05
2025-12-10 21:23:31 - INFO - Epoch: 35.34, Step: 139980, Train Loss: 1.1419, Learning Rate: 1.23e-05
2025-12-10 21:23:42 - INFO - Epoch: 35.34, Step: 139990, Train Loss: 1.1700, Learning Rate: 1.23e-05
2025-12-10 21:23:53 - INFO - Epoch: 35.34, Step: 140000, Train Loss: 1.1565, Learning Rate: 1.23e-05
2025-12-10 21:24:04 - INFO - Epoch: 35.35, Step: 140010, Train Loss: 1.1246, Learning Rate: 1.22e-05
2025-12-10 21:24:15 - INFO - Epoch: 35.35, Step: 140020, Train Loss: 1.1488, Learning Rate: 1.22e-05
2025-12-10 21:24:26 - INFO - Epoch: 35.35, Step: 140030, Train Loss: 1.1436, Learning Rate: 1.22e-05
2025-12-10 21:24:37 - INFO - Epoch: 35.35, Step: 140040, Train Loss: 1.1342, Learning Rate: 1.22e-05
2025-12-10 21:24:49 - INFO - Epoch: 35.36, Step: 140050, Train Loss: 1.1439, Learning Rate: 1.22e-05
2025-12-10 21:25:00 - INFO - Epoch: 35.36, Step: 140060, Train Loss: 1.1292, Learning Rate: 1.22e-05
2025-12-10 21:25:11 - INFO - Epoch: 35.36, Step: 140070, Train Loss: 1.1395, Learning Rate: 1.22e-05
2025-12-10 21:25:22 - INFO - Epoch: 35.36, Step: 140080, Train Loss: 1.1151, Learning Rate: 1.22e-05
2025-12-10 21:25:33 - INFO - Epoch: 35.37, Step: 140090, Train Loss: 1.1443, Learning Rate: 1.22e-05
2025-12-10 21:25:44 - INFO - Epoch: 35.37, Step: 140100, Train Loss: 1.1862, Learning Rate: 1.22e-05
2025-12-10 21:25:56 - INFO - Epoch: 35.37, Step: 140110, Train Loss: 1.1226, Learning Rate: 1.22e-05
2025-12-10 21:26:07 - INFO - Epoch: 35.37, Step: 140120, Train Loss: 1.1665, Learning Rate: 1.22e-05
2025-12-10 21:26:18 - INFO - Epoch: 35.38, Step: 140130, Train Loss: 1.1454, Learning Rate: 1.22e-05
2025-12-10 21:26:29 - INFO - Epoch: 35.38, Step: 140140, Train Loss: 1.1470, Learning Rate: 1.22e-05
2025-12-10 21:26:40 - INFO - Epoch: 35.38, Step: 140150, Train Loss: 1.1515, Learning Rate: 1.22e-05
2025-12-10 21:26:51 - INFO - Epoch: 35.39, Step: 140160, Train Loss: 1.1444, Learning Rate: 1.21e-05
2025-12-10 21:27:02 - INFO - Epoch: 35.39, Step: 140170, Train Loss: 1.1528, Learning Rate: 1.21e-05
2025-12-10 21:27:14 - INFO - Epoch: 35.39, Step: 140180, Train Loss: 1.1466, Learning Rate: 1.21e-05
2025-12-10 21:27:25 - INFO - Epoch: 35.39, Step: 140190, Train Loss: 1.1606, Learning Rate: 1.21e-05
2025-12-10 21:27:36 - INFO - Epoch: 35.40, Step: 140200, Train Loss: 1.1150, Learning Rate: 1.21e-05
2025-12-10 21:27:47 - INFO - Epoch: 35.40, Step: 140210, Train Loss: 1.1435, Learning Rate: 1.21e-05
2025-12-10 21:27:58 - INFO - Epoch: 35.40, Step: 140220, Train Loss: 1.1492, Learning Rate: 1.21e-05
2025-12-10 21:28:09 - INFO - Epoch: 35.40, Step: 140230, Train Loss: 1.1313, Learning Rate: 1.21e-05
2025-12-10 21:28:21 - INFO - Epoch: 35.41, Step: 140240, Train Loss: 1.1616, Learning Rate: 1.21e-05
2025-12-10 21:28:32 - INFO - Epoch: 35.41, Step: 140250, Train Loss: 1.1407, Learning Rate: 1.21e-05
2025-12-10 21:28:43 - INFO - Epoch: 35.41, Step: 140260, Train Loss: 1.1353, Learning Rate: 1.21e-05
2025-12-10 21:28:54 - INFO - Epoch: 35.41, Step: 140270, Train Loss: 1.1348, Learning Rate: 1.21e-05
2025-12-10 21:29:05 - INFO - Epoch: 35.42, Step: 140280, Train Loss: 1.1330, Learning Rate: 1.21e-05
2025-12-10 21:29:16 - INFO - Epoch: 35.42, Step: 140290, Train Loss: 1.1661, Learning Rate: 1.21e-05
2025-12-10 21:29:27 - INFO - Epoch: 35.42, Step: 140300, Train Loss: 1.1588, Learning Rate: 1.21e-05
2025-12-10 21:29:39 - INFO - Epoch: 35.42, Step: 140310, Train Loss: 1.1354, Learning Rate: 1.20e-05
2025-12-10 21:29:50 - INFO - Epoch: 35.43, Step: 140320, Train Loss: 1.1431, Learning Rate: 1.20e-05
2025-12-10 21:30:01 - INFO - Epoch: 35.43, Step: 140330, Train Loss: 1.1194, Learning Rate: 1.20e-05
2025-12-10 21:30:12 - INFO - Epoch: 35.43, Step: 140340, Train Loss: 1.1207, Learning Rate: 1.20e-05
2025-12-10 21:30:23 - INFO - Epoch: 35.43, Step: 140350, Train Loss: 1.1045, Learning Rate: 1.20e-05
2025-12-10 21:30:34 - INFO - Epoch: 35.44, Step: 140360, Train Loss: 1.1346, Learning Rate: 1.20e-05
2025-12-10 21:30:45 - INFO - Epoch: 35.44, Step: 140370, Train Loss: 1.1696, Learning Rate: 1.20e-05
2025-12-10 21:30:57 - INFO - Epoch: 35.44, Step: 140380, Train Loss: 1.1236, Learning Rate: 1.20e-05
2025-12-10 21:31:08 - INFO - Epoch: 35.44, Step: 140390, Train Loss: 1.1448, Learning Rate: 1.20e-05
2025-12-10 21:31:19 - INFO - Epoch: 35.45, Step: 140400, Train Loss: 1.1709, Learning Rate: 1.20e-05
2025-12-10 21:31:30 - INFO - Epoch: 35.45, Step: 140410, Train Loss: 1.1570, Learning Rate: 1.20e-05
2025-12-10 21:31:41 - INFO - Epoch: 35.45, Step: 140420, Train Loss: 1.1494, Learning Rate: 1.20e-05
2025-12-10 21:31:52 - INFO - Epoch: 35.45, Step: 140430, Train Loss: 1.1421, Learning Rate: 1.20e-05
2025-12-10 21:32:04 - INFO - Epoch: 35.46, Step: 140440, Train Loss: 1.1670, Learning Rate: 1.20e-05
2025-12-10 21:32:15 - INFO - Epoch: 35.46, Step: 140450, Train Loss: 1.1397, Learning Rate: 1.20e-05
2025-12-10 21:32:26 - INFO - Epoch: 35.46, Step: 140460, Train Loss: 1.1406, Learning Rate: 1.19e-05
2025-12-10 21:32:37 - INFO - Epoch: 35.46, Step: 140470, Train Loss: 1.1778, Learning Rate: 1.19e-05
2025-12-10 21:32:48 - INFO - Epoch: 35.47, Step: 140480, Train Loss: 1.1601, Learning Rate: 1.19e-05
2025-12-10 21:32:59 - INFO - Epoch: 35.47, Step: 140490, Train Loss: 1.1482, Learning Rate: 1.19e-05
2025-12-10 21:33:10 - INFO - Epoch: 35.47, Step: 140500, Train Loss: 1.1379, Learning Rate: 1.19e-05
2025-12-10 21:33:22 - INFO - Epoch: 35.47, Step: 140510, Train Loss: 1.1524, Learning Rate: 1.19e-05
2025-12-10 21:33:33 - INFO - Epoch: 35.48, Step: 140520, Train Loss: 1.1470, Learning Rate: 1.19e-05
2025-12-10 21:33:44 - INFO - Epoch: 35.48, Step: 140530, Train Loss: 1.1346, Learning Rate: 1.19e-05
2025-12-10 21:33:55 - INFO - Epoch: 35.48, Step: 140540, Train Loss: 1.1287, Learning Rate: 1.19e-05
2025-12-10 21:34:06 - INFO - Epoch: 35.48, Step: 140550, Train Loss: 1.1355, Learning Rate: 1.19e-05
2025-12-10 21:34:17 - INFO - Epoch: 35.49, Step: 140560, Train Loss: 1.1384, Learning Rate: 1.19e-05
2025-12-10 21:34:29 - INFO - Epoch: 35.49, Step: 140570, Train Loss: 1.1585, Learning Rate: 1.19e-05
2025-12-10 21:34:40 - INFO - Epoch: 35.49, Step: 140580, Train Loss: 1.1562, Learning Rate: 1.19e-05
2025-12-10 21:34:51 - INFO - Epoch: 35.49, Step: 140590, Train Loss: 1.1297, Learning Rate: 1.19e-05
2025-12-10 21:35:02 - INFO - Epoch: 35.50, Step: 140600, Train Loss: 1.1596, Learning Rate: 1.19e-05
2025-12-10 21:35:13 - INFO - Epoch: 35.50, Step: 140610, Train Loss: 1.1676, Learning Rate: 1.18e-05
2025-12-10 21:35:24 - INFO - Epoch: 35.50, Step: 140620, Train Loss: 1.1539, Learning Rate: 1.18e-05
2025-12-10 21:35:35 - INFO - Epoch: 35.50, Step: 140630, Train Loss: 1.1135, Learning Rate: 1.18e-05
2025-12-10 21:35:47 - INFO - Epoch: 35.51, Step: 140640, Train Loss: 1.1283, Learning Rate: 1.18e-05
2025-12-10 21:35:58 - INFO - Epoch: 35.51, Step: 140650, Train Loss: 1.1479, Learning Rate: 1.18e-05
2025-12-10 21:36:09 - INFO - Epoch: 35.51, Step: 140660, Train Loss: 1.1319, Learning Rate: 1.18e-05
2025-12-10 21:36:20 - INFO - Epoch: 35.51, Step: 140670, Train Loss: 1.1278, Learning Rate: 1.18e-05
2025-12-10 21:36:31 - INFO - Epoch: 35.52, Step: 140680, Train Loss: 1.1493, Learning Rate: 1.18e-05
2025-12-10 21:36:42 - INFO - Epoch: 35.52, Step: 140690, Train Loss: 1.1334, Learning Rate: 1.18e-05
2025-12-10 21:36:54 - INFO - Epoch: 35.52, Step: 140700, Train Loss: 1.1285, Learning Rate: 1.18e-05
2025-12-10 21:37:05 - INFO - Epoch: 35.52, Step: 140710, Train Loss: 1.1330, Learning Rate: 1.18e-05
2025-12-10 21:37:16 - INFO - Epoch: 35.53, Step: 140720, Train Loss: 1.1295, Learning Rate: 1.18e-05
2025-12-10 21:37:27 - INFO - Epoch: 35.53, Step: 140730, Train Loss: 1.1483, Learning Rate: 1.18e-05
2025-12-10 21:37:38 - INFO - Epoch: 35.53, Step: 140740, Train Loss: 1.1455, Learning Rate: 1.18e-05
2025-12-10 21:37:49 - INFO - Epoch: 35.53, Step: 140750, Train Loss: 1.1282, Learning Rate: 1.18e-05
2025-12-10 21:38:00 - INFO - Epoch: 35.54, Step: 140760, Train Loss: 1.1302, Learning Rate: 1.17e-05
2025-12-10 21:38:12 - INFO - Epoch: 35.54, Step: 140770, Train Loss: 1.1453, Learning Rate: 1.17e-05
2025-12-10 21:38:23 - INFO - Epoch: 35.54, Step: 140780, Train Loss: 1.1495, Learning Rate: 1.17e-05
2025-12-10 21:38:34 - INFO - Epoch: 35.54, Step: 140790, Train Loss: 1.1169, Learning Rate: 1.17e-05
2025-12-10 21:38:45 - INFO - Epoch: 35.55, Step: 140800, Train Loss: 1.1670, Learning Rate: 1.17e-05
2025-12-10 21:38:56 - INFO - Epoch: 35.55, Step: 140810, Train Loss: 1.1568, Learning Rate: 1.17e-05
2025-12-10 21:39:07 - INFO - Epoch: 35.55, Step: 140820, Train Loss: 1.1294, Learning Rate: 1.17e-05
2025-12-10 21:39:19 - INFO - Epoch: 35.55, Step: 140830, Train Loss: 1.1892, Learning Rate: 1.17e-05
2025-12-10 21:39:30 - INFO - Epoch: 35.56, Step: 140840, Train Loss: 1.1573, Learning Rate: 1.17e-05
2025-12-10 21:39:41 - INFO - Epoch: 35.56, Step: 140850, Train Loss: 1.1392, Learning Rate: 1.17e-05
2025-12-10 21:39:52 - INFO - Epoch: 35.56, Step: 140860, Train Loss: 1.1170, Learning Rate: 1.17e-05
2025-12-10 21:40:03 - INFO - Epoch: 35.56, Step: 140870, Train Loss: 1.1203, Learning Rate: 1.17e-05
2025-12-10 21:40:14 - INFO - Epoch: 35.57, Step: 140880, Train Loss: 1.1590, Learning Rate: 1.17e-05
2025-12-10 21:40:25 - INFO - Epoch: 35.57, Step: 140890, Train Loss: 1.1395, Learning Rate: 1.17e-05
2025-12-10 21:40:37 - INFO - Epoch: 35.57, Step: 140900, Train Loss: 1.1386, Learning Rate: 1.17e-05
2025-12-10 21:40:48 - INFO - Epoch: 35.57, Step: 140910, Train Loss: 1.0977, Learning Rate: 1.16e-05
2025-12-10 21:40:59 - INFO - Epoch: 35.58, Step: 140920, Train Loss: 1.1667, Learning Rate: 1.16e-05
2025-12-10 21:41:10 - INFO - Epoch: 35.58, Step: 140930, Train Loss: 1.1553, Learning Rate: 1.16e-05
2025-12-10 21:41:21 - INFO - Epoch: 35.58, Step: 140940, Train Loss: 1.0991, Learning Rate: 1.16e-05
2025-12-10 21:41:32 - INFO - Epoch: 35.58, Step: 140950, Train Loss: 1.1592, Learning Rate: 1.16e-05
2025-12-10 21:41:43 - INFO - Epoch: 35.59, Step: 140960, Train Loss: 1.1067, Learning Rate: 1.16e-05
2025-12-10 21:41:55 - INFO - Epoch: 35.59, Step: 140970, Train Loss: 1.1468, Learning Rate: 1.16e-05
2025-12-10 21:42:06 - INFO - Epoch: 35.59, Step: 140980, Train Loss: 1.1202, Learning Rate: 1.16e-05
2025-12-10 21:42:17 - INFO - Epoch: 35.59, Step: 140990, Train Loss: 1.1344, Learning Rate: 1.16e-05
2025-12-10 21:42:28 - INFO - Epoch: 35.60, Step: 141000, Train Loss: 1.1567, Learning Rate: 1.16e-05
2025-12-10 21:42:39 - INFO - Epoch: 35.60, Step: 141010, Train Loss: 1.1298, Learning Rate: 1.16e-05
2025-12-10 21:42:50 - INFO - Epoch: 35.60, Step: 141020, Train Loss: 1.1142, Learning Rate: 1.16e-05
2025-12-10 21:43:02 - INFO - Epoch: 35.60, Step: 141030, Train Loss: 1.1318, Learning Rate: 1.16e-05
2025-12-10 21:43:13 - INFO - Epoch: 35.61, Step: 141040, Train Loss: 1.1544, Learning Rate: 1.16e-05
2025-12-10 21:43:24 - INFO - Epoch: 35.61, Step: 141050, Train Loss: 1.1539, Learning Rate: 1.16e-05
2025-12-10 21:43:35 - INFO - Epoch: 35.61, Step: 141060, Train Loss: 1.1118, Learning Rate: 1.15e-05
2025-12-10 21:43:46 - INFO - Epoch: 35.61, Step: 141070, Train Loss: 1.0995, Learning Rate: 1.15e-05
2025-12-10 21:43:57 - INFO - Epoch: 35.62, Step: 141080, Train Loss: 1.1297, Learning Rate: 1.15e-05
2025-12-10 21:44:08 - INFO - Epoch: 35.62, Step: 141090, Train Loss: 1.1749, Learning Rate: 1.15e-05
2025-12-10 21:44:20 - INFO - Epoch: 35.62, Step: 141100, Train Loss: 1.1262, Learning Rate: 1.15e-05
2025-12-10 21:44:31 - INFO - Epoch: 35.62, Step: 141110, Train Loss: 1.1677, Learning Rate: 1.15e-05
2025-12-10 21:44:42 - INFO - Epoch: 35.63, Step: 141120, Train Loss: 1.1304, Learning Rate: 1.15e-05
2025-12-10 21:44:53 - INFO - Epoch: 35.63, Step: 141130, Train Loss: 1.1281, Learning Rate: 1.15e-05
2025-12-10 21:45:04 - INFO - Epoch: 35.63, Step: 141140, Train Loss: 1.1275, Learning Rate: 1.15e-05
2025-12-10 21:45:15 - INFO - Epoch: 35.63, Step: 141150, Train Loss: 1.1369, Learning Rate: 1.15e-05
2025-12-10 21:45:27 - INFO - Epoch: 35.64, Step: 141160, Train Loss: 1.1167, Learning Rate: 1.15e-05
2025-12-10 21:45:38 - INFO - Epoch: 35.64, Step: 141170, Train Loss: 1.1777, Learning Rate: 1.15e-05
2025-12-10 21:45:49 - INFO - Epoch: 35.64, Step: 141180, Train Loss: 1.1515, Learning Rate: 1.15e-05
2025-12-10 21:46:00 - INFO - Epoch: 35.65, Step: 141190, Train Loss: 1.1646, Learning Rate: 1.15e-05
2025-12-10 21:46:11 - INFO - Epoch: 35.65, Step: 141200, Train Loss: 1.1304, Learning Rate: 1.15e-05
2025-12-10 21:46:22 - INFO - Epoch: 35.65, Step: 141210, Train Loss: 1.1249, Learning Rate: 1.14e-05
2025-12-10 21:46:33 - INFO - Epoch: 35.65, Step: 141220, Train Loss: 1.1399, Learning Rate: 1.14e-05
2025-12-10 21:46:45 - INFO - Epoch: 35.66, Step: 141230, Train Loss: 1.0862, Learning Rate: 1.14e-05
2025-12-10 21:46:56 - INFO - Epoch: 35.66, Step: 141240, Train Loss: 1.1376, Learning Rate: 1.14e-05
2025-12-10 21:47:07 - INFO - Epoch: 35.66, Step: 141250, Train Loss: 1.1189, Learning Rate: 1.14e-05
2025-12-10 21:47:18 - INFO - Epoch: 35.66, Step: 141260, Train Loss: 1.1392, Learning Rate: 1.14e-05
2025-12-10 21:47:29 - INFO - Epoch: 35.67, Step: 141270, Train Loss: 1.1365, Learning Rate: 1.14e-05
2025-12-10 21:47:40 - INFO - Epoch: 35.67, Step: 141280, Train Loss: 1.1831, Learning Rate: 1.14e-05
2025-12-10 21:47:52 - INFO - Epoch: 35.67, Step: 141290, Train Loss: 1.1671, Learning Rate: 1.14e-05
2025-12-10 21:48:03 - INFO - Epoch: 35.67, Step: 141300, Train Loss: 1.1160, Learning Rate: 1.14e-05
2025-12-10 21:48:14 - INFO - Epoch: 35.68, Step: 141310, Train Loss: 1.1230, Learning Rate: 1.14e-05
2025-12-10 21:48:25 - INFO - Epoch: 35.68, Step: 141320, Train Loss: 1.1170, Learning Rate: 1.14e-05
2025-12-10 21:48:36 - INFO - Epoch: 35.68, Step: 141330, Train Loss: 1.1629, Learning Rate: 1.14e-05
2025-12-10 21:48:47 - INFO - Epoch: 35.68, Step: 141340, Train Loss: 1.1251, Learning Rate: 1.14e-05
2025-12-10 21:48:58 - INFO - Epoch: 35.69, Step: 141350, Train Loss: 1.1122, Learning Rate: 1.14e-05
2025-12-10 21:49:10 - INFO - Epoch: 35.69, Step: 141360, Train Loss: 1.1342, Learning Rate: 1.13e-05
2025-12-10 21:49:21 - INFO - Epoch: 35.69, Step: 141370, Train Loss: 1.1527, Learning Rate: 1.13e-05
2025-12-10 21:49:32 - INFO - Epoch: 35.69, Step: 141380, Train Loss: 1.1549, Learning Rate: 1.13e-05
2025-12-10 21:49:43 - INFO - Epoch: 35.70, Step: 141390, Train Loss: 1.1284, Learning Rate: 1.13e-05
2025-12-10 21:49:54 - INFO - Epoch: 35.70, Step: 141400, Train Loss: 1.1249, Learning Rate: 1.13e-05
2025-12-10 21:50:05 - INFO - Epoch: 35.70, Step: 141410, Train Loss: 1.1391, Learning Rate: 1.13e-05
2025-12-10 21:50:16 - INFO - Epoch: 35.70, Step: 141420, Train Loss: 1.1420, Learning Rate: 1.13e-05
2025-12-10 21:50:28 - INFO - Epoch: 35.71, Step: 141430, Train Loss: 1.1463, Learning Rate: 1.13e-05
2025-12-10 21:50:39 - INFO - Epoch: 35.71, Step: 141440, Train Loss: 1.1447, Learning Rate: 1.13e-05
2025-12-10 21:50:50 - INFO - Epoch: 35.71, Step: 141450, Train Loss: 1.1819, Learning Rate: 1.13e-05
2025-12-10 21:51:01 - INFO - Epoch: 35.71, Step: 141460, Train Loss: 1.1611, Learning Rate: 1.13e-05
2025-12-10 21:51:12 - INFO - Epoch: 35.72, Step: 141470, Train Loss: 1.1394, Learning Rate: 1.13e-05
2025-12-10 21:51:23 - INFO - Epoch: 35.72, Step: 141480, Train Loss: 1.1473, Learning Rate: 1.13e-05
2025-12-10 21:51:35 - INFO - Epoch: 35.72, Step: 141490, Train Loss: 1.1381, Learning Rate: 1.13e-05
2025-12-10 21:51:46 - INFO - Epoch: 35.72, Step: 141500, Train Loss: 1.1675, Learning Rate: 1.13e-05
2025-12-10 21:51:57 - INFO - Epoch: 35.73, Step: 141510, Train Loss: 1.1877, Learning Rate: 1.12e-05
2025-12-10 21:52:08 - INFO - Epoch: 35.73, Step: 141520, Train Loss: 1.1779, Learning Rate: 1.12e-05
2025-12-10 21:52:19 - INFO - Epoch: 35.73, Step: 141530, Train Loss: 1.1581, Learning Rate: 1.12e-05
2025-12-10 21:52:30 - INFO - Epoch: 35.73, Step: 141540, Train Loss: 1.1605, Learning Rate: 1.12e-05
2025-12-10 21:52:41 - INFO - Epoch: 35.74, Step: 141550, Train Loss: 1.1652, Learning Rate: 1.12e-05
2025-12-10 21:52:53 - INFO - Epoch: 35.74, Step: 141560, Train Loss: 1.1434, Learning Rate: 1.12e-05
2025-12-10 21:53:04 - INFO - Epoch: 35.74, Step: 141570, Train Loss: 1.1326, Learning Rate: 1.12e-05
2025-12-10 21:53:15 - INFO - Epoch: 35.74, Step: 141580, Train Loss: 1.1453, Learning Rate: 1.12e-05
2025-12-10 21:53:26 - INFO - Epoch: 35.75, Step: 141590, Train Loss: 1.1534, Learning Rate: 1.12e-05
2025-12-10 21:53:37 - INFO - Epoch: 35.75, Step: 141600, Train Loss: 1.1288, Learning Rate: 1.12e-05
2025-12-10 21:53:48 - INFO - Epoch: 35.75, Step: 141610, Train Loss: 1.1370, Learning Rate: 1.12e-05
2025-12-10 21:54:00 - INFO - Epoch: 35.75, Step: 141620, Train Loss: 1.1477, Learning Rate: 1.12e-05
2025-12-10 21:54:11 - INFO - Epoch: 35.76, Step: 141630, Train Loss: 1.1408, Learning Rate: 1.12e-05
2025-12-10 21:54:22 - INFO - Epoch: 35.76, Step: 141640, Train Loss: 1.1230, Learning Rate: 1.12e-05
2025-12-10 21:54:33 - INFO - Epoch: 35.76, Step: 141650, Train Loss: 1.1419, Learning Rate: 1.12e-05
2025-12-10 21:54:44 - INFO - Epoch: 35.76, Step: 141660, Train Loss: 1.1218, Learning Rate: 1.11e-05
2025-12-10 21:54:55 - INFO - Epoch: 35.77, Step: 141670, Train Loss: 1.1612, Learning Rate: 1.11e-05
2025-12-10 21:55:06 - INFO - Epoch: 35.77, Step: 141680, Train Loss: 1.1185, Learning Rate: 1.11e-05
2025-12-10 21:55:18 - INFO - Epoch: 35.77, Step: 141690, Train Loss: 1.1795, Learning Rate: 1.11e-05
2025-12-10 21:55:29 - INFO - Epoch: 35.77, Step: 141700, Train Loss: 1.1631, Learning Rate: 1.11e-05
2025-12-10 21:55:40 - INFO - Epoch: 35.78, Step: 141710, Train Loss: 1.1785, Learning Rate: 1.11e-05
2025-12-10 21:55:51 - INFO - Epoch: 35.78, Step: 141720, Train Loss: 1.1385, Learning Rate: 1.11e-05
2025-12-10 21:56:02 - INFO - Epoch: 35.78, Step: 141730, Train Loss: 1.1571, Learning Rate: 1.11e-05
2025-12-10 21:56:13 - INFO - Epoch: 35.78, Step: 141740, Train Loss: 1.1617, Learning Rate: 1.11e-05
2025-12-10 21:56:25 - INFO - Epoch: 35.79, Step: 141750, Train Loss: 1.1663, Learning Rate: 1.11e-05
2025-12-10 21:56:36 - INFO - Epoch: 35.79, Step: 141760, Train Loss: 1.1138, Learning Rate: 1.11e-05
2025-12-10 21:56:47 - INFO - Epoch: 35.79, Step: 141770, Train Loss: 1.1357, Learning Rate: 1.11e-05
2025-12-10 21:56:58 - INFO - Epoch: 35.79, Step: 141780, Train Loss: 1.1258, Learning Rate: 1.11e-05
2025-12-10 21:57:09 - INFO - Epoch: 35.80, Step: 141790, Train Loss: 1.1407, Learning Rate: 1.11e-05
2025-12-10 21:57:20 - INFO - Epoch: 35.80, Step: 141800, Train Loss: 1.1442, Learning Rate: 1.11e-05
2025-12-10 21:57:31 - INFO - Epoch: 35.80, Step: 141810, Train Loss: 1.1746, Learning Rate: 1.10e-05
2025-12-10 21:57:43 - INFO - Epoch: 35.80, Step: 141820, Train Loss: 1.1524, Learning Rate: 1.10e-05
2025-12-10 21:57:54 - INFO - Epoch: 35.81, Step: 141830, Train Loss: 1.1200, Learning Rate: 1.10e-05
2025-12-10 21:58:05 - INFO - Epoch: 35.81, Step: 141840, Train Loss: 1.1575, Learning Rate: 1.10e-05
2025-12-10 21:58:16 - INFO - Epoch: 35.81, Step: 141850, Train Loss: 1.1153, Learning Rate: 1.10e-05
2025-12-10 21:58:27 - INFO - Epoch: 35.81, Step: 141860, Train Loss: 1.1315, Learning Rate: 1.10e-05
2025-12-10 21:58:38 - INFO - Epoch: 35.82, Step: 141870, Train Loss: 1.1367, Learning Rate: 1.10e-05
2025-12-10 21:58:49 - INFO - Epoch: 35.82, Step: 141880, Train Loss: 1.1834, Learning Rate: 1.10e-05
2025-12-10 21:59:01 - INFO - Epoch: 35.82, Step: 141890, Train Loss: 1.1278, Learning Rate: 1.10e-05
2025-12-10 21:59:12 - INFO - Epoch: 35.82, Step: 141900, Train Loss: 1.1402, Learning Rate: 1.10e-05
2025-12-10 21:59:23 - INFO - Epoch: 35.83, Step: 141910, Train Loss: 1.1192, Learning Rate: 1.10e-05
2025-12-10 21:59:34 - INFO - Epoch: 35.83, Step: 141920, Train Loss: 1.1446, Learning Rate: 1.10e-05
2025-12-10 21:59:45 - INFO - Epoch: 35.83, Step: 141930, Train Loss: 1.1482, Learning Rate: 1.10e-05
2025-12-10 21:59:56 - INFO - Epoch: 35.83, Step: 141940, Train Loss: 1.1803, Learning Rate: 1.10e-05
2025-12-10 22:00:08 - INFO - Epoch: 35.84, Step: 141950, Train Loss: 1.1465, Learning Rate: 1.10e-05
2025-12-10 22:00:19 - INFO - Epoch: 35.84, Step: 141960, Train Loss: 1.1491, Learning Rate: 1.09e-05
2025-12-10 22:00:30 - INFO - Epoch: 35.84, Step: 141970, Train Loss: 1.1579, Learning Rate: 1.09e-05
2025-12-10 22:00:41 - INFO - Epoch: 35.84, Step: 141980, Train Loss: 1.1124, Learning Rate: 1.09e-05
2025-12-10 22:00:52 - INFO - Epoch: 35.85, Step: 141990, Train Loss: 1.1216, Learning Rate: 1.09e-05
2025-12-10 22:01:03 - INFO - Epoch: 35.85, Step: 142000, Train Loss: 1.1328, Learning Rate: 1.09e-05
2025-12-10 22:01:14 - INFO - Epoch: 35.85, Step: 142010, Train Loss: 1.1294, Learning Rate: 1.09e-05
2025-12-10 22:01:26 - INFO - Epoch: 35.85, Step: 142020, Train Loss: 1.1367, Learning Rate: 1.09e-05
2025-12-10 22:01:37 - INFO - Epoch: 35.86, Step: 142030, Train Loss: 1.1443, Learning Rate: 1.09e-05
2025-12-10 22:01:48 - INFO - Epoch: 35.86, Step: 142040, Train Loss: 1.1520, Learning Rate: 1.09e-05
2025-12-10 22:01:59 - INFO - Epoch: 35.86, Step: 142050, Train Loss: 1.1401, Learning Rate: 1.09e-05
2025-12-10 22:02:10 - INFO - Epoch: 35.86, Step: 142060, Train Loss: 1.1624, Learning Rate: 1.09e-05
2025-12-10 22:02:21 - INFO - Epoch: 35.87, Step: 142070, Train Loss: 1.1409, Learning Rate: 1.09e-05
2025-12-10 22:02:33 - INFO - Epoch: 35.87, Step: 142080, Train Loss: 1.1548, Learning Rate: 1.09e-05
2025-12-10 22:02:44 - INFO - Epoch: 35.87, Step: 142090, Train Loss: 1.1585, Learning Rate: 1.09e-05
2025-12-10 22:02:55 - INFO - Epoch: 35.87, Step: 142100, Train Loss: 1.1374, Learning Rate: 1.09e-05
2025-12-10 22:03:06 - INFO - Epoch: 35.88, Step: 142110, Train Loss: 1.1515, Learning Rate: 1.08e-05
2025-12-10 22:03:17 - INFO - Epoch: 35.88, Step: 142120, Train Loss: 1.1194, Learning Rate: 1.08e-05
2025-12-10 22:03:28 - INFO - Epoch: 35.88, Step: 142130, Train Loss: 1.1046, Learning Rate: 1.08e-05
2025-12-10 22:03:39 - INFO - Epoch: 35.88, Step: 142140, Train Loss: 1.1006, Learning Rate: 1.08e-05
2025-12-10 22:03:51 - INFO - Epoch: 35.89, Step: 142150, Train Loss: 1.1550, Learning Rate: 1.08e-05
2025-12-10 22:04:02 - INFO - Epoch: 35.89, Step: 142160, Train Loss: 1.1795, Learning Rate: 1.08e-05
2025-12-10 22:04:13 - INFO - Epoch: 35.89, Step: 142170, Train Loss: 1.1659, Learning Rate: 1.08e-05
2025-12-10 22:04:24 - INFO - Epoch: 35.89, Step: 142180, Train Loss: 1.1646, Learning Rate: 1.08e-05
2025-12-10 22:04:35 - INFO - Epoch: 35.90, Step: 142190, Train Loss: 1.1165, Learning Rate: 1.08e-05
2025-12-10 22:04:46 - INFO - Epoch: 35.90, Step: 142200, Train Loss: 1.1130, Learning Rate: 1.08e-05
2025-12-10 22:04:58 - INFO - Epoch: 35.90, Step: 142210, Train Loss: 1.1713, Learning Rate: 1.08e-05
2025-12-10 22:05:09 - INFO - Epoch: 35.91, Step: 142220, Train Loss: 1.1367, Learning Rate: 1.08e-05
2025-12-10 22:05:20 - INFO - Epoch: 35.91, Step: 142230, Train Loss: 1.1396, Learning Rate: 1.08e-05
2025-12-10 22:05:31 - INFO - Epoch: 35.91, Step: 142240, Train Loss: 1.1452, Learning Rate: 1.08e-05
2025-12-10 22:05:42 - INFO - Epoch: 35.91, Step: 142250, Train Loss: 1.1166, Learning Rate: 1.08e-05
2025-12-10 22:05:53 - INFO - Epoch: 35.92, Step: 142260, Train Loss: 1.1666, Learning Rate: 1.08e-05
2025-12-10 22:06:04 - INFO - Epoch: 35.92, Step: 142270, Train Loss: 1.1751, Learning Rate: 1.07e-05
2025-12-10 22:06:16 - INFO - Epoch: 35.92, Step: 142280, Train Loss: 1.1158, Learning Rate: 1.07e-05
2025-12-10 22:06:27 - INFO - Epoch: 35.92, Step: 142290, Train Loss: 1.1459, Learning Rate: 1.07e-05
2025-12-10 22:06:38 - INFO - Epoch: 35.93, Step: 142300, Train Loss: 1.1681, Learning Rate: 1.07e-05
2025-12-10 22:06:49 - INFO - Epoch: 35.93, Step: 142310, Train Loss: 1.1222, Learning Rate: 1.07e-05
2025-12-10 22:07:00 - INFO - Epoch: 35.93, Step: 142320, Train Loss: 1.1378, Learning Rate: 1.07e-05
2025-12-10 22:07:11 - INFO - Epoch: 35.93, Step: 142330, Train Loss: 1.1601, Learning Rate: 1.07e-05
2025-12-10 22:07:23 - INFO - Epoch: 35.94, Step: 142340, Train Loss: 1.1259, Learning Rate: 1.07e-05
2025-12-10 22:07:34 - INFO - Epoch: 35.94, Step: 142350, Train Loss: 1.1287, Learning Rate: 1.07e-05
2025-12-10 22:07:45 - INFO - Epoch: 35.94, Step: 142360, Train Loss: 1.1302, Learning Rate: 1.07e-05
2025-12-10 22:07:56 - INFO - Epoch: 35.94, Step: 142370, Train Loss: 1.1426, Learning Rate: 1.07e-05
2025-12-10 22:08:07 - INFO - Epoch: 35.95, Step: 142380, Train Loss: 1.1514, Learning Rate: 1.07e-05
2025-12-10 22:08:18 - INFO - Epoch: 35.95, Step: 142390, Train Loss: 1.1780, Learning Rate: 1.07e-05
2025-12-10 22:08:29 - INFO - Epoch: 35.95, Step: 142400, Train Loss: 1.1733, Learning Rate: 1.07e-05
2025-12-10 22:08:41 - INFO - Epoch: 35.95, Step: 142410, Train Loss: 1.1599, Learning Rate: 1.07e-05
2025-12-10 22:08:52 - INFO - Epoch: 35.96, Step: 142420, Train Loss: 1.1497, Learning Rate: 1.06e-05
2025-12-10 22:09:03 - INFO - Epoch: 35.96, Step: 142430, Train Loss: 1.1105, Learning Rate: 1.06e-05
2025-12-10 22:09:14 - INFO - Epoch: 35.96, Step: 142440, Train Loss: 1.1548, Learning Rate: 1.06e-05
2025-12-10 22:09:25 - INFO - Epoch: 35.96, Step: 142450, Train Loss: 1.1439, Learning Rate: 1.06e-05
2025-12-10 22:09:36 - INFO - Epoch: 35.97, Step: 142460, Train Loss: 1.1648, Learning Rate: 1.06e-05
2025-12-10 22:09:47 - INFO - Epoch: 35.97, Step: 142470, Train Loss: 1.1152, Learning Rate: 1.06e-05
2025-12-10 22:09:59 - INFO - Epoch: 35.97, Step: 142480, Train Loss: 1.1639, Learning Rate: 1.06e-05
2025-12-10 22:10:10 - INFO - Epoch: 35.97, Step: 142490, Train Loss: 1.1417, Learning Rate: 1.06e-05
2025-12-10 22:10:21 - INFO - Epoch: 35.98, Step: 142500, Train Loss: 1.1512, Learning Rate: 1.06e-05
2025-12-10 22:10:32 - INFO - Epoch: 35.98, Step: 142510, Train Loss: 1.1237, Learning Rate: 1.06e-05
2025-12-10 22:10:43 - INFO - Epoch: 35.98, Step: 142520, Train Loss: 1.1632, Learning Rate: 1.06e-05
2025-12-10 22:10:54 - INFO - Epoch: 35.98, Step: 142530, Train Loss: 1.1857, Learning Rate: 1.06e-05
2025-12-10 22:11:06 - INFO - Epoch: 35.99, Step: 142540, Train Loss: 1.1123, Learning Rate: 1.06e-05
2025-12-10 22:11:17 - INFO - Epoch: 35.99, Step: 142550, Train Loss: 1.1423, Learning Rate: 1.06e-05
2025-12-10 22:11:28 - INFO - Epoch: 35.99, Step: 142560, Train Loss: 1.1346, Learning Rate: 1.06e-05
2025-12-10 22:11:39 - INFO - Epoch: 35.99, Step: 142570, Train Loss: 1.1365, Learning Rate: 1.05e-05
2025-12-10 22:11:50 - INFO - Epoch: 36.00, Step: 142580, Train Loss: 1.1007, Learning Rate: 1.05e-05
2025-12-10 22:12:01 - INFO - Epoch: 36.00, Step: 142590, Train Loss: 1.1050, Learning Rate: 1.05e-05
2025-12-10 22:12:12 - INFO - Epoch: 36.00, Step: 142600, Train Loss: 1.1642, Learning Rate: 1.05e-05
2025-12-10 22:12:24 - INFO - Epoch: 36.00, Step: 142610, Train Loss: 1.1397, Learning Rate: 1.05e-05
2025-12-10 22:12:35 - INFO - Epoch: 36.01, Step: 142620, Train Loss: 1.1616, Learning Rate: 1.05e-05
2025-12-10 22:12:46 - INFO - Epoch: 36.01, Step: 142630, Train Loss: 1.1534, Learning Rate: 1.05e-05
2025-12-10 22:12:57 - INFO - Epoch: 36.01, Step: 142640, Train Loss: 1.1785, Learning Rate: 1.05e-05
2025-12-10 22:13:08 - INFO - Epoch: 36.01, Step: 142650, Train Loss: 1.1608, Learning Rate: 1.05e-05
2025-12-10 22:13:19 - INFO - Epoch: 36.02, Step: 142660, Train Loss: 1.1172, Learning Rate: 1.05e-05
2025-12-10 22:13:30 - INFO - Epoch: 36.02, Step: 142670, Train Loss: 1.1762, Learning Rate: 1.05e-05
2025-12-10 22:13:42 - INFO - Epoch: 36.02, Step: 142680, Train Loss: 1.1412, Learning Rate: 1.05e-05
2025-12-10 22:13:53 - INFO - Epoch: 36.02, Step: 142690, Train Loss: 1.1430, Learning Rate: 1.05e-05
2025-12-10 22:14:04 - INFO - Epoch: 36.03, Step: 142700, Train Loss: 1.1109, Learning Rate: 1.05e-05
2025-12-10 22:14:15 - INFO - Epoch: 36.03, Step: 142710, Train Loss: 1.1569, Learning Rate: 1.05e-05
2025-12-10 22:14:26 - INFO - Epoch: 36.03, Step: 142720, Train Loss: 1.1382, Learning Rate: 1.04e-05
2025-12-10 22:14:37 - INFO - Epoch: 36.03, Step: 142730, Train Loss: 1.1076, Learning Rate: 1.04e-05
2025-12-10 22:14:49 - INFO - Epoch: 36.04, Step: 142740, Train Loss: 1.1483, Learning Rate: 1.04e-05
2025-12-10 22:15:00 - INFO - Epoch: 36.04, Step: 142750, Train Loss: 1.1501, Learning Rate: 1.04e-05
2025-12-10 22:15:11 - INFO - Epoch: 36.04, Step: 142760, Train Loss: 1.1532, Learning Rate: 1.04e-05
2025-12-10 22:15:22 - INFO - Epoch: 36.04, Step: 142770, Train Loss: 1.1295, Learning Rate: 1.04e-05
2025-12-10 22:15:33 - INFO - Epoch: 36.05, Step: 142780, Train Loss: 1.1820, Learning Rate: 1.04e-05
2025-12-10 22:15:44 - INFO - Epoch: 36.05, Step: 142790, Train Loss: 1.1383, Learning Rate: 1.04e-05
2025-12-10 22:15:55 - INFO - Epoch: 36.05, Step: 142800, Train Loss: 1.1405, Learning Rate: 1.04e-05
2025-12-10 22:16:07 - INFO - Epoch: 36.05, Step: 142810, Train Loss: 1.1424, Learning Rate: 1.04e-05
2025-12-10 22:16:18 - INFO - Epoch: 36.06, Step: 142820, Train Loss: 1.1536, Learning Rate: 1.04e-05
2025-12-10 22:16:29 - INFO - Epoch: 36.06, Step: 142830, Train Loss: 1.1718, Learning Rate: 1.04e-05
2025-12-10 22:16:40 - INFO - Epoch: 36.06, Step: 142840, Train Loss: 1.1714, Learning Rate: 1.04e-05
2025-12-10 22:16:51 - INFO - Epoch: 36.06, Step: 142850, Train Loss: 1.1492, Learning Rate: 1.04e-05
2025-12-10 22:17:02 - INFO - Epoch: 36.07, Step: 142860, Train Loss: 1.1136, Learning Rate: 1.04e-05
2025-12-10 22:17:13 - INFO - Epoch: 36.07, Step: 142870, Train Loss: 1.1109, Learning Rate: 1.03e-05
2025-12-10 22:17:25 - INFO - Epoch: 36.07, Step: 142880, Train Loss: 1.1359, Learning Rate: 1.03e-05
2025-12-10 22:17:36 - INFO - Epoch: 36.07, Step: 142890, Train Loss: 1.1366, Learning Rate: 1.03e-05
2025-12-10 22:17:47 - INFO - Epoch: 36.08, Step: 142900, Train Loss: 1.1399, Learning Rate: 1.03e-05
2025-12-10 22:17:58 - INFO - Epoch: 36.08, Step: 142910, Train Loss: 1.1272, Learning Rate: 1.03e-05
2025-12-10 22:18:09 - INFO - Epoch: 36.08, Step: 142920, Train Loss: 1.1312, Learning Rate: 1.03e-05
2025-12-10 22:18:20 - INFO - Epoch: 36.08, Step: 142930, Train Loss: 1.1817, Learning Rate: 1.03e-05
2025-12-10 22:18:32 - INFO - Epoch: 36.09, Step: 142940, Train Loss: 1.1637, Learning Rate: 1.03e-05
2025-12-10 22:18:43 - INFO - Epoch: 36.09, Step: 142950, Train Loss: 1.1399, Learning Rate: 1.03e-05
2025-12-10 22:18:54 - INFO - Epoch: 36.09, Step: 142960, Train Loss: 1.1661, Learning Rate: 1.03e-05
2025-12-10 22:19:05 - INFO - Epoch: 36.09, Step: 142970, Train Loss: 1.1395, Learning Rate: 1.03e-05
2025-12-10 22:19:16 - INFO - Epoch: 36.10, Step: 142980, Train Loss: 1.1360, Learning Rate: 1.03e-05
2025-12-10 22:19:27 - INFO - Epoch: 36.10, Step: 142990, Train Loss: 1.1618, Learning Rate: 1.03e-05
2025-12-10 22:19:38 - INFO - Epoch: 36.10, Step: 143000, Train Loss: 1.1341, Learning Rate: 1.03e-05
2025-12-10 22:19:50 - INFO - Epoch: 36.10, Step: 143010, Train Loss: 1.1533, Learning Rate: 1.03e-05
2025-12-10 22:20:01 - INFO - Epoch: 36.11, Step: 143020, Train Loss: 1.1186, Learning Rate: 1.02e-05
2025-12-10 22:20:12 - INFO - Epoch: 36.11, Step: 143030, Train Loss: 1.1361, Learning Rate: 1.02e-05
2025-12-10 22:20:23 - INFO - Epoch: 36.11, Step: 143040, Train Loss: 1.1281, Learning Rate: 1.02e-05
2025-12-10 22:20:34 - INFO - Epoch: 36.11, Step: 143050, Train Loss: 1.1301, Learning Rate: 1.02e-05
2025-12-10 22:20:45 - INFO - Epoch: 36.12, Step: 143060, Train Loss: 1.1454, Learning Rate: 1.02e-05
2025-12-10 22:20:56 - INFO - Epoch: 36.12, Step: 143070, Train Loss: 1.1477, Learning Rate: 1.02e-05
2025-12-10 22:21:08 - INFO - Epoch: 36.12, Step: 143080, Train Loss: 1.1281, Learning Rate: 1.02e-05
2025-12-10 22:21:19 - INFO - Epoch: 36.12, Step: 143090, Train Loss: 1.1310, Learning Rate: 1.02e-05
2025-12-10 22:21:30 - INFO - Epoch: 36.13, Step: 143100, Train Loss: 1.1482, Learning Rate: 1.02e-05
2025-12-10 22:21:41 - INFO - Epoch: 36.13, Step: 143110, Train Loss: 1.1733, Learning Rate: 1.02e-05
2025-12-10 22:21:52 - INFO - Epoch: 36.13, Step: 143120, Train Loss: 1.1211, Learning Rate: 1.02e-05
2025-12-10 22:22:03 - INFO - Epoch: 36.13, Step: 143130, Train Loss: 1.1697, Learning Rate: 1.02e-05
2025-12-10 22:22:14 - INFO - Epoch: 36.14, Step: 143140, Train Loss: 1.1329, Learning Rate: 1.02e-05
2025-12-10 22:22:26 - INFO - Epoch: 36.14, Step: 143150, Train Loss: 1.1272, Learning Rate: 1.02e-05
2025-12-10 22:22:37 - INFO - Epoch: 36.14, Step: 143160, Train Loss: 1.1294, Learning Rate: 1.02e-05
2025-12-10 22:22:48 - INFO - Epoch: 36.14, Step: 143170, Train Loss: 1.1267, Learning Rate: 1.01e-05
2025-12-10 22:22:59 - INFO - Epoch: 36.15, Step: 143180, Train Loss: 1.1336, Learning Rate: 1.01e-05
2025-12-10 22:23:10 - INFO - Epoch: 36.15, Step: 143190, Train Loss: 1.1804, Learning Rate: 1.01e-05
2025-12-10 22:23:21 - INFO - Epoch: 36.15, Step: 143200, Train Loss: 1.1316, Learning Rate: 1.01e-05
2025-12-10 22:23:33 - INFO - Epoch: 36.16, Step: 143210, Train Loss: 1.1267, Learning Rate: 1.01e-05
2025-12-10 22:23:44 - INFO - Epoch: 36.16, Step: 143220, Train Loss: 1.1566, Learning Rate: 1.01e-05
2025-12-10 22:23:55 - INFO - Epoch: 36.16, Step: 143230, Train Loss: 1.1236, Learning Rate: 1.01e-05
2025-12-10 22:24:06 - INFO - Epoch: 36.16, Step: 143240, Train Loss: 1.1798, Learning Rate: 1.01e-05
2025-12-10 22:24:17 - INFO - Epoch: 36.17, Step: 143250, Train Loss: 1.1313, Learning Rate: 1.01e-05
2025-12-10 22:24:28 - INFO - Epoch: 36.17, Step: 143260, Train Loss: 1.1738, Learning Rate: 1.01e-05
2025-12-10 22:24:39 - INFO - Epoch: 36.17, Step: 143270, Train Loss: 1.1084, Learning Rate: 1.01e-05
2025-12-10 22:24:51 - INFO - Epoch: 36.17, Step: 143280, Train Loss: 1.1749, Learning Rate: 1.01e-05
2025-12-10 22:25:02 - INFO - Epoch: 36.18, Step: 143290, Train Loss: 1.0791, Learning Rate: 1.01e-05
2025-12-10 22:25:13 - INFO - Epoch: 36.18, Step: 143300, Train Loss: 1.1292, Learning Rate: 1.01e-05
2025-12-10 22:25:24 - INFO - Epoch: 36.18, Step: 143310, Train Loss: 1.1261, Learning Rate: 1.01e-05
2025-12-10 22:25:35 - INFO - Epoch: 36.18, Step: 143320, Train Loss: 1.1266, Learning Rate: 1.00e-05
2025-12-10 22:25:46 - INFO - Epoch: 36.19, Step: 143330, Train Loss: 1.0684, Learning Rate: 1.00e-05
2025-12-10 22:25:57 - INFO - Epoch: 36.19, Step: 143340, Train Loss: 1.1286, Learning Rate: 1.00e-05
2025-12-10 22:26:09 - INFO - Epoch: 36.19, Step: 143350, Train Loss: 1.1525, Learning Rate: 1.00e-05
2025-12-10 22:26:20 - INFO - Epoch: 36.19, Step: 143360, Train Loss: 1.1378, Learning Rate: 1.00e-05
2025-12-10 22:26:31 - INFO - Epoch: 36.20, Step: 143370, Train Loss: 1.1720, Learning Rate: 1.00e-05
2025-12-10 22:26:42 - INFO - Epoch: 36.20, Step: 143380, Train Loss: 1.1213, Learning Rate: 1.00e-05
2025-12-10 22:26:53 - INFO - Epoch: 36.20, Step: 143390, Train Loss: 1.1480, Learning Rate: 1.00e-05
2025-12-10 22:27:04 - INFO - Epoch: 36.20, Step: 143400, Train Loss: 1.1363, Learning Rate: 9.99e-06
2025-12-10 22:27:15 - INFO - Epoch: 36.21, Step: 143410, Train Loss: 1.1294, Learning Rate: 9.99e-06
2025-12-10 22:27:27 - INFO - Epoch: 36.21, Step: 143420, Train Loss: 1.1222, Learning Rate: 9.98e-06
2025-12-10 22:27:38 - INFO - Epoch: 36.21, Step: 143430, Train Loss: 1.1454, Learning Rate: 9.97e-06
2025-12-10 22:27:49 - INFO - Epoch: 36.21, Step: 143440, Train Loss: 1.1460, Learning Rate: 9.97e-06
2025-12-10 22:28:00 - INFO - Epoch: 36.22, Step: 143450, Train Loss: 1.1359, Learning Rate: 9.96e-06
2025-12-10 22:28:11 - INFO - Epoch: 36.22, Step: 143460, Train Loss: 1.1310, Learning Rate: 9.95e-06
2025-12-10 22:28:22 - INFO - Epoch: 36.22, Step: 143470, Train Loss: 1.1649, Learning Rate: 9.95e-06
2025-12-10 22:28:34 - INFO - Epoch: 36.22, Step: 143480, Train Loss: 1.1134, Learning Rate: 9.94e-06
2025-12-10 22:28:45 - INFO - Epoch: 36.23, Step: 143490, Train Loss: 1.0981, Learning Rate: 9.93e-06
2025-12-10 22:28:56 - INFO - Epoch: 36.23, Step: 143500, Train Loss: 1.1188, Learning Rate: 9.93e-06
2025-12-10 22:29:07 - INFO - Epoch: 36.23, Step: 143510, Train Loss: 1.1429, Learning Rate: 9.92e-06
2025-12-10 22:29:18 - INFO - Epoch: 36.23, Step: 143520, Train Loss: 1.1301, Learning Rate: 9.91e-06
2025-12-10 22:29:29 - INFO - Epoch: 36.24, Step: 143530, Train Loss: 1.1232, Learning Rate: 9.91e-06
2025-12-10 22:29:40 - INFO - Epoch: 36.24, Step: 143540, Train Loss: 1.1473, Learning Rate: 9.90e-06
2025-12-10 22:29:52 - INFO - Epoch: 36.24, Step: 143550, Train Loss: 1.1316, Learning Rate: 9.89e-06
2025-12-10 22:30:03 - INFO - Epoch: 36.24, Step: 143560, Train Loss: 1.1358, Learning Rate: 9.89e-06
2025-12-10 22:30:14 - INFO - Epoch: 36.25, Step: 143570, Train Loss: 1.1244, Learning Rate: 9.88e-06
2025-12-10 22:30:25 - INFO - Epoch: 36.25, Step: 143580, Train Loss: 1.1139, Learning Rate: 9.87e-06
2025-12-10 22:30:36 - INFO - Epoch: 36.25, Step: 143590, Train Loss: 1.1465, Learning Rate: 9.87e-06
2025-12-10 22:30:47 - INFO - Epoch: 36.25, Step: 143600, Train Loss: 1.1627, Learning Rate: 9.86e-06
2025-12-10 22:30:58 - INFO - Epoch: 36.26, Step: 143610, Train Loss: 1.1328, Learning Rate: 9.85e-06
2025-12-10 22:31:10 - INFO - Epoch: 36.26, Step: 143620, Train Loss: 1.1547, Learning Rate: 9.85e-06
2025-12-10 22:31:21 - INFO - Epoch: 36.26, Step: 143630, Train Loss: 1.1536, Learning Rate: 9.84e-06
2025-12-10 22:31:32 - INFO - Epoch: 36.26, Step: 143640, Train Loss: 1.1231, Learning Rate: 9.83e-06
2025-12-10 22:31:43 - INFO - Epoch: 36.27, Step: 143650, Train Loss: 1.1478, Learning Rate: 9.83e-06
2025-12-10 22:31:54 - INFO - Epoch: 36.27, Step: 143660, Train Loss: 1.1480, Learning Rate: 9.82e-06
2025-12-10 22:32:05 - INFO - Epoch: 36.27, Step: 143670, Train Loss: 1.1693, Learning Rate: 9.81e-06
2025-12-10 22:32:16 - INFO - Epoch: 36.27, Step: 143680, Train Loss: 1.1523, Learning Rate: 9.81e-06
2025-12-10 22:32:28 - INFO - Epoch: 36.28, Step: 143690, Train Loss: 1.1237, Learning Rate: 9.80e-06
2025-12-10 22:32:39 - INFO - Epoch: 36.28, Step: 143700, Train Loss: 1.1125, Learning Rate: 9.79e-06
2025-12-10 22:32:50 - INFO - Epoch: 36.28, Step: 143710, Train Loss: 1.1309, Learning Rate: 9.79e-06
2025-12-10 22:33:01 - INFO - Epoch: 36.28, Step: 143720, Train Loss: 1.1518, Learning Rate: 9.78e-06
2025-12-10 22:33:12 - INFO - Epoch: 36.29, Step: 143730, Train Loss: 1.1657, Learning Rate: 9.77e-06
2025-12-10 22:33:23 - INFO - Epoch: 36.29, Step: 143740, Train Loss: 1.1037, Learning Rate: 9.77e-06
2025-12-10 22:33:35 - INFO - Epoch: 36.29, Step: 143750, Train Loss: 1.1574, Learning Rate: 9.76e-06
2025-12-10 22:33:46 - INFO - Epoch: 36.29, Step: 143760, Train Loss: 1.1106, Learning Rate: 9.75e-06
2025-12-10 22:33:57 - INFO - Epoch: 36.30, Step: 143770, Train Loss: 1.1552, Learning Rate: 9.75e-06
2025-12-10 22:34:08 - INFO - Epoch: 36.30, Step: 143780, Train Loss: 1.1358, Learning Rate: 9.74e-06
2025-12-10 22:34:19 - INFO - Epoch: 36.30, Step: 143790, Train Loss: 1.1448, Learning Rate: 9.73e-06
2025-12-10 22:34:30 - INFO - Epoch: 36.30, Step: 143800, Train Loss: 1.1768, Learning Rate: 9.73e-06
2025-12-10 22:34:41 - INFO - Epoch: 36.31, Step: 143810, Train Loss: 1.1295, Learning Rate: 9.72e-06
2025-12-10 22:34:53 - INFO - Epoch: 36.31, Step: 143820, Train Loss: 1.1757, Learning Rate: 9.71e-06
2025-12-10 22:35:04 - INFO - Epoch: 36.31, Step: 143830, Train Loss: 1.1406, Learning Rate: 9.71e-06
2025-12-10 22:35:15 - INFO - Epoch: 36.31, Step: 143840, Train Loss: 1.1247, Learning Rate: 9.70e-06
2025-12-10 22:35:26 - INFO - Epoch: 36.32, Step: 143850, Train Loss: 1.1487, Learning Rate: 9.69e-06
2025-12-10 22:35:37 - INFO - Epoch: 36.32, Step: 143860, Train Loss: 1.1520, Learning Rate: 9.69e-06
2025-12-10 22:35:48 - INFO - Epoch: 36.32, Step: 143870, Train Loss: 1.1061, Learning Rate: 9.68e-06
2025-12-10 22:35:59 - INFO - Epoch: 36.32, Step: 143880, Train Loss: 1.1863, Learning Rate: 9.67e-06
2025-12-10 22:36:11 - INFO - Epoch: 36.33, Step: 143890, Train Loss: 1.1427, Learning Rate: 9.67e-06
2025-12-10 22:36:22 - INFO - Epoch: 36.33, Step: 143900, Train Loss: 1.1202, Learning Rate: 9.66e-06
2025-12-10 22:36:33 - INFO - Epoch: 36.33, Step: 143910, Train Loss: 1.1310, Learning Rate: 9.65e-06
2025-12-10 22:36:44 - INFO - Epoch: 36.33, Step: 143920, Train Loss: 1.1054, Learning Rate: 9.65e-06
2025-12-10 22:36:55 - INFO - Epoch: 36.34, Step: 143930, Train Loss: 1.1243, Learning Rate: 9.64e-06
2025-12-10 22:37:06 - INFO - Epoch: 36.34, Step: 143940, Train Loss: 1.1192, Learning Rate: 9.63e-06
2025-12-10 22:37:17 - INFO - Epoch: 36.34, Step: 143950, Train Loss: 1.1503, Learning Rate: 9.63e-06
2025-12-10 22:37:29 - INFO - Epoch: 36.34, Step: 143960, Train Loss: 1.1204, Learning Rate: 9.62e-06
2025-12-10 22:37:40 - INFO - Epoch: 36.35, Step: 143970, Train Loss: 1.1444, Learning Rate: 9.61e-06
2025-12-10 22:37:51 - INFO - Epoch: 36.35, Step: 143980, Train Loss: 1.1699, Learning Rate: 9.61e-06
2025-12-10 22:38:02 - INFO - Epoch: 36.35, Step: 143990, Train Loss: 1.1484, Learning Rate: 9.60e-06
2025-12-10 22:38:13 - INFO - Epoch: 36.35, Step: 144000, Train Loss: 1.1538, Learning Rate: 9.59e-06
2025-12-10 22:38:24 - INFO - Epoch: 36.36, Step: 144010, Train Loss: 1.1683, Learning Rate: 9.59e-06
2025-12-10 22:38:36 - INFO - Epoch: 36.36, Step: 144020, Train Loss: 1.1665, Learning Rate: 9.58e-06
2025-12-10 22:38:47 - INFO - Epoch: 36.36, Step: 144030, Train Loss: 1.1438, Learning Rate: 9.57e-06
2025-12-10 22:38:58 - INFO - Epoch: 36.36, Step: 144040, Train Loss: 1.1734, Learning Rate: 9.57e-06
2025-12-10 22:39:09 - INFO - Epoch: 36.37, Step: 144050, Train Loss: 1.1464, Learning Rate: 9.56e-06
2025-12-10 22:39:20 - INFO - Epoch: 36.37, Step: 144060, Train Loss: 1.1202, Learning Rate: 9.55e-06
2025-12-10 22:39:31 - INFO - Epoch: 36.37, Step: 144070, Train Loss: 1.1596, Learning Rate: 9.55e-06
2025-12-10 22:39:42 - INFO - Epoch: 36.37, Step: 144080, Train Loss: 1.1108, Learning Rate: 9.54e-06
2025-12-10 22:39:54 - INFO - Epoch: 36.38, Step: 144090, Train Loss: 1.1387, Learning Rate: 9.53e-06
2025-12-10 22:40:05 - INFO - Epoch: 36.38, Step: 144100, Train Loss: 1.1647, Learning Rate: 9.53e-06
2025-12-10 22:40:16 - INFO - Epoch: 36.38, Step: 144110, Train Loss: 1.1417, Learning Rate: 9.52e-06
2025-12-10 22:40:27 - INFO - Epoch: 36.38, Step: 144120, Train Loss: 1.1570, Learning Rate: 9.51e-06
2025-12-10 22:40:38 - INFO - Epoch: 36.39, Step: 144130, Train Loss: 1.1337, Learning Rate: 9.51e-06
2025-12-10 22:40:49 - INFO - Epoch: 36.39, Step: 144140, Train Loss: 1.1523, Learning Rate: 9.50e-06
2025-12-10 22:41:00 - INFO - Epoch: 36.39, Step: 144150, Train Loss: 1.1368, Learning Rate: 9.49e-06
2025-12-10 22:41:12 - INFO - Epoch: 36.39, Step: 144160, Train Loss: 1.1374, Learning Rate: 9.49e-06
2025-12-10 22:41:23 - INFO - Epoch: 36.40, Step: 144170, Train Loss: 1.1273, Learning Rate: 9.48e-06
2025-12-10 22:41:34 - INFO - Epoch: 36.40, Step: 144180, Train Loss: 1.1441, Learning Rate: 9.47e-06
2025-12-10 22:41:45 - INFO - Epoch: 36.40, Step: 144190, Train Loss: 1.1275, Learning Rate: 9.47e-06
2025-12-10 22:41:56 - INFO - Epoch: 36.40, Step: 144200, Train Loss: 1.1286, Learning Rate: 9.46e-06
2025-12-10 22:42:07 - INFO - Epoch: 36.41, Step: 144210, Train Loss: 1.1199, Learning Rate: 9.45e-06
2025-12-10 22:42:19 - INFO - Epoch: 36.41, Step: 144220, Train Loss: 1.1439, Learning Rate: 9.45e-06
2025-12-10 22:42:30 - INFO - Epoch: 36.41, Step: 144230, Train Loss: 1.1294, Learning Rate: 9.44e-06
2025-12-10 22:42:41 - INFO - Epoch: 36.42, Step: 144240, Train Loss: 1.1360, Learning Rate: 9.43e-06
2025-12-10 22:42:52 - INFO - Epoch: 36.42, Step: 144250, Train Loss: 1.1468, Learning Rate: 9.43e-06
2025-12-10 22:43:03 - INFO - Epoch: 36.42, Step: 144260, Train Loss: 1.1422, Learning Rate: 9.42e-06
2025-12-10 22:43:14 - INFO - Epoch: 36.42, Step: 144270, Train Loss: 1.1304, Learning Rate: 9.41e-06
2025-12-10 22:43:25 - INFO - Epoch: 36.43, Step: 144280, Train Loss: 1.1468, Learning Rate: 9.41e-06
2025-12-10 22:43:37 - INFO - Epoch: 36.43, Step: 144290, Train Loss: 1.1065, Learning Rate: 9.40e-06
2025-12-10 22:43:48 - INFO - Epoch: 36.43, Step: 144300, Train Loss: 1.1543, Learning Rate: 9.39e-06
2025-12-10 22:43:59 - INFO - Epoch: 36.43, Step: 144310, Train Loss: 1.1637, Learning Rate: 9.39e-06
2025-12-10 22:44:10 - INFO - Epoch: 36.44, Step: 144320, Train Loss: 1.1065, Learning Rate: 9.38e-06
2025-12-10 22:44:21 - INFO - Epoch: 36.44, Step: 144330, Train Loss: 1.1597, Learning Rate: 9.37e-06
2025-12-10 22:44:32 - INFO - Epoch: 36.44, Step: 144340, Train Loss: 1.1794, Learning Rate: 9.37e-06
2025-12-10 22:44:43 - INFO - Epoch: 36.44, Step: 144350, Train Loss: 1.1317, Learning Rate: 9.36e-06
2025-12-10 22:44:55 - INFO - Epoch: 36.45, Step: 144360, Train Loss: 1.1628, Learning Rate: 9.36e-06
2025-12-10 22:45:06 - INFO - Epoch: 36.45, Step: 144370, Train Loss: 1.1546, Learning Rate: 9.35e-06
2025-12-10 22:45:17 - INFO - Epoch: 36.45, Step: 144380, Train Loss: 1.1497, Learning Rate: 9.34e-06
2025-12-10 22:45:28 - INFO - Epoch: 36.45, Step: 144390, Train Loss: 1.0909, Learning Rate: 9.34e-06
2025-12-10 22:45:39 - INFO - Epoch: 36.46, Step: 144400, Train Loss: 1.1534, Learning Rate: 9.33e-06
2025-12-10 22:45:50 - INFO - Epoch: 36.46, Step: 144410, Train Loss: 1.1264, Learning Rate: 9.32e-06
2025-12-10 22:46:01 - INFO - Epoch: 36.46, Step: 144420, Train Loss: 1.1715, Learning Rate: 9.32e-06
2025-12-10 22:46:13 - INFO - Epoch: 36.46, Step: 144430, Train Loss: 1.1256, Learning Rate: 9.31e-06
2025-12-10 22:46:24 - INFO - Epoch: 36.47, Step: 144440, Train Loss: 1.1566, Learning Rate: 9.30e-06
2025-12-10 22:46:35 - INFO - Epoch: 36.47, Step: 144450, Train Loss: 1.1204, Learning Rate: 9.30e-06
2025-12-10 22:46:46 - INFO - Epoch: 36.47, Step: 144460, Train Loss: 1.1570, Learning Rate: 9.29e-06
2025-12-10 22:46:57 - INFO - Epoch: 36.47, Step: 144470, Train Loss: 1.1137, Learning Rate: 9.28e-06
2025-12-10 22:47:08 - INFO - Epoch: 36.48, Step: 144480, Train Loss: 1.1494, Learning Rate: 9.28e-06
2025-12-10 22:47:20 - INFO - Epoch: 36.48, Step: 144490, Train Loss: 1.1506, Learning Rate: 9.27e-06
2025-12-10 22:47:31 - INFO - Epoch: 36.48, Step: 144500, Train Loss: 1.1210, Learning Rate: 9.26e-06
2025-12-10 22:47:42 - INFO - Epoch: 36.48, Step: 144510, Train Loss: 1.1659, Learning Rate: 9.26e-06
2025-12-10 22:47:53 - INFO - Epoch: 36.49, Step: 144520, Train Loss: 1.1649, Learning Rate: 9.25e-06
2025-12-10 22:48:04 - INFO - Epoch: 36.49, Step: 144530, Train Loss: 1.1574, Learning Rate: 9.24e-06
2025-12-10 22:48:15 - INFO - Epoch: 36.49, Step: 144540, Train Loss: 1.1321, Learning Rate: 9.24e-06
2025-12-10 22:48:26 - INFO - Epoch: 36.49, Step: 144550, Train Loss: 1.1600, Learning Rate: 9.23e-06
2025-12-10 22:48:38 - INFO - Epoch: 36.50, Step: 144560, Train Loss: 1.1253, Learning Rate: 9.22e-06
2025-12-10 22:48:49 - INFO - Epoch: 36.50, Step: 144570, Train Loss: 1.1581, Learning Rate: 9.22e-06
2025-12-10 22:49:00 - INFO - Epoch: 36.50, Step: 144580, Train Loss: 1.1363, Learning Rate: 9.21e-06
2025-12-10 22:49:11 - INFO - Epoch: 36.50, Step: 144590, Train Loss: 1.1491, Learning Rate: 9.20e-06
2025-12-10 22:49:22 - INFO - Epoch: 36.51, Step: 144600, Train Loss: 1.1287, Learning Rate: 9.20e-06
2025-12-10 22:49:33 - INFO - Epoch: 36.51, Step: 144610, Train Loss: 1.1496, Learning Rate: 9.19e-06
2025-12-10 22:49:44 - INFO - Epoch: 36.51, Step: 144620, Train Loss: 1.1506, Learning Rate: 9.18e-06
2025-12-10 22:49:56 - INFO - Epoch: 36.51, Step: 144630, Train Loss: 1.1819, Learning Rate: 9.18e-06
2025-12-10 22:50:07 - INFO - Epoch: 36.52, Step: 144640, Train Loss: 1.1279, Learning Rate: 9.17e-06
2025-12-10 22:50:18 - INFO - Epoch: 36.52, Step: 144650, Train Loss: 1.1452, Learning Rate: 9.16e-06
2025-12-10 22:50:29 - INFO - Epoch: 36.52, Step: 144660, Train Loss: 1.1474, Learning Rate: 9.16e-06
2025-12-10 22:50:40 - INFO - Epoch: 36.52, Step: 144670, Train Loss: 1.1634, Learning Rate: 9.15e-06
2025-12-10 22:50:51 - INFO - Epoch: 36.53, Step: 144680, Train Loss: 1.1349, Learning Rate: 9.14e-06
2025-12-10 22:51:02 - INFO - Epoch: 36.53, Step: 144690, Train Loss: 1.1632, Learning Rate: 9.14e-06
2025-12-10 22:51:14 - INFO - Epoch: 36.53, Step: 144700, Train Loss: 1.1284, Learning Rate: 9.13e-06
2025-12-10 22:51:25 - INFO - Epoch: 36.53, Step: 144710, Train Loss: 1.1149, Learning Rate: 9.12e-06
2025-12-10 22:51:36 - INFO - Epoch: 36.54, Step: 144720, Train Loss: 1.1746, Learning Rate: 9.12e-06
2025-12-10 22:51:47 - INFO - Epoch: 36.54, Step: 144730, Train Loss: 1.1543, Learning Rate: 9.11e-06
2025-12-10 22:51:58 - INFO - Epoch: 36.54, Step: 144740, Train Loss: 1.1366, Learning Rate: 9.10e-06
2025-12-10 22:52:09 - INFO - Epoch: 36.54, Step: 144750, Train Loss: 1.1252, Learning Rate: 9.10e-06
2025-12-10 22:52:21 - INFO - Epoch: 36.55, Step: 144760, Train Loss: 1.1707, Learning Rate: 9.09e-06
2025-12-10 22:52:32 - INFO - Epoch: 36.55, Step: 144770, Train Loss: 1.1512, Learning Rate: 9.08e-06
2025-12-10 22:52:43 - INFO - Epoch: 36.55, Step: 144780, Train Loss: 1.1272, Learning Rate: 9.08e-06
2025-12-10 22:52:54 - INFO - Epoch: 36.55, Step: 144790, Train Loss: 1.1668, Learning Rate: 9.07e-06
2025-12-10 22:53:05 - INFO - Epoch: 36.56, Step: 144800, Train Loss: 1.1376, Learning Rate: 9.06e-06
2025-12-10 22:53:16 - INFO - Epoch: 36.56, Step: 144810, Train Loss: 1.1577, Learning Rate: 9.06e-06
2025-12-10 22:53:27 - INFO - Epoch: 36.56, Step: 144820, Train Loss: 1.1358, Learning Rate: 9.05e-06
2025-12-10 22:53:39 - INFO - Epoch: 36.56, Step: 144830, Train Loss: 1.0797, Learning Rate: 9.04e-06
2025-12-10 22:53:50 - INFO - Epoch: 36.57, Step: 144840, Train Loss: 1.1361, Learning Rate: 9.04e-06
2025-12-10 22:54:01 - INFO - Epoch: 36.57, Step: 144850, Train Loss: 1.1562, Learning Rate: 9.03e-06
2025-12-10 22:54:12 - INFO - Epoch: 36.57, Step: 144860, Train Loss: 1.1277, Learning Rate: 9.02e-06
2025-12-10 22:54:23 - INFO - Epoch: 36.57, Step: 144870, Train Loss: 1.1380, Learning Rate: 9.02e-06
2025-12-10 22:54:34 - INFO - Epoch: 36.58, Step: 144880, Train Loss: 1.1537, Learning Rate: 9.01e-06
2025-12-10 22:54:45 - INFO - Epoch: 36.58, Step: 144890, Train Loss: 1.1112, Learning Rate: 9.00e-06
2025-12-10 22:54:57 - INFO - Epoch: 36.58, Step: 144900, Train Loss: 1.1448, Learning Rate: 9.00e-06
2025-12-10 22:55:08 - INFO - Epoch: 36.58, Step: 144910, Train Loss: 1.1433, Learning Rate: 8.99e-06
2025-12-10 22:55:19 - INFO - Epoch: 36.59, Step: 144920, Train Loss: 1.0977, Learning Rate: 8.98e-06
2025-12-10 22:55:30 - INFO - Epoch: 36.59, Step: 144930, Train Loss: 1.1534, Learning Rate: 8.98e-06
2025-12-10 22:55:41 - INFO - Epoch: 36.59, Step: 144940, Train Loss: 1.1576, Learning Rate: 8.97e-06
2025-12-10 22:55:52 - INFO - Epoch: 36.59, Step: 144950, Train Loss: 1.1502, Learning Rate: 8.96e-06
2025-12-10 22:56:03 - INFO - Epoch: 36.60, Step: 144960, Train Loss: 1.1672, Learning Rate: 8.96e-06
2025-12-10 22:56:15 - INFO - Epoch: 36.60, Step: 144970, Train Loss: 1.1535, Learning Rate: 8.95e-06
2025-12-10 22:56:26 - INFO - Epoch: 36.60, Step: 144980, Train Loss: 1.1200, Learning Rate: 8.94e-06
2025-12-10 22:56:37 - INFO - Epoch: 36.60, Step: 144990, Train Loss: 1.1296, Learning Rate: 8.94e-06
2025-12-10 22:56:48 - INFO - Epoch: 36.61, Step: 145000, Train Loss: 1.1709, Learning Rate: 8.93e-06
2025-12-10 22:56:59 - INFO - Epoch: 36.61, Step: 145010, Train Loss: 1.1611, Learning Rate: 8.92e-06
2025-12-10 22:57:10 - INFO - Epoch: 36.61, Step: 145020, Train Loss: 1.1269, Learning Rate: 8.92e-06
2025-12-10 22:57:22 - INFO - Epoch: 36.61, Step: 145030, Train Loss: 1.1357, Learning Rate: 8.91e-06
2025-12-10 22:57:33 - INFO - Epoch: 36.62, Step: 145040, Train Loss: 1.1640, Learning Rate: 8.90e-06
2025-12-10 22:57:44 - INFO - Epoch: 36.62, Step: 145050, Train Loss: 1.1255, Learning Rate: 8.90e-06
2025-12-10 22:57:55 - INFO - Epoch: 36.62, Step: 145060, Train Loss: 1.1112, Learning Rate: 8.89e-06
2025-12-10 22:58:06 - INFO - Epoch: 36.62, Step: 145070, Train Loss: 1.1608, Learning Rate: 8.88e-06
2025-12-10 22:58:17 - INFO - Epoch: 36.63, Step: 145080, Train Loss: 1.1249, Learning Rate: 8.88e-06
2025-12-10 22:58:28 - INFO - Epoch: 36.63, Step: 145090, Train Loss: 1.1265, Learning Rate: 8.87e-06
2025-12-10 22:58:40 - INFO - Epoch: 36.63, Step: 145100, Train Loss: 1.1414, Learning Rate: 8.86e-06
2025-12-10 22:58:51 - INFO - Epoch: 36.63, Step: 145110, Train Loss: 1.1701, Learning Rate: 8.86e-06
2025-12-10 22:59:02 - INFO - Epoch: 36.64, Step: 145120, Train Loss: 1.1458, Learning Rate: 8.85e-06
2025-12-10 22:59:13 - INFO - Epoch: 36.64, Step: 145130, Train Loss: 1.1215, Learning Rate: 8.84e-06
2025-12-10 22:59:24 - INFO - Epoch: 36.64, Step: 145140, Train Loss: 1.1440, Learning Rate: 8.84e-06
2025-12-10 22:59:35 - INFO - Epoch: 36.64, Step: 145150, Train Loss: 1.1293, Learning Rate: 8.83e-06
2025-12-10 22:59:46 - INFO - Epoch: 36.65, Step: 145160, Train Loss: 1.1543, Learning Rate: 8.82e-06
2025-12-10 22:59:58 - INFO - Epoch: 36.65, Step: 145170, Train Loss: 1.1103, Learning Rate: 8.82e-06
2025-12-10 23:00:09 - INFO - Epoch: 36.65, Step: 145180, Train Loss: 1.1154, Learning Rate: 8.81e-06
2025-12-10 23:00:20 - INFO - Epoch: 36.65, Step: 145190, Train Loss: 1.1637, Learning Rate: 8.80e-06
2025-12-10 23:00:31 - INFO - Epoch: 36.66, Step: 145200, Train Loss: 1.1259, Learning Rate: 8.80e-06
2025-12-10 23:00:42 - INFO - Epoch: 36.66, Step: 145210, Train Loss: 1.1405, Learning Rate: 8.79e-06
2025-12-10 23:00:53 - INFO - Epoch: 36.66, Step: 145220, Train Loss: 1.1278, Learning Rate: 8.78e-06
2025-12-10 23:01:04 - INFO - Epoch: 36.66, Step: 145230, Train Loss: 1.1667, Learning Rate: 8.78e-06
2025-12-10 23:01:16 - INFO - Epoch: 36.67, Step: 145240, Train Loss: 1.1524, Learning Rate: 8.77e-06
2025-12-10 23:01:27 - INFO - Epoch: 36.67, Step: 145250, Train Loss: 1.0893, Learning Rate: 8.76e-06
2025-12-10 23:01:38 - INFO - Epoch: 36.67, Step: 145260, Train Loss: 1.1260, Learning Rate: 8.76e-06
2025-12-10 23:01:49 - INFO - Epoch: 36.68, Step: 145270, Train Loss: 1.1830, Learning Rate: 8.75e-06
2025-12-10 23:02:00 - INFO - Epoch: 36.68, Step: 145280, Train Loss: 1.1292, Learning Rate: 8.74e-06
2025-12-10 23:02:11 - INFO - Epoch: 36.68, Step: 145290, Train Loss: 1.1578, Learning Rate: 8.74e-06
2025-12-10 23:02:23 - INFO - Epoch: 36.68, Step: 145300, Train Loss: 1.1510, Learning Rate: 8.73e-06
2025-12-10 23:02:34 - INFO - Epoch: 36.69, Step: 145310, Train Loss: 1.1704, Learning Rate: 8.72e-06
2025-12-10 23:02:45 - INFO - Epoch: 36.69, Step: 145320, Train Loss: 1.1046, Learning Rate: 8.72e-06
2025-12-10 23:02:56 - INFO - Epoch: 36.69, Step: 145330, Train Loss: 1.1429, Learning Rate: 8.71e-06
2025-12-10 23:03:07 - INFO - Epoch: 36.69, Step: 145340, Train Loss: 1.1985, Learning Rate: 8.70e-06
2025-12-10 23:03:18 - INFO - Epoch: 36.70, Step: 145350, Train Loss: 1.1146, Learning Rate: 8.70e-06
2025-12-10 23:03:29 - INFO - Epoch: 36.70, Step: 145360, Train Loss: 1.1170, Learning Rate: 8.69e-06
2025-12-10 23:03:41 - INFO - Epoch: 36.70, Step: 145370, Train Loss: 1.1046, Learning Rate: 8.68e-06
2025-12-10 23:03:52 - INFO - Epoch: 36.70, Step: 145380, Train Loss: 1.1317, Learning Rate: 8.68e-06
2025-12-10 23:04:03 - INFO - Epoch: 36.71, Step: 145390, Train Loss: 1.1379, Learning Rate: 8.67e-06
2025-12-10 23:04:14 - INFO - Epoch: 36.71, Step: 145400, Train Loss: 1.1311, Learning Rate: 8.66e-06
2025-12-10 23:04:25 - INFO - Epoch: 36.71, Step: 145410, Train Loss: 1.1263, Learning Rate: 8.66e-06
2025-12-10 23:04:36 - INFO - Epoch: 36.71, Step: 145420, Train Loss: 1.1344, Learning Rate: 8.65e-06
2025-12-10 23:04:47 - INFO - Epoch: 36.72, Step: 145430, Train Loss: 1.1351, Learning Rate: 8.64e-06
2025-12-10 23:04:59 - INFO - Epoch: 36.72, Step: 145440, Train Loss: 1.1274, Learning Rate: 8.64e-06
2025-12-10 23:05:10 - INFO - Epoch: 36.72, Step: 145450, Train Loss: 1.1393, Learning Rate: 8.63e-06
2025-12-10 23:05:21 - INFO - Epoch: 36.72, Step: 145460, Train Loss: 1.1343, Learning Rate: 8.62e-06
2025-12-10 23:05:32 - INFO - Epoch: 36.73, Step: 145470, Train Loss: 1.1338, Learning Rate: 8.62e-06
2025-12-10 23:05:43 - INFO - Epoch: 36.73, Step: 145480, Train Loss: 1.1557, Learning Rate: 8.61e-06
2025-12-10 23:05:54 - INFO - Epoch: 36.73, Step: 145490, Train Loss: 1.1282, Learning Rate: 8.60e-06
2025-12-10 23:06:05 - INFO - Epoch: 36.73, Step: 145500, Train Loss: 1.1572, Learning Rate: 8.60e-06
2025-12-10 23:06:17 - INFO - Epoch: 36.74, Step: 145510, Train Loss: 1.1369, Learning Rate: 8.59e-06
2025-12-10 23:06:28 - INFO - Epoch: 36.74, Step: 145520, Train Loss: 1.1482, Learning Rate: 8.58e-06
2025-12-10 23:06:39 - INFO - Epoch: 36.74, Step: 145530, Train Loss: 1.1393, Learning Rate: 8.58e-06
2025-12-10 23:06:50 - INFO - Epoch: 36.74, Step: 145540, Train Loss: 1.1326, Learning Rate: 8.57e-06
2025-12-10 23:07:01 - INFO - Epoch: 36.75, Step: 145550, Train Loss: 1.1400, Learning Rate: 8.56e-06
2025-12-10 23:07:12 - INFO - Epoch: 36.75, Step: 145560, Train Loss: 1.1672, Learning Rate: 8.56e-06
2025-12-10 23:07:24 - INFO - Epoch: 36.75, Step: 145570, Train Loss: 1.1352, Learning Rate: 8.55e-06
2025-12-10 23:07:35 - INFO - Epoch: 36.75, Step: 145580, Train Loss: 1.0760, Learning Rate: 8.54e-06
2025-12-10 23:07:46 - INFO - Epoch: 36.76, Step: 145590, Train Loss: 1.1380, Learning Rate: 8.54e-06
2025-12-10 23:07:57 - INFO - Epoch: 36.76, Step: 145600, Train Loss: 1.1417, Learning Rate: 8.53e-06
2025-12-10 23:08:08 - INFO - Epoch: 36.76, Step: 145610, Train Loss: 1.1673, Learning Rate: 8.52e-06
2025-12-10 23:08:19 - INFO - Epoch: 36.76, Step: 145620, Train Loss: 1.1451, Learning Rate: 8.52e-06
2025-12-10 23:08:30 - INFO - Epoch: 36.77, Step: 145630, Train Loss: 1.0958, Learning Rate: 8.51e-06
2025-12-10 23:08:42 - INFO - Epoch: 36.77, Step: 145640, Train Loss: 1.1094, Learning Rate: 8.50e-06
2025-12-10 23:08:53 - INFO - Epoch: 36.77, Step: 145650, Train Loss: 1.1214, Learning Rate: 8.50e-06
2025-12-10 23:09:04 - INFO - Epoch: 36.77, Step: 145660, Train Loss: 1.1425, Learning Rate: 8.49e-06
2025-12-10 23:09:15 - INFO - Epoch: 36.78, Step: 145670, Train Loss: 1.1117, Learning Rate: 8.48e-06
2025-12-10 23:09:26 - INFO - Epoch: 36.78, Step: 145680, Train Loss: 1.1262, Learning Rate: 8.48e-06
2025-12-10 23:09:37 - INFO - Epoch: 36.78, Step: 145690, Train Loss: 1.1288, Learning Rate: 8.47e-06
2025-12-10 23:09:48 - INFO - Epoch: 36.78, Step: 145700, Train Loss: 1.1201, Learning Rate: 8.46e-06
2025-12-10 23:10:00 - INFO - Epoch: 36.79, Step: 145710, Train Loss: 1.1366, Learning Rate: 8.46e-06
2025-12-10 23:10:11 - INFO - Epoch: 36.79, Step: 145720, Train Loss: 1.1232, Learning Rate: 8.45e-06
2025-12-10 23:10:22 - INFO - Epoch: 36.79, Step: 145730, Train Loss: 1.1788, Learning Rate: 8.44e-06
2025-12-10 23:10:33 - INFO - Epoch: 36.79, Step: 145740, Train Loss: 1.1536, Learning Rate: 8.44e-06
2025-12-10 23:10:44 - INFO - Epoch: 36.80, Step: 145750, Train Loss: 1.1378, Learning Rate: 8.43e-06
2025-12-10 23:10:55 - INFO - Epoch: 36.80, Step: 145760, Train Loss: 1.1246, Learning Rate: 8.42e-06
2025-12-10 23:11:07 - INFO - Epoch: 36.80, Step: 145770, Train Loss: 1.1323, Learning Rate: 8.42e-06
2025-12-10 23:11:18 - INFO - Epoch: 36.80, Step: 145780, Train Loss: 1.1052, Learning Rate: 8.41e-06
2025-12-10 23:11:29 - INFO - Epoch: 36.81, Step: 145790, Train Loss: 1.1394, Learning Rate: 8.40e-06
2025-12-10 23:11:40 - INFO - Epoch: 36.81, Step: 145800, Train Loss: 1.1524, Learning Rate: 8.40e-06
2025-12-10 23:11:51 - INFO - Epoch: 36.81, Step: 145810, Train Loss: 1.1618, Learning Rate: 8.39e-06
2025-12-10 23:12:02 - INFO - Epoch: 36.81, Step: 145820, Train Loss: 1.1277, Learning Rate: 8.39e-06
2025-12-10 23:12:13 - INFO - Epoch: 36.82, Step: 145830, Train Loss: 1.1263, Learning Rate: 8.38e-06
2025-12-10 23:12:25 - INFO - Epoch: 36.82, Step: 145840, Train Loss: 1.0748, Learning Rate: 8.37e-06
2025-12-10 23:12:36 - INFO - Epoch: 36.82, Step: 145850, Train Loss: 1.1531, Learning Rate: 8.37e-06
2025-12-10 23:12:47 - INFO - Epoch: 36.82, Step: 145860, Train Loss: 1.1411, Learning Rate: 8.36e-06
2025-12-10 23:12:58 - INFO - Epoch: 36.83, Step: 145870, Train Loss: 1.1897, Learning Rate: 8.35e-06
2025-12-10 23:13:09 - INFO - Epoch: 36.83, Step: 145880, Train Loss: 1.1616, Learning Rate: 8.35e-06
2025-12-10 23:13:20 - INFO - Epoch: 36.83, Step: 145890, Train Loss: 1.1267, Learning Rate: 8.34e-06
2025-12-10 23:13:31 - INFO - Epoch: 36.83, Step: 145900, Train Loss: 1.1387, Learning Rate: 8.33e-06
2025-12-10 23:13:43 - INFO - Epoch: 36.84, Step: 145910, Train Loss: 1.1343, Learning Rate: 8.33e-06
2025-12-10 23:13:54 - INFO - Epoch: 36.84, Step: 145920, Train Loss: 1.1372, Learning Rate: 8.32e-06
2025-12-10 23:14:05 - INFO - Epoch: 36.84, Step: 145930, Train Loss: 1.1315, Learning Rate: 8.31e-06
2025-12-10 23:14:16 - INFO - Epoch: 36.84, Step: 145940, Train Loss: 1.1309, Learning Rate: 8.31e-06
2025-12-10 23:14:27 - INFO - Epoch: 36.85, Step: 145950, Train Loss: 1.1302, Learning Rate: 8.30e-06
2025-12-10 23:14:38 - INFO - Epoch: 36.85, Step: 145960, Train Loss: 1.1999, Learning Rate: 8.29e-06
2025-12-10 23:14:49 - INFO - Epoch: 36.85, Step: 145970, Train Loss: 1.1483, Learning Rate: 8.29e-06
2025-12-10 23:15:01 - INFO - Epoch: 36.85, Step: 145980, Train Loss: 1.1203, Learning Rate: 8.28e-06
2025-12-10 23:15:12 - INFO - Epoch: 36.86, Step: 145990, Train Loss: 1.1246, Learning Rate: 8.27e-06
2025-12-10 23:15:23 - INFO - Epoch: 36.86, Step: 146000, Train Loss: 1.1163, Learning Rate: 8.27e-06
2025-12-10 23:15:34 - INFO - Epoch: 36.86, Step: 146010, Train Loss: 1.0683, Learning Rate: 8.26e-06
2025-12-10 23:15:45 - INFO - Epoch: 36.86, Step: 146020, Train Loss: 1.1175, Learning Rate: 8.25e-06
2025-12-10 23:15:56 - INFO - Epoch: 36.87, Step: 146030, Train Loss: 1.1579, Learning Rate: 8.25e-06
2025-12-10 23:16:08 - INFO - Epoch: 36.87, Step: 146040, Train Loss: 1.1372, Learning Rate: 8.24e-06
2025-12-10 23:16:19 - INFO - Epoch: 36.87, Step: 146050, Train Loss: 1.1364, Learning Rate: 8.23e-06
2025-12-10 23:16:30 - INFO - Epoch: 36.87, Step: 146060, Train Loss: 1.1065, Learning Rate: 8.23e-06
2025-12-10 23:16:41 - INFO - Epoch: 36.88, Step: 146070, Train Loss: 1.1632, Learning Rate: 8.22e-06
2025-12-10 23:16:52 - INFO - Epoch: 36.88, Step: 146080, Train Loss: 1.1272, Learning Rate: 8.21e-06
2025-12-10 23:17:03 - INFO - Epoch: 36.88, Step: 146090, Train Loss: 1.1301, Learning Rate: 8.21e-06
2025-12-10 23:17:14 - INFO - Epoch: 36.88, Step: 146100, Train Loss: 1.1469, Learning Rate: 8.20e-06
2025-12-10 23:17:26 - INFO - Epoch: 36.89, Step: 146110, Train Loss: 1.1131, Learning Rate: 8.19e-06
2025-12-10 23:17:37 - INFO - Epoch: 36.89, Step: 146120, Train Loss: 1.1573, Learning Rate: 8.19e-06
2025-12-10 23:17:48 - INFO - Epoch: 36.89, Step: 146130, Train Loss: 1.1180, Learning Rate: 8.18e-06
2025-12-10 23:17:59 - INFO - Epoch: 36.89, Step: 146140, Train Loss: 1.1324, Learning Rate: 8.17e-06
2025-12-10 23:18:10 - INFO - Epoch: 36.90, Step: 146150, Train Loss: 1.1673, Learning Rate: 8.17e-06
2025-12-10 23:18:21 - INFO - Epoch: 36.90, Step: 146160, Train Loss: 1.1265, Learning Rate: 8.16e-06
2025-12-10 23:18:32 - INFO - Epoch: 36.90, Step: 146170, Train Loss: 1.1508, Learning Rate: 8.15e-06
2025-12-10 23:18:44 - INFO - Epoch: 36.90, Step: 146180, Train Loss: 1.1380, Learning Rate: 8.15e-06
2025-12-10 23:18:55 - INFO - Epoch: 36.91, Step: 146190, Train Loss: 1.1746, Learning Rate: 8.14e-06
2025-12-10 23:19:06 - INFO - Epoch: 36.91, Step: 146200, Train Loss: 1.1423, Learning Rate: 8.13e-06
2025-12-10 23:19:17 - INFO - Epoch: 36.91, Step: 146210, Train Loss: 1.1347, Learning Rate: 8.13e-06
2025-12-10 23:19:28 - INFO - Epoch: 36.91, Step: 146220, Train Loss: 1.1475, Learning Rate: 8.12e-06
2025-12-10 23:19:39 - INFO - Epoch: 36.92, Step: 146230, Train Loss: 1.1459, Learning Rate: 8.11e-06
2025-12-10 23:19:50 - INFO - Epoch: 36.92, Step: 146240, Train Loss: 1.1409, Learning Rate: 8.11e-06
2025-12-10 23:20:02 - INFO - Epoch: 36.92, Step: 146250, Train Loss: 1.1398, Learning Rate: 8.10e-06
2025-12-10 23:20:13 - INFO - Epoch: 36.93, Step: 146260, Train Loss: 1.1682, Learning Rate: 8.09e-06
2025-12-10 23:20:24 - INFO - Epoch: 36.93, Step: 146270, Train Loss: 1.1523, Learning Rate: 8.09e-06
2025-12-10 23:20:35 - INFO - Epoch: 36.93, Step: 146280, Train Loss: 1.1471, Learning Rate: 8.08e-06
2025-12-10 23:20:46 - INFO - Epoch: 36.93, Step: 146290, Train Loss: 1.1213, Learning Rate: 8.07e-06
2025-12-10 23:20:57 - INFO - Epoch: 36.94, Step: 146300, Train Loss: 1.1624, Learning Rate: 8.07e-06
2025-12-10 23:21:09 - INFO - Epoch: 36.94, Step: 146310, Train Loss: 1.1201, Learning Rate: 8.06e-06
2025-12-10 23:21:20 - INFO - Epoch: 36.94, Step: 146320, Train Loss: 1.1319, Learning Rate: 8.05e-06
2025-12-10 23:21:31 - INFO - Epoch: 36.94, Step: 146330, Train Loss: 1.1322, Learning Rate: 8.05e-06
2025-12-10 23:21:42 - INFO - Epoch: 36.95, Step: 146340, Train Loss: 1.1073, Learning Rate: 8.04e-06
2025-12-10 23:21:53 - INFO - Epoch: 36.95, Step: 146350, Train Loss: 1.1158, Learning Rate: 8.03e-06
2025-12-10 23:22:04 - INFO - Epoch: 36.95, Step: 146360, Train Loss: 1.1357, Learning Rate: 8.03e-06
2025-12-10 23:22:15 - INFO - Epoch: 36.95, Step: 146370, Train Loss: 1.1578, Learning Rate: 8.02e-06
2025-12-10 23:22:27 - INFO - Epoch: 36.96, Step: 146380, Train Loss: 1.1076, Learning Rate: 8.01e-06
2025-12-10 23:22:38 - INFO - Epoch: 36.96, Step: 146390, Train Loss: 1.1685, Learning Rate: 8.01e-06
2025-12-10 23:22:49 - INFO - Epoch: 36.96, Step: 146400, Train Loss: 1.0995, Learning Rate: 8.00e-06
2025-12-10 23:23:00 - INFO - Epoch: 36.96, Step: 146410, Train Loss: 1.1499, Learning Rate: 7.99e-06
2025-12-10 23:23:11 - INFO - Epoch: 36.97, Step: 146420, Train Loss: 1.1381, Learning Rate: 7.99e-06
2025-12-10 23:23:22 - INFO - Epoch: 36.97, Step: 146430, Train Loss: 1.1388, Learning Rate: 7.98e-06
2025-12-10 23:23:33 - INFO - Epoch: 36.97, Step: 146440, Train Loss: 1.1743, Learning Rate: 7.97e-06
2025-12-10 23:23:45 - INFO - Epoch: 36.97, Step: 146450, Train Loss: 1.1349, Learning Rate: 7.97e-06
2025-12-10 23:23:56 - INFO - Epoch: 36.98, Step: 146460, Train Loss: 1.1365, Learning Rate: 7.96e-06
2025-12-10 23:24:07 - INFO - Epoch: 36.98, Step: 146470, Train Loss: 1.1616, Learning Rate: 7.95e-06
2025-12-10 23:24:18 - INFO - Epoch: 36.98, Step: 146480, Train Loss: 1.1303, Learning Rate: 7.95e-06
2025-12-10 23:24:29 - INFO - Epoch: 36.98, Step: 146490, Train Loss: 1.1375, Learning Rate: 7.94e-06
2025-12-10 23:24:40 - INFO - Epoch: 36.99, Step: 146500, Train Loss: 1.1247, Learning Rate: 7.93e-06
2025-12-10 23:24:51 - INFO - Epoch: 36.99, Step: 146510, Train Loss: 1.1611, Learning Rate: 7.93e-06
2025-12-10 23:25:03 - INFO - Epoch: 36.99, Step: 146520, Train Loss: 1.1665, Learning Rate: 7.92e-06
2025-12-10 23:25:14 - INFO - Epoch: 36.99, Step: 146530, Train Loss: 1.1062, Learning Rate: 7.91e-06
2025-12-10 23:25:25 - INFO - Epoch: 37.00, Step: 146540, Train Loss: 1.1186, Learning Rate: 7.91e-06
2025-12-10 23:25:36 - INFO - Epoch: 37.00, Step: 146550, Train Loss: 1.1373, Learning Rate: 7.90e-06
2025-12-10 23:25:47 - INFO - Epoch: 37.00, Step: 146560, Train Loss: 1.1166, Learning Rate: 7.89e-06
2025-12-10 23:25:58 - INFO - Epoch: 37.00, Step: 146570, Train Loss: 1.1104, Learning Rate: 7.89e-06
2025-12-10 23:26:10 - INFO - Epoch: 37.01, Step: 146580, Train Loss: 1.1190, Learning Rate: 7.88e-06
2025-12-10 23:26:21 - INFO - Epoch: 37.01, Step: 146590, Train Loss: 1.1149, Learning Rate: 7.87e-06
2025-12-10 23:26:32 - INFO - Epoch: 37.01, Step: 146600, Train Loss: 1.1334, Learning Rate: 7.87e-06
2025-12-10 23:26:43 - INFO - Epoch: 37.01, Step: 146610, Train Loss: 1.1078, Learning Rate: 7.86e-06
2025-12-10 23:26:54 - INFO - Epoch: 37.02, Step: 146620, Train Loss: 1.0966, Learning Rate: 7.85e-06
2025-12-10 23:27:05 - INFO - Epoch: 37.02, Step: 146630, Train Loss: 1.1253, Learning Rate: 7.85e-06
2025-12-10 23:27:16 - INFO - Epoch: 37.02, Step: 146640, Train Loss: 1.1771, Learning Rate: 7.84e-06
2025-12-10 23:27:28 - INFO - Epoch: 37.02, Step: 146650, Train Loss: 1.1421, Learning Rate: 7.83e-06
2025-12-10 23:27:39 - INFO - Epoch: 37.03, Step: 146660, Train Loss: 1.1484, Learning Rate: 7.83e-06
2025-12-10 23:27:50 - INFO - Epoch: 37.03, Step: 146670, Train Loss: 1.1035, Learning Rate: 7.82e-06
2025-12-10 23:28:01 - INFO - Epoch: 37.03, Step: 146680, Train Loss: 1.1248, Learning Rate: 7.81e-06
2025-12-10 23:28:12 - INFO - Epoch: 37.03, Step: 146690, Train Loss: 1.1220, Learning Rate: 7.81e-06
2025-12-10 23:28:23 - INFO - Epoch: 37.04, Step: 146700, Train Loss: 1.1743, Learning Rate: 7.80e-06
2025-12-10 23:28:34 - INFO - Epoch: 37.04, Step: 146710, Train Loss: 1.1277, Learning Rate: 7.79e-06
2025-12-10 23:28:46 - INFO - Epoch: 37.04, Step: 146720, Train Loss: 1.1290, Learning Rate: 7.79e-06
2025-12-10 23:28:57 - INFO - Epoch: 37.04, Step: 146730, Train Loss: 1.1436, Learning Rate: 7.78e-06
2025-12-10 23:29:08 - INFO - Epoch: 37.05, Step: 146740, Train Loss: 1.1544, Learning Rate: 7.77e-06
2025-12-10 23:29:19 - INFO - Epoch: 37.05, Step: 146750, Train Loss: 1.1378, Learning Rate: 7.77e-06
2025-12-10 23:29:30 - INFO - Epoch: 37.05, Step: 146760, Train Loss: 1.1527, Learning Rate: 7.76e-06
2025-12-10 23:29:41 - INFO - Epoch: 37.05, Step: 146770, Train Loss: 1.1216, Learning Rate: 7.75e-06
2025-12-10 23:29:52 - INFO - Epoch: 37.06, Step: 146780, Train Loss: 1.1211, Learning Rate: 7.75e-06
2025-12-10 23:30:04 - INFO - Epoch: 37.06, Step: 146790, Train Loss: 1.1442, Learning Rate: 7.74e-06
2025-12-10 23:30:15 - INFO - Epoch: 37.06, Step: 146800, Train Loss: 1.1299, Learning Rate: 7.73e-06
2025-12-10 23:30:26 - INFO - Epoch: 37.06, Step: 146810, Train Loss: 1.1007, Learning Rate: 7.73e-06
2025-12-10 23:30:37 - INFO - Epoch: 37.07, Step: 146820, Train Loss: 1.1237, Learning Rate: 7.72e-06
2025-12-10 23:30:48 - INFO - Epoch: 37.07, Step: 146830, Train Loss: 1.1338, Learning Rate: 7.71e-06
2025-12-10 23:30:59 - INFO - Epoch: 37.07, Step: 146840, Train Loss: 1.1504, Learning Rate: 7.71e-06
2025-12-10 23:31:10 - INFO - Epoch: 37.07, Step: 146850, Train Loss: 1.1739, Learning Rate: 7.70e-06
2025-12-10 23:31:22 - INFO - Epoch: 37.08, Step: 146860, Train Loss: 1.1401, Learning Rate: 7.69e-06
2025-12-10 23:31:33 - INFO - Epoch: 37.08, Step: 146870, Train Loss: 1.1148, Learning Rate: 7.69e-06
2025-12-10 23:31:44 - INFO - Epoch: 37.08, Step: 146880, Train Loss: 1.1253, Learning Rate: 7.68e-06
2025-12-10 23:31:55 - INFO - Epoch: 37.08, Step: 146890, Train Loss: 1.0986, Learning Rate: 7.67e-06
2025-12-10 23:32:06 - INFO - Epoch: 37.09, Step: 146900, Train Loss: 1.1305, Learning Rate: 7.67e-06
2025-12-10 23:32:17 - INFO - Epoch: 37.09, Step: 146910, Train Loss: 1.1392, Learning Rate: 7.66e-06
2025-12-10 23:32:29 - INFO - Epoch: 37.09, Step: 146920, Train Loss: 1.1214, Learning Rate: 7.65e-06
2025-12-10 23:32:40 - INFO - Epoch: 37.09, Step: 146930, Train Loss: 1.1151, Learning Rate: 7.65e-06
2025-12-10 23:32:51 - INFO - Epoch: 37.10, Step: 146940, Train Loss: 1.1491, Learning Rate: 7.64e-06
2025-12-10 23:33:02 - INFO - Epoch: 37.10, Step: 146950, Train Loss: 1.1504, Learning Rate: 7.63e-06
2025-12-10 23:33:13 - INFO - Epoch: 37.10, Step: 146960, Train Loss: 1.1395, Learning Rate: 7.63e-06
2025-12-10 23:33:24 - INFO - Epoch: 37.10, Step: 146970, Train Loss: 1.1262, Learning Rate: 7.62e-06
2025-12-10 23:33:35 - INFO - Epoch: 37.11, Step: 146980, Train Loss: 1.1083, Learning Rate: 7.61e-06
2025-12-10 23:33:47 - INFO - Epoch: 37.11, Step: 146990, Train Loss: 1.1476, Learning Rate: 7.61e-06
2025-12-10 23:33:58 - INFO - Epoch: 37.11, Step: 147000, Train Loss: 1.1770, Learning Rate: 7.60e-06
2025-12-10 23:34:09 - INFO - Epoch: 37.11, Step: 147010, Train Loss: 1.1036, Learning Rate: 7.59e-06
2025-12-10 23:34:20 - INFO - Epoch: 37.12, Step: 147020, Train Loss: 1.1277, Learning Rate: 7.59e-06
2025-12-10 23:34:31 - INFO - Epoch: 37.12, Step: 147030, Train Loss: 1.1586, Learning Rate: 7.58e-06
2025-12-10 23:34:42 - INFO - Epoch: 37.12, Step: 147040, Train Loss: 1.0993, Learning Rate: 7.57e-06
2025-12-10 23:34:53 - INFO - Epoch: 37.12, Step: 147050, Train Loss: 1.1382, Learning Rate: 7.57e-06
2025-12-10 23:35:05 - INFO - Epoch: 37.13, Step: 147060, Train Loss: 1.1308, Learning Rate: 7.56e-06
2025-12-10 23:35:16 - INFO - Epoch: 37.13, Step: 147070, Train Loss: 1.1461, Learning Rate: 7.55e-06
2025-12-10 23:35:27 - INFO - Epoch: 37.13, Step: 147080, Train Loss: 1.1108, Learning Rate: 7.55e-06
2025-12-10 23:35:38 - INFO - Epoch: 37.13, Step: 147090, Train Loss: 1.1650, Learning Rate: 7.54e-06
2025-12-10 23:35:49 - INFO - Epoch: 37.14, Step: 147100, Train Loss: 1.1542, Learning Rate: 7.53e-06
2025-12-10 23:36:00 - INFO - Epoch: 37.14, Step: 147110, Train Loss: 1.1070, Learning Rate: 7.53e-06
2025-12-10 23:36:11 - INFO - Epoch: 37.14, Step: 147120, Train Loss: 1.1676, Learning Rate: 7.52e-06
2025-12-10 23:36:23 - INFO - Epoch: 37.14, Step: 147130, Train Loss: 1.1434, Learning Rate: 7.51e-06
2025-12-10 23:36:34 - INFO - Epoch: 37.15, Step: 147140, Train Loss: 1.1409, Learning Rate: 7.51e-06
2025-12-10 23:36:45 - INFO - Epoch: 37.15, Step: 147150, Train Loss: 1.1506, Learning Rate: 7.50e-06
2025-12-10 23:36:56 - INFO - Epoch: 37.15, Step: 147160, Train Loss: 1.1383, Learning Rate: 7.49e-06
2025-12-10 23:37:07 - INFO - Epoch: 37.15, Step: 147170, Train Loss: 1.1263, Learning Rate: 7.49e-06
2025-12-10 23:37:18 - INFO - Epoch: 37.16, Step: 147180, Train Loss: 1.0996, Learning Rate: 7.48e-06
2025-12-10 23:37:29 - INFO - Epoch: 37.16, Step: 147190, Train Loss: 1.1185, Learning Rate: 7.47e-06
2025-12-10 23:37:41 - INFO - Epoch: 37.16, Step: 147200, Train Loss: 1.1719, Learning Rate: 7.47e-06
2025-12-10 23:37:52 - INFO - Epoch: 37.16, Step: 147210, Train Loss: 1.1565, Learning Rate: 7.46e-06
2025-12-10 23:38:03 - INFO - Epoch: 37.17, Step: 147220, Train Loss: 1.1552, Learning Rate: 7.45e-06
2025-12-10 23:38:14 - INFO - Epoch: 37.17, Step: 147230, Train Loss: 1.1715, Learning Rate: 7.45e-06
2025-12-10 23:38:25 - INFO - Epoch: 37.17, Step: 147240, Train Loss: 1.1464, Learning Rate: 7.44e-06
2025-12-10 23:38:36 - INFO - Epoch: 37.17, Step: 147250, Train Loss: 1.1188, Learning Rate: 7.43e-06
2025-12-10 23:38:48 - INFO - Epoch: 37.18, Step: 147260, Train Loss: 1.1425, Learning Rate: 7.43e-06
2025-12-10 23:38:59 - INFO - Epoch: 37.18, Step: 147270, Train Loss: 1.1762, Learning Rate: 7.42e-06
2025-12-10 23:39:10 - INFO - Epoch: 37.18, Step: 147280, Train Loss: 1.1246, Learning Rate: 7.42e-06
2025-12-10 23:39:21 - INFO - Epoch: 37.19, Step: 147290, Train Loss: 1.1232, Learning Rate: 7.41e-06
2025-12-10 23:39:32 - INFO - Epoch: 37.19, Step: 147300, Train Loss: 1.1358, Learning Rate: 7.40e-06
2025-12-10 23:39:43 - INFO - Epoch: 37.19, Step: 147310, Train Loss: 1.1159, Learning Rate: 7.40e-06
2025-12-10 23:39:54 - INFO - Epoch: 37.19, Step: 147320, Train Loss: 1.1459, Learning Rate: 7.39e-06
2025-12-10 23:40:06 - INFO - Epoch: 37.20, Step: 147330, Train Loss: 1.1663, Learning Rate: 7.38e-06
2025-12-10 23:40:17 - INFO - Epoch: 37.20, Step: 147340, Train Loss: 1.1277, Learning Rate: 7.38e-06
2025-12-10 23:40:28 - INFO - Epoch: 37.20, Step: 147350, Train Loss: 1.1467, Learning Rate: 7.37e-06
2025-12-10 23:40:39 - INFO - Epoch: 37.20, Step: 147360, Train Loss: 1.1615, Learning Rate: 7.36e-06
2025-12-10 23:40:50 - INFO - Epoch: 37.21, Step: 147370, Train Loss: 1.1163, Learning Rate: 7.36e-06
2025-12-10 23:41:01 - INFO - Epoch: 37.21, Step: 147380, Train Loss: 1.1205, Learning Rate: 7.35e-06
2025-12-10 23:41:12 - INFO - Epoch: 37.21, Step: 147390, Train Loss: 1.1378, Learning Rate: 7.34e-06
2025-12-10 23:41:24 - INFO - Epoch: 37.21, Step: 147400, Train Loss: 1.1160, Learning Rate: 7.34e-06
2025-12-10 23:41:35 - INFO - Epoch: 37.22, Step: 147410, Train Loss: 1.1213, Learning Rate: 7.33e-06
2025-12-10 23:41:46 - INFO - Epoch: 37.22, Step: 147420, Train Loss: 1.1764, Learning Rate: 7.32e-06
2025-12-10 23:41:57 - INFO - Epoch: 37.22, Step: 147430, Train Loss: 1.1296, Learning Rate: 7.32e-06
2025-12-10 23:42:08 - INFO - Epoch: 37.22, Step: 147440, Train Loss: 1.1037, Learning Rate: 7.31e-06
2025-12-10 23:42:19 - INFO - Epoch: 37.23, Step: 147450, Train Loss: 1.1645, Learning Rate: 7.30e-06
2025-12-10 23:42:30 - INFO - Epoch: 37.23, Step: 147460, Train Loss: 1.1449, Learning Rate: 7.30e-06
2025-12-10 23:42:42 - INFO - Epoch: 37.23, Step: 147470, Train Loss: 1.1569, Learning Rate: 7.29e-06
2025-12-10 23:42:53 - INFO - Epoch: 37.23, Step: 147480, Train Loss: 1.1292, Learning Rate: 7.28e-06
2025-12-10 23:43:04 - INFO - Epoch: 37.24, Step: 147490, Train Loss: 1.1249, Learning Rate: 7.28e-06
2025-12-10 23:43:15 - INFO - Epoch: 37.24, Step: 147500, Train Loss: 1.1408, Learning Rate: 7.27e-06
2025-12-10 23:43:26 - INFO - Epoch: 37.24, Step: 147510, Train Loss: 1.1562, Learning Rate: 7.26e-06
2025-12-10 23:43:37 - INFO - Epoch: 37.24, Step: 147520, Train Loss: 1.1591, Learning Rate: 7.26e-06
2025-12-10 23:43:48 - INFO - Epoch: 37.25, Step: 147530, Train Loss: 1.1288, Learning Rate: 7.25e-06
2025-12-10 23:44:00 - INFO - Epoch: 37.25, Step: 147540, Train Loss: 1.1325, Learning Rate: 7.24e-06
2025-12-10 23:44:11 - INFO - Epoch: 37.25, Step: 147550, Train Loss: 1.1262, Learning Rate: 7.24e-06
2025-12-10 23:44:22 - INFO - Epoch: 37.25, Step: 147560, Train Loss: 1.1055, Learning Rate: 7.23e-06
2025-12-10 23:44:33 - INFO - Epoch: 37.26, Step: 147570, Train Loss: 1.1073, Learning Rate: 7.22e-06
2025-12-10 23:44:44 - INFO - Epoch: 37.26, Step: 147580, Train Loss: 1.1568, Learning Rate: 7.22e-06
2025-12-10 23:44:55 - INFO - Epoch: 37.26, Step: 147590, Train Loss: 1.1243, Learning Rate: 7.21e-06
2025-12-10 23:45:07 - INFO - Epoch: 37.26, Step: 147600, Train Loss: 1.1230, Learning Rate: 7.20e-06
2025-12-10 23:45:18 - INFO - Epoch: 37.27, Step: 147610, Train Loss: 1.0999, Learning Rate: 7.20e-06
2025-12-10 23:45:29 - INFO - Epoch: 37.27, Step: 147620, Train Loss: 1.1574, Learning Rate: 7.19e-06
2025-12-10 23:45:40 - INFO - Epoch: 37.27, Step: 147630, Train Loss: 1.0920, Learning Rate: 7.18e-06
2025-12-10 23:45:51 - INFO - Epoch: 37.27, Step: 147640, Train Loss: 1.1216, Learning Rate: 7.18e-06
2025-12-10 23:46:02 - INFO - Epoch: 37.28, Step: 147650, Train Loss: 1.1180, Learning Rate: 7.17e-06
2025-12-10 23:46:13 - INFO - Epoch: 37.28, Step: 147660, Train Loss: 1.1271, Learning Rate: 7.16e-06
2025-12-10 23:46:25 - INFO - Epoch: 37.28, Step: 147670, Train Loss: 1.1178, Learning Rate: 7.16e-06
2025-12-10 23:46:36 - INFO - Epoch: 37.28, Step: 147680, Train Loss: 1.1340, Learning Rate: 7.15e-06
2025-12-10 23:46:47 - INFO - Epoch: 37.29, Step: 147690, Train Loss: 1.1620, Learning Rate: 7.14e-06
2025-12-10 23:46:58 - INFO - Epoch: 37.29, Step: 147700, Train Loss: 1.1140, Learning Rate: 7.14e-06
2025-12-10 23:47:09 - INFO - Epoch: 37.29, Step: 147710, Train Loss: 1.1474, Learning Rate: 7.13e-06
2025-12-10 23:47:20 - INFO - Epoch: 37.29, Step: 147720, Train Loss: 1.1360, Learning Rate: 7.12e-06
2025-12-10 23:47:31 - INFO - Epoch: 37.30, Step: 147730, Train Loss: 1.1441, Learning Rate: 7.12e-06
2025-12-10 23:47:43 - INFO - Epoch: 37.30, Step: 147740, Train Loss: 1.1558, Learning Rate: 7.11e-06
2025-12-10 23:47:54 - INFO - Epoch: 37.30, Step: 147750, Train Loss: 1.1126, Learning Rate: 7.10e-06
2025-12-10 23:48:05 - INFO - Epoch: 37.30, Step: 147760, Train Loss: 1.1800, Learning Rate: 7.10e-06
2025-12-10 23:48:16 - INFO - Epoch: 37.31, Step: 147770, Train Loss: 1.1397, Learning Rate: 7.09e-06
2025-12-10 23:48:27 - INFO - Epoch: 37.31, Step: 147780, Train Loss: 1.1034, Learning Rate: 7.08e-06
2025-12-10 23:48:38 - INFO - Epoch: 37.31, Step: 147790, Train Loss: 1.1707, Learning Rate: 7.08e-06
2025-12-10 23:48:49 - INFO - Epoch: 37.31, Step: 147800, Train Loss: 1.1110, Learning Rate: 7.07e-06
2025-12-10 23:49:01 - INFO - Epoch: 37.32, Step: 147810, Train Loss: 1.1753, Learning Rate: 7.06e-06
2025-12-10 23:49:12 - INFO - Epoch: 37.32, Step: 147820, Train Loss: 1.1471, Learning Rate: 7.06e-06
2025-12-10 23:49:23 - INFO - Epoch: 37.32, Step: 147830, Train Loss: 1.1336, Learning Rate: 7.05e-06
2025-12-10 23:49:34 - INFO - Epoch: 37.32, Step: 147840, Train Loss: 1.1148, Learning Rate: 7.04e-06
2025-12-10 23:49:45 - INFO - Epoch: 37.33, Step: 147850, Train Loss: 1.1676, Learning Rate: 7.04e-06
2025-12-10 23:49:56 - INFO - Epoch: 37.33, Step: 147860, Train Loss: 1.1166, Learning Rate: 7.03e-06
2025-12-10 23:50:07 - INFO - Epoch: 37.33, Step: 147870, Train Loss: 1.1325, Learning Rate: 7.02e-06
2025-12-10 23:50:19 - INFO - Epoch: 37.33, Step: 147880, Train Loss: 1.1224, Learning Rate: 7.02e-06
2025-12-10 23:50:30 - INFO - Epoch: 37.34, Step: 147890, Train Loss: 1.1280, Learning Rate: 7.01e-06
2025-12-10 23:50:41 - INFO - Epoch: 37.34, Step: 147900, Train Loss: 1.1535, Learning Rate: 7.00e-06
2025-12-10 23:50:52 - INFO - Epoch: 37.34, Step: 147910, Train Loss: 1.1374, Learning Rate: 7.00e-06
2025-12-10 23:51:03 - INFO - Epoch: 37.34, Step: 147920, Train Loss: 1.1239, Learning Rate: 6.99e-06
2025-12-10 23:51:14 - INFO - Epoch: 37.35, Step: 147930, Train Loss: 1.0964, Learning Rate: 6.98e-06
2025-12-10 23:51:26 - INFO - Epoch: 37.35, Step: 147940, Train Loss: 1.1478, Learning Rate: 6.98e-06
2025-12-10 23:51:37 - INFO - Epoch: 37.35, Step: 147950, Train Loss: 1.1290, Learning Rate: 6.97e-06
2025-12-10 23:51:48 - INFO - Epoch: 37.35, Step: 147960, Train Loss: 1.1331, Learning Rate: 6.96e-06
2025-12-10 23:51:59 - INFO - Epoch: 37.36, Step: 147970, Train Loss: 1.1275, Learning Rate: 6.96e-06
2025-12-10 23:52:10 - INFO - Epoch: 37.36, Step: 147980, Train Loss: 1.1075, Learning Rate: 6.95e-06
2025-12-10 23:52:21 - INFO - Epoch: 37.36, Step: 147990, Train Loss: 1.1036, Learning Rate: 6.94e-06
2025-12-10 23:52:32 - INFO - Epoch: 37.36, Step: 148000, Train Loss: 1.1098, Learning Rate: 6.94e-06
2025-12-10 23:52:44 - INFO - Epoch: 37.37, Step: 148010, Train Loss: 1.1713, Learning Rate: 6.93e-06
2025-12-10 23:52:55 - INFO - Epoch: 37.37, Step: 148020, Train Loss: 1.1314, Learning Rate: 6.92e-06
2025-12-10 23:53:06 - INFO - Epoch: 37.37, Step: 148030, Train Loss: 1.1505, Learning Rate: 6.92e-06
2025-12-10 23:53:17 - INFO - Epoch: 37.37, Step: 148040, Train Loss: 1.1439, Learning Rate: 6.91e-06
2025-12-10 23:53:28 - INFO - Epoch: 37.38, Step: 148050, Train Loss: 1.1722, Learning Rate: 6.90e-06
2025-12-10 23:53:39 - INFO - Epoch: 37.38, Step: 148060, Train Loss: 1.1053, Learning Rate: 6.90e-06
2025-12-10 23:53:50 - INFO - Epoch: 37.38, Step: 148070, Train Loss: 1.1237, Learning Rate: 6.89e-06
2025-12-10 23:54:02 - INFO - Epoch: 37.38, Step: 148080, Train Loss: 1.1043, Learning Rate: 6.88e-06
2025-12-10 23:54:13 - INFO - Epoch: 37.39, Step: 148090, Train Loss: 1.1562, Learning Rate: 6.88e-06
2025-12-10 23:54:24 - INFO - Epoch: 37.39, Step: 148100, Train Loss: 1.1725, Learning Rate: 6.87e-06
2025-12-10 23:54:35 - INFO - Epoch: 37.39, Step: 148110, Train Loss: 1.1165, Learning Rate: 6.86e-06
2025-12-10 23:54:46 - INFO - Epoch: 37.39, Step: 148120, Train Loss: 1.1427, Learning Rate: 6.86e-06
2025-12-10 23:54:57 - INFO - Epoch: 37.40, Step: 148130, Train Loss: 1.1484, Learning Rate: 6.85e-06
2025-12-10 23:55:08 - INFO - Epoch: 37.40, Step: 148140, Train Loss: 1.1347, Learning Rate: 6.84e-06
2025-12-10 23:55:20 - INFO - Epoch: 37.40, Step: 148150, Train Loss: 1.1061, Learning Rate: 6.84e-06
2025-12-10 23:55:31 - INFO - Epoch: 37.40, Step: 148160, Train Loss: 1.1619, Learning Rate: 6.83e-06
2025-12-10 23:55:42 - INFO - Epoch: 37.41, Step: 148170, Train Loss: 1.1427, Learning Rate: 6.82e-06
2025-12-10 23:55:53 - INFO - Epoch: 37.41, Step: 148180, Train Loss: 1.1880, Learning Rate: 6.82e-06
2025-12-10 23:56:04 - INFO - Epoch: 37.41, Step: 148190, Train Loss: 1.1262, Learning Rate: 6.81e-06
2025-12-10 23:56:15 - INFO - Epoch: 37.41, Step: 148200, Train Loss: 1.1345, Learning Rate: 6.80e-06
2025-12-10 23:56:26 - INFO - Epoch: 37.42, Step: 148210, Train Loss: 1.1416, Learning Rate: 6.80e-06
2025-12-10 23:56:38 - INFO - Epoch: 37.42, Step: 148220, Train Loss: 1.1355, Learning Rate: 6.79e-06
2025-12-10 23:56:49 - INFO - Epoch: 37.42, Step: 148230, Train Loss: 1.1318, Learning Rate: 6.78e-06
2025-12-10 23:57:00 - INFO - Epoch: 37.42, Step: 148240, Train Loss: 1.1255, Learning Rate: 6.78e-06
2025-12-10 23:57:11 - INFO - Epoch: 37.43, Step: 148250, Train Loss: 1.1589, Learning Rate: 6.77e-06
2025-12-10 23:57:22 - INFO - Epoch: 37.43, Step: 148260, Train Loss: 1.1618, Learning Rate: 6.76e-06
2025-12-10 23:57:33 - INFO - Epoch: 37.43, Step: 148270, Train Loss: 1.1058, Learning Rate: 6.76e-06
2025-12-10 23:57:44 - INFO - Epoch: 37.43, Step: 148280, Train Loss: 1.0864, Learning Rate: 6.75e-06
2025-12-10 23:57:56 - INFO - Epoch: 37.44, Step: 148290, Train Loss: 1.1363, Learning Rate: 6.74e-06
2025-12-10 23:58:07 - INFO - Epoch: 37.44, Step: 148300, Train Loss: 1.0971, Learning Rate: 6.74e-06
2025-12-10 23:58:18 - INFO - Epoch: 37.44, Step: 148310, Train Loss: 1.1526, Learning Rate: 6.73e-06
2025-12-10 23:58:29 - INFO - Epoch: 37.45, Step: 148320, Train Loss: 1.1205, Learning Rate: 6.72e-06
2025-12-10 23:58:40 - INFO - Epoch: 37.45, Step: 148330, Train Loss: 1.1078, Learning Rate: 6.72e-06
2025-12-10 23:58:51 - INFO - Epoch: 37.45, Step: 148340, Train Loss: 1.1202, Learning Rate: 6.71e-06
2025-12-10 23:59:03 - INFO - Epoch: 37.45, Step: 148350, Train Loss: 1.1536, Learning Rate: 6.70e-06
2025-12-10 23:59:14 - INFO - Epoch: 37.46, Step: 148360, Train Loss: 1.1569, Learning Rate: 6.70e-06
2025-12-10 23:59:25 - INFO - Epoch: 37.46, Step: 148370, Train Loss: 1.1508, Learning Rate: 6.69e-06
2025-12-10 23:59:36 - INFO - Epoch: 37.46, Step: 148380, Train Loss: 1.1261, Learning Rate: 6.68e-06
2025-12-10 23:59:47 - INFO - Epoch: 37.46, Step: 148390, Train Loss: 1.1953, Learning Rate: 6.68e-06
2025-12-10 23:59:58 - INFO - Epoch: 37.47, Step: 148400, Train Loss: 1.1022, Learning Rate: 6.67e-06
2025-12-11 00:00:09 - INFO - Epoch: 37.47, Step: 148410, Train Loss: 1.1486, Learning Rate: 6.66e-06
2025-12-11 00:00:21 - INFO - Epoch: 37.47, Step: 148420, Train Loss: 1.1595, Learning Rate: 6.66e-06
2025-12-11 00:00:32 - INFO - Epoch: 37.47, Step: 148430, Train Loss: 1.1127, Learning Rate: 6.65e-06
2025-12-11 00:00:43 - INFO - Epoch: 37.48, Step: 148440, Train Loss: 1.1047, Learning Rate: 6.64e-06
2025-12-11 00:00:54 - INFO - Epoch: 37.48, Step: 148450, Train Loss: 1.1599, Learning Rate: 6.64e-06
2025-12-11 00:01:05 - INFO - Epoch: 37.48, Step: 148460, Train Loss: 1.1246, Learning Rate: 6.63e-06
2025-12-11 00:01:16 - INFO - Epoch: 37.48, Step: 148470, Train Loss: 1.1250, Learning Rate: 6.62e-06
2025-12-11 00:01:27 - INFO - Epoch: 37.49, Step: 148480, Train Loss: 1.1142, Learning Rate: 6.62e-06
2025-12-11 00:01:39 - INFO - Epoch: 37.49, Step: 148490, Train Loss: 1.1225, Learning Rate: 6.61e-06
2025-12-11 00:01:50 - INFO - Epoch: 37.49, Step: 148500, Train Loss: 1.1252, Learning Rate: 6.60e-06
2025-12-11 00:02:01 - INFO - Epoch: 37.49, Step: 148510, Train Loss: 1.1543, Learning Rate: 6.60e-06
2025-12-11 00:02:12 - INFO - Epoch: 37.50, Step: 148520, Train Loss: 1.1363, Learning Rate: 6.59e-06
2025-12-11 00:02:23 - INFO - Epoch: 37.50, Step: 148530, Train Loss: 1.1263, Learning Rate: 6.58e-06
2025-12-11 00:02:34 - INFO - Epoch: 37.50, Step: 148540, Train Loss: 1.1522, Learning Rate: 6.58e-06
2025-12-11 00:02:45 - INFO - Epoch: 37.50, Step: 148550, Train Loss: 1.1302, Learning Rate: 6.57e-06
2025-12-11 00:02:57 - INFO - Epoch: 37.51, Step: 148560, Train Loss: 1.1243, Learning Rate: 6.56e-06
2025-12-11 00:03:08 - INFO - Epoch: 37.51, Step: 148570, Train Loss: 1.1153, Learning Rate: 6.56e-06
2025-12-11 00:03:19 - INFO - Epoch: 37.51, Step: 148580, Train Loss: 1.1106, Learning Rate: 6.55e-06
2025-12-11 00:03:30 - INFO - Epoch: 37.51, Step: 148590, Train Loss: 1.1287, Learning Rate: 6.54e-06
2025-12-11 00:03:41 - INFO - Epoch: 37.52, Step: 148600, Train Loss: 1.1243, Learning Rate: 6.54e-06
2025-12-11 00:03:52 - INFO - Epoch: 37.52, Step: 148610, Train Loss: 1.1310, Learning Rate: 6.53e-06
2025-12-11 00:04:03 - INFO - Epoch: 37.52, Step: 148620, Train Loss: 1.1522, Learning Rate: 6.52e-06
2025-12-11 00:04:15 - INFO - Epoch: 37.52, Step: 148630, Train Loss: 1.1431, Learning Rate: 6.52e-06
2025-12-11 00:04:26 - INFO - Epoch: 37.53, Step: 148640, Train Loss: 1.1247, Learning Rate: 6.51e-06
2025-12-11 00:04:37 - INFO - Epoch: 37.53, Step: 148650, Train Loss: 1.1700, Learning Rate: 6.50e-06
2025-12-11 00:04:48 - INFO - Epoch: 37.53, Step: 148660, Train Loss: 1.0967, Learning Rate: 6.50e-06
2025-12-11 00:04:59 - INFO - Epoch: 37.53, Step: 148670, Train Loss: 1.1420, Learning Rate: 6.49e-06
2025-12-11 00:05:10 - INFO - Epoch: 37.54, Step: 148680, Train Loss: 1.1810, Learning Rate: 6.48e-06
2025-12-11 00:05:22 - INFO - Epoch: 37.54, Step: 148690, Train Loss: 1.1668, Learning Rate: 6.48e-06
2025-12-11 00:05:33 - INFO - Epoch: 37.54, Step: 148700, Train Loss: 1.1280, Learning Rate: 6.47e-06
2025-12-11 00:05:44 - INFO - Epoch: 37.54, Step: 148710, Train Loss: 1.1511, Learning Rate: 6.47e-06
2025-12-11 00:05:55 - INFO - Epoch: 37.55, Step: 148720, Train Loss: 1.1362, Learning Rate: 6.46e-06
2025-12-11 00:06:06 - INFO - Epoch: 37.55, Step: 148730, Train Loss: 1.1396, Learning Rate: 6.45e-06
2025-12-11 00:06:17 - INFO - Epoch: 37.55, Step: 148740, Train Loss: 1.1875, Learning Rate: 6.45e-06
2025-12-11 00:06:28 - INFO - Epoch: 37.55, Step: 148750, Train Loss: 1.1061, Learning Rate: 6.44e-06
2025-12-11 00:06:40 - INFO - Epoch: 37.56, Step: 148760, Train Loss: 1.1615, Learning Rate: 6.43e-06
2025-12-11 00:06:51 - INFO - Epoch: 37.56, Step: 148770, Train Loss: 1.1705, Learning Rate: 6.43e-06
2025-12-11 00:07:02 - INFO - Epoch: 37.56, Step: 148780, Train Loss: 1.1572, Learning Rate: 6.42e-06
2025-12-11 00:07:13 - INFO - Epoch: 37.56, Step: 148790, Train Loss: 1.1494, Learning Rate: 6.41e-06
2025-12-11 00:07:24 - INFO - Epoch: 37.57, Step: 148800, Train Loss: 1.1121, Learning Rate: 6.41e-06
2025-12-11 00:07:35 - INFO - Epoch: 37.57, Step: 148810, Train Loss: 1.1477, Learning Rate: 6.40e-06
2025-12-11 00:07:46 - INFO - Epoch: 37.57, Step: 148820, Train Loss: 1.1330, Learning Rate: 6.39e-06
2025-12-11 00:07:58 - INFO - Epoch: 37.57, Step: 148830, Train Loss: 1.1355, Learning Rate: 6.39e-06
2025-12-11 00:08:09 - INFO - Epoch: 37.58, Step: 148840, Train Loss: 1.1318, Learning Rate: 6.38e-06
2025-12-11 00:08:20 - INFO - Epoch: 37.58, Step: 148850, Train Loss: 1.1468, Learning Rate: 6.37e-06
2025-12-11 00:08:31 - INFO - Epoch: 37.58, Step: 148860, Train Loss: 1.1654, Learning Rate: 6.37e-06
2025-12-11 00:08:42 - INFO - Epoch: 37.58, Step: 148870, Train Loss: 1.1288, Learning Rate: 6.36e-06
2025-12-11 00:08:53 - INFO - Epoch: 37.59, Step: 148880, Train Loss: 1.1075, Learning Rate: 6.35e-06
2025-12-11 00:09:04 - INFO - Epoch: 37.59, Step: 148890, Train Loss: 1.1291, Learning Rate: 6.35e-06
2025-12-11 00:09:16 - INFO - Epoch: 37.59, Step: 148900, Train Loss: 1.1612, Learning Rate: 6.34e-06
2025-12-11 00:09:27 - INFO - Epoch: 37.59, Step: 148910, Train Loss: 1.1531, Learning Rate: 6.33e-06
2025-12-11 00:09:38 - INFO - Epoch: 37.60, Step: 148920, Train Loss: 1.1116, Learning Rate: 6.33e-06
2025-12-11 00:09:49 - INFO - Epoch: 37.60, Step: 148930, Train Loss: 1.1265, Learning Rate: 6.32e-06
2025-12-11 00:10:00 - INFO - Epoch: 37.60, Step: 148940, Train Loss: 1.1592, Learning Rate: 6.31e-06
2025-12-11 00:10:11 - INFO - Epoch: 37.60, Step: 148950, Train Loss: 1.1471, Learning Rate: 6.31e-06
2025-12-11 00:10:22 - INFO - Epoch: 37.61, Step: 148960, Train Loss: 1.1456, Learning Rate: 6.30e-06
2025-12-11 00:10:34 - INFO - Epoch: 37.61, Step: 148970, Train Loss: 1.1216, Learning Rate: 6.29e-06
2025-12-11 00:10:45 - INFO - Epoch: 37.61, Step: 148980, Train Loss: 1.1452, Learning Rate: 6.29e-06
2025-12-11 00:10:56 - INFO - Epoch: 37.61, Step: 148990, Train Loss: 1.1141, Learning Rate: 6.28e-06
2025-12-11 00:11:07 - INFO - Epoch: 37.62, Step: 149000, Train Loss: 1.1345, Learning Rate: 6.27e-06
2025-12-11 00:11:18 - INFO - Epoch: 37.62, Step: 149010, Train Loss: 1.1311, Learning Rate: 6.27e-06
2025-12-11 00:11:29 - INFO - Epoch: 37.62, Step: 149020, Train Loss: 1.1254, Learning Rate: 6.26e-06
2025-12-11 00:11:41 - INFO - Epoch: 37.62, Step: 149030, Train Loss: 1.1364, Learning Rate: 6.25e-06
2025-12-11 00:11:52 - INFO - Epoch: 37.63, Step: 149040, Train Loss: 1.1468, Learning Rate: 6.25e-06
2025-12-11 00:12:03 - INFO - Epoch: 37.63, Step: 149050, Train Loss: 1.1121, Learning Rate: 6.24e-06
2025-12-11 00:12:14 - INFO - Epoch: 37.63, Step: 149060, Train Loss: 1.1172, Learning Rate: 6.23e-06
2025-12-11 00:12:25 - INFO - Epoch: 37.63, Step: 149070, Train Loss: 1.1087, Learning Rate: 6.23e-06
2025-12-11 00:12:36 - INFO - Epoch: 37.64, Step: 149080, Train Loss: 1.1620, Learning Rate: 6.22e-06
2025-12-11 00:12:47 - INFO - Epoch: 37.64, Step: 149090, Train Loss: 1.1339, Learning Rate: 6.21e-06
2025-12-11 00:12:59 - INFO - Epoch: 37.64, Step: 149100, Train Loss: 1.1591, Learning Rate: 6.21e-06
2025-12-11 00:13:10 - INFO - Epoch: 37.64, Step: 149110, Train Loss: 1.1440, Learning Rate: 6.20e-06
2025-12-11 00:13:21 - INFO - Epoch: 37.65, Step: 149120, Train Loss: 1.1535, Learning Rate: 6.19e-06
2025-12-11 00:13:32 - INFO - Epoch: 37.65, Step: 149130, Train Loss: 1.1342, Learning Rate: 6.19e-06
2025-12-11 00:13:43 - INFO - Epoch: 37.65, Step: 149140, Train Loss: 1.1755, Learning Rate: 6.18e-06
2025-12-11 00:13:54 - INFO - Epoch: 37.65, Step: 149150, Train Loss: 1.1031, Learning Rate: 6.17e-06
2025-12-11 00:14:05 - INFO - Epoch: 37.66, Step: 149160, Train Loss: 1.1363, Learning Rate: 6.17e-06
2025-12-11 00:14:17 - INFO - Epoch: 37.66, Step: 149170, Train Loss: 1.1686, Learning Rate: 6.16e-06
2025-12-11 00:14:28 - INFO - Epoch: 37.66, Step: 149180, Train Loss: 1.1398, Learning Rate: 6.15e-06
2025-12-11 00:14:39 - INFO - Epoch: 37.66, Step: 149190, Train Loss: 1.1234, Learning Rate: 6.15e-06
2025-12-11 00:14:50 - INFO - Epoch: 37.67, Step: 149200, Train Loss: 1.1097, Learning Rate: 6.14e-06
2025-12-11 00:15:01 - INFO - Epoch: 37.67, Step: 149210, Train Loss: 1.1307, Learning Rate: 6.13e-06
2025-12-11 00:15:12 - INFO - Epoch: 37.67, Step: 149220, Train Loss: 1.0860, Learning Rate: 6.13e-06
2025-12-11 00:15:23 - INFO - Epoch: 37.67, Step: 149230, Train Loss: 1.1139, Learning Rate: 6.12e-06
2025-12-11 00:15:35 - INFO - Epoch: 37.68, Step: 149240, Train Loss: 1.1579, Learning Rate: 6.11e-06
2025-12-11 00:15:46 - INFO - Epoch: 37.68, Step: 149250, Train Loss: 1.1548, Learning Rate: 6.11e-06
2025-12-11 00:15:57 - INFO - Epoch: 37.68, Step: 149260, Train Loss: 1.1187, Learning Rate: 6.10e-06
2025-12-11 00:16:08 - INFO - Epoch: 37.68, Step: 149270, Train Loss: 1.1122, Learning Rate: 6.09e-06
2025-12-11 00:16:19 - INFO - Epoch: 37.69, Step: 149280, Train Loss: 1.1561, Learning Rate: 6.09e-06
2025-12-11 00:16:30 - INFO - Epoch: 37.69, Step: 149290, Train Loss: 1.1291, Learning Rate: 6.08e-06
2025-12-11 00:16:41 - INFO - Epoch: 37.69, Step: 149300, Train Loss: 1.1554, Learning Rate: 6.07e-06
2025-12-11 00:16:53 - INFO - Epoch: 37.70, Step: 149310, Train Loss: 1.1227, Learning Rate: 6.07e-06
2025-12-11 00:17:04 - INFO - Epoch: 37.70, Step: 149320, Train Loss: 1.1659, Learning Rate: 6.06e-06
2025-12-11 00:17:15 - INFO - Epoch: 37.70, Step: 149330, Train Loss: 1.1325, Learning Rate: 6.05e-06
2025-12-11 00:17:26 - INFO - Epoch: 37.70, Step: 149340, Train Loss: 1.1626, Learning Rate: 6.05e-06
2025-12-11 00:17:37 - INFO - Epoch: 37.71, Step: 149350, Train Loss: 1.1404, Learning Rate: 6.04e-06
2025-12-11 00:17:48 - INFO - Epoch: 37.71, Step: 149360, Train Loss: 1.1449, Learning Rate: 6.03e-06
2025-12-11 00:18:00 - INFO - Epoch: 37.71, Step: 149370, Train Loss: 1.1809, Learning Rate: 6.03e-06
2025-12-11 00:18:11 - INFO - Epoch: 37.71, Step: 149380, Train Loss: 1.1333, Learning Rate: 6.02e-06
2025-12-11 00:18:22 - INFO - Epoch: 37.72, Step: 149390, Train Loss: 1.1514, Learning Rate: 6.01e-06
2025-12-11 00:18:33 - INFO - Epoch: 37.72, Step: 149400, Train Loss: 1.1529, Learning Rate: 6.01e-06
2025-12-11 00:18:44 - INFO - Epoch: 37.72, Step: 149410, Train Loss: 1.1332, Learning Rate: 6.00e-06
2025-12-11 00:18:55 - INFO - Epoch: 37.72, Step: 149420, Train Loss: 1.1263, Learning Rate: 5.99e-06
2025-12-11 00:19:06 - INFO - Epoch: 37.73, Step: 149430, Train Loss: 1.1341, Learning Rate: 5.99e-06
2025-12-11 00:19:18 - INFO - Epoch: 37.73, Step: 149440, Train Loss: 1.1684, Learning Rate: 5.98e-06
2025-12-11 00:19:29 - INFO - Epoch: 37.73, Step: 149450, Train Loss: 1.1434, Learning Rate: 5.97e-06
2025-12-11 00:19:40 - INFO - Epoch: 37.73, Step: 149460, Train Loss: 1.1501, Learning Rate: 5.97e-06
2025-12-11 00:19:51 - INFO - Epoch: 37.74, Step: 149470, Train Loss: 1.0976, Learning Rate: 5.96e-06
2025-12-11 00:20:02 - INFO - Epoch: 37.74, Step: 149480, Train Loss: 1.1491, Learning Rate: 5.95e-06
2025-12-11 00:20:13 - INFO - Epoch: 37.74, Step: 149490, Train Loss: 1.1615, Learning Rate: 5.95e-06
2025-12-11 00:20:24 - INFO - Epoch: 37.74, Step: 149500, Train Loss: 1.1240, Learning Rate: 5.94e-06
2025-12-11 00:20:36 - INFO - Epoch: 37.75, Step: 149510, Train Loss: 1.1204, Learning Rate: 5.93e-06
2025-12-11 00:20:47 - INFO - Epoch: 37.75, Step: 149520, Train Loss: 1.1345, Learning Rate: 5.93e-06
2025-12-11 00:20:58 - INFO - Epoch: 37.75, Step: 149530, Train Loss: 1.1363, Learning Rate: 5.92e-06
2025-12-11 00:21:09 - INFO - Epoch: 37.75, Step: 149540, Train Loss: 1.1453, Learning Rate: 5.91e-06
2025-12-11 00:21:20 - INFO - Epoch: 37.76, Step: 149550, Train Loss: 1.1691, Learning Rate: 5.91e-06
2025-12-11 00:21:31 - INFO - Epoch: 37.76, Step: 149560, Train Loss: 1.1422, Learning Rate: 5.90e-06
2025-12-11 00:21:42 - INFO - Epoch: 37.76, Step: 149570, Train Loss: 1.1376, Learning Rate: 5.89e-06
2025-12-11 00:21:54 - INFO - Epoch: 37.76, Step: 149580, Train Loss: 1.1453, Learning Rate: 5.89e-06
2025-12-11 00:22:05 - INFO - Epoch: 37.77, Step: 149590, Train Loss: 1.0965, Learning Rate: 5.88e-06
2025-12-11 00:22:16 - INFO - Epoch: 37.77, Step: 149600, Train Loss: 1.1235, Learning Rate: 5.87e-06
2025-12-11 00:22:27 - INFO - Epoch: 37.77, Step: 149610, Train Loss: 1.1450, Learning Rate: 5.87e-06
2025-12-11 00:22:38 - INFO - Epoch: 37.77, Step: 149620, Train Loss: 1.1399, Learning Rate: 5.86e-06
2025-12-11 00:22:49 - INFO - Epoch: 37.78, Step: 149630, Train Loss: 1.1450, Learning Rate: 5.85e-06
2025-12-11 00:23:00 - INFO - Epoch: 37.78, Step: 149640, Train Loss: 1.1293, Learning Rate: 5.85e-06
2025-12-11 00:23:12 - INFO - Epoch: 37.78, Step: 149650, Train Loss: 1.1162, Learning Rate: 5.84e-06
2025-12-11 00:23:23 - INFO - Epoch: 37.78, Step: 149660, Train Loss: 1.1388, Learning Rate: 5.83e-06
2025-12-11 00:23:34 - INFO - Epoch: 37.79, Step: 149670, Train Loss: 1.1280, Learning Rate: 5.83e-06
2025-12-11 00:23:45 - INFO - Epoch: 37.79, Step: 149680, Train Loss: 1.1299, Learning Rate: 5.82e-06
2025-12-11 00:23:56 - INFO - Epoch: 37.79, Step: 149690, Train Loss: 1.1813, Learning Rate: 5.81e-06
2025-12-11 00:24:07 - INFO - Epoch: 37.79, Step: 149700, Train Loss: 1.1157, Learning Rate: 5.81e-06
2025-12-11 00:24:19 - INFO - Epoch: 37.80, Step: 149710, Train Loss: 1.1075, Learning Rate: 5.80e-06
2025-12-11 00:24:30 - INFO - Epoch: 37.80, Step: 149720, Train Loss: 1.1650, Learning Rate: 5.79e-06
2025-12-11 00:24:41 - INFO - Epoch: 37.80, Step: 149730, Train Loss: 1.1071, Learning Rate: 5.79e-06
2025-12-11 00:24:52 - INFO - Epoch: 37.80, Step: 149740, Train Loss: 1.1421, Learning Rate: 5.78e-06
2025-12-11 00:25:03 - INFO - Epoch: 37.81, Step: 149750, Train Loss: 1.1187, Learning Rate: 5.77e-06
2025-12-11 00:25:14 - INFO - Epoch: 37.81, Step: 149760, Train Loss: 1.1745, Learning Rate: 5.77e-06
2025-12-11 00:25:25 - INFO - Epoch: 37.81, Step: 149770, Train Loss: 1.1198, Learning Rate: 5.76e-06
2025-12-11 00:25:37 - INFO - Epoch: 37.81, Step: 149780, Train Loss: 1.1335, Learning Rate: 5.75e-06
2025-12-11 00:25:48 - INFO - Epoch: 37.82, Step: 149790, Train Loss: 1.1284, Learning Rate: 5.75e-06
2025-12-11 00:25:59 - INFO - Epoch: 37.82, Step: 149800, Train Loss: 1.1405, Learning Rate: 5.74e-06
2025-12-11 00:26:10 - INFO - Epoch: 37.82, Step: 149810, Train Loss: 1.1331, Learning Rate: 5.73e-06
2025-12-11 00:26:21 - INFO - Epoch: 37.82, Step: 149820, Train Loss: 1.1514, Learning Rate: 5.73e-06
2025-12-11 00:26:32 - INFO - Epoch: 37.83, Step: 149830, Train Loss: 1.1564, Learning Rate: 5.72e-06
2025-12-11 00:26:43 - INFO - Epoch: 37.83, Step: 149840, Train Loss: 1.1339, Learning Rate: 5.71e-06
2025-12-11 00:26:55 - INFO - Epoch: 37.83, Step: 149850, Train Loss: 1.1541, Learning Rate: 5.71e-06
2025-12-11 00:27:06 - INFO - Epoch: 37.83, Step: 149860, Train Loss: 1.1107, Learning Rate: 5.70e-06
2025-12-11 00:27:17 - INFO - Epoch: 37.84, Step: 149870, Train Loss: 1.1667, Learning Rate: 5.69e-06
2025-12-11 00:27:28 - INFO - Epoch: 37.84, Step: 149880, Train Loss: 1.1499, Learning Rate: 5.69e-06
2025-12-11 00:27:39 - INFO - Epoch: 37.84, Step: 149890, Train Loss: 1.1608, Learning Rate: 5.68e-06
2025-12-11 00:27:50 - INFO - Epoch: 37.84, Step: 149900, Train Loss: 1.1388, Learning Rate: 5.67e-06
2025-12-11 00:28:01 - INFO - Epoch: 37.85, Step: 149910, Train Loss: 1.1488, Learning Rate: 5.67e-06
2025-12-11 00:28:13 - INFO - Epoch: 37.85, Step: 149920, Train Loss: 1.1210, Learning Rate: 5.66e-06
2025-12-11 00:28:24 - INFO - Epoch: 37.85, Step: 149930, Train Loss: 1.1122, Learning Rate: 5.65e-06
2025-12-11 00:28:35 - INFO - Epoch: 37.85, Step: 149940, Train Loss: 1.1352, Learning Rate: 5.65e-06
2025-12-11 00:28:46 - INFO - Epoch: 37.86, Step: 149950, Train Loss: 1.1097, Learning Rate: 5.64e-06
2025-12-11 00:28:57 - INFO - Epoch: 37.86, Step: 149960, Train Loss: 1.1514, Learning Rate: 5.63e-06
2025-12-11 00:29:08 - INFO - Epoch: 37.86, Step: 149970, Train Loss: 1.1515, Learning Rate: 5.63e-06
2025-12-11 00:29:19 - INFO - Epoch: 37.86, Step: 149980, Train Loss: 1.1320, Learning Rate: 5.62e-06
2025-12-11 00:29:31 - INFO - Epoch: 37.87, Step: 149990, Train Loss: 1.1252, Learning Rate: 5.61e-06
2025-12-11 00:29:42 - INFO - Epoch: 37.87, Step: 150000, Train Loss: 1.1241, Learning Rate: 5.61e-06
2025-12-11 00:29:53 - INFO - Epoch: 37.87, Step: 150010, Train Loss: 1.1478, Learning Rate: 5.60e-06
2025-12-11 00:30:04 - INFO - Epoch: 37.87, Step: 150020, Train Loss: 1.1043, Learning Rate: 5.59e-06
2025-12-11 00:30:15 - INFO - Epoch: 37.88, Step: 150030, Train Loss: 1.1329, Learning Rate: 5.59e-06
2025-12-11 00:30:26 - INFO - Epoch: 37.88, Step: 150040, Train Loss: 1.1718, Learning Rate: 5.58e-06
2025-12-11 00:30:37 - INFO - Epoch: 37.88, Step: 150050, Train Loss: 1.1529, Learning Rate: 5.57e-06
2025-12-11 00:30:49 - INFO - Epoch: 37.88, Step: 150060, Train Loss: 1.1221, Learning Rate: 5.57e-06
2025-12-11 00:31:00 - INFO - Epoch: 37.89, Step: 150070, Train Loss: 1.1531, Learning Rate: 5.56e-06
2025-12-11 00:31:11 - INFO - Epoch: 37.89, Step: 150080, Train Loss: 1.1073, Learning Rate: 5.55e-06
2025-12-11 00:31:22 - INFO - Epoch: 37.89, Step: 150090, Train Loss: 1.1508, Learning Rate: 5.55e-06
2025-12-11 00:31:33 - INFO - Epoch: 37.89, Step: 150100, Train Loss: 1.1332, Learning Rate: 5.54e-06
2025-12-11 00:31:44 - INFO - Epoch: 37.90, Step: 150110, Train Loss: 1.1270, Learning Rate: 5.53e-06
2025-12-11 00:31:56 - INFO - Epoch: 37.90, Step: 150120, Train Loss: 1.1560, Learning Rate: 5.53e-06
2025-12-11 00:32:07 - INFO - Epoch: 37.90, Step: 150130, Train Loss: 1.1528, Learning Rate: 5.52e-06
2025-12-11 00:32:18 - INFO - Epoch: 37.90, Step: 150140, Train Loss: 1.1561, Learning Rate: 5.51e-06
2025-12-11 00:32:29 - INFO - Epoch: 37.91, Step: 150150, Train Loss: 1.1591, Learning Rate: 5.51e-06
2025-12-11 00:32:40 - INFO - Epoch: 37.91, Step: 150160, Train Loss: 1.0852, Learning Rate: 5.50e-06
2025-12-11 00:32:51 - INFO - Epoch: 37.91, Step: 150170, Train Loss: 1.1580, Learning Rate: 5.50e-06
2025-12-11 00:33:02 - INFO - Epoch: 37.91, Step: 150180, Train Loss: 1.1159, Learning Rate: 5.49e-06
2025-12-11 00:33:14 - INFO - Epoch: 37.92, Step: 150190, Train Loss: 1.1497, Learning Rate: 5.48e-06
2025-12-11 00:33:25 - INFO - Epoch: 37.92, Step: 150200, Train Loss: 1.1396, Learning Rate: 5.48e-06
2025-12-11 00:33:36 - INFO - Epoch: 37.92, Step: 150210, Train Loss: 1.1600, Learning Rate: 5.47e-06
2025-12-11 00:33:47 - INFO - Epoch: 37.92, Step: 150220, Train Loss: 1.1147, Learning Rate: 5.46e-06
2025-12-11 00:33:58 - INFO - Epoch: 37.93, Step: 150230, Train Loss: 1.1184, Learning Rate: 5.46e-06
2025-12-11 00:34:09 - INFO - Epoch: 37.93, Step: 150240, Train Loss: 1.1757, Learning Rate: 5.45e-06
2025-12-11 00:34:20 - INFO - Epoch: 37.93, Step: 150250, Train Loss: 1.1432, Learning Rate: 5.44e-06
2025-12-11 00:34:32 - INFO - Epoch: 37.93, Step: 150260, Train Loss: 1.0857, Learning Rate: 5.44e-06
2025-12-11 00:34:43 - INFO - Epoch: 37.94, Step: 150270, Train Loss: 1.1200, Learning Rate: 5.43e-06
2025-12-11 00:34:54 - INFO - Epoch: 37.94, Step: 150280, Train Loss: 1.1362, Learning Rate: 5.42e-06
2025-12-11 00:35:05 - INFO - Epoch: 37.94, Step: 150290, Train Loss: 1.1426, Learning Rate: 5.42e-06
2025-12-11 00:35:16 - INFO - Epoch: 37.94, Step: 150300, Train Loss: 1.1405, Learning Rate: 5.41e-06
2025-12-11 00:35:27 - INFO - Epoch: 37.95, Step: 150310, Train Loss: 1.1532, Learning Rate: 5.40e-06
2025-12-11 00:35:38 - INFO - Epoch: 37.95, Step: 150320, Train Loss: 1.1458, Learning Rate: 5.40e-06
2025-12-11 00:35:50 - INFO - Epoch: 37.95, Step: 150330, Train Loss: 1.1146, Learning Rate: 5.39e-06
2025-12-11 00:36:01 - INFO - Epoch: 37.96, Step: 150340, Train Loss: 1.1256, Learning Rate: 5.38e-06
2025-12-11 00:36:12 - INFO - Epoch: 37.96, Step: 150350, Train Loss: 1.1199, Learning Rate: 5.38e-06
2025-12-11 00:36:23 - INFO - Epoch: 37.96, Step: 150360, Train Loss: 1.1506, Learning Rate: 5.37e-06
2025-12-11 00:36:34 - INFO - Epoch: 37.96, Step: 150370, Train Loss: 1.1425, Learning Rate: 5.36e-06
2025-12-11 00:36:45 - INFO - Epoch: 37.97, Step: 150380, Train Loss: 1.1389, Learning Rate: 5.36e-06
2025-12-11 00:36:56 - INFO - Epoch: 37.97, Step: 150390, Train Loss: 1.1646, Learning Rate: 5.35e-06
2025-12-11 00:37:08 - INFO - Epoch: 37.97, Step: 150400, Train Loss: 1.1411, Learning Rate: 5.34e-06
2025-12-11 00:37:19 - INFO - Epoch: 37.97, Step: 150410, Train Loss: 1.1346, Learning Rate: 5.34e-06
2025-12-11 00:37:30 - INFO - Epoch: 37.98, Step: 150420, Train Loss: 1.1222, Learning Rate: 5.33e-06
2025-12-11 00:37:41 - INFO - Epoch: 37.98, Step: 150430, Train Loss: 1.1268, Learning Rate: 5.32e-06
2025-12-11 00:37:52 - INFO - Epoch: 37.98, Step: 150440, Train Loss: 1.1185, Learning Rate: 5.32e-06
2025-12-11 00:38:03 - INFO - Epoch: 37.98, Step: 150450, Train Loss: 1.1574, Learning Rate: 5.31e-06
2025-12-11 00:38:15 - INFO - Epoch: 37.99, Step: 150460, Train Loss: 1.1119, Learning Rate: 5.30e-06
2025-12-11 00:38:26 - INFO - Epoch: 37.99, Step: 150470, Train Loss: 1.1689, Learning Rate: 5.30e-06
2025-12-11 00:38:37 - INFO - Epoch: 37.99, Step: 150480, Train Loss: 1.1331, Learning Rate: 5.29e-06
2025-12-11 00:38:48 - INFO - Epoch: 37.99, Step: 150490, Train Loss: 1.1529, Learning Rate: 5.28e-06
2025-12-11 00:38:59 - INFO - Epoch: 38.00, Step: 150500, Train Loss: 1.1287, Learning Rate: 5.28e-06
2025-12-11 00:39:10 - INFO - Epoch: 38.00, Step: 150510, Train Loss: 1.1309, Learning Rate: 5.27e-06
2025-12-11 00:39:21 - INFO - Epoch: 38.00, Step: 150520, Train Loss: 1.1593, Learning Rate: 5.26e-06
2025-12-11 00:39:33 - INFO - Epoch: 38.00, Step: 150530, Train Loss: 1.1295, Learning Rate: 5.26e-06
2025-12-11 00:39:44 - INFO - Epoch: 38.01, Step: 150540, Train Loss: 1.0928, Learning Rate: 5.25e-06
2025-12-11 00:39:55 - INFO - Epoch: 38.01, Step: 150550, Train Loss: 1.1342, Learning Rate: 5.24e-06
2025-12-11 00:40:06 - INFO - Epoch: 38.01, Step: 150560, Train Loss: 1.1329, Learning Rate: 5.24e-06
2025-12-11 00:40:17 - INFO - Epoch: 38.01, Step: 150570, Train Loss: 1.1405, Learning Rate: 5.23e-06
2025-12-11 00:40:28 - INFO - Epoch: 38.02, Step: 150580, Train Loss: 1.0916, Learning Rate: 5.22e-06
2025-12-11 00:40:39 - INFO - Epoch: 38.02, Step: 150590, Train Loss: 1.1404, Learning Rate: 5.22e-06
2025-12-11 00:40:51 - INFO - Epoch: 38.02, Step: 150600, Train Loss: 1.1045, Learning Rate: 5.21e-06
2025-12-11 00:41:02 - INFO - Epoch: 38.02, Step: 150610, Train Loss: 1.1496, Learning Rate: 5.20e-06
2025-12-11 00:41:13 - INFO - Epoch: 38.03, Step: 150620, Train Loss: 1.1606, Learning Rate: 5.20e-06
2025-12-11 00:41:24 - INFO - Epoch: 38.03, Step: 150630, Train Loss: 1.1423, Learning Rate: 5.19e-06
2025-12-11 00:41:35 - INFO - Epoch: 38.03, Step: 150640, Train Loss: 1.1577, Learning Rate: 5.18e-06
2025-12-11 00:41:46 - INFO - Epoch: 38.03, Step: 150650, Train Loss: 1.1295, Learning Rate: 5.18e-06
2025-12-11 00:41:58 - INFO - Epoch: 38.04, Step: 150660, Train Loss: 1.1274, Learning Rate: 5.17e-06
2025-12-11 00:42:09 - INFO - Epoch: 38.04, Step: 150670, Train Loss: 1.1015, Learning Rate: 5.16e-06
2025-12-11 00:42:20 - INFO - Epoch: 38.04, Step: 150680, Train Loss: 1.1537, Learning Rate: 5.16e-06
2025-12-11 00:42:31 - INFO - Epoch: 38.04, Step: 150690, Train Loss: 1.1197, Learning Rate: 5.15e-06
2025-12-11 00:42:42 - INFO - Epoch: 38.05, Step: 150700, Train Loss: 1.1772, Learning Rate: 5.14e-06
2025-12-11 00:42:53 - INFO - Epoch: 38.05, Step: 150710, Train Loss: 1.1308, Learning Rate: 5.14e-06
2025-12-11 00:43:04 - INFO - Epoch: 38.05, Step: 150720, Train Loss: 1.1412, Learning Rate: 5.13e-06
2025-12-11 00:43:16 - INFO - Epoch: 38.05, Step: 150730, Train Loss: 1.1775, Learning Rate: 5.12e-06
2025-12-11 00:43:27 - INFO - Epoch: 38.06, Step: 150740, Train Loss: 1.1301, Learning Rate: 5.12e-06
2025-12-11 00:43:38 - INFO - Epoch: 38.06, Step: 150750, Train Loss: 1.1538, Learning Rate: 5.11e-06
2025-12-11 00:43:49 - INFO - Epoch: 38.06, Step: 150760, Train Loss: 1.1430, Learning Rate: 5.10e-06
2025-12-11 00:44:00 - INFO - Epoch: 38.06, Step: 150770, Train Loss: 1.1302, Learning Rate: 5.10e-06
2025-12-11 00:44:11 - INFO - Epoch: 38.07, Step: 150780, Train Loss: 1.1458, Learning Rate: 5.09e-06
2025-12-11 00:44:22 - INFO - Epoch: 38.07, Step: 150790, Train Loss: 1.1456, Learning Rate: 5.08e-06
2025-12-11 00:44:34 - INFO - Epoch: 38.07, Step: 150800, Train Loss: 1.1776, Learning Rate: 5.08e-06
2025-12-11 00:44:45 - INFO - Epoch: 38.07, Step: 150810, Train Loss: 1.1490, Learning Rate: 5.07e-06
2025-12-11 00:44:56 - INFO - Epoch: 38.08, Step: 150820, Train Loss: 1.1396, Learning Rate: 5.06e-06
2025-12-11 00:45:07 - INFO - Epoch: 38.08, Step: 150830, Train Loss: 1.1340, Learning Rate: 5.06e-06
2025-12-11 00:45:18 - INFO - Epoch: 38.08, Step: 150840, Train Loss: 1.1418, Learning Rate: 5.05e-06
2025-12-11 00:45:29 - INFO - Epoch: 38.08, Step: 150850, Train Loss: 1.1185, Learning Rate: 5.04e-06
2025-12-11 00:45:41 - INFO - Epoch: 38.09, Step: 150860, Train Loss: 1.1373, Learning Rate: 5.04e-06
2025-12-11 00:45:52 - INFO - Epoch: 38.09, Step: 150870, Train Loss: 1.1396, Learning Rate: 5.03e-06
2025-12-11 00:46:03 - INFO - Epoch: 38.09, Step: 150880, Train Loss: 1.1369, Learning Rate: 5.02e-06
2025-12-11 00:46:14 - INFO - Epoch: 38.09, Step: 150890, Train Loss: 1.1620, Learning Rate: 5.02e-06
2025-12-11 00:46:25 - INFO - Epoch: 38.10, Step: 150900, Train Loss: 1.1556, Learning Rate: 5.01e-06
2025-12-11 00:46:36 - INFO - Epoch: 38.10, Step: 150910, Train Loss: 1.1355, Learning Rate: 5.00e-06
2025-12-11 00:46:47 - INFO - Epoch: 38.10, Step: 150920, Train Loss: 1.1616, Learning Rate: 5.00e-06
2025-12-11 00:46:59 - INFO - Epoch: 38.10, Step: 150930, Train Loss: 1.1362, Learning Rate: 4.99e-06
2025-12-11 00:47:10 - INFO - Epoch: 38.11, Step: 150940, Train Loss: 1.1540, Learning Rate: 4.98e-06
2025-12-11 00:47:21 - INFO - Epoch: 38.11, Step: 150950, Train Loss: 1.0966, Learning Rate: 4.98e-06
2025-12-11 00:47:32 - INFO - Epoch: 38.11, Step: 150960, Train Loss: 1.1115, Learning Rate: 4.97e-06
2025-12-11 00:47:43 - INFO - Epoch: 38.11, Step: 150970, Train Loss: 1.1388, Learning Rate: 4.96e-06
2025-12-11 00:47:54 - INFO - Epoch: 38.12, Step: 150980, Train Loss: 1.1567, Learning Rate: 4.96e-06
2025-12-11 00:48:05 - INFO - Epoch: 38.12, Step: 150990, Train Loss: 1.1135, Learning Rate: 4.95e-06
2025-12-11 00:48:17 - INFO - Epoch: 38.12, Step: 151000, Train Loss: 1.1649, Learning Rate: 4.94e-06
2025-12-11 00:48:28 - INFO - Epoch: 38.12, Step: 151010, Train Loss: 1.1495, Learning Rate: 4.94e-06
2025-12-11 00:48:39 - INFO - Epoch: 38.13, Step: 151020, Train Loss: 1.1274, Learning Rate: 4.93e-06
2025-12-11 00:48:50 - INFO - Epoch: 38.13, Step: 151030, Train Loss: 1.1022, Learning Rate: 4.92e-06
2025-12-11 00:49:01 - INFO - Epoch: 38.13, Step: 151040, Train Loss: 1.1090, Learning Rate: 4.92e-06
2025-12-11 00:49:12 - INFO - Epoch: 38.13, Step: 151050, Train Loss: 1.1437, Learning Rate: 4.91e-06
2025-12-11 00:49:24 - INFO - Epoch: 38.14, Step: 151060, Train Loss: 1.1307, Learning Rate: 4.90e-06
2025-12-11 00:49:35 - INFO - Epoch: 38.14, Step: 151070, Train Loss: 1.1456, Learning Rate: 4.90e-06
2025-12-11 00:49:46 - INFO - Epoch: 38.14, Step: 151080, Train Loss: 1.1709, Learning Rate: 4.89e-06
2025-12-11 00:49:57 - INFO - Epoch: 38.14, Step: 151090, Train Loss: 1.1390, Learning Rate: 4.88e-06
2025-12-11 00:50:08 - INFO - Epoch: 38.15, Step: 151100, Train Loss: 1.1388, Learning Rate: 4.88e-06
2025-12-11 00:50:19 - INFO - Epoch: 38.15, Step: 151110, Train Loss: 1.1185, Learning Rate: 4.87e-06
2025-12-11 00:50:30 - INFO - Epoch: 38.15, Step: 151120, Train Loss: 1.1101, Learning Rate: 4.86e-06
2025-12-11 00:50:42 - INFO - Epoch: 38.15, Step: 151130, Train Loss: 1.1460, Learning Rate: 4.86e-06
2025-12-11 00:50:53 - INFO - Epoch: 38.16, Step: 151140, Train Loss: 1.1668, Learning Rate: 4.85e-06
2025-12-11 00:51:04 - INFO - Epoch: 38.16, Step: 151150, Train Loss: 1.1367, Learning Rate: 4.84e-06
2025-12-11 00:51:15 - INFO - Epoch: 38.16, Step: 151160, Train Loss: 1.1436, Learning Rate: 4.84e-06
2025-12-11 00:51:26 - INFO - Epoch: 38.16, Step: 151170, Train Loss: 1.1392, Learning Rate: 4.83e-06
2025-12-11 00:51:37 - INFO - Epoch: 38.17, Step: 151180, Train Loss: 1.1039, Learning Rate: 4.82e-06
2025-12-11 00:51:49 - INFO - Epoch: 38.17, Step: 151190, Train Loss: 1.1188, Learning Rate: 4.82e-06
2025-12-11 00:52:00 - INFO - Epoch: 38.17, Step: 151200, Train Loss: 1.1442, Learning Rate: 4.81e-06
2025-12-11 00:52:11 - INFO - Epoch: 38.17, Step: 151210, Train Loss: 1.1132, Learning Rate: 4.80e-06
2025-12-11 00:52:22 - INFO - Epoch: 38.18, Step: 151220, Train Loss: 1.1143, Learning Rate: 4.80e-06
2025-12-11 00:52:33 - INFO - Epoch: 38.18, Step: 151230, Train Loss: 1.1232, Learning Rate: 4.79e-06
2025-12-11 00:52:44 - INFO - Epoch: 38.18, Step: 151240, Train Loss: 1.1529, Learning Rate: 4.78e-06
2025-12-11 00:52:55 - INFO - Epoch: 38.18, Step: 151250, Train Loss: 1.1384, Learning Rate: 4.78e-06
2025-12-11 00:53:07 - INFO - Epoch: 38.19, Step: 151260, Train Loss: 1.1035, Learning Rate: 4.77e-06
2025-12-11 00:53:18 - INFO - Epoch: 38.19, Step: 151270, Train Loss: 1.1385, Learning Rate: 4.76e-06
2025-12-11 00:53:29 - INFO - Epoch: 38.19, Step: 151280, Train Loss: 1.1400, Learning Rate: 4.76e-06
2025-12-11 00:53:40 - INFO - Epoch: 38.19, Step: 151290, Train Loss: 1.1192, Learning Rate: 4.75e-06
2025-12-11 00:53:51 - INFO - Epoch: 38.20, Step: 151300, Train Loss: 1.1674, Learning Rate: 4.74e-06
2025-12-11 00:54:02 - INFO - Epoch: 38.20, Step: 151310, Train Loss: 1.1168, Learning Rate: 4.74e-06
2025-12-11 00:54:13 - INFO - Epoch: 38.20, Step: 151320, Train Loss: 1.1350, Learning Rate: 4.73e-06
2025-12-11 00:54:25 - INFO - Epoch: 38.20, Step: 151330, Train Loss: 1.1459, Learning Rate: 4.72e-06
2025-12-11 00:54:36 - INFO - Epoch: 38.21, Step: 151340, Train Loss: 1.1228, Learning Rate: 4.72e-06
2025-12-11 00:54:47 - INFO - Epoch: 38.21, Step: 151350, Train Loss: 1.1597, Learning Rate: 4.71e-06
2025-12-11 00:54:58 - INFO - Epoch: 38.21, Step: 151360, Train Loss: 1.1468, Learning Rate: 4.70e-06
2025-12-11 00:55:09 - INFO - Epoch: 38.22, Step: 151370, Train Loss: 1.1519, Learning Rate: 4.70e-06
2025-12-11 00:55:20 - INFO - Epoch: 38.22, Step: 151380, Train Loss: 1.1121, Learning Rate: 4.69e-06
2025-12-11 00:55:32 - INFO - Epoch: 38.22, Step: 151390, Train Loss: 1.1437, Learning Rate: 4.68e-06
2025-12-11 00:55:43 - INFO - Epoch: 38.22, Step: 151400, Train Loss: 1.1732, Learning Rate: 4.68e-06
2025-12-11 00:55:54 - INFO - Epoch: 38.23, Step: 151410, Train Loss: 1.1174, Learning Rate: 4.67e-06
2025-12-11 00:56:05 - INFO - Epoch: 38.23, Step: 151420, Train Loss: 1.1642, Learning Rate: 4.66e-06
2025-12-11 00:56:16 - INFO - Epoch: 38.23, Step: 151430, Train Loss: 1.1139, Learning Rate: 4.66e-06
2025-12-11 00:56:27 - INFO - Epoch: 38.23, Step: 151440, Train Loss: 1.1300, Learning Rate: 4.65e-06
2025-12-11 00:56:38 - INFO - Epoch: 38.24, Step: 151450, Train Loss: 1.1229, Learning Rate: 4.64e-06
2025-12-11 00:56:50 - INFO - Epoch: 38.24, Step: 151460, Train Loss: 1.1255, Learning Rate: 4.64e-06
2025-12-11 00:57:01 - INFO - Epoch: 38.24, Step: 151470, Train Loss: 1.1246, Learning Rate: 4.63e-06
2025-12-11 00:57:12 - INFO - Epoch: 38.24, Step: 151480, Train Loss: 1.1726, Learning Rate: 4.62e-06
2025-12-11 00:57:23 - INFO - Epoch: 38.25, Step: 151490, Train Loss: 1.1575, Learning Rate: 4.62e-06
2025-12-11 00:57:34 - INFO - Epoch: 38.25, Step: 151500, Train Loss: 1.1149, Learning Rate: 4.61e-06
2025-12-11 00:57:45 - INFO - Epoch: 38.25, Step: 151510, Train Loss: 1.1148, Learning Rate: 4.60e-06
2025-12-11 00:57:56 - INFO - Epoch: 38.25, Step: 151520, Train Loss: 1.1142, Learning Rate: 4.60e-06
2025-12-11 00:58:08 - INFO - Epoch: 38.26, Step: 151530, Train Loss: 1.1474, Learning Rate: 4.59e-06
2025-12-11 00:58:19 - INFO - Epoch: 38.26, Step: 151540, Train Loss: 1.1553, Learning Rate: 4.58e-06
2025-12-11 00:58:30 - INFO - Epoch: 38.26, Step: 151550, Train Loss: 1.1278, Learning Rate: 4.58e-06
2025-12-11 00:58:41 - INFO - Epoch: 38.26, Step: 151560, Train Loss: 1.1830, Learning Rate: 4.57e-06
2025-12-11 00:58:52 - INFO - Epoch: 38.27, Step: 151570, Train Loss: 1.1239, Learning Rate: 4.56e-06
2025-12-11 00:59:03 - INFO - Epoch: 38.27, Step: 151580, Train Loss: 1.1317, Learning Rate: 4.56e-06
2025-12-11 00:59:15 - INFO - Epoch: 38.27, Step: 151590, Train Loss: 1.1498, Learning Rate: 4.55e-06
2025-12-11 00:59:26 - INFO - Epoch: 38.27, Step: 151600, Train Loss: 1.1388, Learning Rate: 4.54e-06
2025-12-11 00:59:37 - INFO - Epoch: 38.28, Step: 151610, Train Loss: 1.1624, Learning Rate: 4.54e-06
2025-12-11 00:59:48 - INFO - Epoch: 38.28, Step: 151620, Train Loss: 1.1282, Learning Rate: 4.53e-06
2025-12-11 00:59:59 - INFO - Epoch: 38.28, Step: 151630, Train Loss: 1.1054, Learning Rate: 4.53e-06
2025-12-11 01:00:10 - INFO - Epoch: 38.28, Step: 151640, Train Loss: 1.1495, Learning Rate: 4.52e-06
2025-12-11 01:00:21 - INFO - Epoch: 38.29, Step: 151650, Train Loss: 1.1195, Learning Rate: 4.51e-06
2025-12-11 01:00:33 - INFO - Epoch: 38.29, Step: 151660, Train Loss: 1.1401, Learning Rate: 4.51e-06
2025-12-11 01:00:44 - INFO - Epoch: 38.29, Step: 151670, Train Loss: 1.1242, Learning Rate: 4.50e-06
2025-12-11 01:00:55 - INFO - Epoch: 38.29, Step: 151680, Train Loss: 1.1239, Learning Rate: 4.49e-06
2025-12-11 01:01:06 - INFO - Epoch: 38.30, Step: 151690, Train Loss: 1.1323, Learning Rate: 4.49e-06
2025-12-11 01:01:17 - INFO - Epoch: 38.30, Step: 151700, Train Loss: 1.1388, Learning Rate: 4.48e-06
2025-12-11 01:01:28 - INFO - Epoch: 38.30, Step: 151710, Train Loss: 1.0738, Learning Rate: 4.47e-06
2025-12-11 01:01:40 - INFO - Epoch: 38.30, Step: 151720, Train Loss: 1.1152, Learning Rate: 4.47e-06
2025-12-11 01:01:51 - INFO - Epoch: 38.31, Step: 151730, Train Loss: 1.1339, Learning Rate: 4.46e-06
2025-12-11 01:02:02 - INFO - Epoch: 38.31, Step: 151740, Train Loss: 1.1703, Learning Rate: 4.45e-06
2025-12-11 01:02:13 - INFO - Epoch: 38.31, Step: 151750, Train Loss: 1.1281, Learning Rate: 4.45e-06
2025-12-11 01:02:24 - INFO - Epoch: 38.31, Step: 151760, Train Loss: 1.1061, Learning Rate: 4.44e-06
2025-12-11 01:02:35 - INFO - Epoch: 38.32, Step: 151770, Train Loss: 1.1070, Learning Rate: 4.43e-06
2025-12-11 01:02:46 - INFO - Epoch: 38.32, Step: 151780, Train Loss: 1.1442, Learning Rate: 4.43e-06
2025-12-11 01:02:58 - INFO - Epoch: 38.32, Step: 151790, Train Loss: 1.1498, Learning Rate: 4.42e-06
2025-12-11 01:03:09 - INFO - Epoch: 38.32, Step: 151800, Train Loss: 1.0959, Learning Rate: 4.41e-06
2025-12-11 01:03:20 - INFO - Epoch: 38.33, Step: 151810, Train Loss: 1.1147, Learning Rate: 4.41e-06
2025-12-11 01:03:31 - INFO - Epoch: 38.33, Step: 151820, Train Loss: 1.1314, Learning Rate: 4.40e-06
2025-12-11 01:03:42 - INFO - Epoch: 38.33, Step: 151830, Train Loss: 1.1089, Learning Rate: 4.39e-06
2025-12-11 01:03:53 - INFO - Epoch: 38.33, Step: 151840, Train Loss: 1.1312, Learning Rate: 4.39e-06
2025-12-11 01:04:04 - INFO - Epoch: 38.34, Step: 151850, Train Loss: 1.1351, Learning Rate: 4.38e-06
2025-12-11 01:04:16 - INFO - Epoch: 38.34, Step: 151860, Train Loss: 1.1091, Learning Rate: 4.37e-06
2025-12-11 01:04:27 - INFO - Epoch: 38.34, Step: 151870, Train Loss: 1.1561, Learning Rate: 4.37e-06
2025-12-11 01:04:38 - INFO - Epoch: 38.34, Step: 151880, Train Loss: 1.1527, Learning Rate: 4.36e-06
2025-12-11 01:04:49 - INFO - Epoch: 38.35, Step: 151890, Train Loss: 1.1177, Learning Rate: 4.35e-06
2025-12-11 01:05:00 - INFO - Epoch: 38.35, Step: 151900, Train Loss: 1.1281, Learning Rate: 4.35e-06
2025-12-11 01:05:11 - INFO - Epoch: 38.35, Step: 151910, Train Loss: 1.1148, Learning Rate: 4.34e-06
2025-12-11 01:05:23 - INFO - Epoch: 38.35, Step: 151920, Train Loss: 1.1114, Learning Rate: 4.33e-06
2025-12-11 01:05:34 - INFO - Epoch: 38.36, Step: 151930, Train Loss: 1.1385, Learning Rate: 4.33e-06
2025-12-11 01:05:45 - INFO - Epoch: 38.36, Step: 151940, Train Loss: 1.1373, Learning Rate: 4.32e-06
2025-12-11 01:05:56 - INFO - Epoch: 38.36, Step: 151950, Train Loss: 1.0855, Learning Rate: 4.31e-06
2025-12-11 01:06:07 - INFO - Epoch: 38.36, Step: 151960, Train Loss: 1.1276, Learning Rate: 4.31e-06
2025-12-11 01:06:18 - INFO - Epoch: 38.37, Step: 151970, Train Loss: 1.1015, Learning Rate: 4.30e-06
2025-12-11 01:06:29 - INFO - Epoch: 38.37, Step: 151980, Train Loss: 1.1300, Learning Rate: 4.29e-06
2025-12-11 01:06:41 - INFO - Epoch: 38.37, Step: 151990, Train Loss: 1.1061, Learning Rate: 4.29e-06
2025-12-11 01:06:52 - INFO - Epoch: 38.37, Step: 152000, Train Loss: 1.1446, Learning Rate: 4.28e-06
2025-12-11 01:07:03 - INFO - Epoch: 38.38, Step: 152010, Train Loss: 1.0933, Learning Rate: 4.27e-06
2025-12-11 01:07:14 - INFO - Epoch: 38.38, Step: 152020, Train Loss: 1.1387, Learning Rate: 4.27e-06
2025-12-11 01:07:25 - INFO - Epoch: 38.38, Step: 152030, Train Loss: 1.1429, Learning Rate: 4.26e-06
2025-12-11 01:07:36 - INFO - Epoch: 38.38, Step: 152040, Train Loss: 1.1547, Learning Rate: 4.25e-06
2025-12-11 01:07:47 - INFO - Epoch: 38.39, Step: 152050, Train Loss: 1.1040, Learning Rate: 4.25e-06
2025-12-11 01:07:59 - INFO - Epoch: 38.39, Step: 152060, Train Loss: 1.1123, Learning Rate: 4.24e-06
2025-12-11 01:08:10 - INFO - Epoch: 38.39, Step: 152070, Train Loss: 1.1107, Learning Rate: 4.23e-06
2025-12-11 01:08:21 - INFO - Epoch: 38.39, Step: 152080, Train Loss: 1.1371, Learning Rate: 4.23e-06
2025-12-11 01:08:32 - INFO - Epoch: 38.40, Step: 152090, Train Loss: 1.0915, Learning Rate: 4.22e-06
2025-12-11 01:08:43 - INFO - Epoch: 38.40, Step: 152100, Train Loss: 1.1445, Learning Rate: 4.21e-06
2025-12-11 01:08:54 - INFO - Epoch: 38.40, Step: 152110, Train Loss: 1.1567, Learning Rate: 4.21e-06
2025-12-11 01:09:06 - INFO - Epoch: 38.40, Step: 152120, Train Loss: 1.1118, Learning Rate: 4.20e-06
2025-12-11 01:09:17 - INFO - Epoch: 38.41, Step: 152130, Train Loss: 1.1475, Learning Rate: 4.19e-06
2025-12-11 01:09:28 - INFO - Epoch: 38.41, Step: 152140, Train Loss: 1.1091, Learning Rate: 4.19e-06
2025-12-11 01:09:39 - INFO - Epoch: 38.41, Step: 152150, Train Loss: 1.1618, Learning Rate: 4.18e-06
2025-12-11 01:09:50 - INFO - Epoch: 38.41, Step: 152160, Train Loss: 1.1417, Learning Rate: 4.17e-06
2025-12-11 01:10:01 - INFO - Epoch: 38.42, Step: 152170, Train Loss: 1.1565, Learning Rate: 4.17e-06
2025-12-11 01:10:12 - INFO - Epoch: 38.42, Step: 152180, Train Loss: 1.1721, Learning Rate: 4.16e-06
2025-12-11 01:10:24 - INFO - Epoch: 38.42, Step: 152190, Train Loss: 1.1646, Learning Rate: 4.15e-06
2025-12-11 01:10:35 - INFO - Epoch: 38.42, Step: 152200, Train Loss: 1.1427, Learning Rate: 4.15e-06
2025-12-11 01:10:46 - INFO - Epoch: 38.43, Step: 152210, Train Loss: 1.1776, Learning Rate: 4.14e-06
2025-12-11 01:10:57 - INFO - Epoch: 38.43, Step: 152220, Train Loss: 1.1347, Learning Rate: 4.13e-06
2025-12-11 01:11:08 - INFO - Epoch: 38.43, Step: 152230, Train Loss: 1.1416, Learning Rate: 4.13e-06
2025-12-11 01:11:19 - INFO - Epoch: 38.43, Step: 152240, Train Loss: 1.1522, Learning Rate: 4.12e-06
2025-12-11 01:11:31 - INFO - Epoch: 38.44, Step: 152250, Train Loss: 1.1829, Learning Rate: 4.11e-06
2025-12-11 01:11:42 - INFO - Epoch: 38.44, Step: 152260, Train Loss: 1.1068, Learning Rate: 4.11e-06
2025-12-11 01:11:53 - INFO - Epoch: 38.44, Step: 152270, Train Loss: 1.1253, Learning Rate: 4.10e-06
2025-12-11 01:12:04 - INFO - Epoch: 38.44, Step: 152280, Train Loss: 1.1285, Learning Rate: 4.09e-06
2025-12-11 01:12:15 - INFO - Epoch: 38.45, Step: 152290, Train Loss: 1.1039, Learning Rate: 4.09e-06
2025-12-11 01:12:26 - INFO - Epoch: 38.45, Step: 152300, Train Loss: 1.1534, Learning Rate: 4.08e-06
2025-12-11 01:12:37 - INFO - Epoch: 38.45, Step: 152310, Train Loss: 1.1383, Learning Rate: 4.07e-06
2025-12-11 01:12:49 - INFO - Epoch: 38.45, Step: 152320, Train Loss: 1.1237, Learning Rate: 4.07e-06
2025-12-11 01:13:00 - INFO - Epoch: 38.46, Step: 152330, Train Loss: 1.1575, Learning Rate: 4.06e-06
2025-12-11 01:13:11 - INFO - Epoch: 38.46, Step: 152340, Train Loss: 1.1213, Learning Rate: 4.05e-06
2025-12-11 01:13:22 - INFO - Epoch: 38.46, Step: 152350, Train Loss: 1.1366, Learning Rate: 4.05e-06
2025-12-11 01:13:33 - INFO - Epoch: 38.47, Step: 152360, Train Loss: 1.1271, Learning Rate: 4.04e-06
2025-12-11 01:13:44 - INFO - Epoch: 38.47, Step: 152370, Train Loss: 1.1422, Learning Rate: 4.03e-06
2025-12-11 01:13:55 - INFO - Epoch: 38.47, Step: 152380, Train Loss: 1.1058, Learning Rate: 4.03e-06
2025-12-11 01:14:07 - INFO - Epoch: 38.47, Step: 152390, Train Loss: 1.1603, Learning Rate: 4.02e-06
2025-12-11 01:14:18 - INFO - Epoch: 38.48, Step: 152400, Train Loss: 1.1161, Learning Rate: 4.01e-06
2025-12-11 01:14:29 - INFO - Epoch: 38.48, Step: 152410, Train Loss: 1.1261, Learning Rate: 4.01e-06
2025-12-11 01:14:40 - INFO - Epoch: 38.48, Step: 152420, Train Loss: 1.1043, Learning Rate: 4.00e-06
2025-12-11 01:14:51 - INFO - Epoch: 38.48, Step: 152430, Train Loss: 1.1400, Learning Rate: 3.99e-06
2025-12-11 01:15:02 - INFO - Epoch: 38.49, Step: 152440, Train Loss: 1.1101, Learning Rate: 3.99e-06
2025-12-11 01:15:14 - INFO - Epoch: 38.49, Step: 152450, Train Loss: 1.1755, Learning Rate: 3.98e-06
2025-12-11 01:15:25 - INFO - Epoch: 38.49, Step: 152460, Train Loss: 1.1473, Learning Rate: 3.97e-06
2025-12-11 01:15:36 - INFO - Epoch: 38.49, Step: 152470, Train Loss: 1.1442, Learning Rate: 3.97e-06
2025-12-11 01:15:47 - INFO - Epoch: 38.50, Step: 152480, Train Loss: 1.1415, Learning Rate: 3.96e-06
2025-12-11 01:15:58 - INFO - Epoch: 38.50, Step: 152490, Train Loss: 1.1292, Learning Rate: 3.95e-06
2025-12-11 01:16:09 - INFO - Epoch: 38.50, Step: 152500, Train Loss: 1.1345, Learning Rate: 3.95e-06
2025-12-11 01:16:20 - INFO - Epoch: 38.50, Step: 152510, Train Loss: 1.1114, Learning Rate: 3.94e-06
2025-12-11 01:16:32 - INFO - Epoch: 38.51, Step: 152520, Train Loss: 1.1341, Learning Rate: 3.93e-06
2025-12-11 01:16:43 - INFO - Epoch: 38.51, Step: 152530, Train Loss: 1.1305, Learning Rate: 3.93e-06
2025-12-11 01:16:54 - INFO - Epoch: 38.51, Step: 152540, Train Loss: 1.1225, Learning Rate: 3.92e-06
2025-12-11 01:17:05 - INFO - Epoch: 38.51, Step: 152550, Train Loss: 1.1238, Learning Rate: 3.91e-06
2025-12-11 01:17:16 - INFO - Epoch: 38.52, Step: 152560, Train Loss: 1.1342, Learning Rate: 3.91e-06
2025-12-11 01:17:27 - INFO - Epoch: 38.52, Step: 152570, Train Loss: 1.1215, Learning Rate: 3.90e-06
2025-12-11 01:17:38 - INFO - Epoch: 38.52, Step: 152580, Train Loss: 1.1654, Learning Rate: 3.89e-06
2025-12-11 01:17:50 - INFO - Epoch: 38.52, Step: 152590, Train Loss: 1.1017, Learning Rate: 3.89e-06
2025-12-11 01:18:01 - INFO - Epoch: 38.53, Step: 152600, Train Loss: 1.1292, Learning Rate: 3.88e-06
2025-12-11 01:18:12 - INFO - Epoch: 38.53, Step: 152610, Train Loss: 1.1376, Learning Rate: 3.87e-06
2025-12-11 01:18:23 - INFO - Epoch: 38.53, Step: 152620, Train Loss: 1.1511, Learning Rate: 3.87e-06
2025-12-11 01:18:34 - INFO - Epoch: 38.53, Step: 152630, Train Loss: 1.0984, Learning Rate: 3.86e-06
2025-12-11 01:18:45 - INFO - Epoch: 38.54, Step: 152640, Train Loss: 1.1341, Learning Rate: 3.85e-06
2025-12-11 01:18:57 - INFO - Epoch: 38.54, Step: 152650, Train Loss: 1.1476, Learning Rate: 3.85e-06
2025-12-11 01:19:08 - INFO - Epoch: 38.54, Step: 152660, Train Loss: 1.1097, Learning Rate: 3.84e-06
2025-12-11 01:19:19 - INFO - Epoch: 38.54, Step: 152670, Train Loss: 1.1358, Learning Rate: 3.83e-06
2025-12-11 01:19:30 - INFO - Epoch: 38.55, Step: 152680, Train Loss: 1.1215, Learning Rate: 3.83e-06
2025-12-11 01:19:41 - INFO - Epoch: 38.55, Step: 152690, Train Loss: 1.1377, Learning Rate: 3.82e-06
2025-12-11 01:19:52 - INFO - Epoch: 38.55, Step: 152700, Train Loss: 1.1628, Learning Rate: 3.81e-06
2025-12-11 01:20:03 - INFO - Epoch: 38.55, Step: 152710, Train Loss: 1.1478, Learning Rate: 3.81e-06
2025-12-11 01:20:15 - INFO - Epoch: 38.56, Step: 152720, Train Loss: 1.1296, Learning Rate: 3.80e-06
2025-12-11 01:20:26 - INFO - Epoch: 38.56, Step: 152730, Train Loss: 1.1112, Learning Rate: 3.79e-06
2025-12-11 01:20:37 - INFO - Epoch: 38.56, Step: 152740, Train Loss: 1.1358, Learning Rate: 3.79e-06
2025-12-11 01:20:48 - INFO - Epoch: 38.56, Step: 152750, Train Loss: 1.1570, Learning Rate: 3.78e-06
2025-12-11 01:20:59 - INFO - Epoch: 38.57, Step: 152760, Train Loss: 1.1400, Learning Rate: 3.77e-06
2025-12-11 01:21:10 - INFO - Epoch: 38.57, Step: 152770, Train Loss: 1.1018, Learning Rate: 3.77e-06
2025-12-11 01:21:22 - INFO - Epoch: 38.57, Step: 152780, Train Loss: 1.1564, Learning Rate: 3.76e-06
2025-12-11 01:21:33 - INFO - Epoch: 38.57, Step: 152790, Train Loss: 1.1496, Learning Rate: 3.75e-06
2025-12-11 01:21:44 - INFO - Epoch: 38.58, Step: 152800, Train Loss: 1.1525, Learning Rate: 3.75e-06
2025-12-11 01:21:55 - INFO - Epoch: 38.58, Step: 152810, Train Loss: 1.1149, Learning Rate: 3.74e-06
2025-12-11 01:22:06 - INFO - Epoch: 38.58, Step: 152820, Train Loss: 1.1542, Learning Rate: 3.73e-06
2025-12-11 01:22:17 - INFO - Epoch: 38.58, Step: 152830, Train Loss: 1.1122, Learning Rate: 3.73e-06
2025-12-11 01:22:28 - INFO - Epoch: 38.59, Step: 152840, Train Loss: 1.1396, Learning Rate: 3.72e-06
2025-12-11 01:22:40 - INFO - Epoch: 38.59, Step: 152850, Train Loss: 1.1125, Learning Rate: 3.71e-06
2025-12-11 01:22:51 - INFO - Epoch: 38.59, Step: 152860, Train Loss: 1.1274, Learning Rate: 3.71e-06
2025-12-11 01:23:02 - INFO - Epoch: 38.59, Step: 152870, Train Loss: 1.1598, Learning Rate: 3.70e-06
2025-12-11 01:23:13 - INFO - Epoch: 38.60, Step: 152880, Train Loss: 1.1534, Learning Rate: 3.69e-06
2025-12-11 01:23:24 - INFO - Epoch: 38.60, Step: 152890, Train Loss: 1.1614, Learning Rate: 3.69e-06
2025-12-11 01:23:35 - INFO - Epoch: 38.60, Step: 152900, Train Loss: 1.1201, Learning Rate: 3.68e-06
2025-12-11 01:23:46 - INFO - Epoch: 38.60, Step: 152910, Train Loss: 1.1248, Learning Rate: 3.67e-06
2025-12-11 01:23:58 - INFO - Epoch: 38.61, Step: 152920, Train Loss: 1.1383, Learning Rate: 3.67e-06
2025-12-11 01:24:09 - INFO - Epoch: 38.61, Step: 152930, Train Loss: 1.1513, Learning Rate: 3.66e-06
2025-12-11 01:24:20 - INFO - Epoch: 38.61, Step: 152940, Train Loss: 1.1317, Learning Rate: 3.65e-06
2025-12-11 01:24:31 - INFO - Epoch: 38.61, Step: 152950, Train Loss: 1.1243, Learning Rate: 3.65e-06
2025-12-11 01:24:42 - INFO - Epoch: 38.62, Step: 152960, Train Loss: 1.1272, Learning Rate: 3.64e-06
2025-12-11 01:24:53 - INFO - Epoch: 38.62, Step: 152970, Train Loss: 1.1393, Learning Rate: 3.63e-06
2025-12-11 01:25:05 - INFO - Epoch: 38.62, Step: 152980, Train Loss: 1.1232, Learning Rate: 3.63e-06
2025-12-11 01:25:16 - INFO - Epoch: 38.62, Step: 152990, Train Loss: 1.1383, Learning Rate: 3.62e-06
2025-12-11 01:25:27 - INFO - Epoch: 38.63, Step: 153000, Train Loss: 1.1300, Learning Rate: 3.61e-06
2025-12-11 01:25:38 - INFO - Epoch: 38.63, Step: 153010, Train Loss: 1.1459, Learning Rate: 3.61e-06
2025-12-11 01:25:49 - INFO - Epoch: 38.63, Step: 153020, Train Loss: 1.1238, Learning Rate: 3.60e-06
2025-12-11 01:26:00 - INFO - Epoch: 38.63, Step: 153030, Train Loss: 1.1002, Learning Rate: 3.59e-06
2025-12-11 01:26:11 - INFO - Epoch: 38.64, Step: 153040, Train Loss: 1.0913, Learning Rate: 3.59e-06
2025-12-11 01:26:23 - INFO - Epoch: 38.64, Step: 153050, Train Loss: 1.0972, Learning Rate: 3.58e-06
2025-12-11 01:26:34 - INFO - Epoch: 38.64, Step: 153060, Train Loss: 1.1191, Learning Rate: 3.57e-06
2025-12-11 01:26:45 - INFO - Epoch: 38.64, Step: 153070, Train Loss: 1.1305, Learning Rate: 3.57e-06
2025-12-11 01:26:56 - INFO - Epoch: 38.65, Step: 153080, Train Loss: 1.1374, Learning Rate: 3.56e-06
2025-12-11 01:27:07 - INFO - Epoch: 38.65, Step: 153090, Train Loss: 1.1123, Learning Rate: 3.56e-06
2025-12-11 01:27:18 - INFO - Epoch: 38.65, Step: 153100, Train Loss: 1.1640, Learning Rate: 3.55e-06
2025-12-11 01:27:29 - INFO - Epoch: 38.65, Step: 153110, Train Loss: 1.1614, Learning Rate: 3.54e-06
2025-12-11 01:27:41 - INFO - Epoch: 38.66, Step: 153120, Train Loss: 1.1688, Learning Rate: 3.54e-06
2025-12-11 01:27:52 - INFO - Epoch: 38.66, Step: 153130, Train Loss: 1.1494, Learning Rate: 3.53e-06
2025-12-11 01:28:03 - INFO - Epoch: 38.66, Step: 153140, Train Loss: 1.1110, Learning Rate: 3.52e-06
2025-12-11 01:28:14 - INFO - Epoch: 38.66, Step: 153150, Train Loss: 1.1508, Learning Rate: 3.52e-06
2025-12-11 01:28:25 - INFO - Epoch: 38.67, Step: 153160, Train Loss: 1.1417, Learning Rate: 3.51e-06
2025-12-11 01:28:36 - INFO - Epoch: 38.67, Step: 153170, Train Loss: 1.1401, Learning Rate: 3.50e-06
2025-12-11 01:28:48 - INFO - Epoch: 38.67, Step: 153180, Train Loss: 1.1050, Learning Rate: 3.50e-06
2025-12-11 01:28:59 - INFO - Epoch: 38.67, Step: 153190, Train Loss: 1.1450, Learning Rate: 3.49e-06
2025-12-11 01:29:10 - INFO - Epoch: 38.68, Step: 153200, Train Loss: 1.1630, Learning Rate: 3.48e-06
2025-12-11 01:29:21 - INFO - Epoch: 38.68, Step: 153210, Train Loss: 1.1155, Learning Rate: 3.48e-06
2025-12-11 01:29:32 - INFO - Epoch: 38.68, Step: 153220, Train Loss: 1.1394, Learning Rate: 3.47e-06
2025-12-11 01:29:43 - INFO - Epoch: 38.68, Step: 153230, Train Loss: 1.1300, Learning Rate: 3.46e-06
2025-12-11 01:29:54 - INFO - Epoch: 38.69, Step: 153240, Train Loss: 1.1727, Learning Rate: 3.46e-06
2025-12-11 01:30:06 - INFO - Epoch: 38.69, Step: 153250, Train Loss: 1.1252, Learning Rate: 3.45e-06
2025-12-11 01:30:17 - INFO - Epoch: 38.69, Step: 153260, Train Loss: 1.1179, Learning Rate: 3.44e-06
2025-12-11 01:30:28 - INFO - Epoch: 38.69, Step: 153270, Train Loss: 1.1514, Learning Rate: 3.44e-06
2025-12-11 01:30:39 - INFO - Epoch: 38.70, Step: 153280, Train Loss: 1.1523, Learning Rate: 3.43e-06
2025-12-11 01:30:50 - INFO - Epoch: 38.70, Step: 153290, Train Loss: 1.1250, Learning Rate: 3.42e-06
2025-12-11 01:31:01 - INFO - Epoch: 38.70, Step: 153300, Train Loss: 1.1498, Learning Rate: 3.42e-06
2025-12-11 01:31:13 - INFO - Epoch: 38.70, Step: 153310, Train Loss: 1.1544, Learning Rate: 3.41e-06
2025-12-11 01:31:24 - INFO - Epoch: 38.71, Step: 153320, Train Loss: 1.1259, Learning Rate: 3.40e-06
2025-12-11 01:31:35 - INFO - Epoch: 38.71, Step: 153330, Train Loss: 1.1415, Learning Rate: 3.40e-06
2025-12-11 01:31:46 - INFO - Epoch: 38.71, Step: 153340, Train Loss: 1.1437, Learning Rate: 3.39e-06
2025-12-11 01:31:57 - INFO - Epoch: 38.71, Step: 153350, Train Loss: 1.1136, Learning Rate: 3.38e-06
2025-12-11 01:32:08 - INFO - Epoch: 38.72, Step: 153360, Train Loss: 1.1500, Learning Rate: 3.38e-06
2025-12-11 01:32:19 - INFO - Epoch: 38.72, Step: 153370, Train Loss: 1.1211, Learning Rate: 3.37e-06
2025-12-11 01:32:31 - INFO - Epoch: 38.72, Step: 153380, Train Loss: 1.1177, Learning Rate: 3.36e-06
2025-12-11 01:32:42 - INFO - Epoch: 38.73, Step: 153390, Train Loss: 1.1073, Learning Rate: 3.36e-06
2025-12-11 01:32:53 - INFO - Epoch: 38.73, Step: 153400, Train Loss: 1.1354, Learning Rate: 3.35e-06
2025-12-11 01:33:04 - INFO - Epoch: 38.73, Step: 153410, Train Loss: 1.1206, Learning Rate: 3.34e-06
2025-12-11 01:33:15 - INFO - Epoch: 38.73, Step: 153420, Train Loss: 1.1145, Learning Rate: 3.34e-06
2025-12-11 01:33:26 - INFO - Epoch: 38.74, Step: 153430, Train Loss: 1.1227, Learning Rate: 3.33e-06
2025-12-11 01:33:37 - INFO - Epoch: 38.74, Step: 153440, Train Loss: 1.1657, Learning Rate: 3.32e-06
2025-12-11 01:33:49 - INFO - Epoch: 38.74, Step: 153450, Train Loss: 1.1388, Learning Rate: 3.32e-06
2025-12-11 01:34:00 - INFO - Epoch: 38.74, Step: 153460, Train Loss: 1.1062, Learning Rate: 3.31e-06
2025-12-11 01:34:11 - INFO - Epoch: 38.75, Step: 153470, Train Loss: 1.1385, Learning Rate: 3.30e-06
2025-12-11 01:34:22 - INFO - Epoch: 38.75, Step: 153480, Train Loss: 1.1531, Learning Rate: 3.30e-06
2025-12-11 01:34:33 - INFO - Epoch: 38.75, Step: 153490, Train Loss: 1.1021, Learning Rate: 3.29e-06
2025-12-11 01:34:44 - INFO - Epoch: 38.75, Step: 153500, Train Loss: 1.1521, Learning Rate: 3.28e-06
2025-12-11 01:34:56 - INFO - Epoch: 38.76, Step: 153510, Train Loss: 1.1564, Learning Rate: 3.28e-06
2025-12-11 01:35:07 - INFO - Epoch: 38.76, Step: 153520, Train Loss: 1.1037, Learning Rate: 3.27e-06
2025-12-11 01:35:18 - INFO - Epoch: 38.76, Step: 153530, Train Loss: 1.1558, Learning Rate: 3.26e-06
2025-12-11 01:35:29 - INFO - Epoch: 38.76, Step: 153540, Train Loss: 1.1445, Learning Rate: 3.26e-06
2025-12-11 01:35:40 - INFO - Epoch: 38.77, Step: 153550, Train Loss: 1.1209, Learning Rate: 3.25e-06
2025-12-11 01:35:51 - INFO - Epoch: 38.77, Step: 153560, Train Loss: 1.1273, Learning Rate: 3.24e-06
2025-12-11 01:36:02 - INFO - Epoch: 38.77, Step: 153570, Train Loss: 1.1850, Learning Rate: 3.24e-06
2025-12-11 01:36:14 - INFO - Epoch: 38.77, Step: 153580, Train Loss: 1.1776, Learning Rate: 3.23e-06
2025-12-11 01:36:25 - INFO - Epoch: 38.78, Step: 153590, Train Loss: 1.0987, Learning Rate: 3.22e-06
2025-12-11 01:36:36 - INFO - Epoch: 38.78, Step: 153600, Train Loss: 1.0941, Learning Rate: 3.22e-06
2025-12-11 01:36:47 - INFO - Epoch: 38.78, Step: 153610, Train Loss: 1.1422, Learning Rate: 3.21e-06
2025-12-11 01:36:58 - INFO - Epoch: 38.78, Step: 153620, Train Loss: 1.1356, Learning Rate: 3.20e-06
2025-12-11 01:37:09 - INFO - Epoch: 38.79, Step: 153630, Train Loss: 1.1379, Learning Rate: 3.20e-06
2025-12-11 01:37:20 - INFO - Epoch: 38.79, Step: 153640, Train Loss: 1.1382, Learning Rate: 3.19e-06
2025-12-11 01:37:32 - INFO - Epoch: 38.79, Step: 153650, Train Loss: 1.1390, Learning Rate: 3.18e-06
2025-12-11 01:37:43 - INFO - Epoch: 38.79, Step: 153660, Train Loss: 1.1666, Learning Rate: 3.18e-06
2025-12-11 01:37:54 - INFO - Epoch: 38.80, Step: 153670, Train Loss: 1.1116, Learning Rate: 3.17e-06
2025-12-11 01:38:05 - INFO - Epoch: 38.80, Step: 153680, Train Loss: 1.1533, Learning Rate: 3.16e-06
2025-12-11 01:38:16 - INFO - Epoch: 38.80, Step: 153690, Train Loss: 1.1043, Learning Rate: 3.16e-06
2025-12-11 01:38:27 - INFO - Epoch: 38.80, Step: 153700, Train Loss: 1.1649, Learning Rate: 3.15e-06
2025-12-11 01:38:39 - INFO - Epoch: 38.81, Step: 153710, Train Loss: 1.1181, Learning Rate: 3.14e-06
2025-12-11 01:38:50 - INFO - Epoch: 38.81, Step: 153720, Train Loss: 1.1587, Learning Rate: 3.14e-06
2025-12-11 01:39:01 - INFO - Epoch: 38.81, Step: 153730, Train Loss: 1.1508, Learning Rate: 3.13e-06
2025-12-11 01:39:12 - INFO - Epoch: 38.81, Step: 153740, Train Loss: 1.1099, Learning Rate: 3.12e-06
2025-12-11 01:39:23 - INFO - Epoch: 38.82, Step: 153750, Train Loss: 1.1644, Learning Rate: 3.12e-06
2025-12-11 01:39:34 - INFO - Epoch: 38.82, Step: 153760, Train Loss: 1.1247, Learning Rate: 3.11e-06
2025-12-11 01:39:45 - INFO - Epoch: 38.82, Step: 153770, Train Loss: 1.1546, Learning Rate: 3.10e-06
2025-12-11 01:39:57 - INFO - Epoch: 38.82, Step: 153780, Train Loss: 1.1277, Learning Rate: 3.10e-06
2025-12-11 01:40:08 - INFO - Epoch: 38.83, Step: 153790, Train Loss: 1.1354, Learning Rate: 3.09e-06
2025-12-11 01:40:19 - INFO - Epoch: 38.83, Step: 153800, Train Loss: 1.1504, Learning Rate: 3.08e-06
2025-12-11 01:40:30 - INFO - Epoch: 38.83, Step: 153810, Train Loss: 1.1260, Learning Rate: 3.08e-06
2025-12-11 01:40:41 - INFO - Epoch: 38.83, Step: 153820, Train Loss: 1.1212, Learning Rate: 3.07e-06
2025-12-11 01:40:52 - INFO - Epoch: 38.84, Step: 153830, Train Loss: 1.1570, Learning Rate: 3.06e-06
2025-12-11 01:41:04 - INFO - Epoch: 38.84, Step: 153840, Train Loss: 1.1778, Learning Rate: 3.06e-06
2025-12-11 01:41:15 - INFO - Epoch: 38.84, Step: 153850, Train Loss: 1.1176, Learning Rate: 3.05e-06
2025-12-11 01:41:26 - INFO - Epoch: 38.84, Step: 153860, Train Loss: 1.1414, Learning Rate: 3.04e-06
2025-12-11 01:41:37 - INFO - Epoch: 38.85, Step: 153870, Train Loss: 1.1518, Learning Rate: 3.04e-06
2025-12-11 01:41:48 - INFO - Epoch: 38.85, Step: 153880, Train Loss: 1.1205, Learning Rate: 3.03e-06
2025-12-11 01:41:59 - INFO - Epoch: 38.85, Step: 153890, Train Loss: 1.1291, Learning Rate: 3.02e-06
2025-12-11 01:42:10 - INFO - Epoch: 38.85, Step: 153900, Train Loss: 1.1628, Learning Rate: 3.02e-06
2025-12-11 01:42:22 - INFO - Epoch: 38.86, Step: 153910, Train Loss: 1.1156, Learning Rate: 3.01e-06
2025-12-11 01:42:33 - INFO - Epoch: 38.86, Step: 153920, Train Loss: 1.1332, Learning Rate: 3.00e-06
2025-12-11 01:42:44 - INFO - Epoch: 38.86, Step: 153930, Train Loss: 1.1769, Learning Rate: 3.00e-06
2025-12-11 01:42:55 - INFO - Epoch: 38.86, Step: 153940, Train Loss: 1.1365, Learning Rate: 2.99e-06
2025-12-11 01:43:06 - INFO - Epoch: 38.87, Step: 153950, Train Loss: 1.1143, Learning Rate: 2.98e-06
2025-12-11 01:43:17 - INFO - Epoch: 38.87, Step: 153960, Train Loss: 1.1319, Learning Rate: 2.98e-06
2025-12-11 01:43:28 - INFO - Epoch: 38.87, Step: 153970, Train Loss: 1.1613, Learning Rate: 2.97e-06
2025-12-11 01:43:40 - INFO - Epoch: 38.87, Step: 153980, Train Loss: 1.1683, Learning Rate: 2.96e-06
2025-12-11 01:43:51 - INFO - Epoch: 38.88, Step: 153990, Train Loss: 1.1541, Learning Rate: 2.96e-06
2025-12-11 01:44:02 - INFO - Epoch: 38.88, Step: 154000, Train Loss: 1.1384, Learning Rate: 2.95e-06
2025-12-11 01:44:13 - INFO - Epoch: 38.88, Step: 154010, Train Loss: 1.1122, Learning Rate: 2.94e-06
2025-12-11 01:44:24 - INFO - Epoch: 38.88, Step: 154020, Train Loss: 1.1270, Learning Rate: 2.94e-06
2025-12-11 01:44:35 - INFO - Epoch: 38.89, Step: 154030, Train Loss: 1.1386, Learning Rate: 2.93e-06
2025-12-11 01:44:47 - INFO - Epoch: 38.89, Step: 154040, Train Loss: 1.1154, Learning Rate: 2.92e-06
2025-12-11 01:44:58 - INFO - Epoch: 38.89, Step: 154050, Train Loss: 1.1256, Learning Rate: 2.92e-06
2025-12-11 01:45:09 - INFO - Epoch: 38.89, Step: 154060, Train Loss: 1.1300, Learning Rate: 2.91e-06
2025-12-11 01:45:20 - INFO - Epoch: 38.90, Step: 154070, Train Loss: 1.1190, Learning Rate: 2.90e-06
2025-12-11 01:45:31 - INFO - Epoch: 38.90, Step: 154080, Train Loss: 1.1775, Learning Rate: 2.90e-06
2025-12-11 01:45:42 - INFO - Epoch: 38.90, Step: 154090, Train Loss: 1.1189, Learning Rate: 2.89e-06
2025-12-11 01:45:53 - INFO - Epoch: 38.90, Step: 154100, Train Loss: 1.1426, Learning Rate: 2.88e-06
2025-12-11 01:46:05 - INFO - Epoch: 38.91, Step: 154110, Train Loss: 1.1506, Learning Rate: 2.88e-06
2025-12-11 01:46:16 - INFO - Epoch: 38.91, Step: 154120, Train Loss: 1.1070, Learning Rate: 2.87e-06
2025-12-11 01:46:27 - INFO - Epoch: 38.91, Step: 154130, Train Loss: 1.1321, Learning Rate: 2.86e-06
2025-12-11 01:46:38 - INFO - Epoch: 38.91, Step: 154140, Train Loss: 1.1192, Learning Rate: 2.86e-06
2025-12-11 01:46:49 - INFO - Epoch: 38.92, Step: 154150, Train Loss: 1.1315, Learning Rate: 2.85e-06
2025-12-11 01:47:00 - INFO - Epoch: 38.92, Step: 154160, Train Loss: 1.1108, Learning Rate: 2.84e-06
2025-12-11 01:47:11 - INFO - Epoch: 38.92, Step: 154170, Train Loss: 1.0941, Learning Rate: 2.84e-06
2025-12-11 01:47:23 - INFO - Epoch: 38.92, Step: 154180, Train Loss: 1.1465, Learning Rate: 2.83e-06
2025-12-11 01:47:34 - INFO - Epoch: 38.93, Step: 154190, Train Loss: 1.1035, Learning Rate: 2.82e-06
2025-12-11 01:47:45 - INFO - Epoch: 38.93, Step: 154200, Train Loss: 1.1152, Learning Rate: 2.82e-06
2025-12-11 01:47:56 - INFO - Epoch: 38.93, Step: 154210, Train Loss: 1.1457, Learning Rate: 2.81e-06
2025-12-11 01:48:07 - INFO - Epoch: 38.93, Step: 154220, Train Loss: 1.1025, Learning Rate: 2.80e-06
2025-12-11 01:48:18 - INFO - Epoch: 38.94, Step: 154230, Train Loss: 1.1191, Learning Rate: 2.80e-06
2025-12-11 01:48:30 - INFO - Epoch: 38.94, Step: 154240, Train Loss: 1.1363, Learning Rate: 2.79e-06
2025-12-11 01:48:41 - INFO - Epoch: 38.94, Step: 154250, Train Loss: 1.1358, Learning Rate: 2.78e-06
2025-12-11 01:48:52 - INFO - Epoch: 38.94, Step: 154260, Train Loss: 1.1663, Learning Rate: 2.78e-06
2025-12-11 01:49:03 - INFO - Epoch: 38.95, Step: 154270, Train Loss: 1.1443, Learning Rate: 2.77e-06
2025-12-11 01:49:14 - INFO - Epoch: 38.95, Step: 154280, Train Loss: 1.1299, Learning Rate: 2.76e-06
2025-12-11 01:49:25 - INFO - Epoch: 38.95, Step: 154290, Train Loss: 1.1295, Learning Rate: 2.76e-06
2025-12-11 01:49:36 - INFO - Epoch: 38.95, Step: 154300, Train Loss: 1.1167, Learning Rate: 2.75e-06
2025-12-11 01:49:48 - INFO - Epoch: 38.96, Step: 154310, Train Loss: 1.1444, Learning Rate: 2.74e-06
2025-12-11 01:49:59 - INFO - Epoch: 38.96, Step: 154320, Train Loss: 1.1464, Learning Rate: 2.74e-06
2025-12-11 01:50:10 - INFO - Epoch: 38.96, Step: 154330, Train Loss: 1.1056, Learning Rate: 2.73e-06
2025-12-11 01:50:21 - INFO - Epoch: 38.96, Step: 154340, Train Loss: 1.0810, Learning Rate: 2.72e-06
2025-12-11 01:50:32 - INFO - Epoch: 38.97, Step: 154350, Train Loss: 1.0995, Learning Rate: 2.72e-06
2025-12-11 01:50:43 - INFO - Epoch: 38.97, Step: 154360, Train Loss: 1.1719, Learning Rate: 2.71e-06
2025-12-11 01:50:55 - INFO - Epoch: 38.97, Step: 154370, Train Loss: 1.1118, Learning Rate: 2.70e-06
2025-12-11 01:51:06 - INFO - Epoch: 38.98, Step: 154380, Train Loss: 1.1188, Learning Rate: 2.70e-06
2025-12-11 01:51:17 - INFO - Epoch: 38.98, Step: 154390, Train Loss: 1.1560, Learning Rate: 2.69e-06
2025-12-11 01:51:28 - INFO - Epoch: 38.98, Step: 154400, Train Loss: 1.0865, Learning Rate: 2.68e-06
2025-12-11 01:51:39 - INFO - Epoch: 38.98, Step: 154410, Train Loss: 1.0869, Learning Rate: 2.68e-06
2025-12-11 01:51:50 - INFO - Epoch: 38.99, Step: 154420, Train Loss: 1.0775, Learning Rate: 2.67e-06
2025-12-11 01:52:01 - INFO - Epoch: 38.99, Step: 154430, Train Loss: 1.1315, Learning Rate: 2.66e-06
2025-12-11 01:52:13 - INFO - Epoch: 38.99, Step: 154440, Train Loss: 1.1301, Learning Rate: 2.66e-06
2025-12-11 01:52:24 - INFO - Epoch: 38.99, Step: 154450, Train Loss: 1.1178, Learning Rate: 2.65e-06
2025-12-11 01:52:35 - INFO - Epoch: 39.00, Step: 154460, Train Loss: 1.1366, Learning Rate: 2.64e-06
2025-12-11 01:52:46 - INFO - Epoch: 39.00, Step: 154470, Train Loss: 1.1657, Learning Rate: 2.64e-06
2025-12-11 01:52:57 - INFO - Epoch: 39.00, Step: 154480, Train Loss: 1.1505, Learning Rate: 2.63e-06
2025-12-11 01:53:08 - INFO - Epoch: 39.00, Step: 154490, Train Loss: 1.1464, Learning Rate: 2.62e-06
2025-12-11 01:53:19 - INFO - Epoch: 39.01, Step: 154500, Train Loss: 1.1404, Learning Rate: 2.62e-06
2025-12-11 01:53:31 - INFO - Epoch: 39.01, Step: 154510, Train Loss: 1.1373, Learning Rate: 2.61e-06
2025-12-11 01:53:42 - INFO - Epoch: 39.01, Step: 154520, Train Loss: 1.1280, Learning Rate: 2.61e-06
2025-12-11 01:53:53 - INFO - Epoch: 39.01, Step: 154530, Train Loss: 1.1389, Learning Rate: 2.60e-06
2025-12-11 01:54:04 - INFO - Epoch: 39.02, Step: 154540, Train Loss: 1.1637, Learning Rate: 2.59e-06
2025-12-11 01:54:15 - INFO - Epoch: 39.02, Step: 154550, Train Loss: 1.1096, Learning Rate: 2.59e-06
2025-12-11 01:54:26 - INFO - Epoch: 39.02, Step: 154560, Train Loss: 1.1347, Learning Rate: 2.58e-06
2025-12-11 01:54:38 - INFO - Epoch: 39.02, Step: 154570, Train Loss: 1.1213, Learning Rate: 2.57e-06
2025-12-11 01:54:49 - INFO - Epoch: 39.03, Step: 154580, Train Loss: 1.1916, Learning Rate: 2.57e-06
2025-12-11 01:55:00 - INFO - Epoch: 39.03, Step: 154590, Train Loss: 1.1380, Learning Rate: 2.56e-06
2025-12-11 01:55:11 - INFO - Epoch: 39.03, Step: 154600, Train Loss: 1.1425, Learning Rate: 2.55e-06
2025-12-11 01:55:22 - INFO - Epoch: 39.03, Step: 154610, Train Loss: 1.1224, Learning Rate: 2.55e-06
2025-12-11 01:55:33 - INFO - Epoch: 39.04, Step: 154620, Train Loss: 1.1388, Learning Rate: 2.54e-06
2025-12-11 01:55:44 - INFO - Epoch: 39.04, Step: 154630, Train Loss: 1.1408, Learning Rate: 2.53e-06
2025-12-11 01:55:56 - INFO - Epoch: 39.04, Step: 154640, Train Loss: 1.1029, Learning Rate: 2.53e-06
2025-12-11 01:56:07 - INFO - Epoch: 39.04, Step: 154650, Train Loss: 1.1506, Learning Rate: 2.52e-06
2025-12-11 01:56:18 - INFO - Epoch: 39.05, Step: 154660, Train Loss: 1.1667, Learning Rate: 2.51e-06
2025-12-11 01:56:29 - INFO - Epoch: 39.05, Step: 154670, Train Loss: 1.1335, Learning Rate: 2.51e-06
2025-12-11 01:56:40 - INFO - Epoch: 39.05, Step: 154680, Train Loss: 1.1417, Learning Rate: 2.50e-06
2025-12-11 01:56:51 - INFO - Epoch: 39.05, Step: 154690, Train Loss: 1.1565, Learning Rate: 2.49e-06
2025-12-11 01:57:02 - INFO - Epoch: 39.06, Step: 154700, Train Loss: 1.1230, Learning Rate: 2.49e-06
2025-12-11 01:57:14 - INFO - Epoch: 39.06, Step: 154710, Train Loss: 1.1510, Learning Rate: 2.48e-06
2025-12-11 01:57:25 - INFO - Epoch: 39.06, Step: 154720, Train Loss: 1.1012, Learning Rate: 2.47e-06
2025-12-11 01:57:36 - INFO - Epoch: 39.06, Step: 154730, Train Loss: 1.1389, Learning Rate: 2.47e-06
2025-12-11 01:57:47 - INFO - Epoch: 39.07, Step: 154740, Train Loss: 1.1251, Learning Rate: 2.46e-06
2025-12-11 01:57:58 - INFO - Epoch: 39.07, Step: 154750, Train Loss: 1.1011, Learning Rate: 2.45e-06
2025-12-11 01:58:09 - INFO - Epoch: 39.07, Step: 154760, Train Loss: 1.1340, Learning Rate: 2.45e-06
2025-12-11 01:58:21 - INFO - Epoch: 39.07, Step: 154770, Train Loss: 1.1486, Learning Rate: 2.44e-06
2025-12-11 01:58:32 - INFO - Epoch: 39.08, Step: 154780, Train Loss: 1.1202, Learning Rate: 2.43e-06
2025-12-11 01:58:43 - INFO - Epoch: 39.08, Step: 154790, Train Loss: 1.1218, Learning Rate: 2.43e-06
2025-12-11 01:58:54 - INFO - Epoch: 39.08, Step: 154800, Train Loss: 1.1360, Learning Rate: 2.42e-06
2025-12-11 01:59:05 - INFO - Epoch: 39.08, Step: 154810, Train Loss: 1.1289, Learning Rate: 2.41e-06
2025-12-11 01:59:16 - INFO - Epoch: 39.09, Step: 154820, Train Loss: 1.1283, Learning Rate: 2.41e-06
2025-12-11 01:59:27 - INFO - Epoch: 39.09, Step: 154830, Train Loss: 1.1080, Learning Rate: 2.40e-06
2025-12-11 01:59:39 - INFO - Epoch: 39.09, Step: 154840, Train Loss: 1.1383, Learning Rate: 2.39e-06
2025-12-11 01:59:50 - INFO - Epoch: 39.09, Step: 154850, Train Loss: 1.1154, Learning Rate: 2.39e-06
2025-12-11 02:00:01 - INFO - Epoch: 39.10, Step: 154860, Train Loss: 1.1290, Learning Rate: 2.38e-06
2025-12-11 02:00:12 - INFO - Epoch: 39.10, Step: 154870, Train Loss: 1.1491, Learning Rate: 2.37e-06
2025-12-11 02:00:23 - INFO - Epoch: 39.10, Step: 154880, Train Loss: 1.1224, Learning Rate: 2.37e-06
2025-12-11 02:00:34 - INFO - Epoch: 39.10, Step: 154890, Train Loss: 1.1652, Learning Rate: 2.36e-06
2025-12-11 02:00:45 - INFO - Epoch: 39.11, Step: 154900, Train Loss: 1.1452, Learning Rate: 2.35e-06
2025-12-11 02:00:57 - INFO - Epoch: 39.11, Step: 154910, Train Loss: 1.1317, Learning Rate: 2.35e-06
2025-12-11 02:01:08 - INFO - Epoch: 39.11, Step: 154920, Train Loss: 1.1271, Learning Rate: 2.34e-06
2025-12-11 02:01:19 - INFO - Epoch: 39.11, Step: 154930, Train Loss: 1.1297, Learning Rate: 2.33e-06
2025-12-11 02:01:30 - INFO - Epoch: 39.12, Step: 154940, Train Loss: 1.1249, Learning Rate: 2.33e-06
2025-12-11 02:01:41 - INFO - Epoch: 39.12, Step: 154950, Train Loss: 1.1020, Learning Rate: 2.32e-06
2025-12-11 02:01:52 - INFO - Epoch: 39.12, Step: 154960, Train Loss: 1.1648, Learning Rate: 2.31e-06
2025-12-11 02:02:04 - INFO - Epoch: 39.12, Step: 154970, Train Loss: 1.1703, Learning Rate: 2.31e-06
2025-12-11 02:02:15 - INFO - Epoch: 39.13, Step: 154980, Train Loss: 1.1324, Learning Rate: 2.30e-06
2025-12-11 02:02:26 - INFO - Epoch: 39.13, Step: 154990, Train Loss: 1.1427, Learning Rate: 2.29e-06
2025-12-11 02:02:37 - INFO - Epoch: 39.13, Step: 155000, Train Loss: 1.1394, Learning Rate: 2.29e-06
2025-12-11 02:02:48 - INFO - Epoch: 39.13, Step: 155010, Train Loss: 1.1330, Learning Rate: 2.28e-06
2025-12-11 02:02:59 - INFO - Epoch: 39.14, Step: 155020, Train Loss: 1.1316, Learning Rate: 2.27e-06
2025-12-11 02:03:10 - INFO - Epoch: 39.14, Step: 155030, Train Loss: 1.1192, Learning Rate: 2.27e-06
2025-12-11 02:03:22 - INFO - Epoch: 39.14, Step: 155040, Train Loss: 1.1268, Learning Rate: 2.26e-06
2025-12-11 02:03:33 - INFO - Epoch: 39.14, Step: 155050, Train Loss: 1.1213, Learning Rate: 2.25e-06
2025-12-11 02:03:44 - INFO - Epoch: 39.15, Step: 155060, Train Loss: 1.1283, Learning Rate: 2.25e-06
2025-12-11 02:03:55 - INFO - Epoch: 39.15, Step: 155070, Train Loss: 1.1155, Learning Rate: 2.24e-06
2025-12-11 02:04:06 - INFO - Epoch: 39.15, Step: 155080, Train Loss: 1.1157, Learning Rate: 2.23e-06
2025-12-11 02:04:17 - INFO - Epoch: 39.15, Step: 155090, Train Loss: 1.1375, Learning Rate: 2.23e-06
2025-12-11 02:04:28 - INFO - Epoch: 39.16, Step: 155100, Train Loss: 1.1477, Learning Rate: 2.22e-06
2025-12-11 02:04:40 - INFO - Epoch: 39.16, Step: 155110, Train Loss: 1.1402, Learning Rate: 2.21e-06
2025-12-11 02:04:51 - INFO - Epoch: 39.16, Step: 155120, Train Loss: 1.1443, Learning Rate: 2.21e-06
2025-12-11 02:05:02 - INFO - Epoch: 39.16, Step: 155130, Train Loss: 1.1079, Learning Rate: 2.20e-06
2025-12-11 02:05:13 - INFO - Epoch: 39.17, Step: 155140, Train Loss: 1.1389, Learning Rate: 2.19e-06
2025-12-11 02:05:24 - INFO - Epoch: 39.17, Step: 155150, Train Loss: 1.0994, Learning Rate: 2.19e-06
2025-12-11 02:05:35 - INFO - Epoch: 39.17, Step: 155160, Train Loss: 1.0901, Learning Rate: 2.18e-06
2025-12-11 02:05:47 - INFO - Epoch: 39.17, Step: 155170, Train Loss: 1.1560, Learning Rate: 2.17e-06
2025-12-11 02:05:58 - INFO - Epoch: 39.18, Step: 155180, Train Loss: 1.1446, Learning Rate: 2.17e-06
2025-12-11 02:06:09 - INFO - Epoch: 39.18, Step: 155190, Train Loss: 1.1133, Learning Rate: 2.16e-06
2025-12-11 02:06:20 - INFO - Epoch: 39.18, Step: 155200, Train Loss: 1.1284, Learning Rate: 2.15e-06
2025-12-11 02:06:31 - INFO - Epoch: 39.18, Step: 155210, Train Loss: 1.1231, Learning Rate: 2.15e-06
2025-12-11 02:06:42 - INFO - Epoch: 39.19, Step: 155220, Train Loss: 1.0818, Learning Rate: 2.14e-06
2025-12-11 02:06:53 - INFO - Epoch: 39.19, Step: 155230, Train Loss: 1.1183, Learning Rate: 2.13e-06
2025-12-11 02:07:05 - INFO - Epoch: 39.19, Step: 155240, Train Loss: 1.1534, Learning Rate: 2.13e-06
2025-12-11 02:07:16 - INFO - Epoch: 39.19, Step: 155250, Train Loss: 1.1158, Learning Rate: 2.12e-06
2025-12-11 02:07:27 - INFO - Epoch: 39.20, Step: 155260, Train Loss: 1.1280, Learning Rate: 2.11e-06
2025-12-11 02:07:38 - INFO - Epoch: 39.20, Step: 155270, Train Loss: 1.1126, Learning Rate: 2.11e-06
2025-12-11 02:07:49 - INFO - Epoch: 39.20, Step: 155280, Train Loss: 1.1075, Learning Rate: 2.10e-06
2025-12-11 02:08:00 - INFO - Epoch: 39.20, Step: 155290, Train Loss: 1.1316, Learning Rate: 2.09e-06
2025-12-11 02:08:11 - INFO - Epoch: 39.21, Step: 155300, Train Loss: 1.1582, Learning Rate: 2.09e-06
2025-12-11 02:08:23 - INFO - Epoch: 39.21, Step: 155310, Train Loss: 1.1404, Learning Rate: 2.08e-06
2025-12-11 02:08:34 - INFO - Epoch: 39.21, Step: 155320, Train Loss: 1.1308, Learning Rate: 2.07e-06
2025-12-11 02:08:45 - INFO - Epoch: 39.21, Step: 155330, Train Loss: 1.1475, Learning Rate: 2.07e-06
2025-12-11 02:08:56 - INFO - Epoch: 39.22, Step: 155340, Train Loss: 1.1180, Learning Rate: 2.06e-06
2025-12-11 02:09:07 - INFO - Epoch: 39.22, Step: 155350, Train Loss: 1.1131, Learning Rate: 2.05e-06
2025-12-11 02:09:18 - INFO - Epoch: 39.22, Step: 155360, Train Loss: 1.1576, Learning Rate: 2.05e-06
2025-12-11 02:09:30 - INFO - Epoch: 39.22, Step: 155370, Train Loss: 1.1276, Learning Rate: 2.04e-06
2025-12-11 02:09:41 - INFO - Epoch: 39.23, Step: 155380, Train Loss: 1.1265, Learning Rate: 2.03e-06
2025-12-11 02:09:52 - INFO - Epoch: 39.23, Step: 155390, Train Loss: 1.1451, Learning Rate: 2.03e-06
2025-12-11 02:10:03 - INFO - Epoch: 39.23, Step: 155400, Train Loss: 1.1063, Learning Rate: 2.02e-06
2025-12-11 02:10:14 - INFO - Epoch: 39.24, Step: 155410, Train Loss: 1.1241, Learning Rate: 2.01e-06
2025-12-11 02:10:25 - INFO - Epoch: 39.24, Step: 155420, Train Loss: 1.1012, Learning Rate: 2.01e-06
2025-12-11 02:10:36 - INFO - Epoch: 39.24, Step: 155430, Train Loss: 1.1462, Learning Rate: 2.00e-06
2025-12-11 02:10:48 - INFO - Epoch: 39.24, Step: 155440, Train Loss: 1.1440, Learning Rate: 1.99e-06
2025-12-11 02:10:59 - INFO - Epoch: 39.25, Step: 155450, Train Loss: 1.1446, Learning Rate: 1.99e-06
2025-12-11 02:11:10 - INFO - Epoch: 39.25, Step: 155460, Train Loss: 1.1339, Learning Rate: 1.98e-06
2025-12-11 02:11:21 - INFO - Epoch: 39.25, Step: 155470, Train Loss: 1.0925, Learning Rate: 1.97e-06
2025-12-11 02:11:32 - INFO - Epoch: 39.25, Step: 155480, Train Loss: 1.1586, Learning Rate: 1.97e-06
2025-12-11 02:11:43 - INFO - Epoch: 39.26, Step: 155490, Train Loss: 1.1379, Learning Rate: 1.96e-06
2025-12-11 02:11:54 - INFO - Epoch: 39.26, Step: 155500, Train Loss: 1.1309, Learning Rate: 1.95e-06
2025-12-11 02:12:06 - INFO - Epoch: 39.26, Step: 155510, Train Loss: 1.1187, Learning Rate: 1.95e-06
2025-12-11 02:12:17 - INFO - Epoch: 39.26, Step: 155520, Train Loss: 1.1189, Learning Rate: 1.94e-06
2025-12-11 02:12:28 - INFO - Epoch: 39.27, Step: 155530, Train Loss: 1.1718, Learning Rate: 1.93e-06
2025-12-11 02:12:39 - INFO - Epoch: 39.27, Step: 155540, Train Loss: 1.1282, Learning Rate: 1.93e-06
2025-12-11 02:12:50 - INFO - Epoch: 39.27, Step: 155550, Train Loss: 1.1295, Learning Rate: 1.92e-06
2025-12-11 02:13:01 - INFO - Epoch: 39.27, Step: 155560, Train Loss: 1.1317, Learning Rate: 1.91e-06
2025-12-11 02:13:12 - INFO - Epoch: 39.28, Step: 155570, Train Loss: 1.0907, Learning Rate: 1.91e-06
2025-12-11 02:13:24 - INFO - Epoch: 39.28, Step: 155580, Train Loss: 1.0999, Learning Rate: 1.90e-06
2025-12-11 02:13:35 - INFO - Epoch: 39.28, Step: 155590, Train Loss: 1.1341, Learning Rate: 1.89e-06
2025-12-11 02:13:46 - INFO - Epoch: 39.28, Step: 155600, Train Loss: 1.1071, Learning Rate: 1.89e-06
2025-12-11 02:13:57 - INFO - Epoch: 39.29, Step: 155610, Train Loss: 1.1198, Learning Rate: 1.88e-06
2025-12-11 02:14:08 - INFO - Epoch: 39.29, Step: 155620, Train Loss: 1.1497, Learning Rate: 1.87e-06
2025-12-11 02:14:19 - INFO - Epoch: 39.29, Step: 155630, Train Loss: 1.1358, Learning Rate: 1.87e-06
2025-12-11 02:14:31 - INFO - Epoch: 39.29, Step: 155640, Train Loss: 1.1336, Learning Rate: 1.86e-06
2025-12-11 02:14:42 - INFO - Epoch: 39.30, Step: 155650, Train Loss: 1.1758, Learning Rate: 1.85e-06
2025-12-11 02:14:53 - INFO - Epoch: 39.30, Step: 155660, Train Loss: 1.1792, Learning Rate: 1.85e-06
2025-12-11 02:15:04 - INFO - Epoch: 39.30, Step: 155670, Train Loss: 1.1511, Learning Rate: 1.84e-06
2025-12-11 02:15:15 - INFO - Epoch: 39.30, Step: 155680, Train Loss: 1.1611, Learning Rate: 1.83e-06
2025-12-11 02:15:26 - INFO - Epoch: 39.31, Step: 155690, Train Loss: 1.1234, Learning Rate: 1.83e-06
2025-12-11 02:15:37 - INFO - Epoch: 39.31, Step: 155700, Train Loss: 1.1329, Learning Rate: 1.82e-06
2025-12-11 02:15:49 - INFO - Epoch: 39.31, Step: 155710, Train Loss: 1.1167, Learning Rate: 1.81e-06
2025-12-11 02:16:00 - INFO - Epoch: 39.31, Step: 155720, Train Loss: 1.1310, Learning Rate: 1.81e-06
2025-12-11 02:16:11 - INFO - Epoch: 39.32, Step: 155730, Train Loss: 1.1147, Learning Rate: 1.80e-06
2025-12-11 02:16:22 - INFO - Epoch: 39.32, Step: 155740, Train Loss: 1.1582, Learning Rate: 1.79e-06
2025-12-11 02:16:33 - INFO - Epoch: 39.32, Step: 155750, Train Loss: 1.1517, Learning Rate: 1.79e-06
2025-12-11 02:16:44 - INFO - Epoch: 39.32, Step: 155760, Train Loss: 1.1470, Learning Rate: 1.78e-06
2025-12-11 02:16:55 - INFO - Epoch: 39.33, Step: 155770, Train Loss: 1.1461, Learning Rate: 1.77e-06
2025-12-11 02:17:07 - INFO - Epoch: 39.33, Step: 155780, Train Loss: 1.1098, Learning Rate: 1.77e-06
2025-12-11 02:17:18 - INFO - Epoch: 39.33, Step: 155790, Train Loss: 1.1378, Learning Rate: 1.76e-06
2025-12-11 02:17:29 - INFO - Epoch: 39.33, Step: 155800, Train Loss: 1.1471, Learning Rate: 1.75e-06
2025-12-11 02:17:40 - INFO - Epoch: 39.34, Step: 155810, Train Loss: 1.1657, Learning Rate: 1.75e-06
2025-12-11 02:17:51 - INFO - Epoch: 39.34, Step: 155820, Train Loss: 1.1105, Learning Rate: 1.74e-06
2025-12-11 02:18:02 - INFO - Epoch: 39.34, Step: 155830, Train Loss: 1.1167, Learning Rate: 1.73e-06
2025-12-11 02:18:14 - INFO - Epoch: 39.34, Step: 155840, Train Loss: 1.1477, Learning Rate: 1.73e-06
2025-12-11 02:18:25 - INFO - Epoch: 39.35, Step: 155850, Train Loss: 1.1294, Learning Rate: 1.72e-06
2025-12-11 02:18:36 - INFO - Epoch: 39.35, Step: 155860, Train Loss: 1.1134, Learning Rate: 1.71e-06
2025-12-11 02:18:47 - INFO - Epoch: 39.35, Step: 155870, Train Loss: 1.1390, Learning Rate: 1.71e-06
2025-12-11 02:18:58 - INFO - Epoch: 39.35, Step: 155880, Train Loss: 1.1691, Learning Rate: 1.70e-06
2025-12-11 02:19:09 - INFO - Epoch: 39.36, Step: 155890, Train Loss: 1.1067, Learning Rate: 1.69e-06
2025-12-11 02:19:20 - INFO - Epoch: 39.36, Step: 155900, Train Loss: 1.0894, Learning Rate: 1.69e-06
2025-12-11 02:19:32 - INFO - Epoch: 39.36, Step: 155910, Train Loss: 1.1104, Learning Rate: 1.68e-06
2025-12-11 02:19:43 - INFO - Epoch: 39.36, Step: 155920, Train Loss: 1.1207, Learning Rate: 1.67e-06
2025-12-11 02:19:54 - INFO - Epoch: 39.37, Step: 155930, Train Loss: 1.1370, Learning Rate: 1.67e-06
2025-12-11 02:20:05 - INFO - Epoch: 39.37, Step: 155940, Train Loss: 1.1076, Learning Rate: 1.66e-06
2025-12-11 02:20:16 - INFO - Epoch: 39.37, Step: 155950, Train Loss: 1.0986, Learning Rate: 1.65e-06
2025-12-11 02:20:27 - INFO - Epoch: 39.37, Step: 155960, Train Loss: 1.1515, Learning Rate: 1.65e-06
2025-12-11 02:20:38 - INFO - Epoch: 39.38, Step: 155970, Train Loss: 1.1512, Learning Rate: 1.64e-06
2025-12-11 02:20:50 - INFO - Epoch: 39.38, Step: 155980, Train Loss: 1.1396, Learning Rate: 1.64e-06
2025-12-11 02:21:01 - INFO - Epoch: 39.38, Step: 155990, Train Loss: 1.1392, Learning Rate: 1.63e-06
2025-12-11 02:21:12 - INFO - Epoch: 39.38, Step: 156000, Train Loss: 1.1140, Learning Rate: 1.62e-06
2025-12-11 02:21:23 - INFO - Epoch: 39.39, Step: 156010, Train Loss: 1.1250, Learning Rate: 1.62e-06
2025-12-11 02:21:34 - INFO - Epoch: 39.39, Step: 156020, Train Loss: 1.1183, Learning Rate: 1.61e-06
2025-12-11 02:21:45 - INFO - Epoch: 39.39, Step: 156030, Train Loss: 1.1038, Learning Rate: 1.60e-06
2025-12-11 02:21:57 - INFO - Epoch: 39.39, Step: 156040, Train Loss: 1.1446, Learning Rate: 1.60e-06
2025-12-11 02:22:08 - INFO - Epoch: 39.40, Step: 156050, Train Loss: 1.1465, Learning Rate: 1.59e-06
2025-12-11 02:22:19 - INFO - Epoch: 39.40, Step: 156060, Train Loss: 1.1394, Learning Rate: 1.58e-06
2025-12-11 02:22:30 - INFO - Epoch: 39.40, Step: 156070, Train Loss: 1.1349, Learning Rate: 1.58e-06
2025-12-11 02:22:41 - INFO - Epoch: 39.40, Step: 156080, Train Loss: 1.1082, Learning Rate: 1.57e-06
2025-12-11 02:22:52 - INFO - Epoch: 39.41, Step: 156090, Train Loss: 1.1537, Learning Rate: 1.56e-06
2025-12-11 02:23:03 - INFO - Epoch: 39.41, Step: 156100, Train Loss: 1.1375, Learning Rate: 1.56e-06
2025-12-11 02:23:15 - INFO - Epoch: 39.41, Step: 156110, Train Loss: 1.0869, Learning Rate: 1.55e-06
2025-12-11 02:23:26 - INFO - Epoch: 39.41, Step: 156120, Train Loss: 1.1301, Learning Rate: 1.54e-06
2025-12-11 02:23:37 - INFO - Epoch: 39.42, Step: 156130, Train Loss: 1.1245, Learning Rate: 1.54e-06
2025-12-11 02:23:48 - INFO - Epoch: 39.42, Step: 156140, Train Loss: 1.1099, Learning Rate: 1.53e-06
2025-12-11 02:23:59 - INFO - Epoch: 39.42, Step: 156150, Train Loss: 1.0992, Learning Rate: 1.52e-06
2025-12-11 02:24:10 - INFO - Epoch: 39.42, Step: 156160, Train Loss: 1.1294, Learning Rate: 1.52e-06
2025-12-11 02:24:21 - INFO - Epoch: 39.43, Step: 156170, Train Loss: 1.1493, Learning Rate: 1.51e-06
2025-12-11 02:24:33 - INFO - Epoch: 39.43, Step: 156180, Train Loss: 1.0895, Learning Rate: 1.50e-06
2025-12-11 02:24:44 - INFO - Epoch: 39.43, Step: 156190, Train Loss: 1.1485, Learning Rate: 1.50e-06
2025-12-11 02:24:55 - INFO - Epoch: 39.43, Step: 156200, Train Loss: 1.1466, Learning Rate: 1.49e-06
2025-12-11 02:25:06 - INFO - Epoch: 39.44, Step: 156210, Train Loss: 1.1160, Learning Rate: 1.48e-06
2025-12-11 02:25:17 - INFO - Epoch: 39.44, Step: 156220, Train Loss: 1.1212, Learning Rate: 1.48e-06
2025-12-11 02:25:28 - INFO - Epoch: 39.44, Step: 156230, Train Loss: 1.1041, Learning Rate: 1.47e-06
2025-12-11 02:25:40 - INFO - Epoch: 39.44, Step: 156240, Train Loss: 1.0764, Learning Rate: 1.46e-06
2025-12-11 02:25:51 - INFO - Epoch: 39.45, Step: 156250, Train Loss: 1.1186, Learning Rate: 1.46e-06
2025-12-11 02:26:02 - INFO - Epoch: 39.45, Step: 156260, Train Loss: 1.1400, Learning Rate: 1.45e-06
2025-12-11 02:26:13 - INFO - Epoch: 39.45, Step: 156270, Train Loss: 1.1606, Learning Rate: 1.44e-06
2025-12-11 02:26:24 - INFO - Epoch: 39.45, Step: 156280, Train Loss: 1.1389, Learning Rate: 1.44e-06
2025-12-11 02:26:35 - INFO - Epoch: 39.46, Step: 156290, Train Loss: 1.1576, Learning Rate: 1.43e-06
2025-12-11 02:26:46 - INFO - Epoch: 39.46, Step: 156300, Train Loss: 1.1386, Learning Rate: 1.42e-06
2025-12-11 02:26:58 - INFO - Epoch: 39.46, Step: 156310, Train Loss: 1.1381, Learning Rate: 1.42e-06
2025-12-11 02:27:09 - INFO - Epoch: 39.46, Step: 156320, Train Loss: 1.1527, Learning Rate: 1.41e-06
2025-12-11 02:27:20 - INFO - Epoch: 39.47, Step: 156330, Train Loss: 1.1134, Learning Rate: 1.40e-06
2025-12-11 02:27:31 - INFO - Epoch: 39.47, Step: 156340, Train Loss: 1.1551, Learning Rate: 1.40e-06
2025-12-11 02:27:42 - INFO - Epoch: 39.47, Step: 156350, Train Loss: 1.1426, Learning Rate: 1.39e-06
2025-12-11 02:27:53 - INFO - Epoch: 39.47, Step: 156360, Train Loss: 1.1170, Learning Rate: 1.38e-06
2025-12-11 02:28:04 - INFO - Epoch: 39.48, Step: 156370, Train Loss: 1.1556, Learning Rate: 1.38e-06
2025-12-11 02:28:16 - INFO - Epoch: 39.48, Step: 156380, Train Loss: 1.1374, Learning Rate: 1.37e-06
2025-12-11 02:28:27 - INFO - Epoch: 39.48, Step: 156390, Train Loss: 1.1391, Learning Rate: 1.36e-06
2025-12-11 02:28:38 - INFO - Epoch: 39.48, Step: 156400, Train Loss: 1.1426, Learning Rate: 1.36e-06
2025-12-11 02:28:49 - INFO - Epoch: 39.49, Step: 156410, Train Loss: 1.1496, Learning Rate: 1.35e-06
2025-12-11 02:29:00 - INFO - Epoch: 39.49, Step: 156420, Train Loss: 1.1717, Learning Rate: 1.34e-06
2025-12-11 02:29:11 - INFO - Epoch: 39.49, Step: 156430, Train Loss: 1.1282, Learning Rate: 1.34e-06
2025-12-11 02:29:23 - INFO - Epoch: 39.50, Step: 156440, Train Loss: 1.1122, Learning Rate: 1.33e-06
2025-12-11 02:29:34 - INFO - Epoch: 39.50, Step: 156450, Train Loss: 1.1238, Learning Rate: 1.32e-06
2025-12-11 02:29:45 - INFO - Epoch: 39.50, Step: 156460, Train Loss: 1.1717, Learning Rate: 1.32e-06
2025-12-11 02:29:56 - INFO - Epoch: 39.50, Step: 156470, Train Loss: 1.1020, Learning Rate: 1.31e-06
2025-12-11 02:30:07 - INFO - Epoch: 39.51, Step: 156480, Train Loss: 1.1656, Learning Rate: 1.30e-06
2025-12-11 02:30:18 - INFO - Epoch: 39.51, Step: 156490, Train Loss: 1.1475, Learning Rate: 1.30e-06
2025-12-11 02:30:29 - INFO - Epoch: 39.51, Step: 156500, Train Loss: 1.0993, Learning Rate: 1.29e-06
2025-12-11 02:30:41 - INFO - Epoch: 39.51, Step: 156510, Train Loss: 1.1008, Learning Rate: 1.28e-06
2025-12-11 02:30:52 - INFO - Epoch: 39.52, Step: 156520, Train Loss: 1.1684, Learning Rate: 1.28e-06
2025-12-11 02:31:03 - INFO - Epoch: 39.52, Step: 156530, Train Loss: 1.1406, Learning Rate: 1.27e-06
2025-12-11 02:31:14 - INFO - Epoch: 39.52, Step: 156540, Train Loss: 1.1231, Learning Rate: 1.26e-06
2025-12-11 02:31:25 - INFO - Epoch: 39.52, Step: 156550, Train Loss: 1.1467, Learning Rate: 1.26e-06
2025-12-11 02:31:36 - INFO - Epoch: 39.53, Step: 156560, Train Loss: 1.1393, Learning Rate: 1.25e-06
2025-12-11 02:31:47 - INFO - Epoch: 39.53, Step: 156570, Train Loss: 1.1433, Learning Rate: 1.24e-06
2025-12-11 02:31:59 - INFO - Epoch: 39.53, Step: 156580, Train Loss: 1.1131, Learning Rate: 1.24e-06
2025-12-11 02:32:10 - INFO - Epoch: 39.53, Step: 156590, Train Loss: 1.1058, Learning Rate: 1.23e-06
2025-12-11 02:32:21 - INFO - Epoch: 39.54, Step: 156600, Train Loss: 1.1326, Learning Rate: 1.22e-06
2025-12-11 02:32:32 - INFO - Epoch: 39.54, Step: 156610, Train Loss: 1.1185, Learning Rate: 1.22e-06
2025-12-11 02:32:43 - INFO - Epoch: 39.54, Step: 156620, Train Loss: 1.1502, Learning Rate: 1.21e-06
2025-12-11 02:32:54 - INFO - Epoch: 39.54, Step: 156630, Train Loss: 1.1428, Learning Rate: 1.20e-06
2025-12-11 02:33:06 - INFO - Epoch: 39.55, Step: 156640, Train Loss: 1.1529, Learning Rate: 1.20e-06
2025-12-11 02:33:17 - INFO - Epoch: 39.55, Step: 156650, Train Loss: 1.1449, Learning Rate: 1.19e-06
2025-12-11 02:33:28 - INFO - Epoch: 39.55, Step: 156660, Train Loss: 1.1661, Learning Rate: 1.18e-06
2025-12-11 02:33:39 - INFO - Epoch: 39.55, Step: 156670, Train Loss: 1.0832, Learning Rate: 1.18e-06
2025-12-11 02:33:50 - INFO - Epoch: 39.56, Step: 156680, Train Loss: 1.1454, Learning Rate: 1.17e-06
2025-12-11 02:34:01 - INFO - Epoch: 39.56, Step: 156690, Train Loss: 1.1174, Learning Rate: 1.16e-06
2025-12-11 02:34:12 - INFO - Epoch: 39.56, Step: 156700, Train Loss: 1.1370, Learning Rate: 1.16e-06
2025-12-11 02:34:24 - INFO - Epoch: 39.56, Step: 156710, Train Loss: 1.1383, Learning Rate: 1.15e-06
2025-12-11 02:34:35 - INFO - Epoch: 39.57, Step: 156720, Train Loss: 1.1494, Learning Rate: 1.14e-06
2025-12-11 02:34:46 - INFO - Epoch: 39.57, Step: 156730, Train Loss: 1.1946, Learning Rate: 1.14e-06
2025-12-11 02:34:57 - INFO - Epoch: 39.57, Step: 156740, Train Loss: 1.1398, Learning Rate: 1.13e-06
2025-12-11 02:35:08 - INFO - Epoch: 39.57, Step: 156750, Train Loss: 1.1343, Learning Rate: 1.12e-06
2025-12-11 02:35:19 - INFO - Epoch: 39.58, Step: 156760, Train Loss: 1.1235, Learning Rate: 1.12e-06
2025-12-11 02:35:30 - INFO - Epoch: 39.58, Step: 156770, Train Loss: 1.1611, Learning Rate: 1.11e-06
2025-12-11 02:35:42 - INFO - Epoch: 39.58, Step: 156780, Train Loss: 1.1239, Learning Rate: 1.10e-06
2025-12-11 02:35:53 - INFO - Epoch: 39.58, Step: 156790, Train Loss: 1.1584, Learning Rate: 1.10e-06
2025-12-11 02:36:04 - INFO - Epoch: 39.59, Step: 156800, Train Loss: 1.1522, Learning Rate: 1.09e-06
2025-12-11 02:36:15 - INFO - Epoch: 39.59, Step: 156810, Train Loss: 1.1483, Learning Rate: 1.08e-06
2025-12-11 02:36:26 - INFO - Epoch: 39.59, Step: 156820, Train Loss: 1.1079, Learning Rate: 1.08e-06
2025-12-11 02:36:37 - INFO - Epoch: 39.59, Step: 156830, Train Loss: 1.1322, Learning Rate: 1.07e-06
2025-12-11 02:36:49 - INFO - Epoch: 39.60, Step: 156840, Train Loss: 1.1401, Learning Rate: 1.06e-06
2025-12-11 02:37:00 - INFO - Epoch: 39.60, Step: 156850, Train Loss: 1.1391, Learning Rate: 1.06e-06
2025-12-11 02:37:11 - INFO - Epoch: 39.60, Step: 156860, Train Loss: 1.1386, Learning Rate: 1.05e-06
2025-12-11 02:37:22 - INFO - Epoch: 39.60, Step: 156870, Train Loss: 1.1307, Learning Rate: 1.04e-06
2025-12-11 02:37:33 - INFO - Epoch: 39.61, Step: 156880, Train Loss: 1.1742, Learning Rate: 1.04e-06
2025-12-11 02:37:44 - INFO - Epoch: 39.61, Step: 156890, Train Loss: 1.1307, Learning Rate: 1.03e-06
2025-12-11 02:37:55 - INFO - Epoch: 39.61, Step: 156900, Train Loss: 1.1403, Learning Rate: 1.02e-06
2025-12-11 02:38:07 - INFO - Epoch: 39.61, Step: 156910, Train Loss: 1.1372, Learning Rate: 1.02e-06
2025-12-11 02:38:18 - INFO - Epoch: 39.62, Step: 156920, Train Loss: 1.1306, Learning Rate: 1.01e-06
2025-12-11 02:38:29 - INFO - Epoch: 39.62, Step: 156930, Train Loss: 1.1145, Learning Rate: 1.00e-06
2025-12-11 02:38:40 - INFO - Epoch: 39.62, Step: 156940, Train Loss: 1.1576, Learning Rate: 9.97e-07
2025-12-11 02:38:51 - INFO - Epoch: 39.62, Step: 156950, Train Loss: 1.1231, Learning Rate: 9.91e-07
2025-12-11 02:39:02 - INFO - Epoch: 39.63, Step: 156960, Train Loss: 1.1606, Learning Rate: 9.84e-07
2025-12-11 02:39:13 - INFO - Epoch: 39.63, Step: 156970, Train Loss: 1.1366, Learning Rate: 9.77e-07
2025-12-11 02:39:25 - INFO - Epoch: 39.63, Step: 156980, Train Loss: 1.1172, Learning Rate: 9.71e-07
2025-12-11 02:39:36 - INFO - Epoch: 39.63, Step: 156990, Train Loss: 1.1603, Learning Rate: 9.64e-07
2025-12-11 02:39:47 - INFO - Epoch: 39.64, Step: 157000, Train Loss: 1.1168, Learning Rate: 9.57e-07
2025-12-11 02:39:58 - INFO - Epoch: 39.64, Step: 157010, Train Loss: 1.1387, Learning Rate: 9.51e-07
2025-12-11 02:40:09 - INFO - Epoch: 39.64, Step: 157020, Train Loss: 1.1439, Learning Rate: 9.44e-07
2025-12-11 02:40:20 - INFO - Epoch: 39.64, Step: 157030, Train Loss: 1.1229, Learning Rate: 9.37e-07
2025-12-11 02:40:32 - INFO - Epoch: 39.65, Step: 157040, Train Loss: 1.1510, Learning Rate: 9.31e-07
2025-12-11 02:40:43 - INFO - Epoch: 39.65, Step: 157050, Train Loss: 1.1550, Learning Rate: 9.24e-07
2025-12-11 02:40:54 - INFO - Epoch: 39.65, Step: 157060, Train Loss: 1.1439, Learning Rate: 9.17e-07
2025-12-11 02:41:05 - INFO - Epoch: 39.65, Step: 157070, Train Loss: 1.0928, Learning Rate: 9.11e-07
2025-12-11 02:41:16 - INFO - Epoch: 39.66, Step: 157080, Train Loss: 1.1329, Learning Rate: 9.04e-07
2025-12-11 02:41:27 - INFO - Epoch: 39.66, Step: 157090, Train Loss: 1.0905, Learning Rate: 8.98e-07
2025-12-11 02:41:38 - INFO - Epoch: 39.66, Step: 157100, Train Loss: 1.1185, Learning Rate: 8.91e-07
2025-12-11 02:41:50 - INFO - Epoch: 39.66, Step: 157110, Train Loss: 1.1416, Learning Rate: 8.84e-07
2025-12-11 02:42:01 - INFO - Epoch: 39.67, Step: 157120, Train Loss: 1.1252, Learning Rate: 8.78e-07
2025-12-11 02:42:12 - INFO - Epoch: 39.67, Step: 157130, Train Loss: 1.0851, Learning Rate: 8.71e-07
2025-12-11 02:42:23 - INFO - Epoch: 39.67, Step: 157140, Train Loss: 1.1359, Learning Rate: 8.64e-07
2025-12-11 02:42:34 - INFO - Epoch: 39.67, Step: 157150, Train Loss: 1.1290, Learning Rate: 8.58e-07
2025-12-11 02:42:45 - INFO - Epoch: 39.68, Step: 157160, Train Loss: 1.1317, Learning Rate: 8.51e-07
2025-12-11 02:42:56 - INFO - Epoch: 39.68, Step: 157170, Train Loss: 1.1127, Learning Rate: 8.44e-07
2025-12-11 02:43:08 - INFO - Epoch: 39.68, Step: 157180, Train Loss: 1.1109, Learning Rate: 8.38e-07
2025-12-11 02:43:19 - INFO - Epoch: 39.68, Step: 157190, Train Loss: 1.1300, Learning Rate: 8.31e-07
2025-12-11 02:43:30 - INFO - Epoch: 39.69, Step: 157200, Train Loss: 1.0874, Learning Rate: 8.24e-07
2025-12-11 02:43:41 - INFO - Epoch: 39.69, Step: 157210, Train Loss: 1.1473, Learning Rate: 8.18e-07
2025-12-11 02:43:52 - INFO - Epoch: 39.69, Step: 157220, Train Loss: 1.1138, Learning Rate: 8.11e-07
2025-12-11 02:44:03 - INFO - Epoch: 39.69, Step: 157230, Train Loss: 1.1346, Learning Rate: 8.05e-07
2025-12-11 02:44:15 - INFO - Epoch: 39.70, Step: 157240, Train Loss: 1.1377, Learning Rate: 7.98e-07
2025-12-11 02:44:26 - INFO - Epoch: 39.70, Step: 157250, Train Loss: 1.1656, Learning Rate: 7.91e-07
2025-12-11 02:44:37 - INFO - Epoch: 39.70, Step: 157260, Train Loss: 1.1159, Learning Rate: 7.85e-07
2025-12-11 02:44:48 - INFO - Epoch: 39.70, Step: 157270, Train Loss: 1.1544, Learning Rate: 7.78e-07
2025-12-11 02:44:59 - INFO - Epoch: 39.71, Step: 157280, Train Loss: 1.0956, Learning Rate: 7.71e-07
2025-12-11 02:45:10 - INFO - Epoch: 39.71, Step: 157290, Train Loss: 1.1170, Learning Rate: 7.65e-07
2025-12-11 02:45:21 - INFO - Epoch: 39.71, Step: 157300, Train Loss: 1.1415, Learning Rate: 7.58e-07
2025-12-11 02:45:33 - INFO - Epoch: 39.71, Step: 157310, Train Loss: 1.1330, Learning Rate: 7.51e-07
2025-12-11 02:45:44 - INFO - Epoch: 39.72, Step: 157320, Train Loss: 1.1224, Learning Rate: 7.45e-07
2025-12-11 02:45:55 - INFO - Epoch: 39.72, Step: 157330, Train Loss: 1.1437, Learning Rate: 7.38e-07
2025-12-11 02:46:06 - INFO - Epoch: 39.72, Step: 157340, Train Loss: 1.1436, Learning Rate: 7.31e-07
2025-12-11 02:46:17 - INFO - Epoch: 39.72, Step: 157350, Train Loss: 1.1128, Learning Rate: 7.25e-07
2025-12-11 02:46:28 - INFO - Epoch: 39.73, Step: 157360, Train Loss: 1.1276, Learning Rate: 7.18e-07
2025-12-11 02:46:39 - INFO - Epoch: 39.73, Step: 157370, Train Loss: 1.1208, Learning Rate: 7.12e-07
2025-12-11 02:46:51 - INFO - Epoch: 39.73, Step: 157380, Train Loss: 1.1652, Learning Rate: 7.05e-07
2025-12-11 02:47:02 - INFO - Epoch: 39.73, Step: 157390, Train Loss: 1.1168, Learning Rate: 6.98e-07
2025-12-11 02:47:13 - INFO - Epoch: 39.74, Step: 157400, Train Loss: 1.1645, Learning Rate: 6.92e-07
2025-12-11 02:47:24 - INFO - Epoch: 39.74, Step: 157410, Train Loss: 1.1452, Learning Rate: 6.85e-07
2025-12-11 02:47:35 - INFO - Epoch: 39.74, Step: 157420, Train Loss: 1.1220, Learning Rate: 6.78e-07
2025-12-11 02:47:46 - INFO - Epoch: 39.75, Step: 157430, Train Loss: 1.1256, Learning Rate: 6.72e-07
2025-12-11 02:47:57 - INFO - Epoch: 39.75, Step: 157440, Train Loss: 1.1426, Learning Rate: 6.65e-07
2025-12-11 02:48:09 - INFO - Epoch: 39.75, Step: 157450, Train Loss: 1.1116, Learning Rate: 6.58e-07
2025-12-11 02:48:20 - INFO - Epoch: 39.75, Step: 157460, Train Loss: 1.1180, Learning Rate: 6.52e-07
2025-12-11 02:48:31 - INFO - Epoch: 39.76, Step: 157470, Train Loss: 1.1196, Learning Rate: 6.45e-07
2025-12-11 02:48:42 - INFO - Epoch: 39.76, Step: 157480, Train Loss: 1.1426, Learning Rate: 6.38e-07
2025-12-11 02:48:53 - INFO - Epoch: 39.76, Step: 157490, Train Loss: 1.1083, Learning Rate: 6.32e-07
2025-12-11 02:49:04 - INFO - Epoch: 39.76, Step: 157500, Train Loss: 1.1238, Learning Rate: 6.25e-07
2025-12-11 02:49:16 - INFO - Epoch: 39.77, Step: 157510, Train Loss: 1.1240, Learning Rate: 6.19e-07
2025-12-11 02:49:27 - INFO - Epoch: 39.77, Step: 157520, Train Loss: 1.0920, Learning Rate: 6.12e-07
2025-12-11 02:49:38 - INFO - Epoch: 39.77, Step: 157530, Train Loss: 1.1234, Learning Rate: 6.05e-07
2025-12-11 02:49:49 - INFO - Epoch: 39.77, Step: 157540, Train Loss: 1.1397, Learning Rate: 5.99e-07
2025-12-11 02:50:00 - INFO - Epoch: 39.78, Step: 157550, Train Loss: 1.1373, Learning Rate: 5.92e-07
2025-12-11 02:50:11 - INFO - Epoch: 39.78, Step: 157560, Train Loss: 1.0928, Learning Rate: 5.85e-07
2025-12-11 02:50:22 - INFO - Epoch: 39.78, Step: 157570, Train Loss: 1.1450, Learning Rate: 5.79e-07
2025-12-11 02:50:34 - INFO - Epoch: 39.78, Step: 157580, Train Loss: 1.1518, Learning Rate: 5.72e-07
2025-12-11 02:50:45 - INFO - Epoch: 39.79, Step: 157590, Train Loss: 1.1243, Learning Rate: 5.65e-07
2025-12-11 02:50:56 - INFO - Epoch: 39.79, Step: 157600, Train Loss: 1.1122, Learning Rate: 5.59e-07
2025-12-11 02:51:07 - INFO - Epoch: 39.79, Step: 157610, Train Loss: 1.1210, Learning Rate: 5.52e-07
2025-12-11 02:51:18 - INFO - Epoch: 39.79, Step: 157620, Train Loss: 1.1123, Learning Rate: 5.45e-07
2025-12-11 02:51:29 - INFO - Epoch: 39.80, Step: 157630, Train Loss: 1.1142, Learning Rate: 5.39e-07
2025-12-11 02:51:40 - INFO - Epoch: 39.80, Step: 157640, Train Loss: 1.0999, Learning Rate: 5.32e-07
2025-12-11 02:51:52 - INFO - Epoch: 39.80, Step: 157650, Train Loss: 1.1338, Learning Rate: 5.26e-07
2025-12-11 02:52:03 - INFO - Epoch: 39.80, Step: 157660, Train Loss: 1.1507, Learning Rate: 5.19e-07
2025-12-11 02:52:14 - INFO - Epoch: 39.81, Step: 157670, Train Loss: 1.1300, Learning Rate: 5.12e-07
2025-12-11 02:52:25 - INFO - Epoch: 39.81, Step: 157680, Train Loss: 1.1646, Learning Rate: 5.06e-07
2025-12-11 02:52:36 - INFO - Epoch: 39.81, Step: 157690, Train Loss: 1.0952, Learning Rate: 4.99e-07
2025-12-11 02:52:47 - INFO - Epoch: 39.81, Step: 157700, Train Loss: 1.1170, Learning Rate: 4.92e-07
2025-12-11 02:52:59 - INFO - Epoch: 39.82, Step: 157710, Train Loss: 1.1283, Learning Rate: 4.86e-07
2025-12-11 02:53:10 - INFO - Epoch: 39.82, Step: 157720, Train Loss: 1.1177, Learning Rate: 4.79e-07
2025-12-11 02:53:21 - INFO - Epoch: 39.82, Step: 157730, Train Loss: 1.1151, Learning Rate: 4.72e-07
2025-12-11 02:53:32 - INFO - Epoch: 39.82, Step: 157740, Train Loss: 1.1656, Learning Rate: 4.66e-07
2025-12-11 02:53:43 - INFO - Epoch: 39.83, Step: 157750, Train Loss: 1.1537, Learning Rate: 4.59e-07
2025-12-11 02:53:54 - INFO - Epoch: 39.83, Step: 157760, Train Loss: 1.1241, Learning Rate: 4.52e-07
2025-12-11 02:54:05 - INFO - Epoch: 39.83, Step: 157770, Train Loss: 1.1198, Learning Rate: 4.46e-07
2025-12-11 02:54:17 - INFO - Epoch: 39.83, Step: 157780, Train Loss: 1.1303, Learning Rate: 4.39e-07
2025-12-11 02:54:28 - INFO - Epoch: 39.84, Step: 157790, Train Loss: 1.1111, Learning Rate: 4.33e-07
2025-12-11 02:54:39 - INFO - Epoch: 39.84, Step: 157800, Train Loss: 1.1728, Learning Rate: 4.26e-07
2025-12-11 02:54:50 - INFO - Epoch: 39.84, Step: 157810, Train Loss: 1.1375, Learning Rate: 4.19e-07
2025-12-11 02:55:01 - INFO - Epoch: 39.84, Step: 157820, Train Loss: 1.1177, Learning Rate: 4.13e-07
2025-12-11 02:55:12 - INFO - Epoch: 39.85, Step: 157830, Train Loss: 1.1386, Learning Rate: 4.06e-07
2025-12-11 02:55:23 - INFO - Epoch: 39.85, Step: 157840, Train Loss: 1.1132, Learning Rate: 3.99e-07
2025-12-11 02:55:35 - INFO - Epoch: 39.85, Step: 157850, Train Loss: 1.1809, Learning Rate: 3.93e-07
2025-12-11 02:55:46 - INFO - Epoch: 39.85, Step: 157860, Train Loss: 1.0926, Learning Rate: 3.86e-07
2025-12-11 02:55:57 - INFO - Epoch: 39.86, Step: 157870, Train Loss: 1.1162, Learning Rate: 3.79e-07
2025-12-11 02:56:08 - INFO - Epoch: 39.86, Step: 157880, Train Loss: 1.1813, Learning Rate: 3.73e-07
2025-12-11 02:56:19 - INFO - Epoch: 39.86, Step: 157890, Train Loss: 1.1357, Learning Rate: 3.66e-07
2025-12-11 02:56:30 - INFO - Epoch: 39.86, Step: 157900, Train Loss: 1.1057, Learning Rate: 3.59e-07
2025-12-11 02:56:42 - INFO - Epoch: 39.87, Step: 157910, Train Loss: 1.1630, Learning Rate: 3.53e-07
2025-12-11 02:56:53 - INFO - Epoch: 39.87, Step: 157920, Train Loss: 1.1435, Learning Rate: 3.46e-07
2025-12-11 02:57:04 - INFO - Epoch: 39.87, Step: 157930, Train Loss: 1.0856, Learning Rate: 3.39e-07
2025-12-11 02:57:15 - INFO - Epoch: 39.87, Step: 157940, Train Loss: 1.1573, Learning Rate: 3.33e-07
2025-12-11 02:57:26 - INFO - Epoch: 39.88, Step: 157950, Train Loss: 1.1402, Learning Rate: 3.26e-07
2025-12-11 02:57:37 - INFO - Epoch: 39.88, Step: 157960, Train Loss: 1.1309, Learning Rate: 3.20e-07
2025-12-11 02:57:48 - INFO - Epoch: 39.88, Step: 157970, Train Loss: 1.1168, Learning Rate: 3.13e-07
2025-12-11 02:58:00 - INFO - Epoch: 39.88, Step: 157980, Train Loss: 1.1348, Learning Rate: 3.06e-07
2025-12-11 02:58:11 - INFO - Epoch: 39.89, Step: 157990, Train Loss: 1.1099, Learning Rate: 3.00e-07
2025-12-11 02:58:22 - INFO - Epoch: 39.89, Step: 158000, Train Loss: 1.1400, Learning Rate: 2.93e-07
2025-12-11 02:58:33 - INFO - Epoch: 39.89, Step: 158010, Train Loss: 1.1323, Learning Rate: 2.86e-07
2025-12-11 02:58:44 - INFO - Epoch: 39.89, Step: 158020, Train Loss: 1.1378, Learning Rate: 2.80e-07
2025-12-11 02:58:55 - INFO - Epoch: 39.90, Step: 158030, Train Loss: 1.1327, Learning Rate: 2.73e-07
2025-12-11 02:59:06 - INFO - Epoch: 39.90, Step: 158040, Train Loss: 1.1339, Learning Rate: 2.66e-07
2025-12-11 02:59:18 - INFO - Epoch: 39.90, Step: 158050, Train Loss: 1.1105, Learning Rate: 2.60e-07
2025-12-11 02:59:29 - INFO - Epoch: 39.90, Step: 158060, Train Loss: 1.1117, Learning Rate: 2.53e-07
2025-12-11 02:59:40 - INFO - Epoch: 39.91, Step: 158070, Train Loss: 1.1051, Learning Rate: 2.46e-07
2025-12-11 02:59:51 - INFO - Epoch: 39.91, Step: 158080, Train Loss: 1.1504, Learning Rate: 2.40e-07
2025-12-11 03:00:02 - INFO - Epoch: 39.91, Step: 158090, Train Loss: 1.1466, Learning Rate: 2.33e-07
2025-12-11 03:00:13 - INFO - Epoch: 39.91, Step: 158100, Train Loss: 1.1462, Learning Rate: 2.27e-07
2025-12-11 03:00:25 - INFO - Epoch: 39.92, Step: 158110, Train Loss: 1.1044, Learning Rate: 2.20e-07
2025-12-11 03:00:36 - INFO - Epoch: 39.92, Step: 158120, Train Loss: 1.1004, Learning Rate: 2.13e-07
2025-12-11 03:00:47 - INFO - Epoch: 39.92, Step: 158130, Train Loss: 1.1566, Learning Rate: 2.07e-07
2025-12-11 03:00:58 - INFO - Epoch: 39.92, Step: 158140, Train Loss: 1.1445, Learning Rate: 2.00e-07
2025-12-11 03:01:09 - INFO - Epoch: 39.93, Step: 158150, Train Loss: 1.1281, Learning Rate: 1.93e-07
2025-12-11 03:01:20 - INFO - Epoch: 39.93, Step: 158160, Train Loss: 1.1409, Learning Rate: 1.87e-07
2025-12-11 03:01:31 - INFO - Epoch: 39.93, Step: 158170, Train Loss: 1.1100, Learning Rate: 1.80e-07
2025-12-11 03:01:43 - INFO - Epoch: 39.93, Step: 158180, Train Loss: 1.1497, Learning Rate: 1.73e-07
2025-12-11 03:01:54 - INFO - Epoch: 39.94, Step: 158190, Train Loss: 1.1318, Learning Rate: 1.67e-07
2025-12-11 03:02:05 - INFO - Epoch: 39.94, Step: 158200, Train Loss: 1.1290, Learning Rate: 1.60e-07
2025-12-11 03:02:16 - INFO - Epoch: 39.94, Step: 158210, Train Loss: 1.1240, Learning Rate: 1.53e-07
2025-12-11 03:02:27 - INFO - Epoch: 39.94, Step: 158220, Train Loss: 1.1382, Learning Rate: 1.47e-07
2025-12-11 03:02:38 - INFO - Epoch: 39.95, Step: 158230, Train Loss: 1.1273, Learning Rate: 1.40e-07
2025-12-11 03:02:49 - INFO - Epoch: 39.95, Step: 158240, Train Loss: 1.1254, Learning Rate: 1.34e-07
2025-12-11 03:03:01 - INFO - Epoch: 39.95, Step: 158250, Train Loss: 1.0889, Learning Rate: 1.27e-07
2025-12-11 03:03:12 - INFO - Epoch: 39.95, Step: 158260, Train Loss: 1.0931, Learning Rate: 1.20e-07
2025-12-11 03:03:23 - INFO - Epoch: 39.96, Step: 158270, Train Loss: 1.1251, Learning Rate: 1.14e-07
2025-12-11 03:03:34 - INFO - Epoch: 39.96, Step: 158280, Train Loss: 1.1800, Learning Rate: 1.07e-07
2025-12-11 03:03:45 - INFO - Epoch: 39.96, Step: 158290, Train Loss: 1.0793, Learning Rate: 1.00e-07
2025-12-11 03:03:56 - INFO - Epoch: 39.96, Step: 158300, Train Loss: 1.1265, Learning Rate: 9.37e-08
2025-12-11 03:04:08 - INFO - Epoch: 39.97, Step: 158310, Train Loss: 1.1054, Learning Rate: 8.70e-08
2025-12-11 03:04:19 - INFO - Epoch: 39.97, Step: 158320, Train Loss: 1.1122, Learning Rate: 8.04e-08
2025-12-11 03:04:30 - INFO - Epoch: 39.97, Step: 158330, Train Loss: 1.1471, Learning Rate: 7.37e-08
2025-12-11 03:04:41 - INFO - Epoch: 39.97, Step: 158340, Train Loss: 1.1469, Learning Rate: 6.71e-08
2025-12-11 03:04:52 - INFO - Epoch: 39.98, Step: 158350, Train Loss: 1.1112, Learning Rate: 6.05e-08
2025-12-11 03:05:03 - INFO - Epoch: 39.98, Step: 158360, Train Loss: 1.1002, Learning Rate: 5.38e-08
2025-12-11 03:05:14 - INFO - Epoch: 39.98, Step: 158370, Train Loss: 1.1370, Learning Rate: 4.72e-08
2025-12-11 03:05:26 - INFO - Epoch: 39.98, Step: 158380, Train Loss: 1.1284, Learning Rate: 4.05e-08
2025-12-11 03:05:37 - INFO - Epoch: 39.99, Step: 158390, Train Loss: 1.1164, Learning Rate: 3.39e-08
2025-12-11 03:05:48 - INFO - Epoch: 39.99, Step: 158400, Train Loss: 1.1325, Learning Rate: 2.72e-08
2025-12-11 03:05:59 - INFO - Epoch: 39.99, Step: 158410, Train Loss: 1.1570, Learning Rate: 2.06e-08
2025-12-11 03:06:10 - INFO - Epoch: 39.99, Step: 158420, Train Loss: 1.1186, Learning Rate: 1.40e-08
2025-12-11 03:06:21 - INFO - Epoch: 40.00, Step: 158430, Train Loss: 1.1508, Learning Rate: 7.31e-09
2025-12-11 03:06:32 - INFO - Epoch: 40.00, Step: 158440, Train Loss: 1.1454, Learning Rate: 6.64e-10
